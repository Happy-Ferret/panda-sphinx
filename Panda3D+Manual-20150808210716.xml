<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.6/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.6/ http://www.mediawiki.org/xml/export-0.6.xsd" version="0.6" xml:lang="en">
  <siteinfo>
    <sitename>Panda3D Manual</sitename>
    <base>http://www.panda3d.org/manual/index.php/Main_Page</base>
    <generator>MediaWiki 1.19.4</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Panda3D Manual</namespace>
      <namespace key="5" case="first-letter">Panda3D Manual talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="500" case="first-letter">Dev</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>Features</title>
    <ns>0</ns>
    <id>2671</id>
      <sha1>6ark8m2gb6offwijcqtnmonkknzlowf</sha1>
    <revision>
      <id>60302</id>
      <timestamp>2014-12-01T13:45:01Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>/* Performance Monitoring */</comment>
      <text xml:space="preserve" bytes="5272">__NOTOC__

&lt;div style=&quot;clear: left&quot;&gt;
==Just Works, Right out of the Box==
&lt;div style=&quot;float: left; width: 150px; margin: -12px 2em 0 0;&quot;&gt;
[[Image:Feature-outofbox.jpg]]
&lt;/div&gt;
No-hassle install:
* Convenient installer packages for Windows, Mac OS X and Linux
* Only one external dependency: working graphics driver
* Sample programs run right out of Start Menu
* No compilation step needed

&lt;div style=&quot;clear: left&quot;&gt;
==Full Python Integration==
&lt;div style=&quot;float: left; width: 150px; margin: -12px 2em 0 0;&quot;&gt;
[[Image:Feature-python.jpg]]
&lt;/div&gt;
Automatically-generated wrappers expose full functionality of the engine.
* All Python versions from about 2.4 to newest 2.x supported
* Highly optimized: all core functionality in C++
* Thoroughly-tested: two commercial MMOs in Python
* Panda3D structures garbage collected when using Python
* Manual and sample programs use Python

&lt;div style=&quot;clear: left&quot;&gt;
==Exposes Full Power of Graphics API==
&lt;div style=&quot;float: left; width: 150px; margin: -12px 2em 0 0;&quot;&gt;
[[Image:Feature-graphics.jpg]]
&lt;/div&gt;
Modern OpenGL/DirectX features exposed directly to Panda3D user:
* High-level shader languages: Cg, GLSL
* Powerful interface between shaders and engine
* Support for render-to-texture, multiple render targets
* Use of depth/shadow/stencil textures

&lt;div style=&quot;clear: left&quot;&gt;
==Shader Generation==
&lt;div style=&quot;float: left; width: 150px; margin: -12px 2em 0 0;&quot;&gt;
[[Image:Feature-builtins.jpg]]
&lt;/div&gt;
Many advanced rendering techniques now fully automatic:
* Special Maps: Normal Map, Gloss Map, Glow Map 
* HDR Rendering: Tone Mapping, Bloom Filter 
* Cel Shading: Threshold Lighting, Inking
* Shadow Mapping
* Fullscreen filters such as Bloom, Cartoon Inking, Volumetric Lightning, Blur/Sharpen and Ambient Occlusion, as well as the ability to use your own
* More to come

&lt;div style=&quot;clear: left&quot;&gt;
==3D Pipeline==
&lt;div style=&quot;float: left; width: 150px; margin: -12px 2em 0 0;&quot;&gt;
[[Image:Feature-pipeline.png]]
&lt;/div&gt;
Get models from your 3d modeller to Panda3D easily:
* Powerful EGG/BAM format
* EGG exporters for Maya, Blender and 3ds Max
* Support for other 3d formats (collada, x, lwo, obj, dxf, wrl, flt)
* Converters between different 3d formats and EGG

&lt;div style=&quot;clear: left&quot;&gt;
==Audio==
&lt;div style=&quot;float: left; width: 150px; margin: -12px 2em 0 0;&quot;&gt;
[[Image:Feature-audio.jpg]]
&lt;/div&gt;
Several options for adding sounds to your game:
* Support for the OpenAL audio engine
* Support for the FMOD audio engine
* Support for the Miles audio engine

&lt;div style=&quot;clear: left&quot;&gt;
==Physics==
&lt;div style=&quot;float: left; width: 150px; margin: -12px 2em 0 0;&quot;&gt;
[[Image:Feature-physics.png]]
&lt;/div&gt;
Several options for physics simulation:
* Built-in simple physics engine
* Support for the Bullet physics engine
* Support for the ODE physics engine
* Support for the PhysX physics engine

&lt;div style=&quot;clear: left&quot;&gt;
==Particle Effects==
&lt;div style=&quot;float: left; width: 150px; margin: -12px 2em 0 0;&quot;&gt;
[[Image:Feature-particles.jpg]]
&lt;/div&gt;
Panda3D has its own Particle System:
* Particle effects can be stored in text files
* Particle editor included for creating and editing particle effects

&lt;div style=&quot;clear: left&quot;&gt;
==GUI==
&lt;div style=&quot;float: left; width: 150px; margin: -12px 2em 0 0;&quot;&gt;
[[Image:Feature-gui.jpg]]
&lt;/div&gt;
Panda3D comes with a set of tools for the creation of a graphical interface:
* Native DirectGUI system
* Support for the libRocket GUI library

&lt;div style=&quot;clear: left&quot;&gt;
==Artificial Intelligence==
&lt;div style=&quot;float: left; width: 150px; margin: -12px 2em 0 0;&quot;&gt;
[[Image:Feature-ai.jpg]]
&lt;/div&gt;
Simple AI library &quot;PandaAI&quot; included:
* Steering behaviors: Seek, Flee, Pursue, Evade, Wander, Flock, Obstacle Avoidance, Path Following
* Path Finding
* Navigation Mesh generator for EGG files

&lt;div style=&quot;clear: left&quot;&gt;
==Performance Monitoring==
&lt;/div&gt;
&lt;div style=&quot;float: left; width: 150px; margin: -12px 2em 0 0;&quot;&gt;
[[Image:Feature-perfmon.jpg]]
&lt;/div&gt;
Powerful performance monitoring and optimization tools: 
* Identifies bottlenecks, both CPU and GPU
* CPU time use decomposed into more than 250 categories
* Counts meshes, polygons, textures, transforms, state changes, etc
* Allows user-defined CPU-usage categories
* Tools for batching and state-change minimization
* Tools to merge textures and minimize texture switches
* Times draw calls using GPU timer queries

&lt;div style=&quot;clear: left&quot;&gt;

==Debugging Tools==
&lt;div style=&quot;float: left; width: 150px; margin: -12px 2em 0 0;&quot;&gt;
[[Image:Feature-debug.jpg]]
&lt;/div&gt;
Heavy emphasis on error tolerance and debuggable code:
* Extreme resistance to crashing, even when errors are made
* More than 5000 assertion-checks to catch errors early
* Reference-counted data structures minimize memory leaks
* Many tools to examine internal state (one shown here) 

&lt;div style=&quot;clear: left&quot;&gt;
==Mature, Complete System==
&lt;div style=&quot;float: left; width: 150px; margin: -12px 2em 0 0;&quot;&gt;
[[Image:Feature-wizard.jpg]]
&lt;/div&gt;
Mature system used to deliver several commercial games.
Contains everything you need, not just the &quot;sexy&quot; stuff:
* Converters for a number of file formats
* Font file importers
* Tools to package games into redistributables
* Means to pack art assets into encrypted bundles
* Lots of other boring but essential stuff
&lt;div style=&quot;clear: left;&quot;&gt;
&lt;/div&gt;</text>
    </revision>
  </page>
  <page>
    <title>Cheat Sheets</title>
    <ns>0</ns>
    <id>2450</id>
      <sha1>rmzvurf8tx6grsb80dui3k8d80cv59v</sha1>
    <revision>
      <id>60323</id>
      <timestamp>2014-12-30T12:54:29Z</timestamp>
      <contributor>
        <username>Frainfreeze</username>
        <id>22860</id>
      </contributor>
      <comment>/* Read Me */</comment>
      <text xml:space="preserve" bytes="2584">== Read Me ==
The &quot;Cheat Sheets&quot; are still a ''work in progress''.

&lt;!--Please check [http://www.p3dp.com/doku.php?id=dotherwise:start this] web page for the latest versions: --&gt;
Please check [http://tcoenterprises.com/p3dStuff/cs/index.html this] web page for the latest versions.

When they are done (and checked for bugs) they will be added to this manual page. Everyone is invited to look for bugs and make suggestions. &lt;!-- The source file (SVG) is also available. --&gt;

==Panda Nodes==
&lt;!--http://dotherwise.p3dp.com/diagrams/PandaNodes.png --&gt;
http://tcoenterprises.com/p3dStuff/cs/PandaNodes.png

==Node Paths==
&lt;!-- http://dotherwise.p3dp.com/diagrams/NodePaths.png --&gt;
http://i.imgur.com/CmJynvC.png

==Global Variables==
&lt;!-- http://dotherwise.p3dp.com/diagrams/GlobalVars.png --&gt;
http://tcoenterprises.com/p3dStuff/cs/GlobalVars.png

==The Scene Graph==
&lt;!-- http://dotherwise.p3dp.com/diagrams/SceneGraph.png --&gt;
http://tcoenterprises.com/p3dStuff/cs/SceneGraph.png

==Parenting==
&lt;!-- http://dotherwise.p3dp.com/diagrams/Parenting.png --&gt;

&lt;!-- http://dotherwise.p3dp.com/diagrams/Parenting2.png --&gt;

http://tcoenterprises.com/p3dStuff/cs/Parenting.png
http://tcoenterprises.com/p3dStuff/cs/Parenting2.png

==Positioning==
&lt;!-- http://dotherwise.p3dp.com/diagrams/CommonManipulations.png --&gt;
&lt;!-- http://dotherwise.p3dp.com/diagrams/Man.png --&gt;
http://tcoenterprises.com/p3dStuff/cs/CommonManipulations.png
http://tcoenterprises.com/p3dStuff/cs/Man.png

==Models==
&lt;!-- http://dotherwise.p3dp.com/diagrams/AppEggBam.png --&gt;
&lt;!-- http://dotherwise.p3dp.com/diagrams/ModelPath.png --&gt;
http://tcoenterprises.com/p3dStuff/cs/AppEggBam.png
http://tcoenterprises.com/p3dStuff/cs/ModelPath.png

==Camera==
&lt;!-- http://dotherwise.p3dp.com/diagrams/Camera.png --&gt;
&lt;!-- http://dotherwise.p3dp.com/diagrams/Orthographic.png --&gt;
&lt;!-- http://dotherwise.p3dp.com/diagrams/PerspectiveCamera.png --&gt;
&lt;!-- http://dotherwise.p3dp.com/diagrams/CameraCode.png --&gt;
http://tcoenterprises.com/p3dStuff/cs/Camera.png
http://tcoenterprises.com/p3dStuff/cs/Orthographic.png
http://tcoenterprises.com/p3dStuff/cs/PerspectiveCamera.png
http://tcoenterprises.com/p3dStuff/cs/CameraCode.png

Diagrams by ''dotherwise''. &lt;!-- [http://www.p3dp.com/doku.php?id=dotherwise:start Website].  --&gt;

==BVW Material==

These quick reference sheets are from the Building Virtual Worlds project course at CMU's ETC and explain some basic concepts. Note that they may be outdated.

[http://www.panda3d.org/manual/pdfs/BVWQuickReference.pdf Part 1]&lt;br&gt;
[http://www.panda3d.org/manual/pdfs/QuickReference.pdf Part 2]</text>
    </revision>
  </page>
  <page>
    <title>3-D Textures</title>
    <ns>0</ns>
    <id>1216</id>
      <sha1>4mr21w5ub3bv3aoiqmb8zvc34t4yocx</sha1>
    <revision>
      <id>6685</id>
      <timestamp>2010-02-21T17:05:57Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>Quick &lt;pre&gt; to &lt;code lang&gt; fix for Python.</comment>
      <text xml:space="preserve" bytes="6626">So far, we have only talked about ordinary 2-D texture maps.
Beginning with version 1.1, Panda3D also supports the concept of a 3-D
texture map.  This is a volumetric texture: in addition to a height
and a width, it also has a depth:

[[Image:3dtexture cube.png|A sample 3-D texture.]]

The 3-D texture image is solid all the way through; if we were to cut
away part of the cube we would discover that the checkerboard pattern
continues within:

[[Image:3dtexture sphere.png|A sample 3-D texture on a sphere.]]

This is true no matter what shape we carve out of the cube:

[[Image:3dtexture teapot.png|A sample 3-D texture on a teapot.]]

In addition to the usual &lt;i&gt;u&lt;/i&gt; and &lt;i&gt;v&lt;/i&gt; texture dimensions, a
3-D texture also has &lt;i&gt;w&lt;/i&gt;.  In order to apply a 3-D texture to
geometry, you will therefore need to have 3-D texture coordinates
&lt;i&gt;(u, v, w)&lt;/i&gt; on your geometry, instead of just the ordinary &lt;i&gt;(u,
v)&lt;/i&gt;.

There are several ways to get 3-D texture coordinates on a model.  One
way is to assign appropriate 3-D texture coordinates to each
vertex when you create the model, the same way you might assign 2-D
texture coordinates.  This requires that your modeling package (and
its Panda converter) support 3-D texture coordinates; however, at the
time of this writing, none of the existing Panda converters currently
do support 3-D texture coordinates.

More commonly, 3-D texture coordinates are assigned to a model
automatically with one of the [[Automatic Texture Coordinates|TexGen modes]],
especially &lt;code&gt;MWorldPosition&lt;/code&gt;.  For example, to
assign 3-D texture coordinates to the teapot, you might do something
like this:

&lt;code python&gt;
teapot = loader.loadModel('teapot.egg')
teapot.setTexGen(TextureStage.getDefault(), TexGenAttrib.MWorldPosition)
teapot.setTexProjector(TextureStage.getDefault(), render, teapot)
teapot.setTexPos(TextureStage.getDefault(), 0.44, 0.5, 0.2)
teapot.setTexScale(TextureStage.getDefault(), 0.2)
&lt;/code&gt;

The above assigns 3-D texture coordinates to the teapot based on the
(x, y, z) positions of its vertices, which is a common way to assign
3-D texture coordinates.  The &lt;code&gt;setTexPos()&lt;/code&gt; and
&lt;code&gt;setTexScale()&lt;/code&gt; calls in the above are particular to the
teapot model; these numbers are chosen to scale the texture so that
its unit cube covers the teapot.

Storing 3-D texture maps on disk is a bit of a problem, since most
image formats only support 2-D images.  By convention, then, Panda3D
will store a 3-D texture image by slicing it into horizontal
cross-sections and writing each slice as a separate 2-D image.  When
you load a 3-D texture, you specify a series of 2-D images which
Panda3D will load and stack up like pancakes to make the full 3-D
image.

The above 3-D texture image, for instance, is stored as four separate
image files:

[[Image:3dtexture levels 0.png|The four images that make up the 3-D Texture]]

Note that, although the image is stored as four separate images on
disk, internally Panda3D stores it as a single, three-dimensional
image, with height, width, and depth.

The Panda3D convention for naming the slices of a 3-D texture is
fairly rigid.  Each slice must be numbered, and all of the filenames
must be the same except for the number; and the first (bottom) slice
must be numbered 0.  If you have followed this convention, then you
can load a 3-D texture with a call like this:

&lt;code python&gt;
tex = loader.load3DTexture(&quot;grid_#.png&quot;)
&lt;/code&gt;

The hash sign (&quot;#&quot;) in the filename passed to
&lt;code&gt;loader.load3DTexture()&lt;/code&gt; will be filled in with the
sequence number of each slice, so the above loads files named
&quot;grid_0.png&quot;, &quot;grid_1.png&quot;, &quot;grid_2.png&quot;, and so on.  If you prefer to
pad the slice number with zeros to a certain number of digits, repeat
the hash sign; for instance, loading &quot;grid_###.png&quot; would look for
files named &quot;grid_000.png&quot;, &quot;grid_001.png&quot;, and so on.  Note that you
don't have to use multiple hash marks to count higher than 9.  You can
count as high as you like even with only one hash mark; it just won't pad
the numbers with zeros.

Remember that you must usually [[Choosing a Texture Size|choose a power of two]] for the size of your texture images.  This extends to the &lt;i&gt;w&lt;/i&gt; size, too: for most graphics cards, the number of slices of your texture should be a power of two.  Unlike the ordinary &lt;i&gt;(u, v)&lt;/i&gt; dimensions, Panda3D won't automatically rescale your 3-D texture if it has a non-power-of-two size in the &lt;i&gt;w&lt;/i&gt; dimension, so it is important that you choose the size correctly yourself.

&lt;h2&gt;Applications for 3-D textures&lt;/h2&gt;

3-D textures are often used in scientific and medical imagery
applications, but they are used only rarely in 3-D game programs.  One
reason for this is the amount of memory they require; since a 3-D
texture requires storing &lt;i&gt;(u&amp;nbsp;&amp;times;&amp;nbsp;v&amp;nbsp;&amp;times;&amp;nbsp;w)&lt;/i&gt; texels, a large 3-D
texture can easily consume a substantial fraction of your available
texture memory.

But probably the bigger reason that 3-D textures are rarely used in
games is that the texture images in games are typically hand-painted,
and it is difficult for an artist to paint a 3-D texture.  It is
usually much easier just to paint the surface of an object.

So when 3-D textures are used at all, they are often generated
procedurally.  One classic example of a procedural 3-D texture is wood
grain; it is fairly easy to define a convincing woodgrain texture
procedurally.  For instance, [[Woodgrain Example|click here]] to view
a Panda3D program that generates a woodgrain texture and stores it as
a series of files named woodgrain_0.png, woodgrain_1.png, and so on.
The following code applies this woodgrain texture to the teapot, to
make a teapot that looks like it was carved from a single block of
wood:

&lt;code python&gt;
teapot = loader.loadModel('teapot.egg')
teapot.setTexGen(TextureStage.getDefault(), TexGenAttrib.MWorldPosition)
teapot.setTexProjector(TextureStage.getDefault(), render, teapot)
teapot.setTexPos(TextureStage.getDefault(), 0.44, 0.5, 0.2)
teapot.setTexScale(TextureStage.getDefault(), 0.2)

tex = loader.load3DTexture('woodgrain_#.png')
teapot.setTexture(tex)
&lt;/code&gt;

[[Image:Wooden teapot.jpg|A wooden teapot.]]

However, even procedurally-generated 3-D textures like this are used
only occasionally.  If the algorithm to generate your texture is not too
complex, it may make more sense to program a [[Pixel and Vertex Shaders|pixel shader]]
to generate the texture implicitly, as your models are rendered.

Still, even if it is used only occasionally, the 3-D texture remains a
powerful rendering technique to keep in your back pocket.</text>
    </revision>
  </page>
  <page>
    <title>3DAudio</title>
    <ns>0</ns>
    <id>2372</id>
    <redirect title="3D Audio" />
      <sha1>nn570r5oulg7fvcjd5vq6xzxouafpdg</sha1>
    <revision>
      <id>5958</id>
      <timestamp>2009-07-12T19:47:17Z</timestamp>
      <contributor>
        <username>Chroipahtz</username>
        <id>297</id>
      </contributor>
      <comment>[[3DAudio]] moved to [[3D Audio]]: Aesthetics</comment>
      <text xml:space="preserve" bytes="22">#REDIRECT [[3D Audio]]</text>
    </revision>
  </page>
  <page>
    <title>3D Audio</title>
    <ns>0</ns>
    <id>1785</id>
      <sha1>14r7sdc14b71scspw1qrq0lrjwquyar</sha1>
    <revision>
      <id>5957</id>
      <timestamp>2009-07-12T19:47:17Z</timestamp>
      <contributor>
        <username>Chroipahtz</username>
        <id>297</id>
      </contributor>
      <minor/>
      <comment>[[3DAudio]] moved to [[3D Audio]]: Aesthetics</comment>
      <text xml:space="preserve" bytes="2528">A wrapper &lt;code&gt;Audio3DManager&lt;/code&gt; class has been implemented to help do positional audio. &lt;code&gt;Audio3DManager&lt;/code&gt; takes as input an &lt;code&gt;AudioManager&lt;/code&gt; and a listener for the sound. A listener is the point of reference from where the sound should be heard. For a player in a Panda3D session, this will most likely be the camera. Sounds further away from the camera will not be loud. Objects nearer to the camera will be loud.

&lt;code python&gt;
from direct.showbase import Audio3DManager
audio3d = Audio3DManager.Audio3DManager(base.sfxManagerList[0], camera)
&lt;/code&gt;

To create a sound that is positional, you need to use the &lt;code&gt;loadSfx()&lt;/code&gt; function on the &lt;code&gt;Audio3DManager&lt;/code&gt; rather than the normal &lt;code&gt;loader.loadSfx()&lt;/code&gt; which is for non-positional sounds. e.g.

&lt;code python&gt;
mySound = audio3d.loadSfx('blue.wav')
&lt;/code&gt;

Sounds can be attached to objects such that when they move, the sound source will move along with them. 

&lt;code python&gt;
audio3d.attachSoundToObject(mySound, teapot)
&lt;/code&gt;

You can use the &lt;code&gt;Audio3DManager's setSoundVelocity()&lt;/code&gt; and &lt;code&gt;setListenerVelocity()&lt;/code&gt; to set the velocity of sounds or the listener to get the doppler pitch shifting of moving objects. If you would like the &lt;code&gt;Audio3DManager&lt;/code&gt; to help you adjust the velocity of moving objects automatically like it does with their position, you can call &lt;code&gt;setSoundVelocityAuto()&lt;/code&gt; or &lt;code&gt;setListenerVelocityAuto()&lt;/code&gt; like this:

&lt;code python&gt;
audio3d.setSoundVelocity(sound,velocityVector)
audio3d.setListenerVelocity(velocityVector)

base.cTrav = CollisionTraverser()
audio3d.setSoundVelocityAuto(sound)
audio3d.setListenerVelocityAuto()
&lt;/code&gt;

Currently, for the latter to work, a CollisionTraverser must be attached to base.cTrav as you see in the example. If you already have one assigned to do collision detection that will be sufficient. Read more about [[Collision Traversers]].

The attenuation of moving sounds by distance and the doppler shift are based the way sound works in the real world. By default it assumes a scale of 1 panda unit equal to 1 foot. If you use another scale you'll need to use &lt;code&gt;setDistanceFactor&lt;/code&gt; to adjust the scale.  

&lt;code python&gt;
audio3d.setDistanceFactor(scale)
&lt;/code&gt;

You can adjust the rate that sounds attenuate by distance. If you want to position the sounds but don't want the volume to be effected by their distance, you can set the drop off factor to 0.

&lt;code python&gt;
audio3d.setDropOffFactor(scale)
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>3D audio</title>
    <ns>0</ns>
    <id>2095</id>
    <redirect title="3DAudio" />
      <sha1>sh6yv73jjtragtpklvhqyjm5zw8tyeb</sha1>
    <revision>
      <id>4264</id>
      <timestamp>2007-04-10T14:30:27Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>redirected</comment>
      <text xml:space="preserve" bytes="21">#REDIRECT [[3DAudio]]</text>
    </revision>
  </page>
  <page>
    <title>3Daudio</title>
    <ns>0</ns>
    <id>2094</id>
    <redirect title="3DAudio" />
      <sha1>sh6yv73jjtragtpklvhqyjm5zw8tyeb</sha1>
    <revision>
      <id>4263</id>
      <timestamp>2007-04-10T14:30:00Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>redirected</comment>
      <text xml:space="preserve" bytes="21">#REDIRECT [[3DAudio]]</text>
    </revision>
  </page>
  <page>
    <title>API Reference Materials</title>
    <ns>0</ns>
    <id>952</id>
      <sha1>phoiac9h4m842xq45sp7s6u21eteeq1</sha1>
    <revision>
      <id>4530</id>
      <timestamp>2007-09-01T20:53:54Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="0" />
    </revision>
  </page>
  <page>
    <title>A Panda3D &quot;Hello World&quot;</title>
    <ns>0</ns>
    <id>2454</id>
    <redirect title="Tutorial: &quot;A Panda3D Hello World&quot;" />
      <sha1>6426lxwsx7oocfvxjc4giaqx8luwd4c</sha1>
    <revision>
      <id>6599</id>
      <timestamp>2010-02-07T04:32:00Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>[[A Panda3D &quot;Hello World&quot;]] moved to [[Tutorial: &quot;A Panda3D Hello World&quot;]]: Clarifies to new readers that this is the Panda3D tutorial, and the name of the tutorial includes &quot;A Panda3D&quot;.</comment>
      <text xml:space="preserve" bytes="47">#REDIRECT [[Tutorial: &quot;A Panda3D Hello World&quot;]]</text>
    </revision>
  </page>
  <page>
    <title>A Panda3D Hello World Tutorial</title>
    <ns>0</ns>
    <id>934</id>
      <sha1>8k3wav76ydib3fz7cwkgedkqd7da2f7</sha1>
    <revision>
      <id>6690</id>
      <timestamp>2010-02-24T11:54:57Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>[[Tutorial: &quot;A Panda3D Hello World&quot;]] moved to [[A Panda3D Hello World Tutorial]]: Remove special characters for CHM stuff</comment>
      <text xml:space="preserve" bytes="470">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

&lt;p&gt;This tutorial is called &quot;A Panda Hello World&quot;. It is a typical example of a simple Panda3D program. Walking through this tutorial will enable you to obtain some limited familiarity with the Panda3D API without having to learn the entire thing.&lt;/p&gt;

&lt;p&gt;The program that we are going to create will load up a small scene containing some grass and a panda. The panda will be animated to walk back and forth over the grass.&lt;/p&gt;</text>
    </revision>
  </page>
  <page>
    <title>A Panda &quot;Hello World&quot;</title>
    <ns>0</ns>
    <id>2071</id>
      <sha1>87k2j7p0wycknx0a90ei9nshs0zkb1k</sha1>
    <revision>
      <id>4231</id>
      <timestamp>2007-03-13T17:15:23Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>added links to the two different versions, python and c++</comment>
      <text xml:space="preserve" bytes="563">This tutorial is called &quot;A Panda Hello World.&quot;  It is a typical example
of a simple Panda3D program.  Walking through this tutorial will enable you to
obtain some limited familiarity with the Panda3D API, without having to learn
the entire thing.

The program that we are going to create will load up
a small scene containing some grass and a panda. The panda will be
animated to walk back and forth over the grass.

There are two versions of this tutorial:
* [[A Panda &quot;Hello World&quot; using Python|Python Version]]
* [[A Panda &quot;Hello World&quot; using CXX|C++ Version]]</text>
    </revision>
  </page>
  <page>
    <title>A Panda &quot;Hello World&quot; using CXX</title>
    <ns>0</ns>
    <id>2078</id>
      <sha1>g681x0426dle36u0op3e1t0okjpf56l</sha1>
    <revision>
      <id>4793</id>
      <timestamp>2008-03-07T11:05:31Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="1808">&lt;h2&gt;Recommendation: Use Python&lt;/h2&gt;

Caution: we do not recommend writing Panda3D programs in 100% C++.
Instead, we suggest writing your programs in mostly-python, with a 
little C++ here and there.  The reasons we suggest this are:

First, because we've tried it very successfully.  Both Disney and
Carnegie-Mellon have been creating applications in python with excellent
results.  All the commercial Disney games that use Panda3D are written
in mostly-python.  It is very easy to attain
excellent performance using mostly-python, and the development
is a lot quicker and easier than using C++.

Second, there are parts of Panda3D that are written in python.  These are
not the speed-critical parts.  For instance, the scene graph browser is
written in python.  The heads-up-display code is in python.  If you reject
python entirely, you lose access to a lot of important functionality.

Third, the entire Panda3D manual is in python.  Also, all the sample programs
are in python.  It is much harder to learn Panda3D if you try to 
translate the manual from python to C++ at the same time as you're
trying to learn Panda3D.  

&lt;h2&gt;So, You're Determined to Use C++&lt;/h2&gt;

Ah well, we tried to talk you out of it, but you're determined...

This tutorial is called &quot;A Panda Hello World.&quot;  It is a typical example
of a simple Panda3D program.  Walking through this tutorial will enable you to
obtain some limited familiarity with the Panda3D API, without having to learn
the entire thing.

The program that we are going to create will load up
a small scene containing some grass and a panda. The panda will be
animated to walk back and forth over the grass.

&lt;b&gt;Note:&lt;/b&gt; This tutorial is intended for C++ usage only. For the Python equivalent of this tutorial, click [[A Panda &quot;Hello World&quot; using Python|here]].</text>
    </revision>
  </page>
  <page>
    <title>A Panda &quot;Hello World&quot; using Python</title>
    <ns>0</ns>
    <id>2332</id>
    <redirect title="A Panda3D &quot;Hello World&quot;" />
      <sha1>0b5dazq55c2q8kzyl6hhea5mkj3yepm</sha1>
    <revision>
      <id>5813</id>
      <timestamp>2009-06-28T11:08:02Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>[[A Panda &quot;Hello World&quot; using Python]] moved to [[A Panda3D &quot;Hello World&quot;]]: split manual pages</comment>
      <text xml:space="preserve" bytes="37">#REDIRECT [[A Panda3D &quot;Hello World&quot;]]</text>
    </revision>
  </page>
  <page>
    <title>A Panda Hello World</title>
    <ns>0</ns>
    <id>951</id>
    <redirect title="A Panda &quot;Hello World&quot;" />
      <sha1>j4mz0y3jbm8hjv6j1gay6sws89dd5tj</sha1>
    <revision>
      <id>4050</id>
      <timestamp>2007-02-13T18:10:58Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>orphaned page</comment>
      <text xml:space="preserve" bytes="35">#REDIRECT [[A Panda &quot;Hello World&quot;]]</text>
    </revision>
  </page>
  <page>
    <title>About certificates</title>
    <ns>0</ns>
    <id>2398</id>
      <sha1>in891z2w3r8m00o7qkc6cqlf4zdsrmv</sha1>
    <revision>
      <id>6239</id>
      <timestamp>2009-10-17T15:33:49Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="895">When a p3d file is embedded in a web page, it can potentially start
running as soon as a user visits the web page.  This can be a big
security problem for the user, if a malicious person installs malware
in a p3d file.  There needs to be a way for the user to prevent p3d
files from running without his or her approval.

To solve this problem, Panda3D uses a certificate signing approach.
Before you can put a p3d file on a web page, you must sign it with a
special certificate that identifies you and only you.  When the user
visits your web page, and sees your signed p3d file, he or she will be
shown your certificate, and given an opportunity to approve it.

Once the user approves your certificate, the application will be
allowed to run.  (And this application, and all other applications
signed by the same certificate, will also run automatically in the
future without further approval.)</text>
    </revision>
  </page>
  <page>
    <title>Accessing Config Vars in a Program</title>
    <ns>0</ns>
    <id>945</id>
      <sha1>2iu3jhpofhre397pzdy68pnkx0xmc85</sha1>
    <revision>
      <id>6904</id>
      <timestamp>2010-08-11T03:11:23Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <minor/>
      <comment>Removed the word &quot;Python&quot; from &quot;[...] your Python code [...]&quot;, which was showing up on the C++ side as well.</comment>
      <text xml:space="preserve" bytes="6382">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

&lt;p&gt;Panda3D uses a [[Configuring Panda3D|configuration file]] named Config.prc.
Panda3D supplies functions to easily read values out of Config.prc, and to
alter their values in memory (the modified values are not written back out
to disk). The ability to read an alter configuration settings procedurally has two major uses:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Storing your own configuration data.
&lt;li&gt;Tweaking Panda3D's behavior.
&lt;/ol&gt;
&lt;p&gt;&quot;Storing your own configuration data&quot; means that your game might have its own settings that need to be stored. Rather than writing your own configuration file parser, you might consider adding your configuration data to the panda configuration file instead.&lt;/p&gt;

&lt;p&gt;Suppose hypothetically that you are writing an online game, and your online game connects to a server. You need a configuration file to tell you the name of the server. Open up the &quot;Config.prc&quot; file and add the following line at the end of the file.&lt;/p&gt;
&lt;code prc&gt;
my-game-server panda3dgame.com
&lt;/code&gt;
&lt;p&gt;Note that I invented the variable name &quot;my-game-server&quot; out of thin air. This variable is not recognized by Panda3D in any way. Therefore, this line has no effect on the engine whatsoever.&lt;/p&gt;

&lt;p&gt;To manipulate this variable procedurally, use code not unlike the following, which creates an object of class &lt;code&gt;ConfigVariableString&lt;/code&gt; and then manipulates it using the methods &lt;code&gt;[func]setValue[/func]()&lt;/code&gt; and &lt;code&gt;[func]getValue[/func]()&lt;/code&gt;.&lt;/p&gt;
[python]
&lt;code python&gt;
from panda3d.core import ConfigVariableString

myGameServer = ConfigVariableString('my-game-server', '127.0.0.1')
print('Server specified in config file: ', mygameserver.getValue())

# Allow the user to change servers on the command-line.
if (sys.argv[1] == '--server'):
    myGameServer.setValue(sys.argv[2])
print('Server that we will use: ', mygameserver.getValue())
&lt;/code&gt;
[/python]
&lt;p&gt;The second parameter to the ConfigVariableString constructor is the default value that should be returned, in case the line &quot;my-game-server&quot; does not appear in any Config.prc file.  There is also an optional third parameter, which is a description of the purpose of the variable. [python]This string will be displayed when the user executes the command &lt;code&gt;print(cvMgr)&lt;/code&gt;.[/python]&lt;/p&gt;

&lt;p&gt;The types of configuration variable are:&lt;/p&gt;
&lt;code text&gt;
ConfigVariableString
ConfigVariableInt
ConfigVariableBool
ConfigVariableDouble
ConfigVariableFilename
ConfigVariableList
ConfigVariableSearchPath
&lt;/code&gt;
&lt;p&gt;Most of these follow the same form as ConfigVariableString, above, except that the default value (and the parameter from &lt;code&gt;[func]setValue[/func]()&lt;/code&gt; and &lt;code&gt;[func]getValue[/func]()&lt;/code&gt;) is of the indicated type, rather than a string. The two exceptions are ConfigVariableList and ConfigVariableSearchPath. These types of variables do not accept a default value to the constructor since the default value in both cases is always the empty list or search path.&lt;/p&gt;
[python]
&lt;p&gt;To display the current value of a particular variable interactively (for a string-type variable in this example), type the following:&lt;/p&gt;
&lt;code python&gt;
print(ConfigVariableString(&quot;my-game-server&quot;))
&lt;/code&gt;
[/python]
&lt;p&gt;Panda3D will automatically load any PRC files it finds in its standard config directory at start-up. [python]You can view a list of the files it has actually loaded with the following command:&lt;/p&gt;

&lt;code python&gt;
print(cpMgr)
&lt;/code&gt;
[/python]
&lt;!--[cxx]
&lt;code cxx&gt;
#include &quot;configPageManager.h&quot;

cout &lt;&lt; ConfigPageManager::get_global_ptr();
&lt;/code&gt;
[/cxx]--&gt;
&lt;p&gt;It is helpful to do this to ensure that you are editing the correct Config.prc file.&lt;/p&gt;

&lt;p&gt;Sometimes, it is desirable to load an additional configuration file from disk, by giving an explicit filename. To do so, use &lt;code&gt;[func]loadPrcFile[/func]()&lt;/code&gt;. Note that [[Panda Filename Syntax]] uses a forward slash even under Windows.&lt;/p&gt;
[python]
&lt;code python&gt;
from panda3d.core import loadPrcFile

loadPrcFile(&quot;config/Config.prc&quot;)
&lt;/code&gt;
[/python]
[cxx]
&lt;code cxx&gt;
#include &quot;load_prc_file.h&quot;

load_prc_file(&quot;config/Config.prc&quot;);
&lt;/code&gt;
[/cxx]
&lt;p&gt;The filename you specify is searched for along the model-path, in the same way that an Egg or Bam file is searched for when you use &lt;code&gt;loader.[func]loadModel[/func]()&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;You should load your own PRC file before [python]instantiating ShowBase.[/python][cxx]opening the window.[/cxx] Changing configuration data later on won't affect the window/environment that has already been created.&lt;/p&gt;

&lt;p&gt;You can also use &lt;code&gt;[func]loadPrcFileData[/func]()&lt;/code&gt; to load a string that you define in your code, as if it were the contents read from a disk file. The &lt;code&gt;[func]loadPrcFileData[/func]()&lt;/code&gt; call requires two parameters. The first parameter is an arbitrary string name to assign to this &quot;file&quot; (and it can be the empty string if you don't care), while the second parameter is the contents of the file itself. This second parameter should contain newlines between variable definitions if you want to set the value of more than one variable.&lt;/p&gt;

&lt;p&gt;For example, let's say that Panda3D's configuration file contains this line:&lt;/p&gt;
&lt;code prc&gt;
fullscreen #f
&lt;/code&gt;
&lt;p&gt;By default, Panda3D programs will run in a window; not fullscreen. However, if you do this, then by the time you instantiate ShowBase, you will have changed the fullscreen-flag to true, and your program will run in fullscreen.&lt;/p&gt;
[python]
&lt;code python&gt;
from panda3d.core import loadPrcFileData

loadPrcFileData('', 'fullscreen 1')
&lt;/code&gt;
[/python]
[cxx]
&lt;code cxx&gt;
#include &quot;load_prc_file.h&quot;

load_prc_file_data(&quot;&quot;, &quot;fullscreen 1&quot;);
&lt;/code&gt;
[/cxx]
&lt;p&gt;There are other ways to go to fullscreen. This is not necessarily the most straightforward approach, but it illustrates the point.&lt;/p&gt;

&lt;p&gt;You can get a more complete list of available config variables at runtime[python] (once you have instantiated ShowBase)[/python], with the &lt;code&gt;[func]listVariables[/func]()&lt;/code&gt; command:&lt;/p&gt;
[python]
&lt;code python&gt;
cvMgr.listVariables()
&lt;/code&gt;
[/python]
[cxx]
&lt;code cxx&gt;
ConfigVariableManager::get_global_ptr()-&gt;list_variables();
&lt;/code&gt;
[/cxx]
&lt;p&gt;For a more complete documentation about Panda3D's configuration system, view the [http://panda3d.cvs.sourceforge.net/*checkout*/panda3d/panda/src/doc/howto.use_config.txt original documentation file].&lt;/p&gt;</text>
    </revision>
  </page>
  <page>
    <title>Actor Animations</title>
    <ns>0</ns>
    <id>946</id>
      <sha1>rzexwhy6cahiozqo9hhy5b3jtiycb92</sha1>
    <revision>
      <id>60223</id>
      <timestamp>2014-07-24T19:53:45Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="10240">Since the Actor class inherits from NodePath, everything that can be done to a NodePath, such as &lt;code&gt;reparentTo()&lt;/code&gt; and &lt;code&gt;setPos()&lt;/code&gt;, etc., may also be done to an Actor.  In addition to the basic NodePath functionality, Actors have several additional methods to control animation.  In order for Actors to animate, their pointer (variable) must be retained in memory.  The following is only a brief introduction; see the API reference for a complete list.

&lt;h2&gt;Basic animation playing&lt;/h2&gt;

Animations may either be played or looped. When an animation is played, the actor goes through the animation once. When an animation is looped, the animation will play continuously. There is no tweening done between the last and the first frame, so if an animation is going to be looped, it needs to be constructed with that thought in mind. Finally, animations may be stopped at any point. When an animation is stopped, the actor will stay in the position it stopped on.

[python]
&lt;code python&gt; 
actor.play('Animation Name')
actor.loop('Animation Name')
actor.stop()
&lt;/code&gt;
[/python]

[cxx]&lt;code cxx&gt;
window-&gt;loop_animations(Actor);
&lt;/code&gt;[/cxx]

You may use the &lt;code&gt;pose()&lt;/code&gt; method to tell an actor to hold a particular frame of the animation.  Frames are numbered beginning at 0.

[python]
&lt;code python&gt;
actor.pose('Animation Name', FrameNumber)
&lt;/code&gt;
[/python]

Posing an actor to a frame doesn't automatically specify the start frame of the next starting animation.  Instead, if you don't want to start at the first frame, you can specify these using the optional parameters &lt;code&gt;fromFrame&lt;/code&gt; and &lt;code&gt;toFrame&lt;/code&gt; to the methods &lt;code&gt;play()&lt;/code&gt; and &lt;code&gt;loop()&lt;/code&gt;:

[python]
&lt;code python&gt;
actor.play('Animation Name', fromFrame = 10)
actor.loop('Animation Name', fromFrame = 24, toFrame = 36)
&lt;/code&gt;
[/python]

However, the loop method does have another optional parameter called &lt;code&gt;restart&lt;/code&gt;, which is 1 by default, meaning the animation will restart from the beginning.  If you pass it 0 instead, then the animation will begin looping from the current frame:

[python]
&lt;code python&gt;
actor.pose('Animation Name', 30)
actor.loop('Animation Name', restart = 0, fromFrame = 24, toFrame = 36)
&lt;/code&gt;
[/python]

You can get more information about an animation with these functions:

[python]
&lt;code python&gt;
print actor.getNumFrames('Animation Name') #returns the total number of frames in the animation
print actor.getCurrentAnim() #returns a string containing the name of the current playing animation
print actor.getCurrentFrame('Animation Name') #returns the current frame of the animation.
&lt;/code&gt;
[/python]

&lt;h2&gt;AnimControl&lt;/h2&gt;

AnimControl is a class that provides control over a certain animation. You don't need to use this but this could be useful if you want to have the animation control functions over a certain animation in a separate class.
NOTE: prior to Panda3D version 1.4, there is a required second parameter to actor.getAnimControl, which is the part name, or the literal string &quot;modelRoot&quot; if you don't have a multipart actor.

[python]
&lt;code python&gt;
myAnimControl=actor.getAnimControl('Animation Name') #get the AnimControl

myAnimControl.isPlaying() #returns a boolean whether the animation is playing or not
myAnimControl.getFrame() #returns the current frame number
myAnimControl #returns the speed of the animation, in frames per second
myAnimControl.getFullFframe() #returns a floating-point frame number exceeding the framecount. Not recommended.
myAnimControl.getFullFrame() #returns an integer frame number exceeding the framecount. Not recommended.
myAnimControl.getNextFrame() #returns the number of the next frame on the queue.
myAnimControl.getNumFrames() #returns the total number of frames
myAnimControl.getPlayRate() #returns the playrate. explained further below
myAnimControl.loop() #starts playing the animation in a loop
myAnimControl.play() #starts playing the animation
myAnimControl.pose(frame) #poses at frame frame
myAnimControl.setPlayRate(rate) #sets the playrate. explained further below
myAnimControl.stop() #stops the animation
&lt;/code&gt;
[/python]

&lt;h2&gt;Play rate&lt;/h2&gt;

The animation play rate may be set to any floating point value, which can be used to speed up or slow down the animation.  This is a scale factor on the base animation rate; 1.0 means to play the animation at its normal speed, while 2.0 plays it twice as fast, and 0.5 plays it at half speed.  It is also possible to play an animation backwards by specifying a negative play rate, for instance -1.0.

[python]
&lt;code python&gt;
actor.setPlayRate(newPlayRate, 'Animation Name')
&lt;/code&gt;
[/python]

&lt;h2&gt;Blending&lt;/h2&gt;

Multiple different animations for an actor may be played at the same time, and the animations blended together at runtime.  The net result is that, each frame, the actor ends up somewhere between the different poses it would be in for each contributing animation, if each animation were playing independently.

Note that in blend mode each contributing animation still affects the actor's entire body.  If you want to play one animation on, say, the left arm, while a different animation is playing on the legs, then you need to use half-body animation, which is different from blending.

To use blending, you must first call &lt;code&gt;enableBlend()&lt;/code&gt; to activate the blending mode and indicate your intention to play multiple animations at once.  While the actor is in blend mode, playing a new animation does not automatically stop the previously playing animation.  Also, while in blend mode, you must explicitly specify how much each animation contributes to the overall effect, with the &lt;code&gt;setControlEffect()&lt;/code&gt; method (the default for each animation is 0.0, or no contribution).  For example:

[python]
&lt;code python&gt;
actor.enableBlend()
actor.setControlEffect('animation1', 0.2)
actor.setControlEffect('animation2', 0.8)
actor.loop('animation1')
actor.loop('animation2')
&lt;/code&gt;
[/python]

The above specifies that 20% of animation1 and 80% of animation2 will be visible on the character at the same time.  Note that you still have to start both animations playing (and they can be playing from different frames or at different play rates).  Starting or stopping an animation in blend mode does not change its control effect; you must set an animation's control effect to 0.0 if you don't want it to have any more affect on the actor.

When you call &lt;code&gt;stop()&lt;/code&gt; in blend mode, you can stop a particular animation by name, if you want; or you can stop all of the animations by calling &lt;code&gt;stop()&lt;/code&gt; with no parameters:

[python]
&lt;code python&gt;
actor.stop('animation1')
&lt;/code&gt;
[/python]

Note that specifying an animation name to stop() is only meaningful when you are in blend mode.  When not in blend mode, actor.stop() will always stop whatever animation is currently playing, regardless of the animation name you specify.

When you are done using blending and want to return to the normal mode of only playing one animation at a time, call &lt;code&gt;disableBlend()&lt;/code&gt;:

[python]
&lt;code python&gt;
actor.disableBlend()
&lt;/code&gt;
[/python]

&lt;h2&gt;Half-body animation&lt;/h2&gt;

If you want different parts of your actor to play separate animations without blending them together you have to create subparts. Each of these can then play one animation without influencing the others.
Call actor.makeSupart() with the desired name, a list of joints to be included and a list of joints to be excluded in the subpart. Inclusion / exclusion will descend attached joints. Exclude always overwrite include.

&lt;pre class=&quot;codeblock&quot;&gt;
actor.makeSubpart(&quot;legs&quot;, [&quot;Left Thigh&quot;, &quot;Right Thigh&quot;])
actor.makeSubpart(&quot;torso&quot;, [&quot;Head&quot;], [&quot;Left Thigh&quot;, &quot;Right Thigh&quot;])
&lt;/pre&gt;

If you want to play an animation on a subpart make sure to pass the name.

&lt;pre class=&quot;codeblock&quot;&gt;
actor.loop(&quot;walk&quot;, partName=&quot;legs&quot;)
actor.loop(&quot;reload&quot;, partName=&quot;torso&quot;)
&lt;/pre&gt;

&lt;h2&gt;Interpolation&lt;/h2&gt;

Since Panda 1.3.0 intra-frame interpolation is supported. If you play an animation with only few frames per second you can see your model &quot;jump&quot; from one frame to the next. If you enable interpolation between frames, those &quot;jumps&quot; will  be smoothed out. This allows smooth animations with framerates as low as one frame per second or even less.
Intra-frame interpolation is disabled by default.
To enable it just add the following lines to your code

[python]&lt;code python&gt;
from panda3d.core import loadPrcFileData
loadPrcFileData(&quot;&quot;, &quot;interpolate-frames 1&quot;)
&lt;/code&gt;[/python]

From the FAQ:

&quot;Interpolate-frames flag gets set in the PartBundle at the time it is first created, and then baked into the bam cache.

Thenceforth, later changes to the interpolate-frames variable mean nothing. If you changed interpolate-frames flag, you will also need to empty your modelcache folder.

Actually, it is not recommended to use interpolate-frames; it is a global setting. It's better to achieve the same effect via actor.setBlend(frameBlend = True), which is a per-actor setting (and doesn't get baked into the model cache).&quot;


&lt;h2&gt;Actor Intervals&lt;/h2&gt;

Another way to play an animation on an actor is to use an [[Actor Intervals|ActorInterval]], which gives you a lot more frame-by-frame control over the animation, and is particularly useful when building a complex script using Intervals.  However, the ActorInterval interface is a little bit slower than the above interfaces at runtime, so you should prefer the more fundamental interfaces unless there is a good reason to use ActorInterval.

&lt;h2&gt;The Task manager&lt;/h2&gt;

On a more complex program, you may find that Animations can not be loaded from any point in your program. In any application there needs to be exactly one call to run(), and it should be the last thing you do after starting up. This starts the task manager. Think of this as the main loop of the application: your startup procedure is to set up your loading screen, start any initial tasks or intervals, hang any initial messenger hooks, and then go get lost in run(). Thereafter everything must run in a [[Tasks and Event Handling|task]], in an interval, or is a response to a message. This is true for both animations and [[Loading and Playing Sounds and Music|sound]].</text>
    </revision>
  </page>
  <page>
    <title>Actor Intervals</title>
    <ns>0</ns>
    <id>947</id>
      <sha1>fx3uo2ts2xr1i7sc0gdut9vrq23fhbi</sha1>
    <revision>
      <id>6536</id>
      <timestamp>2010-01-14T19:12:13Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>Added [python] and [cxx] tags; added note that this section does not apply to C++.</comment>
      <text xml:space="preserve" bytes="2795">[python]
Actor intervals allow actor animations to be played as an interval, which allows them to be combined with other intervals through sequences and parallels.  

The subrange of the animation to be played may be specified via frames (&lt;code&gt;startFrame&lt;/code&gt; up to and including &lt;code&gt;endFrame&lt;/code&gt;) or seconds (&lt;code&gt;startTime&lt;/code&gt; up to and including &lt;code&gt;endTime&lt;/code&gt;). It may also be specified with a &lt;code&gt;startFrame&lt;/code&gt; or &lt;code&gt;startTime&lt;/code&gt; in conjunction with the duration, in seconds. If none of these is specified, then the default is to play the entire range of the animation.

If &lt;code&gt;endFrame&lt;/code&gt; is before &lt;code&gt;startFrame&lt;/code&gt;, or if the play rate is negative, then the animation will be played backwards.

You may specify a subrange that is longer than the actual animation, but if you do so, you probably also want to specify either &lt;code&gt;loop=1&lt;/code&gt; or &lt;code&gt;constrainedLoop=1&lt;/code&gt;; see below.

The loop parameter is a boolean value.  When it is true, it means that the animation restarts and plays again if the interval extends beyond the animation's last frame.  When it is false, it means that the animation stops and holds its final pose when the interval extends beyond the animation's last frame.  Note that, in neither case, will the ActorInterval loop indefinitely: all intervals always have a specific, finite duration, and the duration of an ActorInterval is controlled by either the duration parameter, the &lt;code&gt;startTime&lt;/code&gt;/&lt;code&gt;endTime&lt;/code&gt; parameters, or the &lt;code&gt;startFrame&lt;/code&gt;/&lt;code&gt;endFrame&lt;/code&gt; parameters.  Setting &lt;code&gt;loop=1&lt;/code&gt; has no effect on the duration of the ActorInterval, it only controls what the actor does if you try to play past the end of the animation.

The parameter &lt;code&gt;constrainedLoop&lt;/code&gt; works similarly to loop, but while &lt;code&gt;loop=1&lt;/code&gt; implies a loop within the entire range of animation, &lt;code&gt;constrainedLoop=1&lt;/code&gt; implies a loop within &lt;code&gt;startFrame&lt;/code&gt; and &lt;code&gt;endFrame&lt;/code&gt; only. That is, if you specify &lt;code&gt;loop=1&lt;/code&gt; and the animation plays past &lt;code&gt;endFrame&lt;/code&gt;, in the next frame it will play beginning at frame 0; while if you specify &lt;code&gt;constrainedLoop=1&lt;/code&gt; instead, then the next frame after &lt;code&gt;endFrame&lt;/code&gt; will be &lt;code&gt;startFrame&lt;/code&gt; again.

All parameters other than the animation name are optional.

&lt;code python&gt;
from direct.interval.ActorInterval import ActorInterval

myInterval = myactor.actorInterval(
    &quot;Animation Name&quot;,
    loop=&lt;0 or 1&gt;,
    contrainedLoop=&lt;0 or 1&gt;,
    duration=D,
    startTime=T1,
    endTime=T2,
    startFrame=N1,
    endFrame=N2,
    playRate=R,
    partName=PN,
    lodName=LN,
)
&lt;/code&gt;
[/python]
[cxx]
As ActorInterval is implemented in Python, this section does not apply to C++.
[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Actor Manipulations</title>
    <ns>0</ns>
    <id>948</id>
      <sha1>alpmhpu93sp2rqzmt0ttn8x5zo8sg1j</sha1>
    <revision>
      <id>2232</id>
      <timestamp>2005-05-01T01:22:13Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="4561">If an actor has been rigged, then there will be joints. It is possible to access a specific joint and manipulate it. This makes a child node with its own NodePath, which will then let it be manipulated. Even though pre-generated animations may have been created with the help of IK, Panda3D has no such physics engine for it. This means that even through a joint may be controlled, and the joint does affect its connected parts, no inverse kinematics will be applied.

There are two methods for revealing joints, controlJoint and exposeJoint.
They each have an argument 'Model Node' which is generally the string, “modelRoot.”. They also both want the name of the joint. You can look at the name of the bone in a modeling package, or look for a string such as &lt;code&gt;&amp;lt;Joint&amp;gt; Femur&lt;/code&gt; inside of an egg file.

If you only want to get location/rotation information about the joint but don't need to change anything yourself.

&lt;table class=&quot;code&quot;&gt;&lt;tr&gt;&lt;td&gt;
NodePath=ModelNodePath.exposeJoint(None,‘Model Node',‘Joint Name')
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

This creates a new NodePath from the NodePath of the actor that holds the joint. You can reparent objects to this node, and use functions such as getPos(), getHpr(), etc. The transformation of the object that you pass as the first argument to exposeJoint gets directly controlled by the joint. You will not be able to control it independantly, so this argument is often 'None', which creates a dummy object in hte hiearchy.

&lt;table class=&quot;code&quot;&gt;&lt;tr&gt;&lt;td&gt;
NodePath=ModelNodePath.controlJoint(None,‘Model Node',‘Joint Name')
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

This creates a new NodePath from the NodePath of the actor that holds the joint. You can move this object however you want. If you want to use this joint as part of an animation as well you will need to modify the skeleton with optchar as described below.

&lt;h2&gt;egg-optchar&lt;/h2&gt;

&lt;b&gt;Warning:&lt;/b&gt; the following technique is only needed if you want to animate and control a single joint at the same time.  In other words, it's relevant if you want your control movements and the animation movements to be added together. This is very uncommon.  Normally, you would want to completely control some of the joints, and let the animation control the other joints.  Think twice before using this method - are you &lt;i&gt;sure&lt;/i&gt; this is really what you need?

&lt;b&gt;Warning:&lt;/b&gt; We are not sure if this method works.  Or rather, we're fairly sure that it can be made to work, but we're also fairly sure that this description is missing certain critical steps.

When you use controlJoint, it overrides the animation channel that is controlling the joint.  This means that any motion stored in the animation file will be completely ignored.  There is a program named egg-optchar that allows you to add extra bones into the skeleton so that after the model is animated, you can also control the joints in panda.

Example:

You have a model arm.egg,with the hiearchy bArm1,bArm2,bArm3,bArm4.

&lt;p classw=&quot;manual&quot;&gt;You run this command at the command prompt: &lt;/p&gt;
&lt;p classw=&quot;manual&quot;&gt;&lt;strong&gt;egg-optchar Arm.egg -o Arm2.egg&lt;br&gt;
  -new bArm1_2,bArm1 -p bArm1_2, -p bArm1,bArm1_2 -p bArm1_2,&lt;br&gt;
  -new bArm2_2,bArm2 -p bArm2_2, -p bArm2,bArm2_2 -p bArm2_2,bArm1 &lt;br&gt;
  -new bArm3_2,bArm3 -p bArm3_2, -p bArm3,bArm3_2 -p bArm3_2,bArm2 &lt;br&gt;
  -new bArm4_2,bArm4 -p bArm4_2, -p bArm4,bArm4_2 -p bArm4_2,bArm3 &lt;br&gt;
-keepall&lt;/strong&gt;&lt;/p&gt;

Now the hierarchy lookslike this- bArm1, bArm2_2, bArm2, bArm3_2, bArm3, bArm4_2, bArm4. Each of the new bones is right above the bone it is duplicating, which allows your changes to be inherited through the skeleton while the animations to continue to work.

&lt;strong&gt;-new bArm2_2,bArm2&lt;/strong&gt; creates a new joint called bArm2_2 and reparents it to the existing joint bArm2. The local transformation of bArm2_2 is 
the identity so it's world transformation is the same as bArm1.

&lt;strong&gt;-p bArm2_2,&lt;/strong&gt; reparents  bArm2_2 to the root, it's world transformation still preserved, so it is still in the same location and orientation as bArm2

&lt;strong&gt;-p bArm2,bArm2_2&lt;/strong&gt; reparents the bArm2 joint (and therefore anything attached to the bArm2) to   bArm2_2. Because of the wrt reparent and the fact that bArm2 and  bArm2_2 have the same location and orientation, bArm2 
ends up with a local transformation of the identity.

&lt;strong&gt;-p bArm2_2,bArm1&lt;/strong&gt;  finally reparents  bArm2_2 to bArm1 (which bArm2 used to be parented to.) Now   bArm2_2 has the same local transformation  that bArm2 did before this whole rearrangement occurred.</text>
    </revision>
  </page>
  <page>
    <title>Actors and Characters</title>
    <ns>0</ns>
    <id>2188</id>
    <redirect title="Models and Actors" />
      <sha1>0iazzh2i67zwmb4b3t68urzl5e3jrjj</sha1>
    <revision>
      <id>4749</id>
      <timestamp>2008-03-07T07:30:24Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <comment>[[Actors and Characters]] moved to [[Models and Actors]]: Added information about static models, too.</comment>
      <text xml:space="preserve" bytes="31">#REDIRECT [[Models and Actors]]</text>
    </revision>
  </page>
  <page>
    <title>Advanced Display Setup</title>
    <ns>0</ns>
    <id>2623</id>
      <sha1>phoiac9h4m842xq45sp7s6u21eteeq1</sha1>
    <revision>
      <id>7323</id>
      <timestamp>2011-09-15T18:29:14Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <comment>Empty outdated page</comment>
      <text xml:space="preserve" bytes="0" />
    </revision>
  </page>
  <page>
    <title>Advanced FSM Tidbits</title>
    <ns>0</ns>
    <id>1716</id>
      <sha1>7q2r2vwzempfcweklf3qfbs47d6bqd1</sha1>
    <revision>
      <id>6784</id>
      <timestamp>2010-04-05T21:20:52Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>Slight clean-up; added language segregation.</comment>
      <text xml:space="preserve" bytes="4764">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

[python]
== request vs. demand == 

&lt;p&gt;As stated previously, you normally request an FSM to change its state by calling either &lt;code&gt;fsm.request('NewState', arg1, arg2, ...)&lt;/code&gt;, or &lt;code&gt;fsm.request('inputString', arg1, arg2, ...)&lt;/code&gt;, where arg1, arg2, ... represent optional arguments to the destination state's enter function (or to the filter function).  The call to &lt;code&gt;request()&lt;/code&gt; will either succeed or fail, according to what the filter function for the current state does.  If it succeeds, it will return the tuple &lt;code&gt;('NewState', arg1, arg2)&lt;/code&gt;, indicating the new state it has transitioned to.  If it fails, it will simply return None (unless the filter function was written to throw an exception on failure).&lt;/p&gt;

&lt;p&gt;If you request an FSM to make a transition, and the request fails, you might consider this an error condition, and you might prefer to have your code to stop right away rather than continuing.  In this case, you should call &lt;code&gt;fsm.demand()&lt;/code&gt; instead.  The syntax is the same as that for &lt;code&gt;request()&lt;/code&gt;, but instead of returning None on failure, it will always raise an exception if the state transition is denied.  There is no return value from &lt;code&gt;demand()&lt;/code&gt;; if it returns, the transition was accepted.&lt;/p&gt;

== FSM.AlreadyInTransition ==

&lt;p&gt;An FSM is always in exactly one state, except while it is in the process of transitioning between states (that is, while it is calling the exitStateName method for the previous state, followed by the enterStateName method for the new state).  During this time, the FSM is not considered in either state, and if you query &lt;code&gt;fsm.state&lt;/code&gt; it will contain None.&lt;/p&gt;

&lt;p&gt;During this transition time, it is not legal to call &lt;code&gt;fsm.request()&lt;/code&gt; to request a new state.  If you try to do this, the FSM will raise the exception &lt;code&gt;FSM.AlreadyInTransition&lt;/code&gt;.  This is a particularly common error if some cleanup code that is called from the exitStateName method has a side-effect that triggers a transition to a new state.&lt;/p&gt;

&lt;p&gt;However, there's a simple solution to this problem: call &lt;code&gt;fsm.demand()&lt;/code&gt; instead.  Unlike &lt;code&gt;request()&lt;/code&gt;, &lt;code&gt;demand()&lt;/code&gt; can be called while the FSM is currently in transition.  When this happens, the FSM will queue up the demand, and will carry it out as soon as it has fully transitioned into its new state.&lt;/p&gt;

== forceTransition() ==

&lt;p&gt;There is also a method &lt;code&gt;fsm.forceTransition()&lt;/code&gt;.  This is similar to &lt;code&gt;demand()&lt;/code&gt; in that it never fails and does not have a return value, but it's different in that it completely bypasses the filter function.  You should therefore only pass an uppercase state name (along with any optional arguments) to forceTransition, never a lowercase input string.  The FSM will always transition to the named state, even if it wouldn't otherwise be allowed.   Thus, &lt;code&gt;forceTransition()&lt;/code&gt; can be useful in special cases to skip to another state that's not necessarily connected to the current state (for instance, to handle emergency cleanup when an exception occurs).  Be careful that you don't overuse &lt;code&gt;forceTransition()&lt;/code&gt;, though; consider whether &lt;code&gt;demand()&lt;/code&gt; would be a better choice.  If you find yourself making lots of calls to &lt;code&gt;forceTransition()&lt;/code&gt;, it may be that your filter functions (or your defaultTransitions) are poorly written and are disallowing what should be legitimate state transitions.&lt;/p&gt;

== Filtering the optional arguments ==

&lt;p&gt;The filterStateName method receives two parameters: the string request, and a tuple, which contains the additional arguments passed to the request (or demand) call.  It then normally returns the state name the FSM should transition to, or it returns None to indicate the transition is denied.&lt;/p&gt;

&lt;p&gt;However, the filter function can also return a tuple.  If it returns a tuple, it should be of the form ('StateName', arg1, arg2, ...), where arg1, arg2, ... represent the optional arguments that should be passed to the enterStateName method.  Usually, these are the same arguments that were passed to the filterStateName method (in this case, you can generate the return value tuple with the python syntax &lt;code&gt;('StateName',) + args&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;The returned arguments are not necessarily the same as the ones passed in, however.  The filter function is free to check, modify, or rearrange any of them; or it might even make up a completely new set of arguments.  In this way, the filter function can filter not only the state transitions themselves, but also the set of data passed along with the request.&lt;/p&gt;
[/python]
[cxx]
&lt;p&gt;This section does not apply to C++ users.&lt;/p&gt;
[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Advanced FSM usage</title>
    <ns>0</ns>
    <id>1717</id>
    <redirect title="Advanced FSM Tidbits" />
      <sha1>c7luk19fitfbcgz3iyz7pw9ievqjqkn</sha1>
    <revision>
      <id>3183</id>
      <timestamp>2006-01-22T03:11:12Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <comment>Advanced FSM usage moved to Advanced FSM Tidbits</comment>
      <text xml:space="preserve" bytes="34">#redirect [[Advanced FSM Tidbits]]</text>
    </revision>
  </page>
  <page>
    <title>Advanced object tags</title>
    <ns>0</ns>
    <id>2418</id>
      <sha1>59ubg43hy98hhxyvma1t23ucp0slruh</sha1>
    <revision>
      <id>6281</id>
      <timestamp>2009-10-25T16:23:07Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="2419">When you embed a Panda3D application in a web page, either with the &lt;object&gt; tag or with P3D_RunContent, you specify certain key pieces of information such as window size and p3d URL.

You can specify more exotic things too:

{| border=&quot;1&quot;
! Token !! Meaning 
|- 
| auto_start || &quot;1&quot; to launch the app without waiting for the green &quot;play&quot; button
|-
| hidden || &quot;1&quot; to avoid opening a Panda3D window
|-
| keep_pythonpath || &quot;1&quot; to allow the user's PYTHONPATH environment variable to remain intact, and thus to override Python files within the app (requires -D on p3d file)
|-
| log_basename || Specifies the log file within Panda3D/log to write to for this app
|-
| prc_name || Specifies a directory name within Panda3D/prc from which user prc files custom to this app will be loaded
|-
| alt_host || Specifies one of the &quot;alternate host&quot; keywords defined for the p3d file's download host, to enable alternate download contents
|}

In addition to the above list, you may specify any of numerous splash image URL's, or any of the plugin notify callbacks; these are described on the following pages.

Furthermore, you can specify tokens that have particular meaning to your own application.  Any additional tokens you specify are passed to the application and can be queried by Python code via base.appRunner.getToken('keyword'), so any application is free to define its own custom tokens.

To use any of the above, specify the token and the value as a pair in the embedding HTML syntax.  In the Internet Explorer syntax, this means you use the &lt;param&gt; element, e.g.:

&lt;code html4strict&gt;
&lt;object width=&quot;640&quot; height=&quot;480&quot;
  classid=&quot;CLSID:924B4927-D3BA-41EA-9F7E-8A89194AB3AC&quot;&gt;
    &lt;param name=&quot;data&quot; value=&quot;myapp.p3d&quot;&gt;
    &lt;param name=&quot;splash_img&quot; value=&quot;my_splash.jpg&quot;&gt;
    &lt;param name=&quot;auto_start&quot; value=&quot;1&quot;&gt;
&lt;/object&gt;
&lt;/code&gt;

In the non-Internet Explorer syntax, you can use the &lt;param&gt; element as above, or you can insert the token directly within the &lt;object&gt; tag, e.g.:

&lt;code html4strict&gt;
&lt;object width=&quot;640&quot; height=&quot;480&quot;
  type=&quot;application/x-panda3d&quot; data=&quot;myapp.p3d&quot;
  splash_img=&quot;my_splash.jpg&quot; auto_start=&quot;1&quot;&gt;
&lt;/object&gt;
&lt;/code&gt;

When using RunPanda3D, you just add the token and value as a pair of strings to the P3D_RunContent() call:

&lt;code javascript&gt;
P3D_RunContent('data', 'myapp.p3d', 'id', 'myapp_id',
    'width', '640', 'height', '480',
    'splash_img', 'my_splash.jpg', 'auto_start', '1')
}
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>Advanced operations with Panda's internal structures</title>
    <ns>0</ns>
    <id>2460</id>
    <redirect title="Advanced operations with Panda3D&#039;s internal structures" />
      <sha1>fi6pzjg45hwmztp75p72dw4war5y743</sha1>
    <revision>
      <id>6612</id>
      <timestamp>2010-02-07T04:39:38Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>[[Advanced operations with Panda's internal structures]] moved to [[Advanced operations with Panda3D's internal structures]]: Panda3D is the name of the engine; not Panda.</comment>
      <text xml:space="preserve" bytes="68">#REDIRECT [[Advanced operations with Panda3D's internal structures]]</text>
    </revision>
  </page>
  <page>
    <title>Advanced operations with Panda3D's internal structures</title>
    <ns>0</ns>
    <id>1778</id>
      <sha1>6xmu41hisj4u2n5pzese45vm2soje31</sha1>
    <revision>
      <id>6611</id>
      <timestamp>2010-02-07T04:39:38Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <minor/>
      <comment>[[Advanced operations with Panda's internal structures]] moved to [[Advanced operations with Panda3D's internal structures]]: Panda3D is the name of the engine; not Panda.</comment>
      <text xml:space="preserve" bytes="362">The following pages provide descriptions of Panda's internal representation of vertices and the renderable geometry that uses them, as well as instructions for directly reading or manipulating this data.

This is an advanced topic of Panda3D and is not necessary for ordinary model rendering and animation, but the advanced user may find this information useful.</text>
    </revision>
  </page>
  <page>
    <title>Advanced scripting techniques</title>
    <ns>0</ns>
    <id>2416</id>
      <sha1>p1bcgnmb9a664eormwrum15cluv7iwk</sha1>
    <revision>
      <id>6279</id>
      <timestamp>2009-10-25T16:20:00Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="191">The following pages describe some of the more advanced techniques when embedding your application in a web page, especially for using JavaScript to control and interact with your application.</text>
    </revision>
  </page>
  <page>
    <title>AlphaTestAttrib</title>
    <ns>0</ns>
    <id>2248</id>
    <redirect title="Alpha Testing" />
      <sha1>1vkrdu4qljo7o5j7ltz1d45sjxxqf2c</sha1>
    <revision>
      <id>5336</id>
      <timestamp>2008-04-05T18:12:47Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[Alpha Testing]]</comment>
      <text xml:space="preserve" bytes="27">#REDIRECT [[Alpha Testing]]</text>
    </revision>
  </page>
  <page>
    <title>Alpha Test Attribute</title>
    <ns>0</ns>
    <id>2213</id>
    <redirect title="Alpha Testing" />
      <sha1>1vkrdu4qljo7o5j7ltz1d45sjxxqf2c</sha1>
    <revision>
      <id>4893</id>
      <timestamp>2008-03-14T09:36:39Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <comment>[[Alpha Test Attribute]] moved to [[Alpha Testing]]: New naming convention: not putting the word 'Attribute' into every manual section that involves an Attrib.</comment>
      <text xml:space="preserve" bytes="27">#REDIRECT [[Alpha Testing]]</text>
    </revision>
  </page>
  <page>
    <title>Alpha Testing</title>
    <ns>0</ns>
    <id>2097</id>
      <sha1>e8v5eagb1exxcukd1aj34ptoenr3krm</sha1>
    <revision>
      <id>6219</id>
      <timestamp>2009-10-12T12:03:27Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>c++</comment>
      <text xml:space="preserve" bytes="1523">==Alpha Testing==

&lt;p&gt;The alpha test attribute governs whether or not a part of a node will be rendered based on the alpha value of its texture.  This is particularly useful for rendering complex geometry into the depth or stencil buffer with a textured card rather than explicitly creating the shapes.&lt;/p&gt;

&lt;p&gt;This test is different from rendering with respect to alpha transparency value.  If you set an alpha test attribute on a node which is rendering into the color buffer, you may be surprised by the result.  All pixels that pass the alpha test will be rendered just as if no test had been performed, including their appropriate transparency and pixels that fail the test will not be rendered at all.&lt;/p&gt;

&lt;p&gt;Remember to set your attribute's priority to override any other alpha test attributes inherited from higher in the scene graph.&lt;/p&gt;

&lt;p&gt;In the following example, we create an attribute that would cause objects to render only if their alpha value is below one quarter intensity.&lt;/p&gt;

[python]&lt;code python&gt;
lowPassFilter = AlphaTestAttrib.make(RenderAttrib.MLess,0.25)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
CPT(RenderAttrib) lowPassFilter = AlphaTestAttrib::make(PandaCompareFunc::M_less, 0.25);
&lt;/code&gt;[/cxx]

&lt;p&gt;And now, this attribute can be added to a node to enable the action.&lt;/p&gt;

[python]&lt;code python&gt;
nodePath.setAttrib(lowPassFilter)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
nodePath.set_attrib(lowPassFilter);
&lt;/code&gt;[/cxx]

&lt;h2&gt;Incomplete Section&lt;/h2&gt;

Note: this section is incomplete.  It will be updated soon.</text>
    </revision>
  </page>
  <page>
    <title>Animated Texture Maps</title>
    <ns>0</ns>
    <id>1079</id>
      <sha1>9d4ug0uvcwzmthcbfpzf7no33usuj0g</sha1>
    <revision>
      <id>4053</id>
      <timestamp>2007-02-13T18:17:33Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>should be removed!</comment>
      <text xml:space="preserve" bytes="206">Now to swap textures in Panda3D you just need to find that geomnode, in our case suppose it's &quot;face&quot;:
&lt;table class=&quot;code&quot;&gt;&lt;tr&gt;&lt;td&gt;
actorName.actor.find(&quot;**/face&quot;).setTexture(newTexture,1)
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</text>
    </revision>
  </page>
  <page>
    <title>Antialiasing</title>
    <ns>0</ns>
    <id>2220</id>
      <sha1>c8am3u2u9g0v3cf5w2vgrpkkk1a5k1c</sha1>
    <revision>
      <id>7313</id>
      <timestamp>2011-08-31T06:50:56Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="2217">&lt;h2&gt;Antialiasing&lt;/h2&gt;

[cxx]
It is recommended to include:
&lt;code cxx&gt;
#include &quot;antialiasAttrib.h&quot;
&lt;/code&gt;[/cxx]

The antialias attribute of a node controls what kind of antialiasing is to be applied to that node.  To choose one of the various forms of antialiasing,
invoke one of the following variants:

[python]
&lt;code python&gt;
np.setAntialias(AntialiasAttrib.MNone)
np.setAntialias(AntialiasAttrib.MPoint)
np.setAntialias(AntialiasAttrib.MLine)
np.setAntialias(AntialiasAttrib.MPolygon)
np.setAntialias(AntialiasAttrib.MMultisample)
np.setAntialias(AntialiasAttrib.MAuto)
&lt;/code&gt;[/python]

[cxx]
&lt;code cxx&gt;
nodePath.set_antialias(AntialiasAttrib::M_none);
nodePath.set_antialias(AntialiasAttrib::M_point);
nodePath.set_antialias(AntialiasAttrib::M_line);
nodePath.set_antialias(AntialiasAttrib::M_polygon);
nodePath.set_antialias(AntialiasAttrib::M_multisample);
nodePath.set_antialias(AntialiasAttrib::M_auto);
&lt;/code&gt;[/cxx]

In general, when rendering polygonal models, multisample antialiasing looks best. However, when rendering lines and points, it usually looks better to choose one of the specialized antialiasing modes.  The &lt;code&gt;MAuto&lt;/code&gt; setting
automatically selects the kind that usually works best for the
geometry in question.  Thus, if you want to enable antialiasing on the whole scene, just use:
[python]
&lt;code python&gt;
render.setAntialias(AntialiasAttrib.MAuto)
&lt;/code&gt;
[/python]
[cxx]
&lt;code cxx&gt;
window-&gt;get_render().set_antialias(AntialiasAttrib::M_auto);
&lt;/code&gt;
[/cxx]

In order for multisample antialiasing to work, you have to have multisample bits available in your framebuffer.  To request this, add:
&lt;code prc&gt;
framebuffer-multisample 1
multisamples 2
&lt;/code&gt;
to your Config.prc file.  Note that not all graphics cards have this capability.  You may also be able to request more multisamples, such as 4 or 8, depending on your graphics card.  If your card can provide additional samples, it produces a higher-quality antialiasing, at a small cost to render time.

The function &lt;code&gt;[func]clearAntialias[/func]&lt;/code&gt; can be used to remove the antialias setting.  The function &lt;code&gt;[func]setAntialias[/func]&lt;/code&gt; takes an optional priority
parameter, to control attribute overrides.</text>
    </revision>
  </page>
  <page>
    <title>AppRunner</title>
    <ns>0</ns>
    <id>2421</id>
      <sha1>c12wlzg2i4t29sb3a28hfpancbk01gu</sha1>
    <revision>
      <id>6284</id>
      <timestamp>2009-10-25T21:13:38Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="669">AppRunner is the Python class that supervises the launching of your application in a p3d file.  There is a global instance of AppRunner available in base.appRunner whenever your application is running as a p3d file.  In fact, this is a reliable way to test your run mode:

&lt;code python&gt;
if base.appRunner:
    print &quot;Running in a p3d file&quot;
else:
    print &quot;Running interactively&quot;
&lt;/code&gt;

All of your interaction with the web environment will go through base.appRunner.  There are several important members and methods of base.appRunner that facilitate communication with JavaScript and with the embedding web page.  They are described in detail in the following pages.</text>
    </revision>
  </page>
  <page>
    <title>Applying a texture to a Generated GeomNode</title>
    <ns>0</ns>
    <id>2680</id>
      <sha1>nubv3119x085crtubi9ddox6ts2wsmc</sha1>
    <revision>
      <id>7765</id>
      <timestamp>2012-05-29T03:41:13Z</timestamp>
      <contributor>
        <username>Eadthem</username>
        <id>561</id>
      </contributor>
      <comment>More progress.  source enterd with descriptions.  not finished yet</comment>
      <text xml:space="preserve" bytes="1851">First you will need a GeomNode, See [[Creating_the_GeomPrimitive_objects]] for how to make one.
We will start here

[cxx]&lt;code cxx&gt;
PT(GeomVertexData) vertexData;
vertexData = new GeomVertexData(&quot;name&quot;,GeomVertexFormat::get_v3c4t2(),Geom::UH_static);
&lt;/code&gt;[/cxx]
You will need to use a [[Creating_and_filling_a_GeomVertexData|format]] with t2 in it, This specifies that you will be giving [[Simple_Texturing|texture coordinates]].
[cxx]&lt;code cxx&gt;
GeomVertexWriter vertex, color, texcoord;
PT(GeomTriangles) primitives;
primitives = new GeomTriangles(Geom::UH_static);
	
vertex = GeomVertexWriter(vertexData,&quot;vertex&quot;);
color = GeomVertexWriter(vertexData,&quot;color&quot;);
texcoord = GeomVertexWriter(vertexData,&quot;texcoord&quot;);
&lt;/code&gt;[/cxx]

Enter the data for all vertices,
[cxx]&lt;code cxx&gt;
vertex.add_data3f(x, y, height);
color.add_data4f(0, 0, 1, 1);
texcoord.add_data2f(0, 0);
&lt;/code&gt;[/cxx]
and the primitave data.
[cxx]&lt;code cxx&gt;
primitives-&gt;add_vertices(0, 1, 3);
primitives-&gt;add_vertices(0, 3, 4);//3x3 grid of vertices
&lt;/code&gt;[/cxx]
[cxx]&lt;font size=&quot;2&quot;&gt;Protip, PointerTo&lt;T&gt; is the same as PT(T), but makes more sense for c++.&lt;/font&gt;[/cxx]
[cxx]&lt;code cxx&gt;
PointerTo&lt;Geom&gt; geom;
geom = new Geom(vertexData);//use vdata to create a geom
geom-&gt;add_primitive(primitives);// add the primitave to it

PointerTo&lt;GeomNode&gt; node;//make a PandaNode subtype GeomNode.
node = new GeomNode(&quot;gnode&quot;);
node-&gt;add_geom(geom);//add the geom data to it.

NodePath * geomPath = new NodePath(node,Thread::get_current_thread());//we are creating a NodePath to a GeomNode. This lets us assign a texture to it.

PointerTo&lt;Texture&gt; thisTexture = TexturePool::load_texture(&quot;texture/grass.jpg&quot;);//load the texture.
geomPath-&gt;set_texture(thisTexture);//and make this texture used for this geomPath/NodePath

return node;
&lt;/code&gt;[/cxx]


Work in progress.

ignore this page for now.</text>
    </revision>
  </page>
  <page>
    <title>Applying physics to a node</title>
    <ns>0</ns>
    <id>1780</id>
      <sha1>iags6itiu8p4b98rioeeevzaoxmvmn9</sha1>
    <revision>
      <id>7684</id>
      <timestamp>2012-03-09T09:38:12Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="3714">To apply forces to a physical object, collect them into a ForceNode and then apply them to the object. The ForceNode is a node that specifies the &quot;context&quot; of the force; i.e. the local coordinate transform that determines the direction of the force. Because ForceNodes are separate from ActorNodes, a ForceNode can be placed in a different portion of the model tree from the ActorNode to which the forces applies. This allows for forces to be applied indirectly to a model (such as wind sweeping across the scene, or a mechanical impulse from an appendage of the model) without having to do the calculations necessary to transform from the ActorNode's coordinates to the coordinates of the force's source.

To add a force to a physical object, add the force using either the addLinearForce method (for translational forces) or the addAngularForce method (for rotational forces):

&lt;code python&gt;
actorNode.addLinearForce(pusherForce)
actorNode.addAngularForce(spinnerForce)
&lt;/code&gt;

Conversely, forces can be removed using the corresponding remove calls:

&lt;code python&gt;
actorNode.removeLinearForce(pusherForce)
actorNode.removeAngularForce(spinnerForce)
&lt;/code&gt;

By default, linear forces don't factor in the mass of the object upon which they act (meaning they are more like accelerations). To factor in the mass of the object when applying the linear force, use the following call to enable mass-dependent calculations:

&lt;code python&gt;
pusherForce.setMassDependent(1)
&lt;/code&gt;

&lt;h2&gt;Example 1: Gravity&lt;/h2&gt;

To apply a gravitational pull to the &quot;jetpack guy&quot; from the previous example:

&lt;code python&gt;
gravityFN=ForceNode('world-forces')
gravityFNP=render.attachNewNode(gravityFN)
gravityForce=LinearVectorForce(0,0,-9.81) #gravity acceleration
gravityFN.addForce(gravityForce)

base.physicsMgr.addLinearForce(gravityForce)
&lt;/code&gt;

Since the gravitational force is relative to the entire world (and shouldn't change if, for example, the jetpack guy tumbles head-over-heels), the gravityForce vector was added to a ForceNode attached to render. So regardless of the orienation of the NodePath controlled by an, the force will always pull towards the bottom of the scene.

Since all objects in the scene should be affected by gravity, the force was added to the set of forces managed by the PhysicsManager itself. Since forces ignore the mass of the objects they act upon by default, this force will pull all objects towards the ground at standard gravitational acceleration. The next example shows how to apply a force to a single object.

&lt;h2&gt;Example 2: Rotary Thruster&lt;/h2&gt;

Here is another example of applying forces to objects and the way in which the ForceNode alters the effect:

&lt;code python&gt;
thruster=NodePath(&quot;thruster&quot;) # make a thruster for the jetpack 
thruster.reparentTo(jetpackGuy) 
thruster.setPos(0,-2,3)  

thrusterFN=ForceNode('jetpackGuy-thruster') # Attach a thruster force
thrusterFNP=thruster.attachNewNode(thrusterFN)
thrusterForce=LinearVectorForce(0,0,4000)
thrusterForce.setMassDependent(1)
thrusterFN.addForce(thrusterForce)

an.getPhysical(0).addLinearForce(thrusterForce)

thruster.setP(-45) # bend the thruster nozzle out at 45 degrees
&lt;/code&gt;

When this force is applied to the jetpack guy, it will push upwards and forwards. If the thruster's pitch and roll were controlled (say, by a joystick), then the jetpack could be moved around merely by changing the pitch and roll values; the ForceNode would inherit the orientation of the thruster and automatically change the direction it pushes.

The effect that this thruster force has upon the jetpack guy should be dependent upon the mass of the system, so the setMassDependent call is used to factor mass into the acceleration analysis.</text>
    </revision>
  </page>
  <page>
    <title>Artificial Intelligence (PANDAI)</title>
    <ns>0</ns>
    <id>2579</id>
      <sha1>2vroubwtu8yeqwetyqntz4ijiwfnag9</sha1>
    <revision>
      <id>7052</id>
      <timestamp>2011-01-25T08:28:36Z</timestamp>
      <contributor>
        <username>NNair</username>
        <id>515</id>
      </contributor>
      <text xml:space="preserve" bytes="665">
Panda3D is currently integrated with the AI library called &lt;b&gt;PandAI v1.0&lt;/b&gt;.

&lt;b&gt;PandAI&lt;/b&gt; is a simple AI library for Panda3D which provides functionality to create 'Artificially Intelligent' behavior in NPC (Non-Playable Characters) in games.

The PandAI library provides functionality for :

1. &lt;b&gt;Steering Behaviors&lt;/b&gt; : 

Seek, Flee, Pursue, Evade, Wander, Flock, Obstacle Avoidance, Path Following

2. &lt;b&gt;Path Finding&lt;/b&gt; :

This section is devoted to intelligently avoiding obstacles via the shortest path (calculated via the A* algorithm with Binary Heap optimizations). Its functionality and limitations are explained in more detail in its own section.</text>
    </revision>
  </page>
  <page>
    <title>Attaching Bodies using Joints</title>
    <ns>0</ns>
    <id>2288</id>
      <sha1>6n0irddm0bum1wjbgzfuw1wxh2b5t64</sha1>
    <revision>
      <id>7687</id>
      <timestamp>2012-03-09T09:51:04Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>new import system</comment>
      <text xml:space="preserve" bytes="4049">&lt;h2&gt;Joints&lt;/h2&gt;
In most situations, you won't have just solid box-shaped or cylinder-shaped models, but for example a human character has multiple body parts which can all move in a different way. If you would make the entire character one solid body, you wouldn't be able to move them independently of each other, and if you made every body part a separate solid body, all the body parts would fall off since they are not attached to each other. This is where Joints come in.

Joints are basically used to attach bodies to each other, or to attach a body to the environment. There are several different kinds of joints: OdeHingeJoint, OdeBallJoint, OdeSliderJoint, just to name a few. (Check the [http://www.panda3d.org/reference/1.7.2/python/namespacepanda3d.ode.php API Reference] for a more complete list).

&lt;h2&gt;OdeBallJoint example&lt;/h2&gt;
To explain how joints work, look at the following example:
&lt;code python&gt;from direct.directbase import DirectStart
from direct.directtools.DirectGeometry import LineNodePath
from panda3d.core import *
from panda3d.ode import *

# Load the smiley and frowney models
smiley = loader.loadModel(&quot;smiley.egg&quot;)
smiley.reparentTo(render)
smiley.setPos(-5, 0, -5)
frowney = loader.loadModel(&quot;frowney.egg&quot;)
frowney.reparentTo(render)
frowney.setPos(-12.5, 0, -7.5)

# Setup our physics world
world = OdeWorld()
world.setGravity(0, 0, -9.81)

# Setup the body for the smiley
smileyBody = OdeBody(world)
M = OdeMass()
M.setSphere(5000, 1.0)
smileyBody.setMass(M)
smileyBody.setPosition(smiley.getPos(render))
smileyBody.setQuaternion(smiley.getQuat(render))

# Now, the body for the frowney
frowneyBody = OdeBody(world)
M = OdeMass()
M.setSphere(5000, 1.0)
frowneyBody.setMass(M)
frowneyBody.setPosition(frowney.getPos(render))
frowneyBody.setQuaternion(frowney.getQuat(render))

# Create the joints
smileyJoint = OdeBallJoint(world)
smileyJoint.attach(smileyBody, None) # Attach it to the environment
smileyJoint.setAnchor(0, 0, 0)
frowneyJoint = OdeBallJoint(world)
frowneyJoint.attach(smileyBody, frowneyBody)
frowneyJoint.setAnchor(-5, 0, -5)

# Set the camera position
base.disableMouse()
base.camera.setPos(0, 50, -7.5)
base.camera.lookAt(0, 0, -7.5)

# We are going to be drawing some lines between the anchor points and the joints
lines = LineNodePath(parent = render, thickness = 3.0, colorVec = Vec4(1, 0, 0, 1))
def drawLines():
  # Draws lines between the smiley and frowney.
  lines.reset()
  lines.drawLines([((frowney.getX(), frowney.getY(), frowney.getZ()),
                    (smiley.getX(), smiley.getY(), smiley.getZ())),
                   ((smiley.getX(), smiley.getY(), smiley.getZ()),
                    (0, 0, 0))])
  lines.create()

# The task for our simulation
def simulationTask(task):
  # Step the simulation and set the new positions
  world.quickStep(globalClock.getDt())
  frowney.setPosQuat(render, frowneyBody.getPosition(), Quat(frowneyBody.getQuaternion()))
  smiley.setPosQuat(render, smileyBody.getPosition(), Quat(smileyBody.getQuaternion()))
  drawLines()
  return task.cont
  
drawLines()
taskMgr.doMethodLater(0.5, simulationTask, &quot;Physics Simulation&quot;)

run()&lt;/code&gt;
The part of the code that does the magic is this:
&lt;code python&gt;# Create the joints
smileyJoint = OdeBallJoint(world)
smileyJoint.attach(smileyBody, None) # Attach it to the environment
smileyJoint.setAnchor(0, 0, 0)
frowneyJoint = OdeBallJoint(world)
frowneyJoint.attach(smileyBody, frowneyBody)
frowneyJoint.setAnchor(-5, 0, -5)&lt;/code&gt;
This creates two joints, the first to attach the smiley to the environment, and the second to attach the frowney to the smiley. The &lt;code&gt;attach()&lt;/code&gt; method on the joint is used to set the two bodies that are attached; you can replace either argument with None to attach them to the environment.
The &lt;code&gt;[func]setAnchor[/func]&lt;/code&gt; method is used to set the anchor point for the joints.

At this image you can see how the joints are set up:
[[Image:BallJointExample2.jpg]]


&lt;h2&gt;Incomplete Section&lt;/h2&gt;

Note: this section is incomplete.  It will be updated soon.</text>
    </revision>
  </page>
  <page>
    <title>Attaching an Object to a Joint</title>
    <ns>0</ns>
    <id>1060</id>
      <sha1>a8l9uzwh9l1xhlzxrztw4lxqthdgvjy</sha1>
    <revision>
      <id>7624</id>
      <timestamp>2012-03-08T17:33:30Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="875">If an actor has a skeleton, then it is possible to locate one of the joints, and attach an object to that joint:

&lt;code python&gt;
myNodePath = actorNodePath.exposeJoint(None,&quot;modelRoot&quot;,&quot;Joint Name&quot;)
&lt;/code&gt;

This function returns a nodepath which is attached to the joint.  By reparenting any object to this nodepath, you can cause it to follow the movement of the joint.

The string &quot;modelRoot&quot; represents the name of the model node - the string &quot;modelRoot&quot; is usually the correct value.

The string &quot;Joint Name&quot; represents the name of the joint.  Typically it would be something like &quot;Femur&quot;, or &quot;Neck&quot;, or &quot;L Finger1&quot;.  This is usually set inside the modeling package.  For example, in MAX, each object in the scene has a name, including the bones.  If necessary, you can determine the joint names by scanning the egg file for strings like &lt;code&gt;&amp;lt;Joint&amp;gt; Femur&lt;/code&gt;.</text>
    </revision>
  </page>
  <page>
    <title>Audio Managers</title>
    <ns>0</ns>
    <id>2370</id>
      <sha1>j0thukemqr4on1q6s99ejs51jms2hrc</sha1>
    <revision>
      <id>5954</id>
      <timestamp>2009-07-12T19:01:58Z</timestamp>
      <contributor>
        <username>Chroipahtz</username>
        <id>297</id>
      </contributor>
      <text xml:space="preserve" bytes="1182">Sound effects and music in code are implemented as &lt;code&gt;AudioManager&lt;/code&gt; objects. You can access these audio managers with the following code:

&lt;code python&gt;
sfxMgr = base.sfxManagerList[0]
musicMgr = base.musicManager
&lt;/code&gt;

In &lt;code&gt;base&lt;/code&gt;, &lt;code&gt;sfxManagerList&lt;/code&gt; is a list of &lt;code&gt;AudioManager&lt;/code&gt; objects intended to be used for sound effects, and &lt;code&gt;musicManager&lt;/code&gt; is an &lt;code&gt;AudioManager&lt;/code&gt; object intended to be used for music.

Each &lt;code&gt;AudioManager&lt;/code&gt; object can have 16 different sounds cached at a given time. This value is actually set as the &lt;code&gt;audio-cache-limit&lt;/code&gt; in the panda config.prc (found in your install directory) and can be changed.

There are times where either sound effects, music, or both should be disabled and later enabled. These commands affect entire categories of sounds. Passing True or False in the last 2 functions will disable or enable the respective groups.

&lt;code python&gt;
base.disableAllAudio()
base.enableAllAudio()
base.enableMusic(True)
base.enableSoundEffects(True)
&lt;/code&gt;

Positional audio is implemented through a wrapper of these objects and is covered in the next section, [[3D Audio]].</text>
    </revision>
  </page>
  <page>
    <title>Automatic Texture Animation</title>
    <ns>0</ns>
    <id>1108</id>
      <sha1>j2cur2pfr4r0ell3ncitcfvpo1vw6xx</sha1>
    <revision>
      <id>7642</id>
      <timestamp>2012-03-08T18:08:13Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tag</comment>
      <text xml:space="preserve" bytes="2025">It's possible to generate a model that automatically rotates through a sequence of textures when it is in the scene graph, without having to run a special task to handle this.

To do this, use the &lt;code&gt;egg-texture-cards&lt;/code&gt; command-line utility.  This program will accept a number of texture filenames on the command line, and output an egg file that rotates through each texture at the specified frame rate:

&lt;pre class=&quot;codeblock&quot;&gt;
egg-texture-cards -o flip.egg -fps 30 explosion*.jpg
&lt;/pre&gt;

This actually creates a model with a different polygon for each frame of the texture animation.  Each polygon is put in a separate node, and all the nodes are made a child of a special node called a &lt;code&gt;SequenceNode&lt;/code&gt;.

The SequenceNode is a special node that only draws one of its children at a time, and it rotates through the list of children at a particular frame rate.  You can parent the model under render and it will automatically start animating through its textures.  If you need it to start at a particular frame, use something like this:

&lt;code python&gt;
flip = loader.loadModel('flip.egg')
flip.find('**/+SequenceNode').node().pose(startFrame)
flip.reparentTo(render)
&lt;/code&gt;

By default, all of the polygons created by &lt;code&gt;egg-texture-cards&lt;/code&gt; will have the same size.  This means that all of your textures must be the same size as well.  While this is a simple configuration, it may not be ideal for certain effects.  For instance, to animate an explosion, which starts small and grows larger, it would be better to use a small texture image on a small polygon when the image is small, and have a larger image on a larger polygon when it grows larger.  You can achieve this effect, with the -p parameter; specifying -p scales each frame's polygon in relation to the size of the corresponding texture.

&lt;pre class=&quot;codeblock&quot;&gt;
egg-texture-cards -o flip.egg -fps 30 -p 240,240 explosion*.jpg
&lt;/pre&gt;

There are several other parameters as well; &lt;code&gt;use egg-texture-cards -h&lt;/code&gt; for a complete list.</text>
    </revision>
  </page>
  <page>
    <title>Automatic Texture Coordinates</title>
    <ns>0</ns>
    <id>1193</id>
      <sha1>nmvgffuy92taign7k7hjajjgcslkurt</sha1>
    <revision>
      <id>60456</id>
      <timestamp>2015-01-16T22:18:42Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <text xml:space="preserve" bytes="9722">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

In addition to using texture coordinates that are built into the
model, it is also possible to generate texture coordinates at runtime.
Usually you would use this technique to achieve some particular
effect, such as projective texturing or environment mapping, but
sometimes you may simply want to apply a texture to a model that does
not already have texture coordinates, and this is the only way to do
that.

The texture coordinates generated by this technique are generated
on-the-fly, and are not stored within the model.  When you turn off
the generation mode, the texture coordinates cease to exist.

Use the following NodePath method to enable automatic generation of
texture coordinates:

&lt;syntaxhighlight lang=&quot;python&quot;&gt;
nodePath.setTexGen(TextureStage, texGenMode)
&lt;/syntaxhighlight&gt;

The texGenMode parameter specifies how the texture coordinates are to
be computed, and may be any of the following options.  In the list
below, &quot;eye&quot; means the coordinate space of the observing camera, and
&quot;world&quot; means world coordinates, e.g. the coordinate space of render,
the root of the scene graph.
&lt;table style=&quot;border-collapse: collapse&quot;&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot; style=&quot;border-top: 1px solid black; padding: 5pt&quot;&gt;&lt;code&gt;TexGenAttrib.MWorldPosition&lt;/code&gt;&lt;/td&gt;

&lt;td style=&quot;border-top: 1px solid black; padding: 5pt&quot;&gt;Copies the (x, y, z) position of each vertex, in world space, to the (u, v, w) texture coordinates.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot; style=&quot;border-top: 1px solid black; padding: 5pt&quot;&gt;&lt;code&gt;TexGenAttrib.MEyePosition&lt;/code&gt;&lt;/td&gt;

&lt;td style=&quot;border-top: 1px solid black; padding: 5pt&quot;&gt;Copies the (x, y, z) position of each vertex, in camera space, to the (u, v, w) texture coordinates.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot; style=&quot;border-top: 1px solid black; padding: 5pt&quot;&gt;&lt;code&gt;TexGenAttrib.MWorldNormal&lt;/code&gt;&lt;/td&gt;

&lt;td style=&quot;border-top: 1px solid black; padding: 5pt&quot;&gt;Copies the (x, y, z) lighting normal of each vertex, in world space, to the (u, v, w) texture coordinates.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot; style=&quot;border-top: 1px solid black; padding: 5pt&quot;&gt;&lt;code&gt;TexGenAttrib.MEyeNormal&lt;/code&gt;&lt;/td&gt;

&lt;td style=&quot;border-top: 1px solid black; padding: 5pt&quot;&gt;Copies the (x, y, z) lighting normal of each vertex, in camera space, to the (u, v, w) texture coordinates.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot; style=&quot;border-top: 1px solid black; padding: 5pt&quot;&gt;&lt;code&gt;TexGenAttrib.MEyeSphereMap&lt;/code&gt;&lt;/td&gt;

&lt;td style=&quot;border-top: 1px solid black; padding: 5pt&quot;&gt;Generates (u, v) texture coordinates based on the lighting normal and the view vector to apply a standard reflection sphere map.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot; style=&quot;border-top: 1px solid black; padding: 5pt&quot;&gt;&lt;code&gt;TexGenAttrib.MEyeCubeMap&lt;/code&gt;&lt;/td&gt;

&lt;td style=&quot;border-top: 1px solid black; padding: 5pt&quot;&gt;Generates (u, v, w) texture coordinates based on the lighting normal and the view vector to apply a standard reflection cube map.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot; style=&quot;border-top: 1px solid black; padding: 5pt&quot;&gt;&lt;code&gt;TexGenAttrib.MWorldCubeMap&lt;/code&gt;&lt;/td&gt;

&lt;td style=&quot;border-top: 1px solid black; padding: 5pt&quot;&gt;Generates (u, v, w) texture coordinates based on the lighting normal and the view vector to apply a standard reflection cube map.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot; style=&quot;border-top: 1px solid black; padding: 5pt&quot;&gt;&lt;code&gt;TexGenAttrib.MPointSprite&lt;/code&gt;&lt;/td&gt;

&lt;td style=&quot;border-top: 1px solid black; padding: 5pt&quot;&gt;Generates (u, v) texture coordinates in the range (0, 0) to (1, 1) for large points so that the full texture covers the square.  This is a special mode that should only be applied when you are rendering &lt;em&gt;sprites,&lt;/em&gt; special point geometry that are rendered as squares.  It doesn't make sense to apply this mode to any other kind of geometry.  Normally you wouldn't set this mode directly; let the [[Particle Renderers|SpriteParticleRenderer]] do it for you.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot; style=&quot;border-top: 1px solid black; border-bottom: 1px solid black; padding: 5pt&quot;&gt;&lt;code&gt;TexGenAttrib.MLightVector&lt;/code&gt;&lt;/td&gt;

&lt;td style=&quot;border-top: 1px solid black; border-bottom: 1px solid black; padding: 5pt&quot;&gt;Generates special (u, v, w) texture coordinates that represent the vector from each vertex to a particular Light in the scene graph, in each vertex's tangent space.  This mode requires that each vertex have a &lt;em&gt;tangent&lt;/em&gt; and a &lt;em&gt;binormal&lt;/em&gt; computed for it ahead of time; you also must specify the NodePath that represents the direction of the light.  Normally, you wouldn't set this mode directly either; use NodePath.setNormalMap(), or implement normal maps using programmable shaders.  This is now deprecated and may be removed soon.&lt;/td&gt;&lt;/tr&gt;

&lt;/table&gt;
Note that several of the above options generate 3-D texture
coordinates: (u, v, w) instead of just (u, v).  The third coordinate
may be important if you have a 3-D texture or a cube map (described
later), but if you just have an ordinary 2-D texture the extra
coordinate is ignored.  (However, even with a 2-D texture, you might
apply a 3-D transform to the texture coordinates, which would bring
the third coordinate back into the equation.)

Also, note that almost all of these options have a very narrow purpose;
you would generally use most of these only to perform the particular
effect that they were designed for.  This manual will discuss these
special-purpose TexGen modes in later sections, as each effect is
discussed; for now, you only need to understand that they exist, and
not worry about exactly what they do.

The mode that is most likely to have general utility is the first one:
&lt;code&gt;MWorldPosition&lt;/code&gt;.  This mode converts each vertex's (x, y, z) position
into world space, and then copies those three numeric values to the
(u, v, w) texture coordinates.  This means, for instance, that if you
apply a normal 2-D texture to the object, the object's (x, y) position
will be used to look up colors in the texture.

For instance, the teapot.egg sample model that ships with Panda has no
texture coordinates built in the model, so you cannot normally apply a
texture to it.  But you can enable automatic generation of texture
coordinates and then apply a texture:

&lt;code python&gt;
teapot = loader.loadModel('teapot.egg')
tex = loader.loadTexture('maps/color-grid.rgb')
teapot.setTexGen(TextureStage.getDefault(), TexGenAttrib.MWorldPosition)
teapot.setTexture(tex)
&lt;/code&gt; 

And you end up with something like this:

[[Image:Tex gen teapot xy.png|Teapot with a grid applied]]

You can use this in conjunction with a texture transform to further
manipulate the texture coordinates.  For instance, to rotate the
texture 90 degrees, you could do something like this:

&lt;code python&gt;
teapot.setTexTransform(TextureStage.getDefault(), TransformState.makeHpr(VBase3(0, 90, 0)))
&lt;/code&gt; 

[[Image:Tex gen teapot xz.png|Teapot with a grid applied, rotated]]

Finally, consider that the only two choices for the coordinate frame
of the texture coordinate generation are &quot;world&quot; and &quot;eye&quot;, for the
root NodePath and the camera NodePath, respectively.  But what if you
want to generate the texture coordinates relative to some other node,
say the teapot itself?  The above images are all well and good for a
teapot that happens to be situated at the origin, but suppose we want
the teapot to remain the same when we move it somewhere else in the
world?

If you use only &lt;code&gt;MWorldPosition&lt;/code&gt;, then when you change the teapot's
position, for instance by parenting it to a moving node, the teapot
will seem to move while its texture pattern stays in place--maybe not
the effect you had in mind.  What you probably intended was for the
teapot to take its texture pattern along with it as it moves around.
To do this, you will need to compute the texture coordinates in the
space of the teapot node, rather than in world space.

Panda3D provides the capability to generate texture coordinates in the
coordinate space of any arbitrary node you like.  To do this, use
&lt;code&gt;MWorldPosition&lt;/code&gt; in conjunction with Panda's &quot;texture projector&quot;, which
applies the relative transform between any two arbitrary NodePaths to
the texture transform; you can use it to compute the relative
transform from world space to teapot space, like this:

&lt;code python&gt;
teapot.setTexGen(TextureStage.getDefault(), TexGenAttrib.MWorldPosition)
teapot.setTexProjector(TextureStage.getDefault(), render, teapot)
&lt;/code&gt;

It may seem a little circuitous to convert the teapot vertices to world space to generate the texture coordinates, and then convert the texture coordinates back to teapot space again--after all, didn't they start out in teapot space?  It would have saved a lot of effort just to keep them there!  Why doesn't Panda just provide an &lt;code&gt;MObjectPosition&lt;/code&gt; mode that would convert texture coordinates from the object's native position?

That's a fair question, and &lt;code&gt;MObjectPosition&lt;/code&gt; would be a fine idea for a model as simple as the teapot, which is after all just one node.  But for more sophisticated models, which can contain multiple sub-nodes each with their own coordinate space, the idea of &lt;code&gt;MObjectPosition&lt;/code&gt; is less useful, unless you truly wanted each sub-node to be re-textured within its own coordinate space.  Rather than provide this feature of questionable value, Panda3D prefers to give you the ability to specify the particular coordinate space you had in mind, unambiguously.

Note that you &lt;i&gt;only&lt;/i&gt; want to call &lt;code&gt;setTexProjector()&lt;/code&gt; when you are using mode &lt;code&gt;MWorldPosition&lt;/code&gt;.  The other modes are generally computed from vectors (for instance, normals), not positions, and it usually doesn't makes sense to apply a relative transform to a vector.</text>
    </revision>
  </page>
  <page>
    <title>Auxiliary Bitplane Control</title>
    <ns>0</ns>
    <id>2221</id>
      <sha1>842c4cm3cwcivdv5yoe0y2jvv8gxg38</sha1>
    <revision>
      <id>7631</id>
      <timestamp>2012-03-08T17:47:02Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="1723">==Auxiliary Bitplane Control==

The framebuffer always contains a color bitplane and a depth bitplane.  It may also have a stencil bitplane or accumulation bitplane.  In addition, if it is a render-to-texture framebuffer, it may have &lt;i&gt;auxiliary bitplanes&lt;/i&gt;.  These auxiliary bitplanes can be used to store more or less
arbitrary user-defined data.

When per-pixel lighting is enabled via [[The Shader Generator|the shader generator]], the shader generator can be asked to produce extra data into the auxiliary bitplanes.  This is done by setting an AuxBitplaneAttrib:

&lt;code python&gt;
np.setAttrib(AuxBitplaneAttrib.make(bits))
&lt;/code&gt;

Where &lt;code&gt;bits&lt;/code&gt; is a set of bits indicating what should be written into
the auxiliary bitplanes.

Although the framebuffer's alpha channel is not technically an auxiliary bitplane.  However, since it is not generally used to store any data of value,
it can also be thought of as an auxiliary bitplane: a place to store
user-defined data.

When the shader generator is not enabled, this attrib has no effect.

&lt;h2&gt;Values That Can be Requested&lt;/h2&gt;

The following is a list of bits that can be passed to AuxBitplaneAttrib.make:

*&lt;b&gt;AuxBitplaneAttrib.ABOGlow&lt;/b&gt;: copy the glow map (aka self-illumination map) into the alpha channel of the framebuffer.  Usually this is a prelude to running a bloom filter over the scene.

*&lt;b&gt;AuxBitplaneAttrib.ABOAuxNormal&lt;/b&gt;: Store the camera-space normal of the polygon surface in the RGB channels of the first auxiliary bitplane.  This is often used to help detect edges in a cartoon inking filter.

*&lt;b&gt;AuxBitplaneAttrib.ABOAuxGlow&lt;/b&gt;: copy the glow map (aka self-illumination map) into the alpha channel of the first auxiliary bitplane.</text>
    </revision>
  </page>
  <page>
    <title>Backface Culling and Frontface Culling</title>
    <ns>0</ns>
    <id>2225</id>
      <sha1>bgx7qkc1iudylk8clguwxw8z61x2vom</sha1>
    <revision>
      <id>6254</id>
      <timestamp>2009-10-18T17:15:49Z</timestamp>
      <contributor>
        <username>Gogg</username>
        <id>389</id>
      </contributor>
      <text xml:space="preserve" bytes="3173">==Backface and Frontface Culling==

By default, Panda3D automatically culls (doesn't render) backfaces of
polygons.  In other words, the polygon acts like a one-way mirror: you
can see it from one side, but from the other side, it's see-through.
Backface culling is a very
useful performance optimization.  Without it, the 3D engine would have to
render the &lt;i&gt;inside surface&lt;/i&gt; of 3D models.  Since this surface is not
visible anyhow, this is entirely wasted work.  Since the surface area
of the inside is equal to the surface area of the outside, this would
roughly double the amount of work the video card has to do.  This is why
backface culling is enabled by default.

Interestingly, this means that if you move the camera inside of a
closed 3D model, you can usually see out.  This is actually pretty convenient
most of the time.

However, there are cases when you do want to be able to see backfaces.
There are also very rare cases when you &lt;i&gt;don't&lt;/i&gt; want to see front-faces.
Therefore, backface and frontface culling can be controlled.

Caution: inexperienced 3D modelers sometimes create models with the polygons
facing &lt;i&gt;inward&lt;/i&gt;: ie, the visible side of the polygon is on the inside
of the 3D model, and the see-through side is on the outside.  As a result,
the 3D model can look very weird - it can have holes, or it can look inside-out.
Turning off backface culling can sort of &quot;fix&quot; these models, at a heavy cost:
first, it makes them render half as fast, and second, it causes weird
lighting artifacts (because the video card is calculating the lighting
for the inside of the model, not the outside).  This is not a real solution
to bad 3D modeling: the only real fix is to make the 3D models correctly
in the first place.

In other words, don't alter the backface or frontface culling unless you're
using an algorithm that requires it, such as stencil shadows.

==Rendering Double-Sided==

There is a quick way to render a certain [[NodePath]] in your scene double-sided, which means no culling is performed at all and both sides are visible, without hassling with attribs:
[python]&lt;code python&gt;
nodePath.setTwoSided(True)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
nodePath.set_two_sided (true);
&lt;/code&gt;[/cxx]
If you want more advanced control over the culling you might want to look at the CullFaceAttrib:

==Controlling Backface and Frontface Culling==

There are three valid settings for culling:

[python]&lt;code python&gt;
nodePath.setAttrib(CullFaceAttrib.make(CullFaceAttrib.MCullNone))
nodePath.setAttrib(CullFaceAttrib.make(CullFaceAttrib.MCullClockwise))
nodePath.setAttrib(CullFaceAttrib.make(CullFaceAttrib.MCullCounterClockwise))
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
// Includes: &quot;cullFaceAttrib.h&quot;

nodePath.set_attrib(CullFaceAttrib::make(CullFaceAttrib::M_cull_none));
nodePath.set_attrib(CullFaceAttrib::make(CullFaceAttrib::M_cull_clockwise));
nodePath.set_attrib(CullFaceAttrib::make(CullFaceAttrib::M_cull_counter_clockwise));
&lt;/code&gt;[/cxx]

None means that all faces are visible, both back and front.  Clockwise is the default setting, it causes backfaces to be culled.  Counter-clockwise is the reverse setting, it causes frontfaces to be culled.</text>
    </revision>
  </page>
  <page>
    <title>Basic Performance Diagnostics</title>
    <ns>0</ns>
    <id>1727</id>
      <sha1>taef9lk6zfty5a0sb7bv2q1qjw2edno</sha1>
    <revision>
      <id>7710</id>
      <timestamp>2012-03-09T10:41:21Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="3777">&lt;h2&gt;Introductory Performance Diagnostics&lt;/h2&gt;

In Panda3D, the &quot;big gun&quot; of performance analysis is called &lt;i&gt;pstats&lt;/i&gt;.
This program gives you real-time diagnostic analysis of a running Panda3D
virtual world broken down into hundreds of different categories.

But sometimes, when you've just encountered a problem, you don't want
that much information.  Sometimes, you just want a simple question
answered, like &quot;how many meshes do I have,&quot; or &quot;is this a
fill-rate problem?&quot;  For simple questions like that, there are lots
of things you can do to get a quick-and-dirty answer.


&lt;h2&gt;The Frame-Rate Meter&lt;/h2&gt;

The frame-rate meter doesn't tell you why your program is running slow,
but it does have one important purpose: it's a lightweight and unobtrusive
utility that you can leave on throughout the entire development process.
This is valuable in that it gives you immediate feedback when you do
something inefficient.
To turn on the frame-rate meter, put this in your config file:

&lt;pre class=&quot;codeblock&quot;&gt;
show-frame-rate-meter #t
&lt;/pre&gt;

Or, if you want to have it set at run-time:
&lt;code python&gt;
base.setFrameRateMeter(True)
&lt;/code&gt;


&lt;h2&gt;The Scene Analyzer&lt;/h2&gt;

If a scene needs to be rendered and has multiple nodes, Panda has to send each node to the graphics hardware as a separate batch of polygons (because the nodes might move independently, or have different state changes on them). Modern graphics hardware hasn't made any improvements recently in handling large numbers of batches, just in handling large numbers of polygons per batch. So if a scene is composed of a large number of nodes with a small number of polygons per node, the frame rate will suffer. This problem is not specific to Panda; any graphics engine will have the same problem.  The problem is due to the nature of the PC and the AGP bus. 

For example, though your graphics card may claim it can easily handle 100,000 polygons, this may be true in practice only if all of those polygons are sent in one batch--that is, just a single [[Geom]].  If, however, your scene consists of 1,000 nodes with 100 polygons each, it may not have nearly as good a frame rate.

To inspect performance the NodePath.analyze() method is extremely useful.  For example:
 
&lt;code python&gt;
render.analyze() 
&lt;/code&gt; 

The response is printed to the command window.  It may look something like this: 

&lt;pre class=&quot;codeblock&quot;&gt; 
371 total nodes (including 43 instances). 
21 transforms; 16% of nodes have some render attribute. 
205 Geoms, with 94 GeomVertexDatas, appear on 133 GeomNodes. 
21665 vertices, 21573 normals, 21557 texture coordinates. 
35183 triangles: 
   3316 of these are on 662 tristrips (5.00906 average tris per strip). 
   0 of these are on 0 trifans. 
   31867 of these are independent triangles. 
0 lines, 0 points. 
99 textures, estimated minimum 326929K texture memory required. 
&lt;/pre&gt; 

For a scene with many static nodes there exists a workaround. 

If a scene is composed of many static objects, for example boxes, and the intent of all of these boxes to just sit around and be part of the background, or to move as a single unit, they can flattened together into a handful of nodes (or even one node). To do this, parent them all to the same node, and use: 

&lt;code python&gt;
node.flattenStrong() 
&lt;/code&gt;

One thing that flattenStrong() won't touch is geometry under a ModelRoot or ModelNode node. Since each egg or bam file loads itself up under a ModelRoot node, the proper way to handle this is to get rid of that node first to make the geometry from multiple different egg files to be flattened together. This can be done with the following:

&lt;code python&gt;
modelRoot = loader.loadModel('myModel.egg') 
newModel = NodePath('model') 
modelRoot.getChildren().reparentTo(newModel) 
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>Billboard Effects</title>
    <ns>0</ns>
    <id>944</id>
      <sha1>k4e128wttx6tidmq49nlu2sangd84hd</sha1>
    <revision>
      <id>6180</id>
      <timestamp>2009-09-28T13:06:38Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>c++ translation</comment>
      <text xml:space="preserve" bytes="2518">A billboard is a special effect that causes a node to rotate automatically to face the camera, regardless of the direction from which the camera is looking.  It is usually applied to a single textured polygon representing a complex object such as a tree.  Judicious use of billboards can be an effective way to create a rich background environment using very few polygons.

Panda indicates that a node should be billboarded to the camera by storing a BillboardEffect on that node.  Normally, you do not need to create a BillboardEffect explicitly, since there are a handful of high-level methods on NodePath that will create one for you:

[python]&lt;code python&gt;
myNodePath.setBillboardAxis()
myNodePath.setBillboardPointWorld()
myNodePath.setBillboardPointEye()
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
myNodePath.set_billboard_axis();
myNodePath.set_billboard_point_world();
myNodePath.set_billboard_point_eye();
&lt;/code&gt;[/cxx]

Each of the above calls is mutually exclusive; there can be only one kind of billboard effect on a node at any given time.  To undo a billboard effect, use:

[python]&lt;code python&gt;
myNodePath.clearBillboard()
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
myNodePath.clear_billboard();
&lt;/code&gt;[/cxx]

The most common billboard type is an axial billboard, created by the &lt;code&gt;setBillboardAxis()&lt;/code&gt; method.  This kind of billboard is constrained to rotate around its vertical axis, so is usually used to represent objects that are radially symmetric about the vertical axis (like trees).

Less often, you may need to use a point billboard, which is free to rotate about any axis.  There are two varieties of point billboard.  The world-relative point billboard always keeps its up vector facing up, i.e. along the Z axis, and is appropriate for objects that are generally spherical and have no particular axis of symmetry, like clouds.  The eye-relative point billboard, on the other hand, always keeps its up vector towards the top of the screen, no matter which way the camera tilts, and is usually used for text labels that float over objects in the world.  

There are several more options available on a BillboardEffect, but these are rarely used.  If you need to take advantage of any of these more esoteric options, you must create a BillboardEffect and apply it to the node yourself:

&lt;code python&gt;
myEffect = BillboardEffect.make(
  upVector = vec3,
  eyeRelative = bool,
  axialRotate = bool,
  offset = float,
  lookAt = nodepath,
  lookAtPoint = point3
)
myNodePath.node().setEffect(myEffect)
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>Billboards</title>
    <ns>0</ns>
    <id>2266</id>
    <redirect title="Billboard Effects" />
      <sha1>nao8tclpoy3c5i42v0pz25lhr8jo7yg</sha1>
    <revision>
      <id>5453</id>
      <timestamp>2008-09-03T18:15:34Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[Billboard Effects]]</comment>
      <text xml:space="preserve" bytes="31">#REDIRECT [[Billboard Effects]]</text>
    </revision>
  </page>
  <page>
    <title>Bitmask Example</title>
    <ns>0</ns>
    <id>953</id>
      <sha1>cinl0edgv9j15eor48nlxpp8pgg33v1</sha1>
    <revision>
      <id>7678</id>
      <timestamp>2012-03-08T20:20:50Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>new import system</comment>
      <text xml:space="preserve" bytes="6785">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

[python]
&lt;p&gt;Here is a short example of using bitmasks to selectively test collisions against different object in the scene:&lt;/p&gt;

&lt;code python&gt;
from direct.showbase.ShowBase import ShowBase
from direct.showbase.DirectObject import DirectObject
from direct.gui.OnscreenText import OnscreenText, TextNode
from panda3d.core import CollisionTraverser
from panda3d.core import CollisionHandlerQueue, CollisionNode, BitMask32
from panda3d.core import CollisionPlane, CollisionSphere, CollisionRay
from panda3d.core import Plane, Vec3, Point3


class World(DirectObject):

    def __init__(self):
        # Create a traverser that Panda3D will automatically use every frame.
        base.cTrav = CollisionTraverser()
        # Create a handler for the events.
        self.collHandler = CollisionHandlerQueue()
        
        # Define a few bitmasks for use.
        # Teaching the concepts of bitmasks is out of the scope of this sample.
        # This just shows a practical application of bitmasks.
        goodMask = BitMask32(0x1)
        badMask = BitMask32(0x2)
        floorMask = BitMask32(0x4)
        
        # Make a list of different combinations of the masks for later use.
        # We will switch between these masks later on.
        self.maskList = [
            [&quot;floor&quot;, floorMask],
            [&quot;smiley&quot;, goodMask],
            [&quot;frowney&quot;, badMask],
            [&quot;characters&quot;, goodMask | badMask],
            [&quot;smiley and floor&quot;, goodMask | floorMask],
            [&quot;frowney and floor&quot;, badMask | floorMask],
            [&quot;all&quot;, floorMask | goodMask | badMask]
        ]
        # This keeps track of where we are in the dictionary.
        self.maskPosition = 0
        
        # First we create a floor collision plane.
        floorNode = render.attachNewNode(&quot;Floor NodePath&quot;)
        # Create a collision plane solid.
        collPlane = CollisionPlane(Plane(Vec3(0, 0, 1), Point3(0, 0, 0)))
        # Call our function that creates a nodepath with a collision node.
        floorCollisionNP = self.makeCollisionNodePath(floorNode, collPlane)
        # Get the collision node the Nodepath is referring to.
        floorCollisionNode = floorCollisionNP.node()
        # The floor is only an into object, so just need to set its into mask.
        floorCollisionNode.setIntoCollideMask(floorMask)
        
        # Create a collision sphere. Since the models we'll be colliding
        # are basically the same we can get away with just creating one
        # collision solid and adding the same solid to both collision nodes.
        collSphere = CollisionSphere(0, 0, 0, 1.5)
        
        # Make a smiley.
        smiley = loader.loadModel('smiley')
        smiley.reparentTo(render)
        smiley.setPos(-3, 3, 3)
        smiley.setName(&quot;Smiley&quot;)
        smileyCollisionNP = self.makeCollisionNodePath(smiley, collSphere)
        # Like with the floor plane we need to set the into mask.
        # Here we shortcut getting the actual collision node.
        smileyCollisionNP.node().setIntoCollideMask(goodMask)
        
        # Make a frowney.
        frowney = loader.loadModel('frowney')
        frowney.reparentTo(render)
        frowney.setPos(-3, 3, 7)
        frowney.setName(&quot;Frowney&quot;)
        frowneyCollisionNP = self.makeCollisionNodePath(frowney, collSphere)
        # Use the the Nodepath.setCollideMask() function to set the into mask.
        # setCollideMask() sets the into mask of all child nodes to the given mask.
        frowneyCollisionNP.setCollideMask(badMask)
        # Note that we don't call setCollideMask() from frowney because this
        # will turn the frowney mesh into a collision mesh which is unwanted.
        
        # Note that we didn't set a from collide mask for previous objects
        # since we're not adding them to the traverser as from objects.
        
        # Make a collision ray that passes through all of the objects.
        self.pointerNode = render.attachNewNode(&quot;Main Collider&quot;)
        self.pointerNode.setPos(-3, 3, 10)
        # Create a ray collision solid that points downwards.
        raySolid = CollisionRay(0, 0, 0, 0, 0, -1)
        mainCollisionNP = self.makeCollisionNodePath(self.pointerNode, raySolid)
        self.mainCollisionNode = mainCollisionNP.node()
        # Set a from collide mask for this ray so that we can selectively
        # collide against the other objects.
        self.mainCollisionNode.setFromCollideMask(self.maskList[self.maskPosition][1])
        base.cTrav.addCollider(mainCollisionNP, self.collHandler)
        
        # Set up the camera.
        base.disableMouse()
        base.camera.setPos(20, -20, 5)
        base.camera.lookAt(0, 0, 5)
        # Debug mode for collision traversers; shows collisions visually.
        base.cTrav.showCollisions(render)
        
        # Setup the title text.
        collideText = self.maskList[self.maskPosition][0]
        self.title = OnscreenText(text=&quot;Colliding with %s&quot; % (collideText),
                                  mayChange=True,
                                  pos=(0.3, 0),
                                  align=TextNode.ALeft,
                                  fg=(1, 1, 1, 1))
        OnscreenText(text=&quot;Press space to change collision mask&quot;,
                     pos=(0, 0.8),
                     fg=(1,1,1,1))
        
        # Set space to change the from collision mask of the collision ray.
        base.accept(&quot;space&quot;, self.switchCollisionMask)
    
    def makeCollisionNodePath(self, nodepath, solid):
        '''
        Creates a collision node and attaches the collision solid to the
        supplied NodePath. Returns the nodepath of the collision node.
        
        '''
        # Creates a collision node named after the name of the NodePath.
        collNode = CollisionNode(&quot;%s c_node&quot; % nodepath.getName()) 
        collNode.addSolid(solid)
        collisionNodepath = nodepath.attachNewNode(collNode)
        # Show the collision node, which makes the solids show up.
        collisionNodepath.show()
        
        return collisionNodepath
    
    def switchCollisionMask(self):
        if self.maskPosition == len(self.maskList) - 1:
            self.maskPosition = 0
        else:
            self.maskPosition += 1
        # Changing the from collide mask of objects allows you to selectively
        # test collisions against different objects.
        self.mainCollisionNode.setFromCollideMask(self.maskList[self.maskPosition][1])
        self.title.setText(&quot;Colliding with %s&quot; % (self.maskList[self.maskPosition][0]))

ShowBase()
world = World()
run()
&lt;/code&gt;
[[Image:CollisionBitmasks.png]]
[/python]

[cxx]
&lt;h2&gt;Incomplete Section&lt;/h2&gt;

&lt;p&gt;Note: this section is incomplete. It will be updated soon.&lt;/p&gt;
[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Bloom</title>
    <ns>0</ns>
    <id>2244</id>
    <redirect title="Common Image Filters" />
      <sha1>hmlzgft01uoo6gg50rhkwjf3pq8cz5l</sha1>
    <revision>
      <id>5320</id>
      <timestamp>2008-03-25T08:58:12Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[Common Image Filters]]</comment>
      <text xml:space="preserve" bytes="34">#REDIRECT [[Common Image Filters]]</text>
    </revision>
  </page>
  <page>
    <title>BoundingVolume</title>
    <ns>0</ns>
    <id>2267</id>
      <sha1>pzlyv33dxdcy6861uko1y94ehu2nzem</sha1>
    <revision>
      <id>5547</id>
      <timestamp>2008-10-15T12:00:36Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>there actually is getTightBounds</comment>
      <text xml:space="preserve" bytes="2534">A [http://panda3d.net/apiref.php?page=BoundingVolume BoundingVolume] is a solid enclosing all the geometry of a node and its children that is used for culling and collision detection.  (If the BoundingVolume for a node is not visible, there is no need to render that node.)  Panda will generate &quot;bounds&quot; for each node automatically by creating BoundingVolumes.

Panda defines the &quot;bounds&quot; of a node to be a geometric bounding volume, of an arbitrary shape (but usually a sphere) that is no smaller than its enclosed geometry. The [http://panda3d.net/apiref.php?page=PandaNode#getBounds getBounds()] method returns an acceptable bounding volume.  It is indeed no smaller than the enclosed geometry. This makes it suitable for use in culling operations and so on.  To check the size of the bounding volume, use [http://panda3d.net/apiref.php?page=NodePath#showBounds showBounds()].

Note that this BoundingVolume is not the smallest possible.  For instance, a sphere of radius 1 has a BoundingSphere with radius 1.73205.  Panda doesn't bother going through all the trouble it would take to compute a tight spherical bounds, because the loose bounds that it computes is good enough for Panda's needs. The extra performance gain you'd get for having a tighter culling bounds isn't worth the effort it would take to compute it.

Although it doesn't use it, Panda can create a tighter bounding box. This &quot;tight&quot; bounding box is the smallest axis-aligned box that is no smaller than its enclosed geometry. Thus, it satisfies its definition as a &quot;tight&quot; bounds, because you will not find a tighter bounding volume that is also a box.  You can retrieve the bounding box using the getTightBounds method. This box can be shown with [http://panda3d.net/apiref.php?page=NodePath#showTightBounds showTightBounds()]

Further tweaking of the bounding volume used must be done manually
&lt;ul&gt;
&lt;li&gt; If all you care about is Panda's usage of bounding boxes, you can create a BoundingVolume for the node you want and tell Panda to use that one with [http://panda3d.net/apiref.php?page=PandaNode#setFinal setFinal(1)].
&lt;br&gt;&lt;br&gt;
&lt;i&gt;
node.setBounds(BoundingVolume(...))&lt;br&gt;
node.setFinal(1)
&lt;/i&gt;
&lt;br&gt;&lt;br&gt;This will tell Panda to stop calculating bounds and use the one you gave it.
&lt;br&gt;&lt;br&gt;&lt;/li&gt;
&lt;li&gt; If you want to have a node with a manual bounding box set for your own nefarious purposes, set the bounds at the bottom: on the Geom within a GeomNode.  This will propagate upwards, assuming there are no other nodes with bounding volumes above it.
&lt;/li&gt;
&lt;/ul&gt;</text>
    </revision>
  </page>
  <page>
    <title>Building Panda3D from Source</title>
    <ns>0</ns>
    <id>1069</id>
      <sha1>qqpcn0ffk6trf5pshidko43cbn4zjnm</sha1>
    <revision>
      <id>60512</id>
      <timestamp>2015-06-03T18:39:20Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <text xml:space="preserve" bytes="776">Note that in the past, it was very difficult to build Panda3D.  Things have improved. It is now fairly straightforward to download and compile panda. In particular, this is a sensible thing to do if you wish to add some functionality to panda.

To avoid possible consistency problems, the documentation for building the source is included with the source, not in the manual.  Download a source package from the panda website, then look at a file called README.md.  It contains instructions for invoking the build system, makepanda.

A link to the latest build instructions can be found here:
https://github.com/panda3d/panda3d/blob/master/README.md

While building you'll get a list of not found dependencies. Further descriptions of those can be found here: [[Dependencies]].</text>
    </revision>
  </page>
  <page>
    <title>Building Panda from Source</title>
    <ns>0</ns>
    <id>2466</id>
    <redirect title="Building Panda3D from Source" />
      <sha1>0kwbhzgo76fjabv28r2755p624fsk94</sha1>
    <revision>
      <id>6624</id>
      <timestamp>2010-02-07T04:43:23Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>[[Building Panda from Source]] moved to [[Building Panda3D from Source]]: Panda3D is the name of the engine; not Panda.</comment>
      <text xml:space="preserve" bytes="42">#REDIRECT [[Building Panda3D from Source]]</text>
    </revision>
  </page>
  <page>
    <title>Building Panda from Source Windows</title>
    <ns>0</ns>
    <id>2239</id>
    <redirect title="Tutorial: Compiling the Panda 3D Source on Windows" />
      <sha1>cyqmbv3s13h5dz2cgxyyfueu38l0x9i</sha1>
    <revision>
      <id>5299</id>
      <timestamp>2008-03-17T04:20:10Z</timestamp>
      <contributor>
        <username>Rninne</username>
        <id>168</id>
      </contributor>
      <comment>[[Building Panda from Source Windows]] moved to [[Tutorial: Compiling the Panda 3D Source on Windows]]: missing link</comment>
      <text xml:space="preserve" bytes="64">#REDIRECT [[Tutorial: Compiling the Panda 3D Source on Windows]]</text>
    </revision>
  </page>
  <page>
    <title>Building a Self-Extracting EXE using packpanda</title>
    <ns>0</ns>
    <id>2308</id>
    <redirect title="Building an installer using packpanda" />
      <sha1>iuk60lkbwcd8v2jej4t4r8kcr98d6ps</sha1>
    <revision>
      <id>5657</id>
      <timestamp>2008-12-15T21:36:15Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>[[Building a Self-Extracting EXE using packpanda]] moved to [[Building an installer using packpanda]]: now also works on linux</comment>
      <text xml:space="preserve" bytes="51">#REDIRECT [[Building an installer using packpanda]]</text>
    </revision>
  </page>
  <page>
    <title>Building a standalone EXE using packpanda</title>
    <ns>0</ns>
    <id>1269</id>
    <redirect title="Building a Self-Extracting EXE using packpanda" />
      <sha1>7o25wgeb4yjb3qwofvhar4wd1lxx7ag</sha1>
    <revision>
      <id>2548</id>
      <timestamp>2005-11-18T20:16:07Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <comment>Building a standalone EXE using packpanda moved to Building a Self-Extracting EXE using packpanda</comment>
      <text xml:space="preserve" bytes="61">#REDIRECT [[Building a Self-Extracting EXE using packpanda]]
</text>
    </revision>
  </page>
  <page>
    <title>Building an installer using packpanda</title>
    <ns>0</ns>
    <id>1268</id>
      <sha1>9qeqcl8v0ptaok76klbu1b0x4a2ltb2</sha1>
    <revision>
      <id>7718</id>
      <timestamp>2012-03-09T10:56:03Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>better code tags</comment>
      <text xml:space="preserve" bytes="8031">Note: In version 1.6.0, support was added for Linux. Before this version, you will only be able to use packpanda on a windows system.

Packpanda is a utility that lets you create an automatic self-extracting installer for a Panda3D game. On Linux, it is capable of creating an .rpm or .deb package. On Windows, it creates an installation wizard, that will look like this:

&lt;p align=&quot;center&quot;&gt; [[Image:packpanda1.jpg]] &lt;/p&gt;

When the installation is done, the end-user will find your game in his start menu:

&lt;p align=&quot;center&quot;&gt; [[Image:packpanda2.jpg]] &lt;/p&gt;

The end-user doesn't need to have a copy of panda.  He doesn't even need to know that he is using panda.  He just installs the game and plays it.

&lt;b&gt;Files that your Game should Contain&lt;/b&gt;

Before you pack up your game, you need to put all of your game files into a single directory (which may have as many subdirectories as you desire).  This directory will be packed up and shipped to the user, along with the panda runtime system.  Your game directory needs to contain several files:


&lt;i&gt;main.py&lt;/i&gt;.  This is your main program.  When the user clicks on the start-menu entry for the game, this is the file that will get executed.

&lt;i&gt;installer.bmp&lt;/i&gt;.  Windows only. This image will appear on the installer screen.   If present, it must be a 164x314 windows BMP file.  This file is not required.

&lt;i&gt;license.txt&lt;/i&gt;.  This is your game's software license.  The file, if present, must be plain ascii.  The game's license will appear inside the installer, and will also be copied to the game's installation directory.  Of course, your license only covers the code that you wrote, not panda itself, which is covered by the panda license.  The license file is not required.

&lt;i&gt;icon.ico&lt;/i&gt;.  Windows only. This is your game's icon, which will appear in the start menu.  If you don't supply an icon, the panda icon will be used instead.  This file is not required.  

&lt;b&gt;Packing up your Game&lt;/b&gt;

The command to pack up your game is &quot;packpanda&quot;, and you must specify the &quot;--dir&quot; command line option to tell it the name of the directory containing your game.  Packpanda will immediately analyze your game and print out a status report:

&lt;p align=&quot;center&quot;&gt; [[Image:packpanda3.jpg]] &lt;/p&gt;

In this example, packpanda has inferred that the name of the game is &quot;Airblade,&quot; based on the directory name.  On Windows, it will install the game into &quot;C:\Airblade&quot;, and to add the start menu folder &quot;Airblade&quot;.  It plans to call the installer &quot;Airblade.exe&quot; (append .rpm or .deb for Linux). Later, we will tell you how to override some of these defaults.

As you can see, packpanda is looking inside the game directory for the files mentioned above: main.py, installer.bmp, icon.ico, and license.txt.  It notes that some of those files are &quot;missing&quot;, which is not a problem.  The only file that is required is main.py.

Packpanda can clean up your source tree before shipping it.  When doing so, packpanda never modifies your original copy of the game.  Instead, it copies the game to a temporary directory, as seen above.

&lt;b&gt;Automatically generating BAM and PYC files while Packing&lt;/b&gt;

Packpanda can optionally create BAM and PYC files and ship them to the end-user. To ask it to do so, use the following command-line options;

&lt;pre class &quot;codeblock&quot;&gt;
packpanda --bam   # Generate and ship BAM files
packpanda --pyc   # Generate and ship PYC files
&lt;/pre&gt;

These command line options do &lt;i&gt;not&lt;/i&gt; remove the corresponding EGG and PY files from the distribution.  If you wish to remove EGG and PY files, you need to use the --rmext option, documented below.

When packpanda generates a BAM or PYC file, it puts it in the same directory as the corresponding EGG or PY file.  If an EGG file contains a texture path, then the generated BAM will contain a &lt;i&gt;relative&lt;/i&gt; texture path that is relative to the game's root directory.  Packpanda makes sure that your game's root directory ends up on the model path.

&lt;b&gt;EGG Verification and PY Verification&lt;/b&gt;

Packpanda will check all of your EGG and PY files to make sure that they compile correctly.  It checks EGG files by running them through egg2bam.  It checks PY files by running the python compiler on them.  If any file fails, the game will not be packed.

In fact, this is related to the --bam and --pyc options mentioned earlier.  In fact, packpanda always generates bam and pyc files.  However, if you do not specify the --bam and --pyc options, then these files will be generated, verified, and then discarded.  The effect of the --bam and --pyc options is to cause these files to be shipped to the end-user.

&lt;b&gt;Preloading the Model Cache&lt;/b&gt;

If your distribution includes EGG files, and if you choose not to remove those using --rmext egg, then panda will convert them to BAM files at install time.  This is a somewhat time consuming process, it makes the install take longer.  If you want to avoid this, do not distribute EGG files --- instead, distribute BAM files, as explained above.

&lt;b&gt;Stripping Files from the Distribution&lt;/b&gt;

Often, your master copy of a game contains files that should not be shipped to the end-user.  For situations like this, packpanda contains command-line options to strip out unnecessary files:

&lt;pre class &quot;codeblock&quot;&gt;
packpanda --rmdir dir  # Strip all directories with given name
packpanda --rmext ext  # Strip all files with given extension
&lt;/pre&gt;

These options are particularly useful in several common situations:

&lt;i&gt;To remove CVS directories&lt;/i&gt;: packpanda --rmdir CVS

&lt;i&gt;To ship BAM instead of EGG&lt;/i&gt;: packpanda --bam --rmext egg

&lt;i&gt;To ship PYC instead of PY&lt;/i&gt;: packpanda --pyc --rmext py

&lt;b&gt;Changing the Game's Name&lt;/b&gt;

Normally, packpanda infers the game's name to be the same as the directory name.  That isn't always convenient, especially when the game has a long name.  The following command line option allows you to tell packpanda the name of the game:

&lt;pre class &quot;codeblock&quot;&gt;
packpanda --name &quot;Evil Space Monkeys of The Planet Zort&quot;
&lt;/pre&gt;

This string will show up in a number of places: in particular, throughout the installation dialogs, and in the start menu.

&lt;b&gt;Version Numbers&lt;/b&gt;

If you wish, you can assign your game a version number using this command line option:

&lt;pre class &quot;codeblock&quot;&gt;
packpanda --version X.Y.Z  # Assign a version number
&lt;/pre&gt;

The only thing this does is to add &quot;X.Y.Z&quot; to the install directory and to the start menu item.  That, in turn, makes it possible for two versions of the same game to coexist on a machine without conflict.

&lt;b&gt;Compression Speed&lt;/b&gt;

On Windows, packpanda uses a very good compression algorithm, but it's excruciatingly slow to compress.  You can specify this command line option to make it go faster, at the cost of compression effectiveness: (not available on Linux)

&lt;pre class &quot;codeblock&quot;&gt;
packpanda --fast  # Quick but not so great compression
&lt;/pre&gt;

&lt;b&gt;Moving Beyond Packpanda&lt;/b&gt;

Packpanda has a lot of limitations.  However, packpanda is actually a front end to more powerful systems. On Linux, it uses the system tools dpkg-deb and rpmbuild. On Windows, it uses NSIS, the &quot;Nullsoft Scriptable Install System.&quot;  NSIS is incredibly powerful, and very flexible, but unfortunately rather complicated to use.  Packpanda hides all that complexity from you, but unfortunately, in so doing, it limits your options.

If you find yourself outgrowing packpanda, one sensible thing to do would be to learn how to use those systems directly.  This is an easy transition to make.  The first step is to simply watch packpanda in action.  It will show you all of the commands it is executing.  You can then copy those commands into a batch file.  If you run that batch file, you're executing those base tools directly.

Once you have direct control over NSIS, you can begin editing the NSIS command-line options and the NSIS configuration file (packpanda.nsi).  Of course, to do so, you'll need to first read the NSIS manual (available on the web).  From that point forward, you have unlimited flexibility.</text>
    </revision>
  </page>
  <page>
    <title>Building and hosting your own packages</title>
    <ns>0</ns>
    <id>2409</id>
      <sha1>r9ow1d72oxmx6g78wk5n4r46v4zlx0v</sha1>
    <revision>
      <id>6266</id>
      <timestamp>2009-10-20T23:58:25Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="1392">Putting your entire application into a p3d file is a useful way to distribute small applications, but there are times when you need to distribute your code a little more intelligently.  Large applications may need to be divided into several smaller pieces for download at runtime; or you might have a large C++-based library that you want to make available to several different applications, without having to re-download it for each one.

For these purposes, you should consider using packages.  A package has several advantages over a simple p3d file:

* It can be downloaded on demand, either automatically at startup, or during runtime if desired.  

* One package can be downloaded once and shared by multiple p3d files.

* Packages will be cached in the user's Panda3D directory.  (p3d files, on the other hand, are saved in the browser cache only, where there may be less space.)

* Patching can be used to automatically update a package with a new version, so that your users need download only the incremental changes, instead of having to completely redownload the package at every change.

* There can be a different version of a package for each hardware/OS platform that you wish to support.  This is the easiest way to provide multiplatform support with C++-based applications.

On the other hand, setting up packages requires a little more work than simply building a p3d file.</text>
    </revision>
  </page>
  <page>
    <title>Building multiplatform packages</title>
    <ns>0</ns>
    <id>2415</id>
      <sha1>fu6hb1k2k559fz96xoecxnvrq33wca3</sha1>
    <revision>
      <id>6971</id>
      <timestamp>2010-11-10T17:25:06Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>mention pmerge</comment>
      <text xml:space="preserve" bytes="1517">When your packages include some compiled C++ code, including dll's or exe's, you will need to produce a different version package for each operating system/hardware platform that you wish to support.

By default, ppackage will detect when a package includes platform-specific files such as dll's, and will automatically write the platform string into the package specification.  This allows you to build the same package on multiple different platforms, and build a different version for each platform.  All of the versions can be stored in the same output directory and hosted at the same host URL.

Each time you run ppackage, it is designed to add its contents to an existing directory (or create a new one).  It assumes that the output directory represents the complete and current package contents at the time you started.

In order to build multiple packages with different platforms, you will probably need to run ppackage on different machines, one at a time, and direct them all to populate the same output directory.  This means either that your output directory should be a shared volume, or you will have to copy the entire output directory from one machine to another between invocations of ppackage.  (I find that rsync is a particularly good tool for copying entire directory structures efficiently, but there are many tools that do this in different ways.)

You can also use ppackage to create several different output directories, and merge those output directories into one using the pmerge utility.</text>
    </revision>
  </page>
  <page>
    <title>Building patches</title>
    <ns>0</ns>
    <id>2473</id>
      <sha1>nlp4mr8qmwidn1qoh3dz5phow8eqta7</sha1>
    <revision>
      <id>6671</id>
      <timestamp>2010-02-09T10:01:35Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <text xml:space="preserve" bytes="3294">One of the key advantages to Panda's package system is that any updates you make to a package are automatically downloaded and installed by users.  You don't need to do anything special for this to work: simply rebuild a new package using the ppackage tool with the latest contents, using the -i parameter to point ppackage to your existing install directory.  This will generate new package data and update the contents.xml file accordingly.  When you then copy this install directory to your webserver host, p3d files that reference your package will automatically download and install the new contents for that package before they start to run.

This will mean all of your users will have to redownload the entire package file, which may be a large download.  As a convenience to your users (and to relieve bandwidth burden on your servers), you may wish to provide &lt;em&gt;patches&lt;/em&gt; instead.  This works on the assumption that most of the package contents are not changing from one release to the next, and it allows your users who already have the previous version of a package to download only the changes necessary between the previous version and the current version, which is often a much smaller download and will save considerable time and bandwidth.

To enable this, you simply run &quot;ppatcher -i /my/install/dir&quot;, where /my/install/dir is your install directory that you have already populated with ppackage.

The first time you run ppatcher on a particular install directory, it prepares that directory for future patches, and declares the current revision number &quot;rev 1&quot;.  You may then use ppackage to build new versions of the packages in that install directory.

The second and later times you run ppatcher, it builds patches from the last-patched version to the current version now visible in the install directory.  Each time you run ppatcher, any packages in the install directory with changes since the last ppatcher will be patched and the current revision number will be incremented.

Thus, you should run ppatcher each time you are ready to make a formal release of your modified code.  This will allow the users to download the minimal patches necessary to receive the latest code.

You may release intermediate versions for testing purposes without running ppatcher.  If you do, users who visit your servers will have to download the entire file again, even if they already have a previous version installed.  This way, these users can test your changes and report success or failure; you can continue to make new releases without running ppatcher and allow your users to continue to test them.  Then, when you are satisfied that the release is ready for the world, you can run ppatcher to formalize it.

We don't recommend running ppatcher for each intermediate release, because each time you run ppatcher, a new patch file is added to the version chain.  This patch file will then forever be a part of the version chain (until it is eventually aged out).  Users who have an older version of the package will have to download and apply &lt;em&gt;all&lt;/em&gt; patch files in the chain in order to update to the latest version.  If there are many intermediate patch files in the chain, this process will be slower and involve more bandwidth than if there are only a few patch files.</text>
    </revision>
  </page>
  <page>
    <title>Bullet Character Controller</title>
    <ns>0</ns>
    <id>2613</id>
      <sha1>n85bjesdr5e1od8btoc0mf3os4cbjea</sha1>
    <revision>
      <id>60511</id>
      <timestamp>2015-05-21T12:22:03Z</timestamp>
      <contributor>
        <username>Fireclaw</username>
        <id>22865</id>
      </contributor>
      <minor/>
      <comment>Fix spelling errors</comment>
      <text xml:space="preserve" bytes="5389">Bullet comes with a simple character controller already included. A character controller is a class intended to provide a simple way of controlling a player (or NPC) object the way we are used to from many first-person-shooters or role-playing-games. Achieving satisfying results for character movement is usually a difficult thing when using &quot;physicals&quot;, e. g. rigid bodies. The solution is to use so-called &quot;kinematic&quot; objects, that is objects which don't respond to forces, and instead get moved by pushing/turning them around by hand.

Notice: The module panda3d.bullet doesn't implement it's own character controller. It simple exposes the character controller which comes with the Bullet physics engine. This character controller is still in an early stage, and it lacks a few features. In particular, Bullet does not implement a proper interaction between dynamic bodies and the character controller.



==Setup==

The following code will first create a shape with total height of 1.75 units and total width of 0.8 units. We have to subtract twice the radius from the total height in order to get the length of the cylindrical part of the capsule shape.

[python]&lt;code python&gt;from panda3d.bullet import BulletCharacterControllerNode
from panda3d.bullet import BulletCapsuleShape
from panda3d.bullet import ZUp

height = 1.75
radius = 0.4
shape = BulletCapsuleShape(radius, height - 2*radius, ZUp)

playerNode = BulletCharacterControllerNode(shape, 0.4, 'Player')
playerNP = self.worldNP.attachNewNode(playerNode)
playerNP.setPos(-2, 0, 14)
playerNP.setH(45)
playerNP.setCollideMask(BitMask32.allOn())

world.attachCharacter(playerNP.node())&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
float height = 1.75;
float radius = 0.4;

PT(BulletCapsuleShape) c_shape = new BulletCapsuleShape(radius, height -2 * radius);
controller = new BulletCharacterControllerNode(c_shape, 0.4f, name.c_str());
physicsWorld-&gt;attach_character(controller);

NodePath cha_np = window-&gt;get_render().attach_new_node(controller);
cha_np.set_pos(-2, 0, 14);
cha_np.set_h(45);
cha_np.set_collide_mask(mask1);&lt;/code&gt;[/cxx]

==Moving==

Now that we have a character controller within our scene we need to control it's movement. The following code snippet shows one way of moving the character controller by keyboard input. Of course a character controller representing a NPC (non-player character) would not read the keyboard state but have the linear velocity (&lt;code&gt;speed&lt;/code&gt;) and the angular velocity (&lt;code&gt;omega&lt;/code&gt;) computed by some kind of AI algorithm.

[python]&lt;code python&gt;
  def processInput(self):
    speed = Vec3(0, 0, 0)
    omega = 0.0

    if inputState.isSet('forward'): speed.setY( 3.0)
    if inputState.isSet('reverse'): speed.setY(-3.0)
    if inputState.isSet('left'):    speed.setX(-3.0)
    if inputState.isSet('right'):   speed.setX( 3.0)
    if inputState.isSet('turnLeft'):  omega =  120.0
    if inputState.isSet('turnRight'): omega = -120.0

    self.player.setAngularMovement(omega)
    self.player.setLinearMovement(speed, True)&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
void characterMove (std::vector&lt;bool&gt; *KeyMap) {
        LVecBase3 speed = LVecBase3(0, 0, 0);
        float omega = 0.0;

        if (KeyMap-&gt;at(MOVE_FORARD)) { speed.set_y (3.0); }
        if (KeyMap-&gt;at(MOVE_REVERSE)) { speed.set_y (-3.0); }
        if (KeyMap-&gt;at(MOVE_LEFT)) { speed.set_x (-3.0); }
        if (KeyMap-&gt;at(MOVE_RIGHT)) { speed.set_x (3.0); }
        if (keyMap-&gt;at(TURN_LEFT)) { omege = 120.0; }
        if (keyMap-&gt;at(TURN_RIGHT)) { omega = -120.0 } 

        controller-&gt;set_linear_movement(speed, true);
        controller-&gt;set_angular_movemen(omega);
}&lt;/code&gt;[/cxx]

==Jumping==

Next we want to make the character controller jump. The following code snippet shows a sample method which will make the character jump. We could for example call this method when the player presses a specific key.

After setting the maximum jump height and the initial upward speed we need to trigger the jump using the [python]&lt;code python&gt;doJump()&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;do_jump()&lt;/code&gt;[/cxx] method.

[python]&lt;code python&gt;
  def doJump(self):
    self.player.setMaxJumpHeight(5.0)
    self.player.setJumpSpeed(8.0)
    self.player.doJump()&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
void do_jump(void ) {
    controller-&gt;set_max_jump_height(5.0)
    controller-&gt;set_jump_speed(8.0)
    controller-&gt;do_jump()
}
&lt;/code&gt;[/cxx]

By the way: we can check if the character controller is airborne using the method [python]&lt;code python&gt;self.player.isOnGround()&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;controller-&gt;is_on_ground()&lt;/code&gt;[/cxx]

==Crouching==

Finally we want the character to crouch or duck. To achieve this we simply change the scale of the character's collision shape. Here in this example we reduce the vertical dimension to 60 percent (0.6) when crouching, while the normal vertical scale is 1.0. We don't change the horizontal scales.

Since we have the visual node of the player reparented to the character controller node it will change it's scale too automatically.

[python]&lt;code python&gt;
    self.crouching = False

  def doCrouch(self):
    self.crouching = not self.crouching
    sz = self.crouching and 0.6 or 1.0

    self.player.getShape().setLocalScale(Vec3(1, 1, sz))

    self.playerNP.setScale(Vec3(1, 1, sz) * 0.3048)
    self.playerNP.setPos(0, 0, -1 * sz)&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Bullet Collision Filtering</title>
    <ns>0</ns>
    <id>2609</id>
      <sha1>34bzmw8c50pfdor4cr3nljs8tbrghpf</sha1>
    <revision>
      <id>59560</id>
      <timestamp>2014-05-02T10:46:46Z</timestamp>
      <contributor>
        <username>AWhetter</username>
        <id>21759</id>
      </contributor>
      <minor/>
      <comment>/* Group Assignment */ Made the third sentence make more sense now that this page also describes the group masks algorithm</comment>
      <text xml:space="preserve" bytes="5448">By default all Bullet collision objects collide with all other Bullet collision objects. Here the term &quot;collision objects&quot; referns to objects which are derived from &lt;code&gt;BulletBodyNode&lt;/code&gt;, namely &lt;code&gt;BulletRigidBodyNode&lt;/code&gt;, &lt;code&gt;BulletGhostNode&lt;/code&gt;, &lt;code&gt;BulletSoftBodyNode&lt;/code&gt;.

Bullet collision objects won't collide with visible geometry, that is objects of type GeomNode!

Sometime we need more control over who collides with whom. This can be achieved by setting up collision filtering properly. Collision filtering is done using bitmasks, which get assigned to every collision object.


==Bit Masks==

Bullet makes use of the regular Panda3D collide masks, which are instances of &lt;code&gt;BitMask32&lt;/code&gt;. Two objects collide if the two masks have at least one bit in common. The following example shows a selection of common ways to set up a bit mask. For more information please refer to the manual page on [[Collision Bitmasks]].

[python]&lt;code python&gt;from panda3d.core import BitMask32

mask1 = BitMask32.allOn()
mask2 = BitMask32.allOff()
mask3 = BitMask32.bit(2)
mask4 = BitMask32.bit(5)
mask5 = BitMask32(0x3)&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;#include &quot;panda3d/bitMask.h&quot;

BitMask32 mask1 = BitMask32::all_on();
BitMask32 mask2 = BitMask32::all_off();
BitMask32 mask3 = BitMask32::bit(2);
BitMask32 mask4 = BitMask32::bit(5);
BitMask32 mask5 = BitMask32(0x3);
&lt;/code&gt;[/cxx]

Given the above bit masks we would get the following results for collision:

&lt;pre&gt;mask1 and mask2 = false
mask1 vs. mask3 = true
mask3 vs. mask4 = false
mask3 vs. mask5 = true
mask4 vs. mask5 = false&lt;/pre&gt;

==Group Masks==

Sometimes BitMasks alone are not flexible enough to represent the relationships between a large number of groups of objects. Group masks are similar to bit masks in that each object belongs to a group, but instead of collisions only occurring between objects that belong to the same group, collision relationships are instead represented by a collision matrix. This means that a larger number of groups can be represented in the same 32 bits of a &lt;code&gt;BitMask32&lt;/code&gt;.

To use group mask filtering instead of the default bit mask filtering mentioned above, set the &lt;code&gt;bullet-filter-algorithm&lt;/code&gt; configuration variable to &lt;code&gt;groups-mask&lt;/code&gt;. The default collision matrix is set to only collide objects that are in the same group. As you make changes, the collision matrix is kept symmetrical along the line of the diagonal for you. So if you set Group 0 to collide with Group 1, then Group 1 will also automatically collide with Group 0.

The following collision matrix shows that the only collisions that occur are between group 1 and group 2, and group 2 with itself.
{| class=&quot;wikitable&quot; border=&quot;1&quot; cellpadding=&quot;5&quot; cellspacing=&quot;0&quot;
! 
! Group 0
! Group 1
! Group 2
|-
| Group 0
| False
| False
| False
|-
| Group 1
| -
| False
| True
|-
| Group 2 
| -
| -
| True
|}

The following code segment shows how this matrix is represented in code.
[python]&lt;code python&gt;
# Group 0 never collides
world.setGroupCollisionFlag(0, 0, False)
world.setGroupCollisionFlag(0, 1, False)
world.setGroupCollisionFlag(0, 2, False)

# Group 1 only collides with Group 2
world.setGroupCollisionFlag(1, 1, False)
world.setGroupCollisionFlag(1, 2, True)

# Group 2 only collides with itself
world.setGroupCollisionFlag(2, 2, True)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
// Group 0 never collides
physics_world-&gt;set_group_collision_flag(0, 0, false);
physics_world-&gt;set_group_collision_flag(0, 1, false);
physics_world-&gt;set_group_collision_flag(0, 2, false);

// Group 1 only collides with Group 2
physics_world-&gt;set_group_collision_flag(1, 1, false);
physics_world-&gt;set_group_collision_flag(1, 2, true);

// Group 2 only collides with itself
physics_world-&gt;set_group_collision_flag(2, 2, true);
&lt;/code&gt;[/cxx]

==Group Assignment==
The example below shows a typical setup for a rigid body. Only the last line of the code block is new. Here we set the collide mask which specifies which collision groups the object belongs to.

[python]&lt;code python&gt;shape = shape = BulletBoxShape(Vec3(0.5, 0.5, 0.5))

body = BulletRigidBodyNode('Body')
body.addShape(shape)

world.attachRigidBody(body)

bodyNP = self.worldNP.attachNewNode(body)
bodyNP.setPos(0, 0, -1)
bodyNP.setCollideMask(mask1) # Here we set the collision mask&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
BulletBoxShape *box_shape = new BulletBoxShape(LVecBase3f(0.5, 0.5, 0.5));
BulletRigidBodyNode *body_rigid_node = new BulletRigidBodyNode(&quot;Body&quot;);
body_rigid_node-&gt;add_shape(box_shape);
physics_world-&gt;attach_rigid_body(box_rigid_node);

NodePath np_body = window-&gt;get_render().attach_new_node(box_rigid_node);
np_body.set_pos(0, 0, 2);
np_body.set_collide_mask(mask1); // Here we set the collision mask
&lt;/code&gt;[/cxx]

PandaNodes have two kinds of collide masks, a &quot;from&quot; collide mask and an &quot;into&quot; collide mask. Panda3D's internal collision system requires both masks set, but when using Bullet physics only the &quot;into&quot; collide mask is used. The following line is an alternate way to set the collide mask:

[python]&lt;code python&gt;bodyNP.node().setIntoCollideMask(mask)&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
np_box.node()-&gt;set_into_collide_mask(mask);
&lt;/code&gt;[/cxx]

This way of setting collide masks can be used for rigid bodies and ghost objects. Soft body collisions (and soft body vs. rigid body collisions) are more complex. Please see the manual pages about soft body configuration for details.</text>
    </revision>
  </page>
  <page>
    <title>Bullet Collision Shapes</title>
    <ns>0</ns>
    <id>2608</id>
      <sha1>19aokp0hw3x1r318z652bvpcapcuk69</sha1>
    <revision>
      <id>7751</id>
      <timestamp>2012-04-10T03:06:11Z</timestamp>
      <contributor>
        <username>EdmundosTown</username>
        <id>570</id>
      </contributor>
      <text xml:space="preserve" bytes="12110">On the previous page we have been introduced to Bullet basics. Two simple collision shapes - a box and a plane - have been used in this simple script. This page will now introduce more collison shapes provided by Bullet, starting with primitive shapes and then moving on to more complex ones.

Primitive shapes:
* Sphere Shape
* Plane Shape
* Box Shape
* Cylinder Shape
* Capsule Shape
* Cone Shape

Complex shapes:
* Compound Shape
* Convex Hull Shape
* Triangle Mesh Shape
* Heightfield Shape
* Soft Body Shape
* Multi Sphere Shape
* Convex Point Cloud Shape


==Sphere Shape==

The most basic collision shape, a sphere with radius radius. The sphere is centered around it's origin.

[python]&lt;code python&gt;from panda3d.bullet import BulletSphereShape
radius = 0.5
shape = BulletSphereShape(radius)&lt;/code&gt;[/python]
[cxx]
&lt;code cxx&gt;
#include &quot;panda3d/bulletSphereShape.h&quot;
...
double radius = 0.5;
BulletSphereShape *sphere_shape = new BulletSphereShape(radius);
&lt;/code&gt;
[/cxx]


==Plane Shape==

Another primitive collision shape, an infinite plane. To create a plane you have to pass both the plane's normal vector (Vec3(nx, ny, nz)) and the plane constant (d, which is the distance of the plane's origin. Planes can only be used for static objects.

[python]&lt;code python&gt;from panda3d.bullet import BulletPlaneShape
normal = Vec3(0, 0, 1)
d = 0
shape = BulletPlaneShape(normal, d)&lt;/code&gt;[/python]
[cxx]
&lt;code cxx&gt;
#include &quot;panda3d/bulletPlaneShape.h&quot;
...
LVecBase3f normal(0, 0, 1);
double d = 1;
BulletPlaneShape *floor_shape = new BulletPlaneShape(normal, d);
...
&lt;/code&gt;
[/cxx]


==Box Shape==

A box-shaped primitive collision shape. To create a box you have to pass a vector with the half-extents (Vec3(dx, dx, dx)). The full extents of the box will be twice the half extents, e. g. from -dx to +dx on the local x-axis.

[python]&lt;code python&gt;from panda3d.bullet import BulletBoxShape
dx = 0.5
dy = 0.5
dz = 1.0
shape = BulletBoxShape(Vec3(dx, dy, dz))&lt;/code&gt;[/python]
[cxx]
&lt;code cxx&gt;
#include &quot;panda3d/bulletBoxShape.h&quot;
...
double dx = 0.5;
double dy = 0.5;
double dz = 0.5;
BulletBoxShape *box_shape = new BulletBoxShape(LVecBase3f(dx,dy,dz));
&lt;/code&gt;[/cxx]


==Cylinder Shape==

A primitive collision shape which is represents a cylinder. We can create a cylinder shape by either passing it's radius, height and cylinder axis, or by passing a vector with half extents and the cylinder axis. The following example creates two cylinder shapes, both with radius 0.5 and height 1.4.

[python]&lt;code python&gt;from panda3d.bullet import BulletCylinderShape
radius = 0.5
height = 1.4
shape1 = BulletCylinderShape(radius, height, ZUp)
shape2 = BulletCylinderShape(Vec3(radius, 0, 0.5*height), ZUp)&lt;/code&gt;[/python]
[cxx]
&lt;code cxx&gt;
#include &quot;panda3d/bulletCylinderShape.h&quot;
...
double radius = 0.5;
double height = 1.4;
BulletCylinderShape *cylinder_shape_one = new BulletCylinderShape(radius, height);
&lt;/code&gt;[/cxx]


==Capsule Shape==

A primitive collision shape which is a &quot;capped&quot; cylinder. &quot;Capped&quot; means that there are half-spheres at both ends, unlike the real cylinder which has flat ends. Capsule shapes are a good choice for character controllers, since they are fast, symmetrical, and allow smooth movement over steps.

To create a capsule shape we have to pass the capsule's radius, the height of the cylindrical part, and the up-axis. The total height of the capsule will be the height of the cylindrical part, plus twice the radius.

[python]&lt;code python&gt;from panda3d.bullet import BulletCapsuleShape
radius = 0.5
height = 1.0
shape = BulletCapsuleShape(radius, height, ZUp)&lt;/code&gt;[/python]
[cxx]
&lt;code cxx&gt;
#include &quot;panda3d/bulletCapsuleShape.h&quot;
...
double radius = 0.5;
double height = 1.0;
BulletCapsuleShape *capsule_shape = new BulletCapsuleShape(radius, height);
&lt;/code&gt;[/cxx]


==Cone Shape==

Again a primitive collision shape, which represents a cone. We have to pass the radius of the circular base of the cone, and it's height.

[python]&lt;code python&gt;from panda3d.bullet import BulletConeShape
radius = 0.6
height = 1.0
shape = BulletConeShape(radius, height, ZUp)&lt;/code&gt;[/python]
[cxx]
&lt;code cxx&gt;
#include &quot;panda3d/bulletConeShape.h&quot;
...
double radius = 0.6;
double height = 1.0;
BulletConeShape *cone_shape = new BulletConeShape(radius, height);
&lt;/code&gt;[/cxx]


==Compound Shape==

Compound shapes are assemblies made up from two or more individual shapes. For example you could create a collision shape for a table from five box shapes. One &quot;flat&quot; box for the table plate, and four &quot;thin&quot; ones for the table legs.

The Panda3D Bullet module has no specialized class for compound shapes. It automatically creates a compound shape if more than one shape is added to a body node.

The following code snippet will create such a compound shape, resembling the before mentioned table.

[python]&lt;code python&gt;shape1 = BulletBoxShape(Vec3(1.3, 1.3, 0.2))
shape2 = BulletBoxShape(Vec3(0.1, 0.1, 0.5))
shape3 = BulletBoxShape(Vec3(0.1, 0.1, 0.5))
shape4 = BulletBoxShape(Vec3(0.1, 0.1, 0.5))
shape5 = BulletBoxShape(Vec3(0.1, 0.1, 0.5))

bodyNP.node().addShape(shape1, TransformState.makePos(Point3(0, 0, 0.1)))
bodyNP.node().addShape(shape2, TransformState.makePos(Point3(-1, -1, -0.5)))
bodyNP.node().addShape(shape3, TransformState.makePos(Point3(-1, 1, -0.5)))
bodyNP.node().addShape(shape4, TransformState.makePos(Point3(1, -1, -0.5)))
bodyNP.node().addShape(shape5, TransformState.makePos(Point3(1, 1, -0.5)))&lt;/code&gt;[/python]
[cxx]
&lt;code cxx&gt;
BulletBoxShape *shape1 = new BulletBoxShape(LVecBase3f(0.1,0.1,0.5));
BulletBoxShape *shape2 = new BulletBoxShape(LVecBase3f(0.1,0.1,0.5));
BulletBoxShape *shape3 = new BulletBoxShape(LVecBase3f(0.1,0.1,0.5));
BulletBoxShape *shape4 = new BulletBoxShape(LVecBase3f(0.1,0.1,0.5));
BulletBoxShape *shape5 = new BulletBoxShape(LVecBase3f(0.1,0.1,0.5));

np_body.node().add_shape (shape1, TransformState::make_pos(LPoint3f(0,0,0.1)));
np_body.node().add_shape (shape2, TransformState::make_pos(LPoint3f(-1,-1,-0.5)));
np_body.node().add_shape (shape3, TransformState::make_pos(LPoint3f(-1,1,-0.5)));
np_body.node().add_shape (shape4, TransformState::make_pos(LPoint3f(1,-1,-0.5)));
np_body.node().add_shape (shape5, TransformState::make_pos(LPoint3f(1,1,-0.5)));
&lt;/code&gt;[/cxx]


==Convex Hull Shape==

The first of the non-primitive collision shapes. A good analogy for a convex hull is an elastic membrane or balloon under pressure which is placed around a given set of vertices. When released the membrane will assume the shape of the convex hull. Convex hull shapes should be used for dynamic objects, if it is not possible to find a good approximation of the objects shape using collision primitives.

Convex hull shapes can be created is several ways:

[python]&lt;code python&gt;from panda3d.bullet import BulletConvexHullShape

# Add each vertex separately
shape1 = BulletConvexHullShape()
shape1.addPoint(Point3(1, 1, 2))
shape1.addPoint(Point3(0, 0, 0))
shape1.addPoint(Point3(2, 0, 0))
shape1.addPoint(Point3(0, 2, 0))
shape1.addPoint(Point3(2, 2, 0))

# Add several vertices with a single call
shape2 = BulletConvexHullShape()
shape2.addArray([
  Point3(1, 1, 2),
  Point3(0, 0, 0),
  Point3(2, 0, 0),
  Point3(0, 2, 0),
  Point3(2, 2, 0),
  ])

# Add all vertices which can be found in a Geom object
geomNodes = loader.loadModel(path).findAllMatches('**/+GeomNode')
geomNode = geomNodes.getPath(0).node()
geom = geomNode.getGeom(0)
shape3 = BulletConvexHullShape()
shape3.addGeom(geom)&lt;/code&gt;[/python]
[cxx]
&lt;code cxx&gt;
#include &quot;panda3d/bulletConvexHullShape.h&quot;
...

// Add each vertex separately
BulletConvexHullShape *convex_hull_shape = new BulletConvexHullShape();
convex_hull_shape-&gt;add_point(LPoint3f(1, 1, 2));
convex_hull_shape-&gt;add_point(LPoint3f(0, 0, 0));
convex_hull_shape-&gt;add_point(LPoint3f(2, 0, 0));
convex_hull_shape-&gt;add_point(LPoint3f(0, 2, 0));
convex_hull_shape-&gt;add_point(LPoint3f(2, 2, 0));
&lt;/code&gt;
[/cxx]


==Triangle Mesh Shape==

Another non-primitive collision shape. A triangle mesh shape is similar to the convex hull shape, except that it is not restricted to convex geometry - it can contain concave parts. A typical use case for triangle mesh shapes is the static geometry of a game level. However, it is possible to use triangle mesh shapes for dynamic object too. We have to explicitly tell Bullet if we want to static or dynamic triangle mesh shape at the time where the shape is created.

To create a triangle mesh shape we first have to create a triangle mesh object. The following example will create a simple quad made up from two triangles.

[python]&lt;code python&gt;from panda3d.bullet import BulletTriangleMeshShape
p0 = Point3(-10, -10, 0)
p1 = Point3(-10, 10, 0)
p2 = Point3(10, -10, 0)
p3 = Point3(10, 10, 0)
mesh = BulletTriangleMesh()
mesh.addTriangle(p0, p1, p2)
mesh.addTriangle(p1, p2, p3)
shape = BulletTriangleMeshShape(mesh, dynamic=False)&lt;/code&gt;[/python]
[cxx]
&lt;code cxx&gt;
#include &quot;panda3d/bulletTriangleMesh.h&quot;
...
LPoint3f * points_array[4] = {
    new LPoint3f(-10, -10, 0),
    new LPoint3f(-10, 10, 0),
    new LPoint3f(10, -10, 0),
    new LPoint3f(10, 10, 0),
};

BulletTriangleMesh *triangle_mesh = new BulletTriangleMesh();
triangle_mesh-&gt;add_triangle(*points_array[0], *points_array[1], *points_array[2]);
triangle_mesh-&gt;add_triangle(*points_array[1], *points_array[2], *points_array[3]);

BulletTriangleMeshShape *triangle_mesh_shape = new BulletTriangleMeshShape(triangle_mesh, false);
&lt;/code&gt;[/cxx]

we can use a convenience method to add all triangles from a Geom object with one method call. The geom will be decomposed first, so it must not contain only triangles; it can contain for example triangle trips too.

[python]&lt;code python&gt;from panda3d.bullet import BulletTriangleMeshShape
mesh = BulletTriangleMesh()
mesh.addGeom(geom)&lt;/code&gt;[/python]
[cxx]
&lt;code cxx&gt;

#include &quot;panda3d/bulletTriangleMesh.h&quot;
...
BulletTriangleMesh *triangle_mesh = new BulletTriangleMesh();
triangle_mesh-&gt;add_geom(geom);
&lt;/code&gt;[/cxx]


==Heightfield Shape==

A special non-primitive collision shape. Give a heightfield image we can construct a terrain mesh with only a few lines of code.

[python]&lt;code python&gt;from panda3d.core import Filename
from panda3d.core import PNMImage
from panda3d.bullet import BulletHeightfieldShape
from panda3d.bullet import ZUp
height = 10.0
img = PNMImage(Filename('elevation.png'))
shape = BulletHeightfieldShape(img, height, ZUp)&lt;/code&gt;[/python]
[cxx]
&lt;code cxx&gt;
#include &quot;panda3d/pnmImage.h&quot;
#include &quot;panda3d/bulletHeightfieldShape.h&quot;

PNMImage *pnm_image = new PNMImage();
pnm_image-&gt;read(*new Filename(&quot;models/elevation.png&quot;));

BulletHeightfieldShape *heightfield_shape = new BulletHeightfieldShape(*pnm_image, height);
&lt;/code&gt;
[/cxx]

The heightfield shape will be oriented the same way as a GeoMipTerrain created from the same image, but GeoMipTerrain and BulletHeightfieldShape have different origins. The BulletHeightfieldShape is centered around the origin, while the GeoMipTerrain uses the lower left corner as its origin. However, this can be easily corrected by positioning the GeoMipTerrain with an offset relative to the static rigid body node.

[python]&lt;code python&gt;from panda3d.core import Filename
offset = img.getXSize() / 2.0 - 0.5
terrain = GeoMipTerrain('terrain')
terrain.setHeightfield(img)
terrainNP = terrain.getRoot()
terrainNP.setSz(height)
terrainNP.setPos(-offset, -offset, -height / 2.0)&lt;/code&gt;[/python]
[cxx]
&lt;code cxx&gt;
GeoMipTerrain *terrain = get_geomip_terrain();
terrain-&gt;set_heightfield(*pnm_image);
terrain-&gt;set_block_size(32);
terrain-&gt;set_near(50);
terrain-&gt;set_far(100);
terrain-&gt;set_focal_point(window-&gt;get_camera_group());

NodePath terrain_root = terrain-&gt;get_root();

float offset = pnm_image-&gt;get_x_size() / 2.0 - 0.5;
terrain_root.set_pos(-offset, -offset, -height / 2.0);

terrain_root.set_scale(terrain_root.get_scale().get_x(), terrain_root.get_scale().get_y(), height);
terrain_root.reparent_to(window-&gt;get_render());
&lt;/code&gt;[/cxx]


==Soft Body Shape==

This special collision shape is used in connection with soft bodies. It can not be created directly. Soft bodies will be discussed later within this manual.</text>
    </revision>
  </page>
  <page>
    <title>Bullet Config Options</title>
    <ns>0</ns>
    <id>2607</id>
      <sha1>jf5eu3wigtv77ocbau2scni4eixvch0</sha1>
    <revision>
      <id>7464</id>
      <timestamp>2011-12-24T12:18:39Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>typos</comment>
      <text xml:space="preserve" bytes="2461">The following list is a listing of all config variables defined by the Panda3D Bullet module.

&lt;center&gt;
&lt;table border=&quot;1&quot; cellpadding=&quot;1&quot; cellspacing=&quot;0&quot;&gt;
&lt;tr&gt;
&lt;th&gt;Variable&lt;/th&gt;
&lt;th&gt;Value Type&lt;/th&gt;
&lt;th&gt;Default&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;bullet-max-objects&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;1024&lt;/td&gt;
&lt;td&gt;Specifies the maximum number of individual objects within a bullet 
physics world.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;bullet-gc-lifetime&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;256&lt;/td&gt;
&lt;td&gt;Specifies the lifetime of data clean up be the soft body world info 
garbage collector.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;bullet-broadphase-algorithm&lt;/td&gt;
&lt;td&gt;enum&lt;/td&gt;
&lt;td&gt;aabb&lt;/td&gt;
&lt;td&gt;Specifies the broadphase algorithm to be used by the physics engine. Default value is 'aabb' (dynamic aabb tree). A second value is 'sap' (sweep and prune).&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;bullet-sap-extents&lt;/td&gt;
&lt;td&gt;float&lt;/td&gt;
&lt;td&gt;1000.0&lt;/td&gt;
&lt;td&gt;Specifies the world extent in all directions. The config variable is only used if bullet-broadphase-algorithm is set to 'sap' (sweep and prune).&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;bullet-enable-contact-events&lt;/td&gt;
&lt;td&gt;bool&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;Specifies if events should be send when new contacts are created or 
existing contacts get remove. Warning: enabling contact events might create more load on the event queue then you might want! Default value is FALSE.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;bullet-solver-iterations&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;Specifies the number of iterations for the Bullet contact solver. This is the native Bullet property btContactSolverInfo::m_numIterations.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;bullet-additional-damping&lt;/td&gt;
&lt;td&gt;bool&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;Enables additional damping on each rigid body, in order to reduce jitter. Additional damping is an experimental feature of the Bullet physics engine. Use with care.&quot;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;bullet-additional-damping-linear-factor&lt;/td&gt;
&lt;td&gt;float&lt;/td&gt;
&lt;td&gt;0.005&lt;/td&gt;
&lt;td&gt;Only used when bullet-additional-damping is set to TRUE.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;bullet-additional-damping-angular-factor&lt;/td&gt;
&lt;td&gt;float&lt;/td&gt;
&lt;td&gt;0.01&lt;/td&gt;
&lt;td&gt;Only used when bullet-additional-damping is set to TRUE.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;bullet-additional-damping-linear-threshold&lt;/td&gt;
&lt;td&gt;float&lt;/td&gt;
&lt;td&gt;0.01&lt;/td&gt;
&lt;td&gt;Only used when bullet-additional-damping is set to TRUE.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;bullet-additional-damping-angular-threshold&lt;/td&gt;
&lt;td&gt;float&lt;/td&gt;
&lt;td&gt;0.01&lt;/td&gt;
&lt;td&gt;Only used when bullet-additional-damping is set to TRUE.&lt;/td&gt;
&lt;/tr&gt;

&lt;/table&gt;
&lt;/center&gt;</text>
    </revision>
  </page>
  <page>
    <title>Bullet Constraints</title>
    <ns>0</ns>
    <id>2622</id>
      <sha1>corhbiei16fd8pvx2bpy3ppsvjj6b0n</sha1>
    <revision>
      <id>7457</id>
      <timestamp>2011-12-24T12:07:02Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>typos</comment>
      <text xml:space="preserve" bytes="4489">Constraints limit the movement of two rigid bodies in relation to each other, or the movement of one body in relation to the global world space. Another often used term word for constraints is joint. 

==Constraint Types==

The following different types of constraints are supported by Bullet:

====Hinge Constraint:====

The hinge constraint has restricts movement of two bodies by means of a shared axis. The axis is defined by a pivot point on each body (within the body's local space). Hinge constraints can be used for example to model doors or chests.

[[Image:BulletHinge.png]]

====Slider Constraint:====

The slider constraint allows the two bodies to move along a shared piston. Rotation around the piston can be limited, if this is required.

[[Image:BulletSlider.png]]

====Spherical Constraint:====

The spherical constraint models a ball-and-socket connection between two rigid bodies.
 
[[Image:BulletSpherical.png]]

====Cone Twist Constraint:====

The cone twist constraint is a specialized version of the spherical constraint. It allows to limit the rotation and the swing (in both perpendicular directions).

====Generic Constraint:====

The generic constraint allows movement in all six degrees of freedom, and it allows to limit this movement as desired.

==Constraint between two rigid bodies==

All constraints can be created and used in similar ways, so we will explain only one constraint in detail, the BulletConeTwistConstraint. For other constraints please refer to the API documentation.

We assume that we already have created two rigid body nodes, and &lt;code&gt;npA&lt;/code&gt; and &lt;code&gt;npB&lt;/code&gt; are NodePaths for these rigid body nodes. For example like the two boxes created in the following snippet
[python]&lt;code python&gt;shape = BulletBoxShape(Vec3(0.5, 0.5, 0.5))

npA = self.worldNP.attachNewNode(BulletRigidBodyNode('A'))
npA.node().setMass(1.0)
npA.node().addShape(shape)
npA.setPos(10, 0, 5)
world.attachRigidBody(npA.node())

npB = self.worldNP.attachNewNode(BulletRigidBodyNode('B'))
npB.node().addShape(shape)
npB.setPos(10, 0, -5)
self.world.attachRigidBody(npB.node())&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]

In the above example body A is dynamic, and body B is static. This means body A will fall down since it is affected by gravity, but body B will always stay where it is. Neither can body B be pushed by dynamic bodies.

Using a cone/twist constraint we can connect body A to body B. The cone/twist constraint will allow body A to move within a cone fixed to body B. Body A will also be able to rotate around the axis from the cone's vertex point to body A ('twist' around this axis).

In order to create the cone/twist constraint we have to define the spatial frames of the cone/twist connector point, as seen from body A and from body B. Then we need to create a new instance of &lt;code&gt;BulletConeTwiseConstraint&lt;/code&gt;, by passing both bodies and both transforms to the constructor. Once created we can set properties like the scale of the debug visualization of this constraint, and limits. Finally we add the new constraint to the physics world.
[python]&lt;code python&gt;frameA = TransformState.makePosHpr(Point3(0, 0, -5), Vec3(0, 0, -90))
frameB = TransformState.makePosHpr(Point3(0, 0, 5), Vec3(0, 0, -90))

swing1 = 60 # degrees
swing2 = 36 # degrees
twist = 120 # degrees

cs = BulletConeTwistConstraint(npA.node(), npB.node(), frameA, frameB)
cs.setDebugDrawSize(2.0)
cs.setLimit(swing1, swing2, twist)
world.attachConstraint(cs)&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]

In this case we have set the following limits:
* Angle of the cone opening in first direction (swing span 1)
* Angle of the cone opening in second direction (swing span 2)
* Maximum twist angle (twist)
In addition we could also add the following parameters: softness, bias factor, relaxation factor.

Which limits are available depends on the constraint type. Please refer to the API documentation.

==Constraint between one rigid body and the world==

Adding a constraint between a single body and a fixed point in the global world is similar to adding a constraint between two rigid bodies. The difference is that you pass only one body and one frame to the constructor of the constraint, for example like in the following snippet
[python]&lt;code python&gt;frameA = TransformState.makePosHpr(Point3(0, 0, -5), Vec3(0, 0, -90))

cs = BulletConeTwistConstraint(npA.node(), frameA)
world.attachConstraint(cs)&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Bullet Continuous Collision Detection</title>
    <ns>0</ns>
    <id>2619</id>
      <sha1>gmmc0v8m70q20ze4s4bmj4szrmki6er</sha1>
    <revision>
      <id>7454</id>
      <timestamp>2011-12-24T12:03:37Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>typo</comment>
      <text xml:space="preserve" bytes="2888">CCD is short for Continuous Collision Detection, which is a workaround for a common problem in game physics: a fast moving body might not collide with an obstacle if in one frame it is &quot;before&quot; the obstacle, and in the next one it is already &quot;behind&quot; the obstacle. At no frame the fast moving body overlaps with the obstacle, and thus no response is created. This is what CCD is for. CCD checks for collisions in between frames, and thus can prevent fast moving objects from passing through thin obstacles.

Bullet has built-in support for CCD, but bodies have to be configured properly to enable CCD checks.

When checking for collision in between frames Bullet does not use the full collision shape (or shapes) of a body - this would make continuous collision detection too slow. Instead Bullet uses a sphere shape, the so-called &quot;swept sphere&quot;. &quot;swept&quot; because the sphere is swept from the original position to the new position of the body. So, in order to enable CCD checks on a body we have to setup this sphere, and a CCD motion threshold:

[python]&lt;code python&gt;bodyNP.node().setCcdMotionThreshold(1e-7)
bodyNP.node().setCcdSweptSphereRadius(0.50)&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]

We have to set up the swept sphere only on the fast moving dynamic bodies. There is no need to do anything for the static or slow moving obstacles.

One particular use for CCD is firing a bullet (bullet is lowercase here, indicating that a projectile is meant, not the Bullet physics engine). Below is a sample showing one way to implement shooting bullets.

[python]&lt;code python&gt;bullets = []

def removeBullet(task):
  if len(bullets) &lt; 1: return

  bulletNP = bullets.pop(0)
  world.removeRigidBody(bulletNP.node())

  return task.done

def shootBullet(ccd):
  # Get from/to points from mouse click
  pMouse = base.mouseWatcherNode.getMouse()
  pFrom = Point3()
  pTo = Point3()
  base.camLens.extrude(pMouse, pFrom, pTo)

  pFrom = render.getRelativePoint(base.cam, pFrom)
  pTo = render.getRelativePoint(base.cam, pTo)

  # Calculate initial velocity
  v = pTo - pFrom
  v.normalize()
  v *= 10000.0

  # Create bullet
  shape = BulletBoxShape(Vec3(0.5, 0.5, 0.5))
  body = BulletRigidBodyNode('Bullet')
  bodyNP = render.attachNewNode(body)
  bodyNP.node().addShape(shape)
  bodyNP.node().setMass(2.0)
  bodyNP.node().setLinearVelocity(v)
  bodyNP.setPos(pFrom)
  bodyNP.setCollideMask(BitMask32.allOn())

  # Enable CCD
  bodyNP.node().setCcdMotionThreshold(1e-7)
  bodyNP.node().setCcdSweptSphereRadius(0.50)

  world.attachRigidBody(bodyNP.node())

  # Remove the bullet again after 1 second
  bullets.append(bodyNP)
  taskMgr.doMethodLater(1, removeBullet, 'removeBullet')&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]

Most of the code is related to finding the initial velocity vector for the bullet, which is calculated from the mouse position when shooting the bullet.</text>
    </revision>
  </page>
  <page>
    <title>Bullet Debug Renderer</title>
    <ns>0</ns>
    <id>2618</id>
      <sha1>7j3470mb5yoymdyjsryfv15bto9pgqf</sha1>
    <revision>
      <id>7750</id>
      <timestamp>2012-04-10T02:34:42Z</timestamp>
      <contributor>
        <username>EdmundosTown</username>
        <id>570</id>
      </contributor>
      <text xml:space="preserve" bytes="8491">In the previous &quot;hello world&quot; sample we have been introduced to a few Bullet physics objects, for example the rigid body (&lt;code&gt;BulletRigidBodyNode&lt;/code&gt;) or box and plane collision shapes (&lt;code&gt;BulletPlaneShape&lt;/code&gt;, &lt;code&gt;BulletBoxShape&lt;/code&gt;).

These objects are part of the Panda3D scene graph. But they are not visible. In order to be able to actually see a rigid body we had to reparent a visible geometry below the rigid body node. This is fine, since we (1) can control the way an object looks like, by choosing whatever visible geoemtry we want, and (2) we can create invisible objects too, by not reparenting any geometry below a rigid body.

But when developing a game it sometimes would be handy to actually see where the physical objects are. This is what the &lt;code&gt;BulletDebugNode&lt;/code&gt; is for. It's not meant for users playing the game, but as an aid in finding problems while developing the game.

The debug node is pretty easy to use. We just need to create such a node, place it in the scene graph, and tell the Bullet world that we have such a node. From now on Bullet will create a &quot;debug&quot; visualisation of the world's content within the debug node, whenever [python]&lt;code&gt;doPhysics&lt;/code&gt;[/python][cxx]&lt;code&gt;do_physics&lt;/code&gt;[/cxx] is called. The following code snippet shows how to do this:

[python]&lt;code python&gt;from panda3d.bullet import BulletDebugNode

debugNode = BulletDebugNode('Debug')
debugNode.showWireframe(True)
debugNode.showConstraints(True)
debugNode.showBoundingBoxes(False)
debugNode.showNormals(False)
debugNP = render.attachNewNode(debugNode)
debugNP.show()

world = BulletWorld()
world.setGravity(Vec3(0, 0, -9.81))
world.setDebugNode(debugNP.node())&lt;/code&gt;[/python]
[cxx]
&lt;code cxx&gt;
#include &quot;panda3d/bulletDebugNode.h&quot;
...
BulletDebugNode *bullet_dbg_node;
bullet_dbg_node = new BulletDebugNode(&quot;Debug&quot;);
bullet_dbg_node-&gt;show_bounding_boxes(true);
bullet_dbg_node-&gt;show_constraints(true);
bullet_dbg_node-&gt;show_normals(true);
bullet_dbg_node-&gt;show_wireframe(true);

NodePath np_dbg_node = window-&gt;get_render().attach_new_node(get_physics_debug_node());
np_dbg_node.show();

physics_world-&gt;set_debug_node(get_physics_debug_node());
...
&lt;/code&gt;
[/cxx]

We can control the amount of information rendered using the following methods:
* [python]showWireframe[/python][cxx]show_wireframe[/cxx]: Displays collisions shapes in wireframe mode.
* [python]showConstraints[/python][cxx]show_constraints[/cxx]: Display limits defined for constraints, e. g. a pivot axis or maximum amplitude.
* [python]showBoundingBoxes[/python][cxx]show_bounding_boxes[/cxx]: Displays axis aligned bounding boxes for objects.
* [python]showNormals[/python][cxx]show_normals[/cxx]: Displays normals for triangle mesh and heightfield faces.

There is one thing to pay attention to: By default the &lt;code&gt;BulletDebugNode&lt;/code&gt; is hidden right after creation. If we want to see the debug visualisation from the first frame on we have to unhide it, using &lt;code&gt;show()&lt;/code&gt;.

Since debug rendering is not very fast we can turn debug rendering on and off, without having to remove the debug node from the scene graph. Turning debug rendering on and of is simply done by hiding or showing the debug node. The following code shows how to toggle debug node visibility on and off, using the F1 key:

[python]&lt;code python&gt;from direct.showbase.DirectObject import DirectObject

o = DirectObject()
o.accept('f1', toggleDebug)

def toggleDebug():
  if debugNP.isHidden():
    debugNP.show()
  else:
    debugNP.hide()&lt;/code&gt;[/python]
[cxx]
&lt;code cxx&gt;
...
void toggle_physics_debug(const Event *e, void *data) {
    static bool show_state = true;
    show_state = !show_state;
    bullet_dbg_node-&gt;show_bounding_boxes(show_state);
    bullet_dbg_node-&gt;show_constraints(show_state);
    bullet_dbg_node-&gt;show_normals(show_state);
    bullet_dbg_node-&gt;show_wireframe(show_state);
}
...
framework.define_key(&quot;f1&quot;, &quot;Toggle Physics debug&quot;, toggle_physics_debug, (void *) NULL);
....
&lt;/code&gt;

You can notice that CXX code made Toggle action in different way than Python code, the reason is simple, CXX uses the BulletDebugNode instead of NodePath that parent first node, anyway you can apply the last one using global variables or static function calls, or use directly BulletDebugNode like the following program.

&lt;code cxx&gt;
// Bullet Debug Node Example.
// The following example is done from Python sources, Panda Reference and Panda Manual,
// for more information, visit Panda3D and/or Bullet physics web site.

// Compiling and Linking documentation and notes are not 
// covered in this file, check manual for mor information.

#include &quot;panda3d/pandaFramework.h&quot;
#include &quot;panda3d/windowFramework.h&quot;
#include &quot;panda3d/nodePath.h&quot;
#include &quot;panda3d/clockObject.h&quot;

#include &quot;panda3d/asyncTask.h&quot;
#include &quot;panda3d/genericAsyncTask.h&quot;

#include &quot;panda3d/bulletWorld.h&quot;
#include &quot;panda3d/bulletDebugNode.h&quot;
#include &quot;panda3d/bulletPlaneShape.h&quot;
#include &quot;panda3d/bulletBoxShape.h&quot;

BulletWorld *get_physics_world() {
    // physics_world is supposed to be an global variable,
    // but declaring global variables is not cool
    // for good programmers lol, instead, should use static keyword.
    static BulletWorld *physics_world = new BulletWorld();
    return physics_world;
}

BulletDebugNode *get_physics_debug_node() {
    // Global variable.
    static BulletDebugNode *bullet_dbg_node = new BulletDebugNode(&quot;Debug&quot;);
    return bullet_dbg_node;
}

void toggle_physics_debug(const Event *e, void *data) {
    static bool show_state = true;
    show_state = !show_state;
    get_physics_debug_node()-&gt;show_bounding_boxes(show_state);
    get_physics_debug_node()-&gt;show_constraints(show_state);
    get_physics_debug_node()-&gt;show_normals(show_state);
    get_physics_debug_node()-&gt;show_wireframe(show_state);
}

AsyncTask::DoneStatus update_scene(GenericAsyncTask* task, void* data) {
    // Get dt (from Python example) and apply to do_physics(float, int, int);
    ClockObject *co = ClockObject::get_global_clock();
    get_physics_world()-&gt;do_physics(co-&gt;get_dt(), 10, 1.0 / 180.0);

    return AsyncTask::DS_cont;
}

int main(int argc, char *argv[]) {
    // All variables.
    PandaFramework framework;
    WindowFramework *window;
    PT(AsyncTaskManager) task_mgr;

    // Init everything :D
    framework.open_framework(argc, argv);
    framework.set_window_title(&quot;Bullet Physics&quot;);

    window = framework.open_window();
    window-&gt;enable_keyboard();
    window-&gt;setup_trackball();

    task_mgr = AsyncTaskManager::get_global_ptr();

    // Make physics simulation.
    // Static world stuff.
    get_physics_world()-&gt;set_gravity(0, 0, -9.8);

    BulletPlaneShape *floor_shape = new BulletPlaneShape(*new LVecBase3f(0, 0, 1), 1);
    BulletRigidBodyNode *floor_rigid_node = new BulletRigidBodyNode(&quot;Ground&quot;);

    floor_rigid_node-&gt;add_shape(floor_shape);

    NodePath np_ground = window-&gt;get_render().attach_new_node(floor_rigid_node);
    np_ground.set_pos(0, 0, -2);
    get_physics_world()-&gt;attach_rigid_body(floor_rigid_node);

    // Dynamic world stuff.
    BulletBoxShape *box_shape = new BulletBoxShape(*new LVecBase3f(0.5, 0.5, 0.5));
    BulletRigidBodyNode *box_rigid_node = new BulletRigidBodyNode(&quot;Box&quot;);

    box_rigid_node-&gt;set_mass(1.0); // Gravity affects this rigid node.
    box_rigid_node-&gt;add_shape(box_shape);

    NodePath np_box = window-&gt;get_render().attach_new_node(box_rigid_node);
    np_box.set_pos(0, 0, 2);
    get_physics_world()-&gt;attach_rigid_body(box_rigid_node);

    NodePath np_box_model = window-&gt;load_model(framework.get_models(), &quot;models/box&quot;);
    np_box_model.set_pos(-0.5, -0.5, -0.5);
    np_box.flatten_light();
    np_box_model.reparent_to(np_box);

    // Debug stuff.
    get_physics_debug_node()-&gt;show_bounding_boxes(true);
    get_physics_debug_node()-&gt;show_constraints(true);
    get_physics_debug_node()-&gt;show_normals(true);
    get_physics_debug_node()-&gt;show_wireframe(true);

    NodePath np_dbg_node = window-&gt;get_render().attach_new_node(get_physics_debug_node());
    np_dbg_node.show();

    get_physics_world()-&gt;set_debug_node(get_physics_debug_node());
    framework.define_key(&quot;f1&quot;, &quot;Toggle Physics debug&quot;, toggle_physics_debug, (void *) NULL);

    // Setup tasks and keys.
    PT(GenericAsyncTask) task;
    task = new GenericAsyncTask(&quot;Scene update&quot;, &amp;update_scene, (void*) NULL);
    task_mgr-&gt;add(task);

    framework.main_loop();
    framework.close_framework();

    return (0);
}
&lt;/code&gt;
[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Bullet FAQ</title>
    <ns>0</ns>
    <id>2653</id>
      <sha1>4luiblhrpbeis46jhffu4ab7iflya08</sha1>
    <revision>
      <id>7347</id>
      <timestamp>2011-10-01T20:47:22Z</timestamp>
      <contributor>
        <username>Enn0x</username>
        <id>414</id>
      </contributor>
      <text xml:space="preserve" bytes="1391">This page contains answers to often asked question and elaborations on different topics related to the Bullet Panda3d module. 

==Bullet and Scale==

When using physics it is always better to avoid scale wherever possible. However, the Bullet module does it's best to support setting scale on RigidBodyNode, GhostNode etc. Shear is not supported at all.

If you know the dimensions of a Bullet collision shape at the time of creation then create it with those dimensions, and don't use scale to adjust the dimensions afterwards. For example, if you need a box with extents 5x3x1 then create it with these extents, and not with extents 1x1x1 and then scale it with Vec3(5,3,1).

If you have convex meshes or triangle meshes then it is better to &quot;bake&quot; the scale before creating the collision shape. Baking means to apply the scale to all vertices first, and then pass the scaled vertex positions to the convex or triangle mesh shape. This can be done before exporting your model from your modelling application, or in code after loading the model.

Please note that the effective scale applied to a Bullet collision shape is the global scale of the node, that is the scale component of the global transform of this node. So if you have the scene graph &quot;A&quot; --&gt; &quot;B&quot; --&gt; &quot;C&quot;, then the effective scale of the node &quot;C&quot; is the scale set on &quot;A&quot; times the scale set on &quot;B&quot; times the scale set on &quot;C&quot;.</text>
    </revision>
  </page>
  <page>
    <title>Bullet Ghosts</title>
    <ns>0</ns>
    <id>2611</id>
      <sha1>5zp6dvyfgjqsmxa674tfm2z4ni8qsme</sha1>
    <revision>
      <id>7234</id>
      <timestamp>2011-08-22T11:49:47Z</timestamp>
      <contributor>
        <username>Community</username>
        <id>527</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="1345">Ghost objects are intangible objects. They do collide with other objects, but they won't create any collision response (forces etc.) from such collisions. Ghost objects keep track of all objects they collide with, and it is possible to query them for all objects they currently overlap with.

Ghost objects therefore can be used to implement a sensor, which detects the presence of any (or a particular) object within the sensor's shape. For example an automatic door which should open if the player is in front of the door, or an area which triggers some event if the player moves through the area.

Example for how to setup a ghost object:

[python]&lt;code python&gt;from panda3d.bullet import BulletGhostNode
from panda3d.bullet import BulletBoxShape

shape = BulletBoxShape(Vec3(1, 1, 1))

ghost = BulletGhostNode('Ghost')
ghost.addShape(shape)
ghostNP = render.attachNewNode(ghost)
ghostNP.setPos(0, 0, 0)
ghostNP.setCollideMask(BitMask32(0x0f))

world.attachGhost(ghost)&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]

Example for how to get overlapping objects:

[python]&lt;code python&gt;def checkGhost(self, task):
  ghost = ghostNP.node()
  print ghost.getNumOverlappingNodes()
  for node in ghost.getOverlappingNodes():
    print node

  return task.cont

taskMgr.add(checkGhost, 'checkGhost')&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Bullet Hello World</title>
    <ns>0</ns>
    <id>2606</id>
      <sha1>9oqjcv2npg6mzasq623x7g8ial5bote</sha1>
    <revision>
      <id>60455</id>
      <timestamp>2015-01-08T20:44:12Z</timestamp>
      <contributor>
        <username>ThomasEgi</username>
        <id>111</id>
      </contributor>
      <minor/>
      <comment>fixed link to the samples (enn0x p3pd was down)</comment>
      <text xml:space="preserve" bytes="11903">This page intends to lead through a minimal &quot;hello world&quot; program using Panda3D and Bullet physics.

[cxx]
==Compiling C++ Panda3D with Bullet code==

Above all, we have to know how to compile C++ code using Panda3D binding to Bullet Engine, that can be done following a few steps.

* Download BulletPhysics SDK (sources or binaries): http://code.google.com/p/bullet/downloads/list, and if apply, compile it, (Docs on http://bulletphysics.org/mediawiki-1.5.8/index.php/Main_Page). 
* Locate libraries and included files, normally '/usr/local/include/bullet' on Linux distros, 'pkg-config bullet --libs' and 'pkg-config bullet --cflags' may work. On Windows or MacOS I'm not sure where the libraries are but may not be difficult to locate.
* Compile and linking it's easy, just follow CXX File manual's paragraph and add -Iyour_include_bullet_folder and -llibs (-lBulletSoftBody -lBulletDynamics -lBulletCollision -lLinearMath).
* If you're using an IDE (such VS 2008 or Netbeans), just add libraries and header files to proyect properties (see manual of your IDE). 

And then, we are ready to compile our Bullet + Panda3D Code.
[/cxx]

==World==

In order to use Bullet physics we need to have a BulletWorld. The world is Panda3D's term for a &lt;i&gt;&quot;space&quot;&lt;/i&gt; or &lt;i&gt;&quot;scene&quot;&lt;/i&gt;. The world holds physical objects like rigid bodies, soft bodies or character controllers. It controls global parameters, such a gravity, and it advances the simulation state.

[python]&lt;code python&gt;from panda3d.bullet import BulletWorld
world = BulletWorld()
world.setGravity(Vec3(0, 0, -9.81))&lt;/code&gt;[/python]
[cxx]
First, include Panda3D bullet binding headers.
&lt;code cxx&gt;
#include &quot;bulletWorld.h&quot;
#include &quot;bulletPlaneShape.h&quot;
#include &quot;bulletBoxShape.h&quot;
...
BulletWorld *physics_world;
physics_world = new BulletWorld();
physics_world-&gt;set_gravity(0, 0, -9.81f);
...
&lt;/code&gt;
[/cxx]

The above code creates a new world, and it sets the worlds gravity to a downward vector with length 9.81. While Bullet is in theory independent from any particular units it is recommended to stick with SI units (kilogram, meter, second). In SI units 9.81 m/s² is the gravity on Earth's surface.

Next we need to advance the simulation state. This is best done by a task which gets called each frame. We find out about the elapsed time (dt), and pass this value to the [python]&lt;code&gt;doPhysics&lt;/code&gt;[/python][cxx]&lt;code&gt;do_physics&lt;/code&gt;[/cxx] method.

[python]&lt;code python&gt;def update(task):
  dt = globalClock.getDt()
  world.doPhysics(dt)
  return task.cont

taskMgr.add(update, 'update')&lt;/code&gt;[/python]

[cxx]
&lt;code cxx&gt;
...
AsyncTask::DoneStatus update_scene(GenericAsyncTask* task, void* data) {
    // Get dt (from Python example) and apply to do_physics(float, int, int);
    ClockObject *co = ClockObject::get_global_clock();
    physics_world-&gt;do_physics(co-&gt;get_dt(), 10, 1.0 / 180.0);

    return AsyncTask::DS_cont;
}
...
PT(GenericAsyncTask) task;
task = new GenericAsyncTask(&quot;Scene update&quot;, &amp;update_scene, (void*) NULL);
task_mgr-&gt;add(task); // Note: task_mgr = AsyncTaskManager::get_global_ptr();
...
&lt;/code&gt;
[/cxx]

The &lt;code&gt;doPhysics&lt;/code&gt; method allows finer control on the way the simulation state is advanced. Internally Bullet splits a timestep into several substeps. We can pass a maximum number of substeps and the size of each substep, like show in the following code.

[python]&lt;code python&gt;  world.doPhysics(dt, 10, 1.0/180.0)&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;  physics_world-&gt;do_physics(co-&gt;get_dt(), 10, 1.0 / 180.0);&lt;/code&gt;[/cxx]

Here we have a maximum of 10 substeps, each with 1/180 seconds. Choosing smaller substeps will make the simulation more realistic, but performance will decrease too. Smaller substeps also reduce jitter.


==Static bodies==

So far we just have an empty world. We next need to add some objects. The most simple objects are static bodies. Static object don't change their position or orientation with time. Typical static objects are the ground or terrain, and houses or other non-moveable obstacles. Here we create a simple plane which will serve as a ground.

[python]&lt;code python&gt;from panda3d.bullet import BulletPlaneShape
from panda3d.bullet import BulletRigidBodyNode

shape = BulletPlaneShape(Vec3(0, 0, 1), 1)

node = BulletRigidBodyNode('Ground')
node.addShape(shape)

np = render.attachNewNode(node)
np.setPos(0, 0, -2)

world.attachRigidBody(node)&lt;/code&gt;[/python]

[cxx]&lt;code cxx&gt;
...
BulletPlaneShape *floor_shape = new BulletPlaneShape(LVecBase3f(0, 0, 1), 1);
BulletRigidBodyNode *floor_rigid_node = new BulletRigidBodyNode(&quot;Ground&quot;);

floor_rigid_node-&gt;add_shape(floor_shape);

NodePath np_ground = window-&gt;get_render().attach_new_node(floor_rigid_node);
np_ground.set_pos(0, 0, -2);
physics_world-&gt;attach_rigid_body(floor_rigid_node);
...
&lt;/code&gt;[/cxx]

First we create a collision shape, in the case a &lt;code&gt;BulletPlaneShape&lt;/code&gt;. We pass the plane's constant and normal vector within the shape's constructor. There is a separate page about setting up the various collision shapes offered by Bullet, so we won't go into more detail here.

Next we create a rigid body and add the previously created shape. &lt;code&gt;BulletRigidBodyNode&lt;/code&gt; is derived from &lt;code&gt;PandaNode&lt;/code&gt;, and thus the rigid body can be placed within the Panda3D scene graph. you can also use methods like &lt;code&gt;setPos&lt;/code&gt; or &lt;/code&gt;setH&lt;/code&gt; to place the rigid body node where you want it to be.

Finally we need to attach the newly created rigid body node to the world. Only rigid bodies attached to the world will be considered when advancing the simulation state.


==Dynamic bodies==

Dynamic bodies are similar to static bodies. Except that dynamic bodies can be moved around the world by applying force or torque. To setup a dynamic body is almost the same as for static bodies. We will have to set one additional property though, the body's mass. Setting a positive finite mass will create a dynamic body, while setting the mass to zero will create a static body. Zero mass is a convention for setting an &lt;i&gt;infinite&lt;/i&gt; mass, which is the same as making the body unmovable (static). 

[python]&lt;code python&gt;from panda3d.bullet import BulletBoxShape

shape = BulletBoxShape(Vec3(0.5, 0.5, 0.5))

node = BulletRigidBodyNode('Box')
node.setMass(1.0)
node.addShape(shape)

np = render.attachNewNode(node)
np.setPos(0, 0, 2)

world.attachRigidBody(node)&lt;/code&gt;[/python]

[cxx]
&lt;code cxx&gt;
...
BulletBoxShape *box_shape = new BulletBoxShape(LVecBase3f(0.5, 0.5, 0.5));
BulletRigidBodyNode *box_rigid_node = new BulletRigidBodyNode(&quot;Box&quot;);

box_rigid_node-&gt;set_mass(1.0f); // Gravity affects this rigid node.
box_rigid_node-&gt;add_shape(box_shape);

NodePath np_box = window-&gt;get_render().attach_new_node(box_rigid_node);
np_box.set_pos(0, 0, 2);
physics_world-&gt;attach_rigid_body(box_rigid_node);
...
&lt;/code&gt;
[/cxx]

Bullet will automatically update a rigid body node's position and orientation if is has changed after advancing the simulation state. So, if you have a &lt;code&gt;GeomNode&lt;/code&gt; - e. g. a textured box - and reparent this geom node below the rigid body node, then the geom node will move around together with the rigid body. You don't have to synchronize the visual world with the physics world.


==The Program==

Let's put everything learned on this page together into a single script, which is shown below. It assumes that you have an .egg model of a 1 by 1 by 1 box.

when running the script you will see a box falling down onto an invisible plane. The plane is invisible simply because we didn't parent a visual mode below the plane's rigid body node. Of course we could have done so. 

The model cube.egg used in this hello word sample can be found in the following archive: https://www.panda3d.org/download/noversion/bullet-samples.zip [cxx]NOTE: Samples are currently available in Python code only. [/cxx]


[python]&lt;code python&gt;import direct.directbase.DirectStart
from panda3d.core import Vec3
from panda3d.bullet import BulletWorld
from panda3d.bullet import BulletPlaneShape
from panda3d.bullet import BulletRigidBodyNode
from panda3d.bullet import BulletBoxShape

base.cam.setPos(0, -10, 0)
base.cam.lookAt(0, 0, 0)

# World
world = BulletWorld()
world.setGravity(Vec3(0, 0, -9.81))

# Plane
shape = BulletPlaneShape(Vec3(0, 0, 1), 1)
node = BulletRigidBodyNode('Ground')
node.addShape(shape)
np = render.attachNewNode(node)
np.setPos(0, 0, -2)
world.attachRigidBody(node)

# Box
shape = BulletBoxShape(Vec3(0.5, 0.5, 0.5))
node = BulletRigidBodyNode('Box')
node.setMass(1.0)
node.addShape(shape)
np = render.attachNewNode(node)
np.setPos(0, 0, 2)
world.attachRigidBody(node)
model = loader.loadModel('models/box.egg')
model.flattenLight()
model.reparentTo(np)

# Update
def update(task):
  dt = globalClock.getDt()
  world.doPhysics(dt)
  return task.cont

taskMgr.add(update, 'update')
run()&lt;/code&gt;[/python]

[cxx]
&lt;code cxx&gt;
// Bullet Physics Example.
// The following example is done from Python sources, Panda Reference and Panda Manual,
// for more information, visit Panda3D and/or Bullet physics web site.

// Compiling and Linking documentation and notes are not 
// covered in this file, check manual for more information.

#include &quot;pandaFramework.h&quot;
#include &quot;windowFramework.h&quot;
#include &quot;nodePath.h&quot;
#include &quot;clockObject.h&quot;

#include &quot;asyncTask.h&quot;
#include &quot;genericAsyncTask.h&quot;

#include &quot;bulletWorld.h&quot;
#include &quot;bulletPlaneShape.h&quot;
#include &quot;bulletBoxShape.h&quot;

BulletWorld *get_physics_world() {
    // physics_world is supposed to be an global variable,
    // but declaring global variables is not cool
    // for good programmers lol, instead, should use static keyword.
    static BulletWorld *physics_world = new BulletWorld();
    return physics_world;
}

AsyncTask::DoneStatus update_scene(GenericAsyncTask* task, void* data) {
    // Get dt (from Python example) and apply to do_physics(float, int, int);
    ClockObject *co = ClockObject::get_global_clock();
    get_physics_world()-&gt;do_physics(co-&gt;get_dt(), 10, 1.0 / 180.0);

    return AsyncTask::DS_cont;
}

int main(int argc, char *argv[]) {
    // All variables.
    PandaFramework framework;
    WindowFramework *window;
    NodePath camera;
    PT(AsyncTaskManager) task_mgr;

    // Init everything :D
    framework.open_framework(argc, argv);
    framework.set_window_title(&quot;Bullet Physics&quot;);

    window = framework.open_window();
    window-&gt;enable_keyboard();
    window-&gt;setup_trackball();

    camera = window-&gt;get_camera_group();
    task_mgr = AsyncTaskManager::get_global_ptr();

    // Make physics simulation.
    // Static world stuff.
    get_physics_world()-&gt;set_gravity(0, 0, -9.81f);
    
    BulletPlaneShape *floor_shape = new BulletPlaneShape(LVecBase3f(0, 0, 1), 1);
    BulletRigidBodyNode *floor_rigid_node = new BulletRigidBodyNode(&quot;Ground&quot;);

    floor_rigid_node-&gt;add_shape(floor_shape);

    NodePath np_ground = window-&gt;get_render().attach_new_node(floor_rigid_node);
    np_ground.set_pos(0, 0, -2);
    get_physics_world()-&gt;attach_rigid_body(floor_rigid_node);
    
    // Dynamic world stuff.
    BulletBoxShape *box_shape = new BulletBoxShape(LVecBase3f(0.5, 0.5, 0.5));
    BulletRigidBodyNode *box_rigid_node = new BulletRigidBodyNode(&quot;Box&quot;);

    box_rigid_node-&gt;set_mass(1.0f); // Gravity affects this rigid node.
    box_rigid_node-&gt;add_shape(box_shape);

    NodePath np_box = window-&gt;get_render().attach_new_node(box_rigid_node);
    np_box.set_pos(0, 0, 2);
    get_physics_world()-&gt;attach_rigid_body(box_rigid_node);

    NodePath np_box_model = window-&gt;load_model(framework.get_models(), &quot;models/box&quot;);
    np_box_model.set_pos(-0.5,-0.5,-0.5);
    np_box.flatten_light();
    np_box_model.reparent_to(np_box);

    PT(GenericAsyncTask) task;
    task = new GenericAsyncTask(&quot;Scene update&quot;, &amp;update_scene, (void*) NULL);
    task_mgr-&gt;add(task);

    framework.main_loop();
    framework.close_framework();

    return (0);
}
&lt;/code&gt;[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Bullet Queries</title>
    <ns>0</ns>
    <id>2610</id>
      <sha1>m7mjy4toxly542igo5mdwe5rkyrtm77</sha1>
    <revision>
      <id>7922</id>
      <timestamp>2013-04-08T09:28:57Z</timestamp>
      <contributor>
        <username>Pataua101</username>
        <id>665</id>
      </contributor>
      <minor/>
      <comment>/* Ray Test */</comment>
      <text xml:space="preserve" bytes="4414">Bullet offers a bunch of different queries for retrieving information about collision objects. A common usecase is sensors needed by game logic components. For example to find out if the space in front of an NPC object is blocked by a solid obstacle, or to find out if an NPC can see some other object.


==Ray Test==

Raycasting is to shoot a ray from one position (the from-position) to another position (the to-position). Both the from-position and the to-position have to be specified in global coordinates. The ray test methods will then return a result object which contains information about which objects the ray has hit.

There are two different ray test method: The first method (&lt;code&gt;rayTestAll&lt;/code&gt;) returns all collision objects hit by the ray. But sometimes we are only interested in the first collision object hit by the ray. Then we can use the second ray test method (&lt;code&gt;rayTestClosest&lt;/code&gt;).

Example for closest hit:

[python]&lt;code python&gt;pFrom = Point3(0, 0, 0)
pTo = Point3(10, 0, 0)

result = world.rayTestClosest(pFrom, pTo)

print result.hasHit()
print result.getHitPos()
print result.getHitNormal()
print result.getHitFraction()
print result.getNode()&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;LPoint3f pFrom = LPoint3f(0,0,0);
LPoint3f pTo = LPoint3f(10,0,0);
BulletAllHitsRayResult result = world-&gt;ray_test_closest(pFrom, pTo);&lt;/code&gt;[/cxx]

Example for all hits:

[python]&lt;code python&gt;pFrom = Point3(0, 0, 0)
pTo = pFrom + Vec3(1, 0, 0) * 99999

result = world.rayTestAll(pFrom, pTo)

print result.hasHits()
print result.getClosestHitFraction()
print result.getNumHits()

for hit in result.getHits():
  print hit.getHitPos()
  print hit.getHitNormal()
  print hit.getHitFraction()
  print hit.getNode()&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;LPoint3f pFrom = LPoint3f(0,0,0);
LPoint3f pTo = pFrom + LVector3d(1,0,0) * 99999;
BulletAllHitsRayResult result = world-&gt;ray_test_all(pFrom, pTo);&lt;/code&gt;[/cxx]

Often users want to pick or select an object by clicking on it with the mouse. We can use the &lt;code&gt;rayTestClosest&lt;/code&gt; to find the collision object which is &quot;under&quot; the mouse pointer, but we have to convert the coordinates in camera space to global coordinates world space. The following example shows how this can be done.

[python]&lt;code python&gt;# Get to and from pos in camera coordinates
pMouse = base.mouseWatcherNode.getMouse()
pFrom = Point3()
pTo = Point3()
base.camLens.extrude(pMouse, pFrom, pTo)

# Transform to global coordinates
pFrom = render.getRelativePoint(base.cam, pFrom)
pTo = render.getRelativePoint(base.cam, pTo)&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]

==Sweep Test==

The sweep test is similar to the ray test. There are two differences: (1) The sweep test does not use an infinite thin ray, like the ray test, but checks for collisions with a convex shape which is &quot;moved&quot; along the from from-position to to-position. (2) The sweep test wants to have &quot;from&quot; and &quot;to&quot; specified as &lt;code&gt;TransformState&lt;/code&gt;. The sweep test can for example be used to predict if an object would collide with something else if it was moving from it's current position to some other position.

Example for sweep testing:

[python]&lt;code python&gt;tsFrom = TransformState.makePos(Point3(0, 0, 0))
tsTo = TransformState.makePos(Point3(10, 0, 0))

shape = BulletSphereShape(0.5)
penetration = 0.0

result = world.sweepTestClosest(shape, tsFrom, tsTo, penetration)

print result.hasHit()
print result.getHitPos()
print result.getHitNormal()
print result.getHitFraction()
print result.getNode()&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]


==Contact Test==

There are two contact tests. One which checks if a collision objects is in contact with other collision objects, and another which checks for a pair of collision objects if they are in contact.

Example for contact testing:

[python]&lt;code python&gt;body1 = BulletRigidBodyNode(&quot;body1&quot;)
...

body2 = BulletRigidBodyNode(&quot;body2&quot;)
...

result = world.contactTest(node1)
result = world.contactTestPair(node1, node2)

print result.getNumContacts()

for contact in result.getContacts():
  print contact.getNode0()
  print contact.getNode1()

  mpoint = contact.getManifoldPoint()
  print mpoint.getDistance()
  print mpoint.getAppliedImpulse()
  print mpoint.getPositionWorldOnA()
  print mpoint.getPositionWorldOnB()
  print mpoint.getLocalPointA()
  print mpoint.getLocalPointB()&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Bullet Samples</title>
    <ns>0</ns>
    <id>2654</id>
      <sha1>i71m9fpckbnh396dhdl7te7t8a8bclz</sha1>
    <revision>
      <id>60187</id>
      <timestamp>2014-07-02T18:36:21Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>fix links</comment>
      <text xml:space="preserve" bytes="1657">Learning the Bullet module is best done by looking at working samples. A bunch of tutorials can be downloaded from the following link. The samples include all models and textures.

[{{SERVER}}/download/noversion/bullet-samples.zip bullet-samples.zip] ([{{SERVER}}/download/noversion/bullet-samples.zip.torrent torrent]) ([magnet:?xt=urn:btih:07d4abd932bc8703249d4fd67da62a7e43b32ca0&amp;dn=bullet-samples.zip magnet])

More samples contributed by various users follow below here:

====Stack of cubes falling on top of each other:====
[python]&lt;code python&gt;import direct.directbase.DirectStart
from panda3d.core import Vec3
from panda3d.bullet import BulletWorld
from panda3d.bullet import BulletPlaneShape
from panda3d.bullet import BulletRigidBodyNode
from panda3d.bullet import BulletBoxShape
 
base.cam.setPos(10, -30, 20)
base.cam.lookAt(0, 0, 5)
 
# World
world = BulletWorld()
world.setGravity(Vec3(0, 0, -9.81))
 
# Plane
shape = BulletPlaneShape(Vec3(0, 0, 1), 1)
node = BulletRigidBodyNode('Ground')
node.addShape(shape)
np = render.attachNewNode(node)
np.setPos(0, 0, -2)
world.attachRigidBody(node)
 
# Boxes
model = loader.loadModel('models/box.egg')
model.setPos(-0.5, -0.5, -0.5)
model.flattenLight()
shape = BulletBoxShape(Vec3(0.5, 0.5, 0.5))
for i in range(10):
    node = BulletRigidBodyNode('Box')
    node.setMass(1.0)
    node.addShape(shape)
    np = render.attachNewNode(node)
    np.setPos(0, 0, 2+i*2)
    world.attachRigidBody(node)
    model.copyTo(np)

# Update
def update(task):
  dt = globalClock.getDt()
  world.doPhysics(dt)
  return task.cont
 
taskMgr.add(update, 'update')
run()&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Bullet Softbodies</title>
    <ns>0</ns>
    <id>2614</id>
      <sha1>ey5xi1kneylkuiej2h5h0nvzmbvdwo2</sha1>
    <revision>
      <id>7459</id>
      <timestamp>2011-12-24T12:10:25Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>typos</comment>
      <text xml:space="preserve" bytes="2325">Soft bodies are similar to rigid bodies, just they are not rigid but soft. This means that the shape of a soft body can change - they are deformable. Bullet is capable of simulating soft body deformation in real-time. This is not to be confused with playback of animation. Animation are computed up in front, usually not in real-time, and then saved to a file.

Bullet simulates soft bodies internally by making up a complex compound objects, consisting of nodes and links. The nodes can be best compared to the vertices of a mesh used to render 3D geometry. The links can be visualized as springs in between the nodes; just that this kind of spring not only responds to compression, but also to bending.

Depending on how the nodes and links are arranged it is possible to create three different kinds of soft bodies:

&lt;ul&gt;
&lt;li&gt;
A one dimensional chain of nodes, called a &lt;b&gt;rope&lt;/b&gt;. Each node has two links, one to the previous node, and one to the next node. The only exception are the first node and the last node - they have only one link.
&lt;/li&gt;

&lt;li&gt;
A two dimensional mesh of nodes, called a &lt;b&gt;patch&lt;/b&gt;. The two dimensional mesh can be closed, e. g. the surface of a sphere. In this case Bullet can also assume the volume inside the closed surface mesh should be contained, more or less depending on the setting for the pressure inside the soft body. Typical uses for this kind of soft body are a flag or cloth, or if the soft body is closed an air-filled tire.
&lt;/li&gt;

&lt;li&gt;
Finally a three dimensional mesh made up from &lt;b&gt;tetrahedrons&lt;/b&gt;. For this kind of soft body a surface mesh is not enough. The whole volume of the body has to be composed from small tetrahedrons.
&lt;/li&gt;
&lt;/ul&gt;

All three kinds of soft bodies are simulated using the same class, &lt;code&gt;BulletSoftBodyNode&lt;/code&gt;. It's just a matter of how the links between the nodes are created.

Panda3D currently provides no low-level interface for creating and modifying the soft body nodes and links directly. Soft bodies are created using factory methods which simplify the process for you.


&lt;b&gt;Warning:&lt;/b&gt;
Bullet soft body support within Panda3D is at an early stage. Use it with care.
It is also highly recommended to keep the original Bullet documentation
close at hand, in order to find the right values e. g. for cluster or
collision configuration.</text>
    </revision>
  </page>
  <page>
    <title>Bullet Softbody Config</title>
    <ns>0</ns>
    <id>2612</id>
      <sha1>i5umqyk14m211vhygsolzsx4uka1jfu</sha1>
    <revision>
      <id>7357</id>
      <timestamp>2011-10-03T08:57:09Z</timestamp>
      <contributor>
        <username>Enn0x</username>
        <id>414</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="4257">Bullet uses abbreviated properties which describe a soft bodies behaviour.
Here are explanations for the most important settings, and their mapping to
Bullet properties:


===btSoftBody::Material vs. BulletSoftBodyMaterial:===

&lt;center&gt;
&lt;table border=&quot;1&quot; cellpadding=&quot;1&quot; cellspacing=&quot;0&quot;&gt;
&lt;tr&gt;
&lt;th&gt;btSoftBody::Material&lt;/th&gt;
&lt;th&gt;BulletSoftBodyMaterial&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;m_kLST&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;get/setLinearStiffness&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Linear stiffness&lt;br&gt;Range [0,1]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;m_kAST&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;get/setAngularStiffness&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Angular stiffness&lt;br&gt;Range [0,1]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;m_kVST&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;get/setVolumePreservation&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Volume preservation&lt;br&gt;Range [0,1]&lt;/td&gt;
&lt;/tr&gt;

&lt;/table&gt;
&lt;/center&gt;
&lt;br&gt;


===btSoftBody::Config vs. BulletSoftBodyConfig===

&lt;center&gt;
&lt;table border=&quot;1&quot; cellpadding=&quot;1&quot; cellspacing=&quot;0&quot;&gt;
&lt;tr&gt;
&lt;th&gt;btSoftBody::Config&lt;/th&gt;
&lt;th&gt;BulletSoftBodyConfig&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;kSRHR_CL&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;get/setSoftVsRigidHardness&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Soft vs rigid hardness (cluster only)&lt;br&gt;Range [0,1]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;kSKHR_CL&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;get/setSoftVsKineticHardness&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Soft vs kinetic hardness (cluster only)&lt;br&gt;Range [0,1]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;kSSHR_CL&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;get/setSoftVsSoftHardness&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Soft vs soft hardness (cluster only)&lt;br&gt;Range [0,1]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;kSR_SPLT_CL&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;get/setSoftVsRigidImpulseSplit&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Soft vs rigid impulse split (cluster only)&lt;br&gt;Range [0,1]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;kSK_SPLT_CL&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;get/setSoftVsKineticImpulseSplit&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Soft vs kinetic impulse split (cluster only)&lt;br&gt;Range [0,1]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;kSS_SPLT_CL&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;get/setSoftVsSoftImpulseSplit&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Soft vs soft impulse split (cluster only)&lt;br&gt;Range [0,1]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;kVCF&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;get/setVelocitiesCorrectionFactor&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Velocities correction factor (Baumgarte)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;kDP&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;get/setDampingCoefficient&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Damping coefficient&lt;br&gt;Range [0,1]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;kDG&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;get/setDragCoefficient&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Drag coefficient&lt;br&gt;Range [0,+inf]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;kLF&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;get/setLiftCoefficient&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Lift coefficient&lt;br&gt;Range [0,+inf]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;kPR&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;get/setPressureCoefficient&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Pressure coefficient&lt;br&gt;Range [-inf,+inf]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;kVC&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;get/setVolumeConversationCoefficient&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Volume conversation coefficient&lt;br&gt;Range [0,+inf]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;kDF&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;get/setDynamicFrictionCoefficient&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Dynamic friction coefficient&lt;br&gt;Range [0,1]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;kMT&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;get/setPoseMatchingCoefficient&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Pose matching coefficient&lt;br&gt;Range [0,1]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;kCHR&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;get/setRigidContactsHardness&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Rigid contacts hardness&lt;br&gt;Range [0,1]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;kKHR&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;get/setKineticContactsHardness&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Kinetic contacts hardness&lt;br&gt;Range [0,1]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;kSHR&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;get/setSoftContactsHardness&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Soft contacts hardness&lt;br&gt;Range [0,1]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;kAHR&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;get/setAnchorsHardness&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Anchors hardness&lt;br&gt;Range [0,1]&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;piterations&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;get/setPositionsSolverIterations&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Positions solver iterations&lt;br&gt;Positive integer&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;viterations&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;get/setVelocitiesSolverIterations&lt;/code&gt;&lt;/td&gt;
&lt;td&gt; Velocities solver iterations&lt;br&gt;Positive integer&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;diterations&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;get/setDriftSolverIterations&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Drift solver iterations&lt;br&gt;Positive integer&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;citerations&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;get/setClusterSolverIterations&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Cluster solver iterations&lt;br&gt;Positive integer&lt;/td&gt;
&lt;/tr&gt;

&lt;/table&gt;
&lt;/center&gt;</text>
    </revision>
  </page>
  <page>
    <title>Bullet Softbody Patch</title>
    <ns>0</ns>
    <id>2617</id>
      <sha1>7dcr7su58q2xvi52m3n4e0ov3bnh7n3</sha1>
    <revision>
      <id>7461</id>
      <timestamp>2011-12-24T12:14:54Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>typos</comment>
      <text xml:space="preserve" bytes="3870">Soft body patches are two-dimensional rectangular meshes, which can be used to simulate for example a flag, a tapestry, or sheets of paper.


==Setup==

Setting up a soft body patch is similar to soft body ropes, but a few extra settings have to be done. The following code will create rectangular path with 31 by 31 segments, and thus 32 x 32 nodes.

[python]&lt;code python&gt;from panda3d.bullet import BulletSoftBodyNode
 
info = self.world.getWorldInfo()
info.setAirDensity(1.2)
info.setWaterDensity(0)
info.setWaterOffset(0)
info.setWaterNormal(Vec3(0, 0, 0))

resx = 31
resy = 31

p00 = Point3(-8, -8, 0)
p10 = Point3( 8, -8, 0)
p01 = Point3(-8,  8, 0)
p11 = Point3( 8,  8, 0)

fixeds = 1+2+4+8
gendiags = True

bodyNode = BulletSoftBodyNode.makePatch(info, p00, p10, p01, p11, resx, resy, fixeds, gendiags)

material = bodyNode.appendMaterial()
material.setLinearStiffness(0.4)
bodyNode.generateBendingConstraints(2, material)

bodyNode.setTotalMass(50.0)
bodyNode.getShape(0).setMargin(0.5)
bodyNP = self.worldNP.attachNewNode(bodyNode)
world.attachSoftBody(bodyNode)&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]

First we have to configure the soft body world properties, like we did for soft body ropes too. Next we define variables for the resolution in x- and y-direction, and for the four corner points of the patch.

The variable fixeds is set to the value 1+2+4+8=15, meaning that the patch should be attached to the world on all four corners. To attach it to the first and third corner (diagonal) we would set the value to 1+8=9, and to not attach it at all we would set it to 0.

Now we can create the soft body node using the factory method &lt;code&gt;makePatch&lt;/code&gt;. The following configuration differs from what we have seen for soft body ropes.

* First we create an additional material attached to the soft body. Initially a soft body has already one material, but for this example we want a second one.
* On the material we set the linear stiffness, and the create bending constraints for this material.
* Finally we choose a value of about the grid spacing for the soft bodies margin. Other bodies colliding with the soft body could fall through in between the nodes if the value is too small, and if it is too large they will already collide with the soft body when still noticeably far away. 


==Visualisation==

In order to have a visual representation of the soft body patch we need a &lt;code&gt;GeomNode&lt;/code&gt;. Panda3D's Bullet module has a helper method which will do the work for us. The following code snippet shows how use this helper method.

[python]&lt;code python&gt;from panda3d.core import GeomVertexFormat
from panda3d.bulletimport BulletHelper

fmt = GeomVertexFormat.getV3n3t2()
geom = BulletHelper.makeGeomFromFaces(bodyNode, fmt, True)
bodyNode.linkGeom(geom)
visNode = GeomNode('')
visNode.addGeom(geom)
visNP = bodyNP.attachNewNode(visNode)&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]

The third parameter to &lt;code&gt;makeGeomFromFaces&lt;/code&gt; is set to &lt;code&gt;True&lt;/code&gt;, making the created geometry be two-sided. If set to &lt;code&gt;False&lt;/code&gt; we would get a one-sided geometry, which might be enough, depending on your requirements.

So far the generated geometry has no texture and no texture coordinates.
But the texture has already a column for texcoords, so we just need to write texcoords using a &lt;code&gt;GeomVertexRewriter&lt;/code&gt;. The following code shows a convenience method which will do this for us.

[python]&lt;code python&gt;tex = loader.loadTexture('models/panda.jpg')
visNP.setTexture(tex)
BulletHelper.makeTexcoordsForPatch(geom, resx, resy)&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]

&lt;b&gt;Note:&lt;/b&gt;
It is also possible to render soft body patches using a &lt;code&gt;NurbsSurfaceEvaluator&lt;/code&gt; and &lt;code&gt;SheetNode&lt;/code&gt;, but results are usually better when rendering patches directly, that is using linked &lt;code&gt;Geom&lt;/code&gt;.</text>
    </revision>
  </page>
  <page>
    <title>Bullet Softbody Rope</title>
    <ns>0</ns>
    <id>2615</id>
      <sha1>e6p5v660dza2ebxt2n44dc15bn558bk</sha1>
    <revision>
      <id>7460</id>
      <timestamp>2011-12-24T12:11:57Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>typos</comment>
      <text xml:space="preserve" bytes="5072">Soft body ropes are best compared to chains of interconnected nodes. This page deals with setup, visualization and attaching things to soft body ropes.


==Setup==

The following code will create a soft body rope with 8 segment (variable &lt;code&gt;res&lt;/code&gt;), and thus 8 + 2 = 10 nodes. &lt;code&gt;p1&lt;/code&gt; is the initial position of the first node, and &lt;code&gt;p2&lt;/code&gt; is the initial position of the last node. &lt;code&gt;fixeds&lt;/code&gt; will be explained later on this page.

[python]&lt;code python&gt;from panda3d.bullet import BulletSoftBodyNode

info = self.world.getWorldInfo()
info.setAirDensity(1.2)
info.setWaterDensity(0)
info.setWaterOffset(0)
info.setWaterNormal(Vec3(0, 0, 0))

res = 8
p1 = Point3(0, 0, 4)
p2 = Point3(10, 0, 4)
fixeds = 0

bodyNode = BulletSoftBodyNode.makeRope(info, p1, p2, res, fixeds) 
bodyNode.setTotalMass(50.0)
bodyNP = worldNP.attachNewNode(bodyNode)
world.attachSoftBody(bodyNode)&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]


==Visualisation==

So far we have a physical object, the soft body rope, but aside from the debug renderer this object is not shown in our scene. We need something to visualize the rope.

There are two ways of rendering the rope. First we can make use of a nurbs curse, or we can simple render the rope using geom lines. First we have a look at how to render the rope using geom lines.

[python]&lt;code python&gt;from panda3d.core import GeomNode

geom = BulletHelper.makeGeomFromLinks(bodyNode)

visNode = GeomNode('')
visNode.addGeom(geom)
visNP = bodyNP.attachNewNode(visNode)

bodyNode.linkGeom(geom)&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]

The class &lt;code&gt;BulletHelper&lt;/code&gt; has a convenience method which creates a ready-to-use &lt;code&gt;Geom&lt;/code&gt; for us. We only need to wrap the &lt;code&gt;Geom&lt;/code&gt; in a &lt;code&gt;GeomNode&lt;/code&gt;, and insert it into the scene graph. Since we want the visualisation of the rope to be at the same place as the rope we insert the &lt;code&gt;GeomNode&lt;/code&gt; as a child of the &lt;code&gt;BulletSoftBodyNode&lt;/code&gt;.

There is just one thing missing. The &lt;code&gt;GeomNode&lt;/code&gt; doesn't know that it is the visualization of a soft body rope. When advancing the simulation time the soft body rope will deform, but the visualization will always stay the way it has been created. To fix this we can tell the soft body node that this particular &lt;code&gt;Geom&lt;/code&gt; is it's visualization. The soft body node will now update the &lt;code&gt;Geom&lt;/code&gt; each frame. This is done in the last line, by linking the geom to the soft body node.

The result doesn't look very good. It's just a thin line. But instead of the above code we can use a nurbs curve for visualization.

[python]&lt;code python&gt;from panda3d.core import RopeNode
from panda3d.core import NurbsCurveEvaluator

curve = NurbsCurveEvaluator()
curve.reset(res + 2)

bodyNode.linkCurve(curve)

visNode = RopeNode('')
visNode.setCurve(curve)
visNode.setRenderMode(RopeNode.RMTube)
visNode.setUvMode(RopeNode.UVParametric)
visNode.setNumSubdiv(4)
visNode.setNumSlices(8)
visNode.setThickness(0.4)
visNP = self.worldNP.attachNewNode(visNode)
visNP.setTexture(loader.loadTexture('some_texture.jpg'))&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]

First we create a nurbs curve (&lt;code&gt;NurbsCurveEvaluator&lt;/code&gt;), and then we link this nurbs curve to the soft body rope node. The soft body node will update the nurbs curve every frame from now on.

But we are not done yet. We still need to create something that can be seen in the scene graph. A &lt;code&gt;RopeNode&lt;/code&gt; can render a &lt;code&gt;NurbsCurveEvaluator&lt;/code&gt;. For details on how to configure the &lt;code&gt;RopeNode&lt;/code&gt; please refer to the Panda3D API documentation; both the &lt;code&gt;RopeNode&lt;/code&gt; and the &lt;code&gt;NurbsCurveEvaluator&lt;/code&gt; are not part of the panda3d.bullet, but core Panda3D classes.


==Attaching the rope==

Now we have created a rope, and we can render it. Next we want to attach the rope to something, that is &quot;glue&quot; it either to some other object, usually a rigid body, or to a specific position of the world.

At the beginning of this page we promised to deal with the &lt;code&gt;fixeds&lt;/code&gt; parameter later on the page. This is the place. Using the &lt;code&gt;fixeds&lt;/code&gt; parameter we can attach the rope to a position in the world (global coordinates!). Depending on the value of this parameter we can attach different nodes/vertices of the rope:

&lt;ul&gt;
&lt;li&gt;0: No node/vertex is attached.&lt;/li&gt;
&lt;li&gt;1: Only the first node/vertex is attached.&lt;/li&gt;
&lt;li&gt;2: Only the last node/vertex is attached.&lt;/li&gt;
&lt;li&gt;3: Both the first and the last node/vertex are attached.&lt;/li&gt;
&lt;/ul&gt;

Or we want to attach the soft body rope to a rigid body. In the following code snippet the last node/vertex of a soft body rope is attached to a rigid body.

[python]&lt;code python&gt;# NodePath for some BulletSoftBody &quot;rope&quot;
softNP = ...

# NodePath for some BulletRigidBody
rigidNP = ...

# Index of the last node of the rope
idx = softNP.node().getNumNodes() - 1

# Attach the last node of the rope with the rigid body
softNP.node().appendAnchor(idx, rigidNP.node())&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Bullet Softbody Tetrahedron</title>
    <ns>0</ns>
    <id>2616</id>
      <sha1>reh7ijqjk9monwf1fsvmovgw98noujr</sha1>
    <revision>
      <id>7463</id>
      <timestamp>2011-12-24T12:17:18Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>typo</comment>
      <text xml:space="preserve" bytes="4144">The last kind of soft bodies are those made up from tetrahedral meshes. A tetrahedral mesh is a mesh where the single elements are not triangles, but tetrahedrons, that is &quot;pyramids&quot; with four corners. Tetrahedral meshes are sometimes called &quot;volume&quot; meshes, since they fill out a volume and not just the surface of the mesh.


==Setup==

Setup for tetrahedral soft bodies is more complicated than the previously shown soft body types, since we first have to get the data which describes a tetrahedral mesh. Common 3D modelling packages usually don't support for modelling tetrahedral meshes.

If we somehow have assumed the tetrahedral data we can set up the soft body directly from the vertices and indices. Let's assume we have the vertices as a list of triples (three times a floating point coordinate), and we have the tetrahedron indices as a list of four-tuples (four indices make up one tetrahedron).

[python]&lt;code python&gt;points = [(x1, y1, z1), (x2, y2, z2), ...]
elements = [(i0, i1, i2, i3), (i4, i5, i6, i7), ...]

points = [Point3(x,y,z) * 3 for x,y,z in nodes]
indices = sum([list(x) for x in elements], [])

bodyNode = BulletSoftBodyNode.makeTetMesh(info, points, indices, True)&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]

The third line just transform the list of coordinates into a list of Panda3D points, and the fourth line transforms the list of four-tuples into a flat list of indices.

Assuming we don't have the tetrahedral data prepared for us; in this case we need to create it ourselves. A good tool for this purpose is &quot;tetgen&quot;, which is a tetrahedral mesh generator and Delaunay triangulator. The tetgen homepage is http://tetgen.berlios.de . Panda3D Bullet module has support for setting up soft bodies directly from tetgen mesh files:

[python]&lt;code python&gt;ele = file('models/tetra.1.ele', 'r').read()
face = file('models/tetra.1.face', 'r').read()
node = file('models/tetra.1.node', 'r').read()

bodyNode = BulletSoftBodyNode.makeTetMesh(info, ele, face, node)&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]

Once the soft body is created we still have to set it up properly. The following code snippet shows how to do so:

[python]&lt;code python&gt;bodyNode.setName('Tetra')
bodyNode.setVolumeMass(300)
bodyNode.getShape(0).setMargin(0.01)
bodyNode.getMaterial(0).setLinearStiffness(0.1)
bodyNode.getCfg().setPositionsSolverIterations(1)
bodyNode.getCfg().clearAllCollisionFlags()
bodyNode.getCfg().setCollisionFlag(BulletSoftBodyConfig.CFClusterSoftSoft, True)
bodyNode.getCfg().setCollisionFlag(BulletSoftBodyConfig.CFClusterRigidSoft, True)
bodyNode.generateClusters(6)

bodyNP = self.worldNP.attachNewNode(bodyNode)
bodyNP.setPos(0, 0, 8)
bodyNP.setHpr(45, 0, 0)
world.attachSoftBody(bodyNode)&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]

The method &lt;code&gt;generateClusters&lt;/code&gt; is new. We didn't use this method so far when setting up non-volume soft bodies. It splits the soft body volume up into the given number of small, convex clusters, which consecutively will be used for collision detection with other soft bodies or rigid bodies.


==Visualisation==

There are two different ways to visualise a tetrahedral soft body. First you can let Panda3D generate a &lt;code&gt;Geom&lt;/code&gt; for you, like in the previous two soft body manual pages. The following code shows how to do this:

[python]&lt;code python&gt;geom = BulletHelper.makeGeomFromFaces(node)
visNode = GeomNode('TetraVisual')
visNode.addGeom(geom)
visNP = softNP.attachNewNode(visNode)
bodyNode.linkGeom(geom)&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]

The second way is to use an already existing model - maybe the model which has been used to calculate the tetrahedronal mesh - and link it to the soft body, like the following code snippet shows. Panda3D will compare the vertices of the model with the nodes of the soft body, and link each vertex to the closest soft body node.

[python]&lt;code python&gt;visNP = loader.loadModel('models/cube.egg')
visNP.reparentTo(softNP)

geom = visNP \
    .findAllMatches('**/+GeomNode').getPath(0).node() \
    .modifyGeom(0)
bodyNode.linkGeom(geom)&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Bullet Softbody Triangles</title>
    <ns>0</ns>
    <id>2620</id>
      <sha1>lg6imrrnhjc1jk618e9qly86grp59p3</sha1>
    <revision>
      <id>7462</id>
      <timestamp>2011-12-24T12:16:00Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>typos</comment>
      <text xml:space="preserve" bytes="3407">Soft bodies made from triangular meshes are similar to soft body patches. just that they are not restricted to rectangular meshes; any two-dimensional triangle mesh will do. An interesting use case for such a soft body is a triangular mesh which is closed. Bullet supports simulation of a pressure for the volume captured inside such a soft body.


==Setup==

The following code snippet shows how to setup an gas-filled soft body. Instead of defining the triangle mesh ourselves we use the convenience method &lt;code&gt;makeEllipsoid&lt;/code&gt;, which returns a ready-to-use soft body with the shape of an ellipsoid. The last parameter to this convenience method is the &quot;resolution&quot; of the ellipsoid. The soft body will have more faces if raising this value. Increasing the value will make the soft body more realistic, but it also requires more performance to simulate the soft body.

[python]&lt;code python&gt;# Soft body world information
info = world.getWorldInfo()
info.setAirDensity(1.2)
info.setWaterDensity(0)
info.setWaterOffset(0)
info.setWaterNormal(Vec3(0, 0, 0))

# Softbody
center = Point3(0, 0, 0)
radius = Vec3(1, 1, 1) * 1.5

bodyNode = BulletSoftBodyNode.makeEllipsoid(info, center, radius, 128)
bodyNode.setName('Ellipsoid')
bodyNode.getMaterial(0).setLinearStiffness(0.1)
bodyNode.getCfg().setDynamicFrictionCoefficient(1)
bodyNode.getCfg().setDampingCoefficient(0.001)
bodyNode.getCfg().setPressureCoefficient(1500)
bodyNode.setTotalMass(30, True)
bodyNode.setPose(True, False)

bodyNP = render.attachNewNode(bodyNode)
bodyNP.setPos(15, 0, 12)
bodyNP.setH(90.0)
world.attachSoftBody(bodyNP.node())&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]

When comparing the soft body setup with the previous page, the soft body patch setup, we will find that there are two differences:

* First, there are three lines which get the configuration objects for this soft body (&lt;code&gt;getCfg&lt;/code&gt;), and then set different parameters on this configuration object, in particular the &quot;pressure coefficient&quot;. For more detailed information on what these parameters do it is best to fall back to the original Bullet documentation. A mapping between the original Bullet members of the btSoftBodyConfig class and the Panda3D BulletSoftBodyConfig object returned by &lt;code&gt;getCfg&lt;/code&gt; is given on the manual page [[Bullet Softbody Config]].

* Second, the method &lt;code&gt;setPose&lt;/code&gt; is called. This method sets the current state of the soft body as a &quot;default pose&quot; or &quot;lowest energy state&quot;. The soft body will try to return to this state if possible. The first parameter to this method is the volume flag, and the second parameter the frame flag. It is usually the best thing to set both flags to &lt;code&gt;True&lt;/code&gt;.


==Visualisation==

Again, in order to have a visual representation of the soft body we need a &lt;code&gt;GeomNode&lt;/code&gt;. We can use almost the same code as we have been using for soft body patches. The only difference is that we don't need to make the created geometry two-sided, since the inside of the closed mesh is usually not visible.

[python]&lt;code python&gt;from panda3d.core import GeomVertexFormat
from panda3d.bulletimport BulletHelper

fmt = GeomVertexFormat.getV3n3t2()
geom = BulletHelper.makeGeomFromFaces(bodyNode, fmt)
bodyNode.linkGeom(geom)
visNode = GeomNode('EllipsoidVisual')
visNode.addGeom(geom)
visNP = bodyNP.attachNewNode(visNode)&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Bullet Vehicles</title>
    <ns>0</ns>
    <id>2621</id>
      <sha1>2gdvnkke1dklghrjjjuunk61mczl1b6</sha1>
    <revision>
      <id>7458</id>
      <timestamp>2011-12-24T12:09:01Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>typos</comment>
      <text xml:space="preserve" bytes="5386">Bullet comes with a simple vehicle controller, which can be used for arcade style vehicle simulations. Instead of simulation of each wheel and chassis as separate rigid bodies connected by joints, it simply uses a single rigid body for the chassis. Collision detection for the wheels is approximated by ray casts, and the tire friction is a basic anisotropic friction model. This approach to vehicle modelling is called &quot;raycast vehicle&quot;, and it is used widely in commercial and non-commercial driving games.


==Setup==

In order to create a vehicle we first have to create an ordinary dynamic rigid body. This rigid body will serve as the vehicle chassis. Then we can create a new instance of &lt;code&gt;BulletVehicle&lt;/code&gt;. We have to pass the &lt;code&gt;BulletWorld&lt;/code&gt; and the &lt;code&gt;BulletRigidBodyNode&lt;/code&gt; as arguments to the vehicle constructor.

The following code snippet shows how this could be done.

[python]&lt;code python&gt;from panda3d.bullet import BulletVehicle

# Chassis body
shape = BulletBoxShape(Vec3(0.7, 1.5, 0.5))
ts = TransformState.makePos(Point3(0, 0, 0.5))

chassisNP = render.attachNewNode(BulletRigidBodyNode('Vehicle'))
chassisNP.node().addShape(shape, ts)
chassisNP.setPos(0, 0, 1)
chassisNP.node().setMass(800.0)
chassisNP.node().setDisableDeactivation(True)

world.attachRigidBody(chassisNP.node())

# Chassis geometry
loader.loadModel('path/to/model').reparentTo(chassisNP)

# Vehicle
vehicle = BulletVehicle(world, chassisNP.node())
vehicle.setCoordinateSystem(ZUp)
world.attachVehicle(vehicle)&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]


==Wheels==

One we have created the chassis and the vehicle we can add wheels to the vehicle. We can create a new wheel using the &lt;code&gt;createWheel&lt;/code&gt; factory method of the previously created vehicle. Once created we still have to configure the wheel, that is set friction parameters, offset of the wheel hub with respect to the chassis, axle direction and so on.

The following sample shows how to create and configure a wheel. In this case a front wheel is created. Front wheels are steerable.

[python]&lt;code python&gt;wheelNP = loader.loadModel('path/to/model')
wheelNP.reparentTo(render)

wheel = vehicle.createWheel()

wheel.setNode(wheelNP.node())
wheel.setChassisConnectionPointCs(Point3(0.8, 1.1, 0.3))
wheel.setFrontWheel(True)

wheel.setWheelDirectionCs(Vec3(0, 0, -1))
wheel.setWheelAxleCs(Vec3(1, 0, 0))
wheel.setWheelRadius(0.25)
wheel.setMaxSuspensionTravelCm(40.0)

wheel.setSuspensionStiffness(40.0)
wheel.setWheelsDampingRelaxation(2.3)
wheel.setWheelsDampingCompression(4.4)
wheel.setFrictionSlip(100.0)
wheel.setRollInfluence(0.1)&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]


==Steering and Engine/Brake==

Finally we need to control steering and engine/brakes. This is best done using a task, and keeping the current steering angle around somewhere in a variable. 

Here we use a very simple model of controlling the steering angle. If 'turnLeft' or 'turnRight' keys are pressed the sterring angle will increase/decrease at a constant rate, until a maximum steering angle is achieved. No relaxation is applied. Therefor we also define constants for the maximum steering angle (here: steeringClamp) and the rate at which the steering angle increases/decreases (here: steeringIncrement).

The engine force and brake model shown is very simple too. If 'forward' is pressed then the engine force will be the maximum engine force, otherwise engine force will be zero. Likewise for the brakes.

Once the steering angle and engine/brake forces are determined they will be applied to the wheels. Each wheel - addressed by it's index, i. e. 0 to 3 for a four-wheel car - can be individually assigned values for steering and engine/brake force. This way front/rear drives or four-wheel-drives can be simulated.

The following code snippet shows pseudocode for controlling steering and engine/brakes.

[python]&lt;code python&gt;# Steering info
steering = 0.0            # degree
steeringClamp = 45.0      # degree
steeringIncrement = 120.0 # degree per second

# Process input
engineForce = 0.0
brakeForce = 0.0

if inputState.isSet('forward'):
  engineForce = 1000.0
  brakeForce = 0.0

if inputState.isSet('reverse'):
  engineForce = 0.0
  brakeForce = 100.0

if inputState.isSet('turnLeft'):
  steering += dt * steeringIncrement
  steering = min(steering, steeringClamp)

if inputState.isSet('turnRight'):
  steering -= dt * steeringIncrement
  steering = max(steering, -steeringClamp)

# Apply steering to front wheels
vehicle.setSteeringValue(steering, 0)
vehicle.setSteeringValue(steering, 1)

# Apply engine and brake to rear wheels
vehicle.applyEngineForce(engineForce, 2)
vehicle.applyEngineForce(engineForce, 3)
vehicle.setBrake(brakeForce, 2)
vehicle.setBrake(brakeForce, 3)&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;TODO&lt;/code&gt;[/cxx]

More realistic control models can be invented, in order to meet the control requirements of individual driving games. For example:
* Relaxing the steering angle to zero if the user does no hold down the left or right keys.
* Reducing the maximum steering angle with increasing vehicle speed. 
* Setting engine force based on an analogue input, or alternatively based on the duration of the forward key being pressed down.

However, it is up to you do invent such controls. What Bullet requires is that you provide the steering angle and the engine and brake force.</text>
    </revision>
  </page>
  <page>
    <title>Camera Control</title>
    <ns>0</ns>
    <id>954</id>
      <sha1>oql75vzzrhvbsoc8r0yjau51fl79lm7</sha1>
    <revision>
      <id>2238</id>
      <timestamp>2005-08-30T05:01:51Z</timestamp>
      <contributor>
        <username>Zpavlov</username>
        <id>16</id>
      </contributor>
      <text xml:space="preserve" bytes="364">Panda3D's camera is considered a PandaNode.  It can therefore be manipulated as any other node.

The actual camera is defined in ShowBase as a NodePath named &lt;code&gt;base.cam&lt;/code&gt;.  There is also a plain node above the camera, which is a NodePath called &lt;code&gt;base.camera&lt;/code&gt;.  Generally you want to control the &lt;code&gt;base.camera&lt;/code&gt; NodePath with your code.</text>
    </revision>
  </page>
  <page>
    <title>CgShaderAttrib</title>
    <ns>0</ns>
    <id>1057</id>
    <redirect title="Using Pixel Shaders in Cg" />
      <sha1>54cik7yfvoy9bknxkeexb6z6wn7krdf</sha1>
    <revision>
      <id>2343</id>
      <timestamp>2005-04-17T01:41:57Z</timestamp>
      <contributor>
        <username>Admin</username>
        <id>1</id>
      </contributor>
      <comment>CgShaderAttrib moved to Using Pixel Shaders in Cg</comment>
      <text xml:space="preserve" bytes="40">#REDIRECT [[Using Pixel Shaders in Cg]]
</text>
    </revision>
  </page>
  <page>
    <title>Cg Shader Tutorial</title>
    <ns>0</ns>
    <id>2289</id>
      <sha1>b0khnpqzjyz4hatdzo0ivlnh2r13q2o</sha1>
    <revision>
      <id>7767</id>
      <timestamp>2012-06-12T06:59:58Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="2759">&lt;h2&gt;Cg Shader Tutorials&lt;/h2&gt;

Panda has the ability to process shaders written in the Cg shader language. In this tutorial series, you will learn how to write shaders for Panda in Cg. While there are panda specific things in this tutorial you should be able to learn how to write Cg shaders that can be used in other engines.

&lt;h2&gt;Pre-requisites&lt;/h2&gt;

You should be able to write a simple math program in C. Do not underestimate this. If you start writing your own shaders without any prior knowledge about a C like language it is as hard as starting to write a Panda3D application without knowing anything about Python. Some resources you might want to look at:

*[http://en.wikibooks.org/wiki/C_Programming C Programming Wikibook]

You should have a solid grasp of Panda basics. Read [[A Panda %22Hello World%22 using Python | the hello world]] tutorial and understand the &quot;Solar System&quot; sample that comes with the panda distribution. You should also have a good understanding of how the [[The_Scene_Graph | scene graph]] works. If you're interested in writing a shadow mapping shader, it helps to have a solid understanding of how the [[Depth_Test_and_Depth_Write | depth buffer]] works.

Read the first chapter from [http://http.developer.nvidia.com/CgTutorial/cg_tutorial_chapter01.html NVIDIA's Cg Tutorial]. You do not have to understand it fully, but at least you know who invented Cg and what it is for. The [http://developer.nvidia.com NVIDIA] and [http://developer.amd.com ATI] developer sites also have plenty of useful information about shaders.

You should also have the [[List of Possible Shader Inputs]] page handy.

&lt;h2&gt;Tutorials&lt;/h2&gt;

# [[Cg_Tutorial_Part_1 | Baseline Panda application]]
# [[Cg_Tutorial_Part_2 | The Simplest Possible Shader]]. So simple that its useless.
# The simplest possible useful shader.
# Applying colors to the model as defined in the model file.
# Applying colors with the vertex and fragment shaders. Pass information between the vertex and fragment shader.
# Passing inputs to the shader and controlling it from Panda
# Applying one texture to your models, disregarding colors.
# Applying two textures to your models.
# Explaining details about diffuse lighting.
# Per vertex diffuse lighting with shaders. The concept of spaces is introduced here.
# Per pixel lighting with one point light. Normalization problems that may arise are explained here.
# Per pixel lighting with multiple point lights and attenuation.

&lt;h2&gt;Incomplete Section&lt;/h2&gt;

Note: this section is incomplete.  It will be updated soon.

Although some pages aren't written yet, the sourcecode for all the tutorials is complete. Read this forum topic for more info and links to codes: http://www.panda3d.org/forums/viewtopic.php?t=12515&amp;start=0</text>
    </revision>
  </page>
  <page>
    <title>Cg Tutorial Part 1</title>
    <ns>0</ns>
    <id>2290</id>
      <sha1>lgqvgwkq1z1143djn4iqhqxoce4kdve</sha1>
    <revision>
      <id>7644</id>
      <timestamp>2012-03-08T18:16:19Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>new import system and python code tags</comment>
      <text xml:space="preserve" bytes="8334">&lt;h2&gt;Cg Tutorial Part 1: The Baseline Panda App&lt;/h2&gt;

We'll start by setting up the tutorial project folder. Create a new folder for the tutorial and download the [http://code.google.com/p/p3dst/source/browse/trunk tutorial media] then put the files in the new folder. The zip file contains all the models and textures you will need to follow this tutorial series.

For this first lesson we'll just create a basic Panda python script. We will be modifying this python script as we continue the other lessons. Copy the script below and save it to the folder.

&lt;code python&gt;
# Lesson1.py
import sys

import direct.directbase.DirectStart
from direct.interval.LerpInterval import LerpFunc
from panda3d.core import Texture, TextureStage

base.setBackgroundColor(0.0, 0.0, 0.0)
base.disableMouse()

base.camLens.setNearFar(1.0, 50.0)
base.camLens.setFov(45.0)

camera.setPos(0.0, -20.0, 10.0)
camera.lookAt(0.0, 0.0, 0.0)

root = render.attachNewNode(&quot;Root&quot;)
root.setPos(0.0, 0.0, 0.0)

textureArrow = loader.loadTexture(&quot;arrow.png&quot;)
textureArrow.setWrapU(Texture.WMClamp)
textureArrow.setWrapV(Texture.WMClamp)

stageArrow = TextureStage(&quot;Arrow&quot;)
stageArrow.setSort(1)

textureCircle = loader.loadTexture(&quot;circle.png&quot;)
textureCircle.setWrapU(Texture.WMClamp)
textureCircle.setWrapV(Texture.WMClamp)

stageCircle = TextureStage(&quot;Circle&quot;)
stageCircle.setSort(2)

modelCube = loader.loadModel(&quot;cube.egg&quot;)

cubes = []
for x in [-3.0, 0.0, 3.0]:
    cube = modelCube.copyTo(root)
    cube.setPos(x, 0.0, 0.0)
    cubes += [ cube ]

base.accept(&quot;escape&quot;, sys.exit)

base.accept(&quot;o&quot;, base.oobe)

def animate(t):
    for i in range(len(cubes)):
        cubes[i].setH(t * (2.0 ** i))

interval = LerpFunc(animate, 5.0, 0.0, 360.0)

base.accept(&quot;i&quot;, interval.start)

def move(x, y, z):
    root.setX(root.getX() + x)
    root.setY(root.getY() + y)
    root.setZ(root.getZ() + z)

base.accept(&quot;d&quot;, move, [1.0, 0.0, 0.0])
base.accept(&quot;a&quot;, move, [-1.0, 0.0, 0.0])
base.accept(&quot;w&quot;, move, [0.0, 1.0, 0.0])
base.accept(&quot;s&quot;, move, [0.0, -1.0, 0.0])
base.accept(&quot;e&quot;, move, [0.0, 0.0, 1.0])
base.accept(&quot;q&quot;, move, [0.0, 0.0, -1.0])

run()
&lt;/code&gt;

If you run that script, you'll get the following output below. The controls are q, w, e, a, s, d for moving the camera; 'o' for moving the camera via the mouse, 'i' to start the cubes rotating and 'esc' to quit. You will be modifying this script as you follow this tutorial series.

[[Image:Cg_lesson1_screen.png]]

&lt;h2&gt;3D Models, Shaders and Hardware&lt;/h2&gt;

Now that we have the basic script, lets take a look at how 3d models, shaders and the 3d hardware interact with each other. Please open the file cube.egg with a text editor. Egg files are human readable. We will need this information later on to understand how the vertex shader and the fragment shader works. You can also see how the model looks like in panda by using the pview model viewer.

[[Image:Cg_tut_cube1.png]]

&lt;code egg&gt;
// A vertex entry in an egg file
&lt;Group&gt; {
  &lt;VertexPool&gt; Cube {
    &lt;Vertex&gt; 0 {
      1.0 1.0 -1.0
      &lt;UV&gt; { 1.0 1.0 }
      &lt;RGBA&gt; { 1.0 0.0 0.0 1.0 }
    }
    ...
&lt;/code&gt;

The cube has six faces. Each face has four different vertices. Therefore this cube has 24 vertices. Theoretically a cube only needs eight vertices with each vertex being shared by three faces. The problem with this is that each vertex can only have one color, but what happens if we want each of the six faces to be a different color? This is impossible if the cube is only defined with eight vertices. There are more disadvantages if we only define the cube with eight vertices, which we will talk about later on. The only advantage of having less vertices is that we have to send less vertices to the graphic card but in almost all applications vertices are not a limiting factor. The memory consumption of vertices in comparison to the memory consumption of textures is negligible. Besides the color entry for a vertex, a vertex also has one UV entry associated with it.

Next look at the colors defined in the egg file. If you compare all the color entries, you will only find eight unique colors in the egg file. Why does the model have thousands of colors when viewed in the model viewer then? This is because of linear interpolation, where a value is generated between two different values based on a &quot;distance&quot;. Today graphic cards are very good at linear interpolation with the ability to do billions of linear interpolations per second. The downside is that sometimes the graphic card can ONLY do linear interpolation and you can't change that, even with a shader.

Back to the colors. If you have a red color (1.0, 0.0, 0.0) on one vertex and a dark blue color (0.0, 0.0, 0.5) on the other vertex the graphic card simply interpolates the color for every pixel between this two vertices, even without shaders (only if requested, but Panda3D ask the graphic card to do this). The graphic card doesn't know that a color comes in three parts: Red, Green and Blue. It only knows that it is manipulating values, in this case adjusting the constituent values for Red Green and Blue. Here is an example of how the graphic card interpolates:

&lt;table border='1' cellpadding='4' align='center'&gt;
&lt;tr&gt;
&lt;th&gt;Red Vertex&lt;/th&gt;&lt;th&gt;Blue Vertex&lt;/th&gt;&lt;th&gt;Color value&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;100%&lt;/td&gt;&lt;td&gt;0%&lt;/td&gt;&lt;td&gt;(1.0, 0.0, 0.0)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;75%&lt;/td&gt;&lt;td&gt;25%&lt;/td&gt;&lt;td&gt;(0.75, 0.0, 0.125)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;50%&lt;/td&gt;&lt;td&gt;50%&lt;/td&gt;&lt;td&gt;(0.5, 0.0, 0.25)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;25%&lt;/td&gt;&lt;td&gt;75%&lt;/td&gt;&lt;td&gt;(0.25, 0.0, 0.375)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0%&lt;/td&gt;&lt;td&gt;100%&lt;/td&gt;&lt;td&gt;(0.0, 0.0, 0.5)&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

A simplified version of how the graphic card draws the model (in reality it does not work exactly like this but the result is the same): If the graphic card needs to draw a pixel on a screen it first looks if this pixel is on a vertex. If it is, it can take the color of the vertex and draw a pixel with this color. If not, the graphic card looks at which triangle this pixel belongs. Then it looks at where the vertices of this triangle are and calculates the distance to each of the vertices. Based on this distance and the color of the vertices, it interpolates all color components and draws a pixel with this color.

We've already seen that the graphic card does not care about the fact that a color consists of the three parts R, G and B. The good thing about this is that the graphic card can do the calculations for R independent of the other parts, as is the case for G and B. You may ask, &quot;why should I care&quot;? The advantage is that the graphic card can do calculations for each part in parallel. A graphic card is in general extremely specialized in parallel computing. This is also true for vertex shaders and pixel shaders. Each calculation for a vertex or pixel is done individually. A vertex never knows how what his neighbor looks like and a pixel never knows what his neighbor's color is. This is a reason why graphic card vendors can improve the performance of GPUs faster then CPUs. Vertex and pixel shaders are inherently parallel. The disadvantage of this is that if you need to do some calculations with respect to the neighboring pixel or vertex, you have to create a complex setup that often (but not always) is not fast enough for 60+ FPS games.

A blur filter (like in the glow example) is an example of such a setup. You need at least two passes to create such an effect.

&lt;h2&gt;Modifying the Script&lt;/h2&gt;

We will now modify the script to see how the normal 3D pipeline blends the vertex colors with textures. In the tutorial media, there are two textures, 'arrow.png' and 'circle.png'. We will apply these to the cubes using only Panda.

Place one of the following lines in the script after the cubes are placed in the scenegraph:

&lt;code python&gt;
root.setTexture(stageArrow, textureArrow)
root.setTexture(stageCircle, textureCircle)
&lt;/code&gt;

You will notice that the textures get applied to all of the cubes. Now try placing the textures on individual cubes:

&lt;code python&gt;
cubes[0].setTexture(stageArrow, textureArrow)
cubes[1].setTexture(stageCircle, textureCircle)
cubes[2].setTexture(stageArrow, textureArrow)
cubes[2].setTexture(stageCircle, textureCircle)
&lt;/code&gt;

Now that we have a general idea of how 3D hardware and models work, lets move on to using shaders.

[[Cg_Tutorial_Part_2 | Part 2: The simplest possible shader]]</text>
    </revision>
  </page>
  <page>
    <title>Cg Tutorial Part 10</title>
    <ns>0</ns>
    <id>2305</id>
      <sha1>1478wgn6b96he9spc2qa6dbsk58iv2b</sha1>
    <revision>
      <id>7735</id>
      <timestamp>2012-03-10T07:11:35Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="12272">&lt;h2&gt;Cg Tutorial Part 10: Per vertex diffuse lighting with shaders&lt;/h2&gt;

&lt;code python&gt;

&quot;&quot;&quot;
This time we start with diffuse lighting on our own. There should be no
difference between 8.py and this example. If there is a small difference, than
it is possible that your GPU does not emulate the old fixed function pipeline
with shaders.
&quot;&quot;&quot;
#Lesson10.py

import sys
import math

import direct.directbase.DirectStart
from direct.interval.LerpInterval import LerpFunc
from panda3d.core import PointLight

base.setBackgroundColor(0.0, 0.0, 0.0)
base.disableMouse()

base.camLens.setNearFar(1.0, 50.0)
base.camLens.setFov(45.0)

camera.setPos(0.0, -20.0, 10.0)
camera.lookAt(0.0, 0.0, 0.0)

root = render.attachNewNode(&quot;Root&quot;)

&quot;&quot;&quot;
Because we calculate our own light we do not need a Panda3D point light anymore.
But we create a dummy node to see where the light is.
&quot;&quot;&quot;
light = render.attachNewNode(&quot;Light&quot;)
modelLight = loader.loadModel(&quot;misc/Pointlight.egg.pz&quot;)
modelLight.reparentTo(light)

modelCube = loader.loadModel(&quot;cube.egg&quot;)

cubes = []
for x in [-3.0, 0.0, 3.0]:
    cube = modelCube.copyTo(root)
    cube.setPos(x, 0.0, 0.0)
    cubes += [ cube ]

&quot;&quot;&quot;
DIRTY
In the previous example we had to use the setLight method. This time we have to
apply a shader input manually. If we move around our light node Panda3D updates
the shader input automagically.
Try to enable the light only on one or two cubes.
&quot;&quot;&quot;
shader = loader.loadShader(&quot;lesson10.sha&quot;)
for cube in cubes:
    cube.setShader(shader)
    cube.setShaderInput(&quot;light&quot;, light)

base.accept(&quot;escape&quot;, sys.exit)
base.accept(&quot;o&quot;, base.oobe)

def animate(t):
    radius = 4.3
    angle = math.radians(t)
    x = math.cos(angle) * radius
    y = math.sin(angle) * radius
    z = math.sin(angle) * radius
    light.setPos(x, y, z)

def intervalStartPauseResume(i):
    if i.isStopped():
        i.start()
    elif i.isPaused():
        i.resume()
    else:
        i.pause()

interval = LerpFunc(animate, 10.0, 0.0, 360.0)

base.accept(&quot;i&quot;, intervalStartPauseResume, [interval])

def move(x, y, z):
    root.setX(root.getX() + x)
    root.setY(root.getY() + y)
    root.setZ(root.getZ() + z)

base.accept(&quot;d&quot;, move, [1.0, 0.0, 0.0])
base.accept(&quot;a&quot;, move, [-1.0, 0.0, 0.0])
base.accept(&quot;w&quot;, move, [0.0, 1.0, 0.0])
base.accept(&quot;s&quot;, move, [0.0, -1.0, 0.0])
base.accept(&quot;e&quot;, move, [0.0, 0.0, 1.0])
base.accept(&quot;q&quot;, move, [0.0, 0.0, -1.0])

run()

&lt;/code&gt;

&lt;pre class=&quot;codeblock&quot;&gt;
//Cg
/* lesson10.sha */

/*
We now try to implement what was written in the introduction in 8.py. To
summarize: We like to calculate our lighting equation for each vertex. For this
we need the position of the light and the normal of the vertex.

To achieve this task we need to first talk about spaces. As you already should
now, the vertex shader is feed with the raw vertices (vtx_vertices) from the egg
file, the normals that are introduced here are also unmodified (vtx_normal).
Each cube has his own model space. Maybe you have read the example 2.sha more
closely and have seen that there is a second, commented, vertex shader. In this
shader the most elaborate version transform each vertex from model space to
world space, then from world space to view space and last to the so called clip
space. The light itself is a node like any other, but without any assigned
vertices. So a light has its own &quot;model&quot; space like any other node. When we move
around a cube, we do not modify the cubes model space, nor do we change the
model space of a light if we move the light around. Maybe you see already a new
problem that arises. If we take the blindly take the light and the cubes and
start to do some fancy lighting, we do not get an useful result. What we have to
do first is to transform the cube and/or the light in a space where can do our
calculations in respect to each other. Maybe you think: &quot;Why do we not take the
world space then?&quot;. World space sound nice because in this space, the distance
between two nodes can be calculated easily if you use the length function. If
you move the light 10 units farther away from a node, the output of length to
this light is increased by 10. Problem here is that we have to transform all
model and all lights to world space. In our shaders we never have done this,
because there was no need for it. But we always transformed our models from
model space to clip space with the mat_modelproj matrix. You may ask then: &quot;So
why do we not do our lighting calculations in clip space&quot;. Problem is that clip
space is in 2D and the length function does not work as intended, because we
have applied the projection matrix. The farther away the scene, the closer are
the cubes on your screen. But should we change the lighting only because the
cubes are far away or not? Ok, back to our world space. If we transform our
model to world space, we also have to transform the normals. If you have rotated
your model e.g. the normals of your model also have to be rotated. This may lead
to a problem, that needs some in depth matrix math. In the next sample I try to
explain what the problem is, but for the moment we stick to another possibility.
Instead of transforming your cubes and lights into world space, we can transform
the lights into model space. But because each cube has its own model space, we
need to transform each light into each cubes model space. This sounds
complicated, but remember, until yet, every transformation we have done, we have
done with a matrix, and Pand3D never forsake us. I have already written that
there is problem if we need to transform normals. But with this version, we do
not need to modify the normals because we transform the light position to the
cubes model space. One more question we may answer here: &quot;We do talk about this
world space transformations if it calls for problems anyway?&quot;. The answer
depends on what you like to do. In more complicated shaders you often need to
transform your vertices anyway into world space e.g. for reflections. The other
problems if you e.g. have a static light e.g. a sun. If there is no sunrise and
sunset in your application you maybe encode your light position directly as
constant into the shader. For this case it would be a bit cumbersome to apply
the correct transformation, because you have to do anything on your own. Now we
need to now we transform our light to model space. Long section, simple
solution: You create an uniform called &quot;mspos_light&quot;. That means that Panda3D
transform the position of the node with the name light into model space. Panda3D
changes this matrix for each cube automagically.

Now it is a good time to read some more information about spaces and the
flexibility of Panda3D:

http://www.panda3d.net/wiki/index.php/Shaders_and_Coordinate_Spaces

Now we have two positions and a normal and all these things are in the same
space. If you remember, we like to do a diffuse lighting effect. For this effect
we need the angle between the vertex normal and the direction from the light to
our vertex. The direction we get when we subtract both positions, the normal we
already have. Sometimes it helps to draw a 2D draft on a paper to see what
happens.

In the following drawing L is the light position, in this example at position
(1, 1). V is the vertex position in this example at (7, 1). The vertex has a
normal direction of (-1, 0). The direction vector between the light and the
vertex is (-6, 0).

 L   &lt;-V

If you imagine this two directions (-1, 0) and (-6, 0) they both lay on each
other, that means the angle between this two directions is 0 degree. If you have
read the Wikipedia article about the dot product you may have seen a cosine
there. If we now take the cosine of 0 degree we get 1. 1 is the maximum a cosine
can yield, therefore 1 must mean maximal lighting. If you look back at our draft
you can see that this is exactly what we want here. Here is another example.

     ^
     |
 L   V

The Light is at (1, 5), the vertex is at (5, 5) and the vertex normal points
toward (0, 1). The direction between the light and vertex is (-4, 0). But this
time the angle between this two directions is 90 degree. The cosine of 90 degree
is 0. Imagine a light beam that travels to a face where all vertex normal look
upwards like in the drawing. This light beam will not touch a single point on
this surface. Therefore if our cosine yields zero or lesser, that means no
lighting at all. In the vertex shader there is a function saturate. Saturate
clamps a value to the range 0 - 1. A cosine yields a number between -1 and +1.
With saturate we can trim it to 0 - 1.

There is one final question about this vertex shader. There are two calls to
normalize. Normalize modifies a vector so it has an exact length of one unit
afterwards. There are tons of reasons why you should normalize, here we talk
only about one reason. Wikipedia says the following about the dot product:

dot(a, b) = length(a) * length(b) * cos(phi)

Do you see the problem? We only care about cos(phi). Not even phi itself
interests us. But if a and b are not normalized, the length of this two
direction vectors may be large. With other words, the farther away our light,
the brighter our light shines. Normally we want the exact opposite, but in this
example we say it is a point sunlight so we have no attenuation at all. If we
normalize our vectors correctly, their length is by definition exactly 1, there
neither length(a) nor length(b) will influence the dot product.

The only problem here is that normalize is an expensive function because it
introduces a square root. 4.sha has the same note about the length function. The
function normalize is defined as follow:

def normalize(n):
    return n / length(n)
*/

/*
Besides the mathematical problems in this sample, there is nothing really new
here. Only the uniform vtx_normal and the uniform mspos_light are new here, but
I hope they are already explained enough.

Maybe you remember the sample 2.sha. There was more than one vertex shader,
although all had an identical result. If you are a brave one, try to rewrite
this shader so it works with world positions. I have written that there are some
problems if we transform the normals, but for the moment forget this (it is only
a problem in some circumstances). The following uniforms may help you:

trans_model_to_world wspos_light

The uniform mspos_light is not needed anymore. Besides this two new uniforms,
two new call to the function mul are needed (You may send me the result if you
like).

you only need to modify the vertex shader for this. You do not have to touch the
python sample. If you have modified the vertex shader make screen shot of our
output and compare it with the unmodified shader here. Only if there is no
visual difference between them you have done everything right. After you have
modified the shader, use the method setHpr (e.g. setH(90.0)) on any cube and
look once more to you example (do not use setScale or setShear for this test).
Still no difference? */
void vshader(
    uniform float4x4 mat_modelproj,
    uniform float4 mspos_light,
    in float4 vtx_position : POSITION,
    in float3 vtx_normal : NORMAL,
    in float4 vtx_color : COLOR,
    out float4 l_color : COLOR,
    out float4 l_position : POSITION)
{
    l_position = mul(mat_modelproj, vtx_position);

    float3 lightposition = mspos_light.xyz;
    float3 modelposition = vtx_position.xyz;
    float3 normal = normalize(vtx_normal);
    float3 direction = normalize(lightposition - modelposition);
    float brightness = saturate(dot(normal, direction));

    l_color = vtx_color * brightness;
}

/*
If something has to be explained here, then something went wrong.

Because all the work is done in the vertex shader, this form if lighting is
called per vertex lighting.
*/
void fshader(
    in float4 l_color : COLOR,
    out float4 o_color : COLOR)
{
    o_color = l_color;
}

/*
A small note why some calculations are done in world space or model space. This
two spaces, behave (at least in Panda3D) like our physical space (relativity
disregarded).

http://en.wikipedia.org/wiki/Euclidean_geometry

E.g. If you have two cubes with a distance of 10 units you can transform them in
any other space with Euclidean properties, and the distance between the two
cubes are still 10 units.
*/
&lt;/pre&gt;</text>
    </revision>
  </page>
  <page>
    <title>Cg Tutorial Part 11</title>
    <ns>0</ns>
    <id>2306</id>
      <sha1>qqtbpqqqer5bdbzz0roh8si4tm8lz44</sha1>
    <revision>
      <id>7736</id>
      <timestamp>2012-03-10T07:12:16Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="9887">&lt;h2&gt;Cg Tutorial Part 11: Per pixel lighting with one point light&lt;/h2&gt;

&lt;code python&gt;
#Lesson 11

&quot;&quot;&quot;
Nothing new here. It is the same as 9.py.
&quot;&quot;&quot;

import sys
import math

import direct.directbase.DirectStart
from direct.interval.LerpInterval import LerpFunc
from panda3d.core import PointLight

base.setBackgroundColor(0.0, 0.0, 0.3)
base.disableMouse()

base.camLens.setNearFar(1.0, 50.0)
base.camLens.setFov(45.0)

camera.setPos(0.0, -20.0, 10.0)
camera.lookAt(0.0, 0.0, 0.0)

root = render.attachNewNode(&quot;Root&quot;)

light = render.attachNewNode(&quot;Light&quot;)
modelLight = loader.loadModel(&quot;misc/Pointlight.egg.pz&quot;)
modelLight.reparentTo(light)

&quot;&quot;&quot;
After reading 10.sha replace cube.egg with cube-smooth.egg once more. Because we
now have per pixel lighting, you see a great visual difference if a light only
covers a small portion of face.
The smaller the faces are, the less you see a difference between per pixel and
per vertex lighting. But if you have large triangles, that may cover your whole
screen, you can see a great difference between this two lighting methods.
&quot;&quot;&quot;
modelCube = loader.loadModel(&quot;cube.egg&quot;)

cubes = []
for x in [-3.0, 0.0, 3.0]:
    cube = modelCube.copyTo(root)
    cube.setPos(x, 0.0, 0.0)
    cubes += [ cube ]

shader = loader.loadShader(&quot;lesson11.sha&quot;)
for cube in cubes:
    cube.setShader(shader)
    cube.setShaderInput(&quot;light&quot;, light)

base.accept(&quot;escape&quot;, sys.exit)
base.accept(&quot;o&quot;, base.oobe)

def animate(t):
    radius = 4.3
    angle = math.radians(t)
    x = math.cos(angle) * radius
    y = math.sin(angle) * radius
    z = math.sin(angle) * radius
    light.setPos(x, y, z)

def intervalStartPauseResume(i):
    if i.isStopped():
        i.start()
    elif i.isPaused():
        i.resume()
    else:
        i.pause()

interval = LerpFunc(animate, 10.0, 0.0, 360.0)

base.accept(&quot;i&quot;, intervalStartPauseResume, [interval])

def move(x, y, z):
    root.setX(root.getX() + x)
    root.setY(root.getY() + y)
    root.setZ(root.getZ() + z)

base.accept(&quot;d&quot;, move, [1.0, 0.0, 0.0])
base.accept(&quot;a&quot;, move, [-1.0, 0.0, 0.0])
base.accept(&quot;w&quot;, move, [0.0, 1.0, 0.0])
base.accept(&quot;s&quot;, move, [0.0, -1.0, 0.0])
base.accept(&quot;e&quot;, move, [0.0, 0.0, 1.0])
base.accept(&quot;q&quot;, move, [0.0, 0.0, -1.0])

run()

&lt;/code&gt;

&lt;pre class=&quot;codeblock&quot;&gt;
//Cg
/* lesson11.sha */

/*
Beside that we have moved most of the source from the vertex shader to the
fragment shader, there is nothing new here. I like to talk about a generic
problem about normalization of normals (not about direction vectors). As I
already explained, one reason why normalization, is because the dot product only
yields useful results for lighting equations if vectors are normalized.

We start with our first problem, that we sometimes need to do our calculations in
world space. It is possible that a cube has is rotated. Therefore we need to
rotate the normals too. The most obvious, but wrong, idea is to transform the
normals with the modelview matrix, like the vertices. Open the figures.svg or
figures.png once more. In figure 10-1 we have a face that consists of two
vertices. Both vertices have a normal. Given that you apply a non uniform
setScale to your model. With non uniform we mean, that you do not scale your
model in each direction with the same scale. In the second picture in figure
10-1 we have a modelview matrix that only scale our model in one direction. If
you know apply the same matrix to your model, the normals look like the red
normals. Even if you normalize them, they look at the wrong direction. If you
apply a better matrix to the normals, they would look like in the third image in
figure 10-1.
There are two possibilities. Never apply non uniform scaling to your models. If
you can avoid using setScale at all, you maybe even do not need a call to
normalize if you like to use your modelview matrix. It is a bit to much math
here if I like to explain how you have to build our own correct normalization
matrix. Google for the term gl_NormalMatrix. The OpenGL Shading Language GLSL
has matrix that solves exactly this problems, and it is not too much magic to
recreate it in Panda3D after you understand the math behind it. The main reason
why I have added this chapter is that you are warned. It is easy to add subtle
(the normals are not completely wrong in the figure even with a non uniform
scaling) errors to your shader if you forget it.

Now to our second problem. If you look closer at the the vertex shader and the
fragment shader you may see that we normalize the normal twice. When you look at
figure 10-2 you see two blue normals in the first image. The left most normal is
not normalized, while the right most is. If the GPU now sends this normals from
the vertex shader to the pixel shader, the normals are linearly interpolated.
But even after normalizing them in the fragment shader you can see that they are
still facing in the wrong direction. If we first normalize both blue normals,
the result may look like in the third image. The normals are not normalized, but
after we do this, the are pointing in the intended direction.

Maybe whenever you design your own shaders, try to draw different cases on a
sheet of paper. Think of some worst cases, and do the interpolation on your own.
A simple graphic program may be helpful, because if you scale your models, most
vector drawing programs, scale your drawings also linearly.
*/

/*
Because we do our calculations in the pixel shader we need the vertex position
and the vertex normal in the pixel shader.
*/
void vshader(
    uniform float4x4 mat_modelproj,
    in float4 vtx_position : POSITION,
    in float3 vtx_normal : NORMAL,
    in float4 vtx_color : COLOR,
    out float4 l_color : COLOR,
    out float3 l_myposition : TEXCOORD0,
    out float3 l_mynormal : TEXCOORD1,
    out float4 l_position : POSITION)
{
    l_position = mul(mat_modelproj, vtx_position);

    l_myposition = vtx_position.xyz;

    /*
    DIRTY
    As already written, remove normalize in the following line only if your
    normals in the egg file are normalized.
    Without a modification all normals in the cube.egg have an exact length of
    1.0. Try to modify the six face normale in the cube.egg file and assign
    different lengths. With the call to normalize you should not see any visual
    difference. After modifying the normals remove the call to normalize.
    */
    l_mynormal = normalize(vtx_normal);

    l_color = vtx_color;
}

/*
We do the same calculations here as in the vertex shader in the previous sample.
You may ask: &quot;We have the same equations here, and only moved around some
code?&quot;. We are a bit lazy here. The calculation of the direction vector
introduces no nonlinearity so it is possible to move this calculation entirely
to the vertex shader (try it on your own, I have not done it here because it
makes things more complex). The problem here is the dot function with the
cosine. If we we calculate the cosine in the vertex shader, the GPU than
interpolate it and we finally use it in the fragment shader, the result is not
exactly the cosine, as if we calculate it in the fragment shader.

If you are able to move only the direction calculation to the vertex shader,
without introducing any visual artifacts, I probably can not teach you anything
more about Cg itself. Congratulation if your attempt was successful.
*/
void fshader(
    uniform float4 mspos_light,
    in float3 l_myposition : TEXCOORD0,
    in float3 l_mynormal : TEXCOORD1,
    in float4 l_color : COLOR,
    out float4 o_color : COLOR)
{
    float3 lightposition = mspos_light.xyz;
    float3 modelposition = l_myposition;
    float3 normal = normalize(l_mynormal);
    float3 direction = normalize(lightposition - modelposition);
    float brightness = saturate(dot(normal, direction));

    o_color = l_color * brightness;
}

/*
Some notes about normalizing normals. If you create an sphere e.g. in Blender
with a length of 1.0 then all vertices should have coordinates, as if the lay on
a perfect sphere, although the whole sphere is only an approximation. Because
the sphere has a radius of 1.0 the length of each vertex should be exactly 1.0.
The same is true for normals. On a smooth sphere every normal should exactly
point outwards and should have a length of 1.0. If you think about it, you come
to the conclusion that the vertex and the normal should have equal coordinates.
But if I export the sphere with Blender there are some differences between the
normal and vertex coordinates. The next problem is that the egg File is human
readable and numbers therefore are stored in decimal system. An FPU internally
stores a float in a binary system, so we loose some precision here. What I like
to say: Maybe it is sometimes not a bad idea to normalize your normals (only in
this unmodified example, sometimes, you throw away accuracy if you normalize a
vector), even if you think they should be already normalized.

Here is a small hint if you were brave enough to implement your own vertex
shader that passes around the direction instead of the light position and the
model position. For this special case you should not normalize your direction
vector in the vertex shader. Try to draw two 2D directions vector on paper, one
4 times longer than the other one. First interpolate between these two vectors
without normalization, then with normalization, maybe you see that the direction
that lays in between is not the same in both cases.
This vertex shader has one drawback that needs a note. If you have eight lights,
you need to pass around eight direction vectors. But every GPU has its own
limitations about the maximum TEXCOORDS that may be used. It is a tradeoff
between speed and GPU requirements.

You may start to see that the greatest problem in writing shaders is not Cg. The
problem is that even simple shaders, often need a lot of brain power to craft
them more or less correctly.
*/
&lt;/pre&gt;</text>
    </revision>
  </page>
  <page>
    <title>Cg Tutorial Part 12</title>
    <ns>0</ns>
    <id>2307</id>
      <sha1>fqm7fjn5du921tavgntl5dbf3j32kfl</sha1>
    <revision>
      <id>7737</id>
      <timestamp>2012-03-10T07:12:48Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="4641">&lt;h2&gt;Cg Tutorial Part 12: Per pixel lighting with multiple point lights and attenuation&lt;/h2&gt;

&lt;code python&gt;
#Lesson 12

&quot;&quot;&quot;
Instead of only one light, we added here two another lights.
&quot;&quot;&quot;

import sys
import math

import direct.directbase.DirectStart
from direct.interval.LerpInterval import LerpFunc
from panda3d.core import PointLight

base.setBackgroundColor(0.0, 0.0, 0.2)
base.disableMouse()

base.camLens.setNearFar(1.0, 50.0)
base.camLens.setFov(45.0)

camera.setPos(0.0, -20.0, 10.0)
camera.lookAt(0.0, 0.0, 0.0)

root = render.attachNewNode(&quot;Root&quot;)

lights = []

for i in range(3):
    light = render.attachNewNode(&quot;Light&quot;)
    modelLight = loader.loadModel(&quot;misc/Pointlight.egg.pz&quot;)
    modelLight.reparentTo(light)
    lights += [ light ]

modelCube = loader.loadModel(&quot;cube.egg&quot;)

cubes = []
for x in [-3.0, 0.0, 3.0]:
    cube = modelCube.copyTo(root)
    cube.setPos(x, 0.0, 0.0)
    cubes += [ cube ]

shader = loader.loadShader(&quot;lesson12.sha&quot;)
for cube in cubes:
    cube.setShader(shader)
    for i in range(len(lights)):
        cube.setShaderInput(&quot;light&quot; + str(i), lights[i])

base.accept(&quot;escape&quot;, sys.exit)
base.accept(&quot;o&quot;, base.oobe)

def animate(t):
    radius = 4.3
    angle = math.radians(t)
    x = math.cos(angle) * radius
    y = math.sin(angle) * radius
    z = math.sin(angle) * radius
    lights[0].setPos(x, y, z)
    lights[1].setPos(y, x, 0.0)
    lights[2].setPos(z, 0.0, x)

def intervalStartPauseResume(i):
    if i.isStopped():
        i.start()
    elif i.isPaused():
        i.resume()
    else:
        i.pause()

interval = LerpFunc(animate, 10.0, 0.0, 360.0)

base.accept(&quot;i&quot;, intervalStartPauseResume, [interval])

def move(x, y, z):
    root.setX(root.getX() + x)
    root.setY(root.getY() + y)
    root.setZ(root.getZ() + z)

base.accept(&quot;d&quot;, move, [1.0, 0.0, 0.0])
base.accept(&quot;a&quot;, move, [-1.0, 0.0, 0.0])
base.accept(&quot;w&quot;, move, [0.0, 1.0, 0.0])
base.accept(&quot;s&quot;, move, [0.0, -1.0, 0.0])
base.accept(&quot;e&quot;, move, [0.0, 0.0, 1.0])
base.accept(&quot;q&quot;, move, [0.0, 0.0, -1.0])

run()

&lt;/code&gt;

&lt;pre class=&quot;codeblock&quot;&gt;
//Cg
/* lesson12.sha */

/*
Cg does not offers lot of high level constructs like classes in C++. It is more
like C. Functions are therefore possible, and are used in this example.
*/

/*
Like in the previous shader we do all our work in the pixel shader, therefore we
do not have to add anything to our vertex shader.
*/
void vshader(
    uniform float4x4 mat_modelproj,
    in float4 vtx_position : POSITION,
    in float3 vtx_normal : NORMAL,
    in float4 vtx_color : COLOR,
    out float4 l_color : COLOR,
    out float3 l_myposition : TEXCOORD0,
    out float3 l_mynormal : TEXCOORD1,
    out float4 l_position : POSITION)
{
    l_position = mul(mat_modelproj, vtx_position);

    l_myposition = vtx_position.xyz;
    l_mynormal = normalize(vtx_normal);

    l_color = vtx_color;
}

float lit(float3 lightposition, float3 modelposition, float3 normal)
{
    float3 direction = lightposition - modelposition;
    float distance = length(direction);
    float diffuse = saturate(dot(normalize(normal), normalize(direction)));
    /*
    Normally you would define the following constants in Python source and pass
    them this shader. We are a bit lazy here and hard code them in this
    function.
    */
    float a = 0.0;
    float b = 0.0;
    float c = 1.0;
    /*
    DIRTY
    If you like to achieve the same results as the fixed function pipeline you
    should add a saturate here. But I think, that it looks quite nice, if you
    get extremely bright spots when a light source is near a face, even is the
    face is dark.
    */
    float attenuation = 1.0 / (a + b * distance + c * distance * distance);
    return attenuation * diffuse;
}

/*
Because we have extended the lighting equations in a separate function, the
fragment shader looks clean. It would be simple to add more lights. The only
limits here is that every GPU only supports a limited number of uniforms and
shader instructions. So you maybe cannot add hundreds of lights, besides that it
takes an endless amount of time to do per pixel lighting with hundred lights.
*/
void fshader(
    uniform float4 mspos_light0,
    uniform float4 mspos_light1,
    uniform float4 mspos_light2,
    in float3 l_myposition : TEXCOORD0,
    in float3 l_mynormal : TEXCOORD1,
    in float4 l_color : COLOR,
    out float4 o_color : COLOR)
{
    float brightness = 0.0;

    brightness += lit(mspos_light0.xyz, l_myposition, l_mynormal);
    brightness += lit(mspos_light1.xyz, l_myposition, l_mynormal);
    brightness += lit(mspos_light2.xyz, l_myposition, l_mynormal);

    o_color = l_color * brightness;
}

&lt;/pre&gt;</text>
    </revision>
  </page>
  <page>
    <title>Cg Tutorial Part 2</title>
    <ns>0</ns>
    <id>2293</id>
      <sha1>4xjajko0dn2pjk30cosrxzjjk2s9qll</sha1>
    <revision>
      <id>6579</id>
      <timestamp>2010-02-04T15:44:55Z</timestamp>
      <contributor>
        <username>Gogg</username>
        <id>389</id>
      </contributor>
      <text xml:space="preserve" bytes="7197">&lt;h2&gt;Cg Tutorial Part 2: The Simplest Shader&lt;/h2&gt;

In this part of the tutorial, we will introduce the barest shader possible and then modify the python application to load this shader to verify that it works. How would we know that it works? Well, this shader is so simple that it basically makes our application useless and all we will see is a black screen.

&lt;h2&gt;The Shader&lt;/h2&gt;

&lt;code cg&gt;
//Cg
/* lesson2.sha */

void vshader(
    out float4 l_position : POSITION)
{
    l_position = float4(0.0, 0.0, 0.0, 1.0);
}

void fshader(
    out float4 o_color : COLOR)
{
    o_color = float4(1.0, 0.0, 1.0, 1.0);
}
&lt;/code&gt;

We'll only go through the basics of this shader for now. Also note that not everything in this tutorial is a Cg requirement, some of the things such as variable names are Panda3d requirements.

The first important thing in this shader is the first line, the &lt;code&gt;//Cg&lt;/code&gt; comment. Removing it will cause the shader to fail compilation. This is a panda requirement, telling the engine that the shader being loaded is a Cg shader. Second, you see two functions; vshader and fshader. These are the respective entry points for the vertex and fragment shaders.

The only requirements for a vertex shader is that it has to generate a position. In Panda, objects move in three dimensions so having an output of 3 positions should be enough but on reading the vertex shader you can see that its output is a float4. A float4 is an array of four float values, so what possible use is the fourth value to the vertex shader? With this fourth value, you can do some fancy stuff that you cannot do with a float3. In later examples we will multiply the output with a float4 matrix, in other words 16 float values. A float3 cannot be multiplied by a float4 matrix. You can think of the fourth value in the same way as the fourth component in an RGBA color, the alpha component. Its not often necessary but it allows you to do interesting things.

In this vertex shader, the only thing that we are doing is assigning the variable l_position a constant float4. In C/C++/C# you cannot assign arrays to arrays the way we do it here, but in Cg this is possible for fixed sized arrays. The l_position variable can be renamed into anything you like, as long as it is prefixed with l_ and it has the &quot;POSITION&quot; keyword attached.

Why do we have to write &quot;out&quot; in front of l_position? In C/C++/C# every function has at most one return value but shaders often need to return more than one value. The NVIDIA guys added an &quot;in&quot; keyword and an &quot;out&quot; keyword to Cg. &quot;out&quot; means that it is a return value. &quot;in&quot; means that is an input value. This basic shader has no inputs at all and this is one of the main reasons it cannot produce any useful results. Here we only output l_position but in later examples we will have more then one output value.

The &quot;POSITION&quot; keyword is a hint for the GPU. The GPU then knows that is should assign l_position to an internal POSITION register (register is a simplification, this term might not be precise). This tells the GPU that it will later have to draw the output of POSITION on the screen. Currently the GPU does not know what color the pixels will have but it can calculate a position on the screen for every given POSITION. The GPU itself is not as smart as one might think, we need to do some not so simple math first to help the GPU calculate the correct position on the screen.

More or less everything that was said about the vertex shader is true for the fragment shader. The minimum requirement is that a fragment shader has to create a color, to do this we have to assign a float4 to o_color. Again, you can name this anything you like, but this time it needs to be prefixed with o_ and have the &quot;COLOR&quot; keyword attached.

Here the GPU needs the keyword &quot;COLOR&quot; for o_color. This is hint for the GPU that we would like to assign a float4 to the color buffer of your screen. As you may know, the range of a color component is 0 - 255 for R, G and B. That is a fact the GPU knows and it translates the floating point values to integers. The advantage of writing shaders in floating point is that if 48 bit color displays become common, we do not have to change our shader and neither would we have to change our shader if we only have a 16 bit color depth.

&lt;h2&gt;The Python Script&lt;/h2&gt;

The only thing we will change in our panda script is to load our shader file and assign the shader on our root node. Run the script and you will see a black screen, so theres no point in providing a screenshot for this one!

&lt;code python&gt;
#Lesson2.py

import sys
import direct.directbase.DirectStart

base.setBackgroundColor(0.0, 0.0, 0.0)
base.disableMouse()

base.camLens.setNearFar(1.0, 50.0)
base.camLens.setFov(45.0)

camera.setPos(0.0, -20.0, 10.0)
camera.lookAt(0.0, 0.0, 0.0)

root = render.attachNewNode(&quot;Root&quot;)

modelCube = loader.loadModel(&quot;cube.egg&quot;)

cubes = []
for x in [-3.0, 0.0, 3.0]:
    cube = modelCube.copyTo(root)
    cube.setPos(x, 0.0, 0.0)
    cubes += [ cube ]

# Load the shader from the file.
shader = loader.loadShader(&quot;lesson2.sha&quot;)
# Assign the shader to work on the root node
# If you remove the line below, you will see
# that panda is actually rendering our scene.
root.setShader(shader)

base.accept(&quot;escape&quot;, sys.exit)
base.accept(&quot;o&quot;, base.oobe)

def move(x, y, z):
    root.setX(root.getX() + x)
    root.setY(root.getY() + y)
    root.setZ(root.getZ() + z)

base.accept(&quot;d&quot;, move, [1.0, 0.0, 0.0])
base.accept(&quot;a&quot;, move, [-1.0, 0.0, 0.0])
base.accept(&quot;w&quot;, move, [0.0, 1.0, 0.0])
base.accept(&quot;s&quot;, move, [0.0, -1.0, 0.0])
base.accept(&quot;e&quot;, move, [0.0, 0.0, 1.0])
base.accept(&quot;q&quot;, move, [0.0, 0.0, -1.0])

run()
&lt;/code&gt;

&lt;h2&gt;Modifying the Shader&lt;/h2&gt;

Let's modify the shader to get some idea of what we can do in Cg. We still won't be producing any output yet but it will give you a good overview of how to write in Cg.

First lets see what happens when we try to use a float3 as the shader output. Try changing the vertex shader to the sample below and then running the panda script. Examine the console output carefully.

&lt;code cg&gt;
void vshader(
    out float4 l_position : POSITION)
{
    l_position = float3(0.0, 0.0, 0.0, 1.0);
}
&lt;/code&gt;

Now this next vertex shader does exactly the same thing as the original shader but shows how you can assign fixed length arrays to other fixed length arrays in Cg.

&lt;code cg&gt;
void vshader(
    out float4 l_position : POSITION)
{
    float4 zero = float4(0.0, 0.0, 0.0, 1.0);
    l_position = zero;
}
&lt;/code&gt;

Finally lets do some useless maths in the vertex shader. Also note how you can assign a value to l_position more than once. You should try making your own modifications to the shader and see if it can compile

&lt;code cg&gt;
void vshader(
    out float4 l_position : POSITION)
{
    float4 zero = float4(0.0, 0.0, 0.0, 1.0);
    zero = zero * float4(1.0, 2.0, 3.0, 4.0);
    zero = zero * 5.0;
    l_position = zero;
    l_position = float4(0.0, 0.0, 0.0, 1.0);
}
&lt;/code&gt;

After modifying the vertex shader, try to modify the fragment shader on your own. In the next tutorial, we will improve the shader's usefulness.

[[Cg Tutorial Part 3|Part 3: The Simplest Possible Useful Shader]]</text>
    </revision>
  </page>
  <page>
    <title>Cg Tutorial Part 3</title>
    <ns>0</ns>
    <id>2296</id>
      <sha1>q4ps02diyrqn260sli69lqa398vy1iu</sha1>
    <revision>
      <id>7768</id>
      <timestamp>2012-06-12T08:09:12Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>geometry shaders now supported</comment>
      <text xml:space="preserve" bytes="3469">&lt;h2&gt;Cg Tutorial Part 3: The Simplest Useful Shader&lt;/h2&gt;

Here our shader will actually have useful output. It won't be anything fancy, just the silhouettes of the boxes since we're not doing anything with the lighting just yet. To recap, there are two types of shaders. Vertex shaders and fragment shaders. In DirectX these are called vertex shaders and pixel shaders. Fragment shader is a more accurate name for it but for the moment think of fragments as the equivalent of pixels.

&lt;h2&gt;The Shader&lt;/h2&gt;

&lt;code cg&gt;
void vshader(
    uniform float4x4 mat_modelproj,
    in float4 vtx_position : POSITION,
    out float4 l_position : POSITION)
{
    l_position = mul(mat_modelproj, vtx_position);
}

void fshader(
    out float4 o_color : COLOR)
{
    o_color = float4(1.0, 0.0, 1.0, 1.0);
}
&lt;/code&gt;

The vshader function is called once for every processed vertex while fshader is called for every drawn pixel. Because our cube has 24 vertices, vshader is called 24 times per cube in this example. fshader is called for every visible pixel of this cube. The larger the cube on the screen, the more often fshader needs to be called. We cannot say if it is called 100 times or 1000 times per cube. If the cube is far away and we only see one pixel on the screen then vshader is still called 24 times while fshader may only be called once. The vertex shader is always called before the fragment shader. As mentioned in the previous tutorial, a vertex that is being processed knows nothing about the other vertices and this allows shader processing to be parallelized, that is the GPU can process multiple shader calls at the same time.

Given a 800x600 screen, the GPU needs to process 480,000 fragment shader calls. As even the highest end GPU right now doesn't have that many processors, each processor will run the fragment shader multiple times. If your fragment or vertex shader is too complex, the GPU would not be able to process it in a timely manner and the FPS would drop. Today shaders can be complex but you should not expect a single shader to be able to do everything. Often you would need to write many specialized shaders which you then carefully apply to your scene. The Auto Shader generator in Panda3D is an example of this. A normal mapped node would have a different shader from a node that has a glow map applied to it but you do not see this as the Auto Shader Generator creates the necessary specialized shader for you.

Now, lets look at the shader that we have in this tutorial. As previously mentioned, the vshader function handles vertices. The only thing a vertex shader can do is calculate properties for vertices. One such property is the position. A vertex shader can move vertices around. In this tutorial  we only move around the vertices but in the next tutorial we will calculate more properties for the vertex. A vertex shader cannot create new vertices nor can it delete vertices. This is a limitation that geometry shaders try to solve. Geometry shaders are supported since Panda3D 1.7.0.

If we take a closer look at the vertex shader, we can see a new line with the keyword &quot;uniform&quot; and a line with the &quot;in&quot; keyword. The &quot;in&quot; keyword means that there is some input from somewhere, in this case the input is named vtx_position. Referencing the [[List of Possible Shader Inputs]], you can see that vtx_position is a reserved name. The input vtx_position gives us is the vertex coordinates for the vertex as it appears in the egg file.</text>
    </revision>
  </page>
  <page>
    <title>Cg Tutorial Part 4</title>
    <ns>0</ns>
    <id>2299</id>
      <sha1>70u1i5o3hrv5xqfifo1gpo9yd38o5sk</sha1>
    <revision>
      <id>5871</id>
      <timestamp>2009-06-29T09:03:30Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <text xml:space="preserve" bytes="6074">&lt;h2&gt;Cg Tutorial Part 4: Applying colors defined in the model file&lt;/h2&gt;

&lt;code python&gt;
&quot;&quot;&quot;
This time no modifications on the Python front. What we try to achieve this time
is to color our models according to the egg file. Your scene should look like
the scene without shaders. If you start the sample there should be no difference
to 0.py.
&quot;&quot;&quot;
#Lesson4.py

import sys

import direct.directbase.DirectStart

base.setBackgroundColor(0.0, 0.0, 0.0)
base.disableMouse()

base.camLens.setNearFar(1.0, 50.0)
base.camLens.setFov(45.0)

camera.setPos(0.0, -20.0, 10.0)
camera.lookAt(0.0, 0.0, 0.0)

root = render.attachNewNode(&quot;Root&quot;)

modelCube = loader.loadModel(&quot;cube.egg&quot;)

cubes = []
for x in [-3.0, 0.0, 3.0]:
    cube = modelCube.copyTo(root)
    cube.setPos(x, 0.0, 0.0)
    cubes += [ cube ]

shader = loader.loadShader(&quot;lesson4.sha&quot;)
root.setShader(shader)

base.accept(&quot;escape&quot;, sys.exit)
base.accept(&quot;o&quot;, base.oobe)

def move(x, y, z):
    root.setX(root.getX() + x)
    root.setY(root.getY() + y)
    root.setZ(root.getZ() + z)

base.accept(&quot;d&quot;, move, [1.0, 0.0, 0.0])
base.accept(&quot;a&quot;, move, [-1.0, 0.0, 0.0])
base.accept(&quot;w&quot;, move, [0.0, 1.0, 0.0])
base.accept(&quot;s&quot;, move, [0.0, -1.0, 0.0])
base.accept(&quot;e&quot;, move, [0.0, 0.0, 1.0])
base.accept(&quot;q&quot;, move, [0.0, 0.0, -1.0])

run()

&lt;/code&gt;

&lt;code cg&gt;
//Cg
/* lesson4.sha */

/*
This is time we write our first shader that passes explicitly information from
the vertex shader to the fragment shader and we talk a bit more about linear
interpolation.

In the last shader examples you may have never seen that there was any linear
interpolation, but there was. If we only draw one triangle on the screen we only
need three vertices. So vshader is called three times. If this triangle is large
our fshader is called 100'000 times and more. What happens here between? The GPU
starts to render a triangle (that is one thing a GPU can without any help). But
how does the GPU connect e.g. vertex 1 with vertex 2? It only does linear
interpolation between the two vertices. That is the reason why we always see a
straight line between two vertices, never any curves or the like. If you like to
draw a sphere you have to approximate the sphere with simple triangles, although
this is rather inefficient (but it is simple and generic).

There is one more thing we were not talking about much. With our vertex shader
we transform our vertices so they look perspectively correct on the screen. But
vertices have three coordinates and your flat screen has only two dimensions. Do
we throw away the third coordinate (that could easily be done, but read on)?
Remember the depth buffer? The depth buffer is sometimes called z buffer and now
you may understand why. When we apply your matrix to a vertex the resulting
vertex has still all three dimensions. We assign then this vertex to o_vertex.
The GPU knows then that if there is depth buffer activated it has to do
something with this Z coordinate (only because we have assigned it to the
POSITION register). When the GPU starts to draw this triangle it interpolates
individual positions and z coordinates for possible future fragments (pixels),
based on our vertex shader output. The graphic card then checks if there is
already a z coordinate (at least the newer ones, old ones call the fragment
shader in any circumstance) in this buffer. If yes, it compares this old z
coordinate with the new. If the new z is nearer than the old (this comparison
function can be changed, but do not care about this yet), the old is overwritten
and the fragment is sent to the fragment shader.

What can a vertex shader do in general? It gets some inputs that change per
vertex (vtx_position, vtx_color, ...), some uniforms that often only change
between objects (mat_modelproj, ...) and some outputs (l_color, l_position,
...). Based on the input we calculate the outputs. The GPU then interpolates all
outputs and most of them we can read back in the fragment shader.

If we make our own shader and we can solve something with linear interpolation,
we always should consider to do this in the vertex shader, and let the GPU do
the interpolation. But sometimes linear interpolation makes things worse and so
we have to do everything in the fragment shader. Normal mapping is perfect
example, where the linear interpolation of the GPU may as well be a problem and
we have to craft carefully the vertex shader and the fragment shader.
*/

/*
We have a new input and a new output. vtx_color is exactly the color inside the
egg file. In the simplest case we do not modify this value and directly give it
back to the GPU. Open &quot;List of Possible Shader Inputs&quot; once more and try to
understand what the names mean.
*/
void vshader(
    uniform float4x4 mat_modelproj,
    in float4 vtx_position : POSITION,
    in float4 vtx_color : COLOR,
    out float4 l_color : COLOR,
    out float4 l_position : POSITION)
{
    l_position = mul(mat_modelproj, vtx_position);
    l_color = vtx_color;

    /*
    DIRTY
    A simple modification that disables the red component of the color.
    */
    //float4 nored = float4(0.0, 1.0, 1.0, 1.0);
    //l_color = vtx_color * nored;
}

/*
The input l_color is the linear interpolated output from the vertex shaders
output l_color.
*/
void fshader(
    in float4 l_color : COLOR,
    out float4 o_color : COLOR)
{
    o_color = l_color;

    /*
    DIRTY
    This is the same modification as in the vertex shader above. But this time
    we do it in the fragment shader. There is no visible difference, only that
    this version is inefficient. That there is no visible difference is a good
    sign, that we can do our work in the vertex shader. Maybe it is even a
    better answer than the more correct answer that says that because our
    modification does not involve any nonlinearity we do not have to do it the
    fragment shader. If it is not visible why should I waste GPU cycles,
    although it is not correct at all? Mathematicians would disagree, I guess.
    */
    //float4 nored = float4(0.0, 1.0, 1.0, 1.0);
    //o_color = l_color * nored;
}
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>Cg Tutorial Part 5</title>
    <ns>0</ns>
    <id>2300</id>
      <sha1>efghxcumul5fx3gkt5t09kq5c65zi8q</sha1>
    <revision>
      <id>5641</id>
      <timestamp>2008-12-09T19:08:59Z</timestamp>
      <contributor>
        <username>Birukoff</username>
        <id>171</id>
      </contributor>
      <text xml:space="preserve" bytes="9338">&lt;h2&gt;Cg Tutorial Part 5: Applying colors with the vertex and fragment shaders&lt;/h2&gt;
&lt;pre class=&quot;codeblock&quot;&gt;
&quot;&quot;&quot;
In this example we start to pass our own variables from the vertex shader to the
fragment shader.
&quot;&quot;&quot;
#Lesson5.py

import sys

import direct.directbase.DirectStart

base.setBackgroundColor(0.0, 0.0, 0.0)
base.disableMouse()

base.camLens.setNearFar(1.0, 50.0)
base.camLens.setFov(45.0)

camera.setPos(0.0, -20.0, 10.0)
camera.lookAt(0.0, 0.0, 0.0)

root = render.attachNewNode(&quot;Root&quot;)

modelCube = loader.loadModel(&quot;cube.egg&quot;)

cubes = []
for x in [-3.0, 0.0, 3.0]:
    cube = modelCube.copyTo(root)
    cube.setPos(x, 0.0, 0.0)
    cubes += [ cube ]

shader = loader.loadShader(&quot;lesson5.sha&quot;)
root.setShader(shader)

&quot;&quot;&quot;
DIRTY
Uncomment this line only after you read the comment in the shader.

Each one of the three cubes has a different position. Before Panda3D sends the
vertices to the graphic card it sends a matrix to the GPU that instructs the GPU
to move all vertices to the new position (only if there is no shader, with a
shader we have to do this on our as you already know). The advantage is that
Panda3D can send the exact same vertices to the GPU for all three cubes. After
calling flattenLight we have different situation. Panda3D applies this move
command on itself to the vertices. Prior to this modification every cube need
his own set vertices, because they cannot share their vertices anymore. The
output of the call to render.analyze may help to see what happens. Advantage in
this case is that Panda3D does not have to send the GPU a command to move the
object around. But the vertices now have new values, so the output of shader may
change too. Try to understand why the cubes[0].getX() does not display the same
value before and after the call to flattenLight.

You only can see a visible change if the vertex shader contains the following
command (the color should depend on the position):

l_my = vtx_position * 0.5 + 0.5;

Try to understand where and why the output differs.
&quot;&quot;&quot;
#print cubes[0].getX()
#root.flattenLight()
#render.analyze()
#print cubes[0].getX()

base.accept(&quot;escape&quot;, sys.exit)
base.accept(&quot;o&quot;, base.oobe)

def move(x, y, z):
    root.setX(root.getX() + x)
    root.setY(root.getY() + y)
    root.setZ(root.getZ() + z)

base.accept(&quot;d&quot;, move, [1.0, 0.0, 0.0])
base.accept(&quot;a&quot;, move, [-1.0, 0.0, 0.0])
base.accept(&quot;w&quot;, move, [0.0, 1.0, 0.0])
base.accept(&quot;s&quot;, move, [0.0, -1.0, 0.0])
base.accept(&quot;e&quot;, move, [0.0, 0.0, 1.0])
base.accept(&quot;q&quot;, move, [0.0, 0.0, -1.0])

run()
&lt;/pre&gt;
&lt;pre class=&quot;codeblock&quot;&gt;
//Cg
/* lesson5.sha */

/*
No new concepts this time. But after you read this tutorial, you have a nice
playground to start playing with. I say you probably understand more than 50% of
Cg. Sure there are some functions that may do things that are not that obvious,
but Cg itself is simple.

There is a PDF available on the Internet, written by a NVIDIA guru:

http://arxiv.org/pdf/cs/0302013

Although it is not bad if you try to understand the content, it is probably more
interesting that this document only has two pages.

One bad thing about shader development is that you cannot easily debug the
shader like say a C application. There is no print statement (and therefore no
easy to understand HelloWorld). If you start to create complex things maybe try
the Cg debugger from NVIDIA.

http://developer.nvidia.com/object/nv_shader_debugger_home.html

But we do not give up so fast. In our examples we colorize our cubes. But in
today applications, this colors are not as important as they were in the last
millennium. So why not abuse this colors for debugging? Sure it is not easy to
read color encoded debugging information, but if you once start, you feel like
the inverse of one Matrix guy. He is able to see a woman out of some digits,
while we see numbers when we look at a colored screen. This method has one
drawback. While you can assign any possible value to the RGBA parts of a color,
it only makes sense if they are visible. Therefore they need to be in range from
0.0 to 1.0. Your fragment shader often needs to be a bit clever, so the
debugging information you get from the colors are not completely useless.
*/

/*
This vertex shader has a new output l_my. The first time in all those tutorials
this is not a predefined Panda3D variable. In the simplest form we pass a
constant value to this variable. This variable is then linearly interpolated and
passed to the fragment shader. If it is a constant value then there is no
interpolation at all, but the GPUs does not know this (maybe the Cg compiler
optimizes this away, but I am not sure about this). In the fragment shader we
assign this value immediately to the o_color, therefore every change to the
vertex shader should immediately be visible on your screen. There is only one
more question left. What does this TEXCOORD0 mean? Sounds like it has something
to do with texturing. This is only half of the truth. The texture capabilities
of a GPU are quite generic. As we later will see, textures can be abused for
other things than texturing. Think of TEXCOORD0 as generic storage that is
interpolated like COLOR or POSITION, but this time, the GPU does really nothing
more than interpolating (no assignment to a depth buffer, color buffer or
anything else). What if we like to pass more manually generated values to the
fragment shader? Then start with TEXCOORD1 and so on.
*/
void vshader(
    uniform float4x4 mat_modelproj,
    in float4 vtx_position : POSITION,
    in float4 vtx_color : COLOR,
    out float4 l_my : TEXCOORD0,
    out float4 l_position : POSITION)
{
    l_position = mul(mat_modelproj, vtx_position);

    /*
    DIRTY
    This shader creates the same output like 3.sha, but this time we pass the
    color through TEXCOORD0 instead of COLOR.
    */
    l_my = vtx_color;

    /*
    DIRTY
    With the previous version the output looks a bit odd. What is the reason?
    When you have once more look at the egg file you will see that the vertex
    coordinates of the cube ranges from -1.0 to 1.0. If we apply these
    coordinates to color directly, what we have done, we have, negative colors.
    Negative values are clamped to 0.0 by the GPU (the poeple working with the
    LHC maybe are the only ones ever seen an anti red). But we can help ourself
    and let it look a bit nicer. The first step is that we divide every
    component by two, therefore the range is reduced from -0.5 to 0.5. Second
    step is to add 0.5 to every component. Now the range is from 0.0 to 1.0,
    exactly what we want. Remember this nifty trick, it may be helpful if you
    try to write your first shadow mapping algorithm.

    Both of the two following lines are equivalent (perhaps one is faster than
    the other).

    You can move this whole calculation to the fragment shader but maybe you can
    already see that there is no difference and therefore it the only thing that
    we can may see is that the FPS counter is not as high as before (But this
    example is maybe to simple for your GPU to notice any speed difference).
    */
    //l_my = vtx_position * float4(0.5, 0.5, 0.5, 0.5) + float4(0.5, 0.5, 0.5, 0.5);
    //l_my = vtx_position * 0.5 + 0.5;

    /*
    DIRTY
    In a previous example we said that you can think of float4 as array with 4
    floats. This is still true, but it is an array and at the same time it
    behaves like multiple C structs at the same time. In the following example
    all cubes have a cyan color.
    In Cg this fancy thing is called swizzling.
    */
    //l_my.rg = float2(0.0, 1.0);
    //l_my[2] = 1.0;

    /*
    DIRTY
    You can mix these identifiers freely. This time the cubes should be yellow.
    A small overview for a given flaot4 f:

    f[0] = f.r = f.x
    f[1] = f.g = f.y
    f[2] = f.b = f.z
    f[3] = f.a = f.w

    Cg itself does not care if something is called r oder x. These names are
    only for carbon based life forms.
    */
    //l_my.xz = float2(1.0, 0.0);
    //l_my.g = 1.0;
}

/*
While we defined l_my as output in the vertex shader, this time we have to
define l_my as input. But refer to the same storage, in this sample TEXCOORD0.
*/
void fshader(
    in float4 l_my : TEXCOORD0,
    out float4 o_color : COLOR)
{
    o_color = l_my;

    /*
    DIRTY
    Cg supports C like keywords like if and else. I do not know how good latest
    GPUs are with branching instructions, but older GPUs were slow or not able
    at all to do branching.
    */
    //if(l_my.r &gt; 0.5) {
    //    o_color = float4(1.0, 0.0, 0.0, 1.0);
    //} else {
    //    o_color = float4(0.0, 1.0, 0.0, 1.0);
    //}

    /*
    You have to see the scene from behind to see what happens. Normaly the
    function &quot;length&quot; is used to calculate the length of a vector. We abuse the
    function here. Length is an expensive function. It is defined as follows for
    a given float3 f:

    length(f) = sqrt(f.x * f.x + f.y * f.y + f.z * f.z)

    Ever tried to square root a number manually? Maybe you guess why it is
    expensive.
    */
    //float l = length(l_my.rgb);
    //if(l &gt; 0.99) {
    //    o_color = float4(1.0, 0.0, 0.0, 1.0);
    //} else {
    //    float4 red = float4(1.0, 0.0, 0.0, 1.0);
    //    float4 green = float4(0.0, 1.0, 0.0, 1.0);
    //    o_color = lerp(red, green, 1.0 - l);
    //}
}
&lt;/pre&gt;</text>
    </revision>
  </page>
  <page>
    <title>Cg Tutorial Part 6</title>
    <ns>0</ns>
    <id>2301</id>
      <sha1>3pc2y3b85553by5j06g36u2qd7yvkep</sha1>
    <revision>
      <id>5642</id>
      <timestamp>2008-12-09T19:10:04Z</timestamp>
      <contributor>
        <username>Birukoff</username>
        <id>171</id>
      </contributor>
      <text xml:space="preserve" bytes="11604">&lt;h2&gt;Cg Tutorial Part 6: Passing inputs to the shader and controlling it from Panda&lt;/h2&gt;

&lt;pre class=&quot;codeblock&quot;&gt;

&quot;&quot;&quot;
In this example we define our own uniforms, we like to send to the GPU.
&quot;&quot;&quot;
#Lesson6.py

import sys
import math

from direct.interval.LerpInterval import LerpFunc
import direct.directbase.DirectStart

base.setBackgroundColor(0.0, 0.0, 0.0)
base.disableMouse()

base.camLens.setNearFar(1.0, 50.0)
base.camLens.setFov(45.0)

camera.setPos(0.0, -20.0, 10.0)
camera.lookAt(0.0, 0.0, 0.0)

root = render.attachNewNode(&quot;Root&quot;)

modelCube = loader.loadModel(&quot;cube.egg&quot;)

cubes = []
for x in [-3.0, 0.0, 3.0]:
    cube = modelCube.copyTo(root)
    cube.setPos(x, 0.0, 0.0)
    cubes += [ cube ]

shader = loader.loadShader(&quot;lesson6.sha&quot;)
root.setShader(shader)

&quot;&quot;&quot;
This is the only new line here. If you comment/remove this line Panda3D sees
that there is a problem. Why? The shader in this example still references to an
uniform, therefore the uniform needs to be set at least once.
&quot;&quot;&quot;
root.setShaderInput(&quot;panda3drocks&quot;, 1.0, 0.0, 1.0, 1.0)

&quot;&quot;&quot;
DIRTY
If you enable to following two lines, without modifying the shader, you have one
more debug utility that may help in some circumstances. With setTransparency
Panda3D instruct the GPU to not only overwrite the color buffer. If the fragment
shader was calculating a color, the GPU reads the old value in the color buffer
back and merges it with the new color. This process is called alpha blending and
most often it is used for transparency. But if transparency is enabled, Panda3D
has to reorder all visible nodes, so they are drawn from back to front (or else
transparency looks not correct). You have to remember this if you &quot;debug&quot; a
scene like this.

Some facts: The new panda3drocks uniform, you can see below, has an alpha
component with a value lesser than 1.0. The background in this scene is black.
Back facing triangles are not drawn. What we conclude from this. If the GPU has
to draw the first cube, the only two colors on the screen are black (0.0, 0.0,
0.0) and a dark purple (0.1, 0.0, 0.1). If the GPU has to draw the second cube,
and they are not side by side, a new purple (theoretically 0.19, 0.0, 0.19,
practically ~0.18, 0.0, ~0.18) appears that is brighter than its predecessor.
The more triangles are on top of one another the brighter the scene. Or in other
words, the brighter the scene the more the fragment shader needs to be called.
Something you should try to avoid.
&quot;&quot;&quot;
#root.setTransparency(True)
#root.setShaderInput(&quot;panda3drocks&quot;, 1.0, 0.0, 1.0, 0.1)

base.accept(&quot;escape&quot;, sys.exit)
base.accept(&quot;o&quot;, base.oobe)

def animate(t):
    c = abs(math.cos(math.radians(t)))
    root.setShaderInput(&quot;panda3drocks&quot;, c, c, c, 1.0)

    &quot;&quot;&quot;
    DIRTY
    Uncomment only one line at a time and see how the scene graph propagates
    shader inputs.

    As an aside: The setHpr method of a NodePath accepts angles in degrees. But
    Python and Cg internally work with radians (Every FPU known to more than
    0xff people internally works with radians).
    &quot;&quot;&quot;
    #r = abs(math.cos(math.radians(t + 0.0)))
    #g = abs(math.cos(math.radians(t + 10.0)))
    #b = abs(math.cos(math.radians(t + 20.0)))
    #cubes[0].setShaderInput(&quot;panda3drocks&quot;, r, 0.0, 0.0, 1.0)
    #cubes[1].setShaderInput(&quot;panda3drocks&quot;, 0.0, g, 0.0, 1.0)
    #cubes[2].setShaderInput(&quot;panda3drocks&quot;, 0.0, 0.0, b, 1.0)

interval = LerpFunc(animate, 5.0, 0.0, 360.0)

base.accept(&quot;i&quot;, interval.start)

def move(x, y, z):
    root.setX(root.getX() + x)
    root.setY(root.getY() + y)
    root.setZ(root.getZ() + z)

base.accept(&quot;d&quot;, move, [1.0, 0.0, 0.0])
base.accept(&quot;a&quot;, move, [-1.0, 0.0, 0.0])
base.accept(&quot;w&quot;, move, [0.0, 1.0, 0.0])
base.accept(&quot;s&quot;, move, [0.0, -1.0, 0.0])
base.accept(&quot;e&quot;, move, [0.0, 0.0, 1.0])
base.accept(&quot;q&quot;, move, [0.0, 0.0, -1.0])

run()

&quot;&quot;&quot;
On more note abount blending. If you enable transparency on a node, Panda3D has
to blend the node together with the existing scene. If you read the Panda3D
manual about this topic, you can see that this is a expensive operation, because
Panda3D has to reorder the scene. So how does this blending work? There is more
than one possibility to blend nodes together. As far as I know Panda3D only uses
the following scheme:

NewDestinationColor = ((1.0 - SourceAlpha) * OldDestinationColor) + (SourceAlpha * SourceColor)

If the there is black screen and we draw the purple triangle with folowing color
attribute 1.0, 0.0, 1.0, 0.1, the following happens:

OldDestinationColor = 0.0, 0.0, 0.0
SourceAlpha = 0.1
SourceColor = 1.0, 0.0, 1.0
=&gt; NewDestinationColor = 0.1, 0.0, 0.1

Our second triangle on top of the first triangle yields:

OldDestinationColor = 0.1, 0.0, 0.1
SourceAlpha = 0.1
SourceColor = 1.0, 0.0, 1.0
=&gt; NewDestinationColor = 0.19, 0.0, 0.19

We assume that the GPU always is calculating with floating point buffers, but
this is not always true. In todays application the color buffer is often not a
floating point buffer, so we see some inaccuracies here. That is the reason why
in the example above I have once written theoretically and then practically.

Why do I explain all this stuff here? Maybe you recognized that this stuff is
once more linear interpolation, but there is no possiblity to influence this
equation with a vertex or fragment shader.
&quot;&quot;&quot;
&lt;/pre&gt;

&lt;pre class=&quot;codeblock&quot;&gt;
//Cg
/* lesson6.sha */

/*
We were using setShaderInput in the Python code. setShaderInput does nothing
more than assign a float4 (there is no possibility to assign a float2 e.g.) to a
shader uniform. Every manually provided input needs a k_ prefix therefore the
panda3drocks shader input has to be written as k_panda3drocks. If you manually
define an uniform in shader, you must at least call setShaderInput on an
appropriate NodePath that uses this shader.
*/
void vshader(
    uniform float4x4 mat_modelproj,
    uniform float4 k_panda3drocks,
    in float4 vtx_position : POSITION,
    out float4 l_my : TEXCOORD0,
    out float4 l_position : POSITION)
{
    l_position = mul(mat_modelproj, vtx_position);
    l_my = k_panda3drocks;
}

/*
This example is a bad idead how to waste a TEXCOORD unit. k_panda3drocks is a
constant assigned to l_my, when l_my it is passed from the vertex shader to
fragment shader it is lineraly interpolated. But a linear interpolated constant,
is a constant. In this sample, it would make more sense if we define our uniform
in the fragment shader than in the vertex shader.
*/
void fshader(
    in float4 l_my : TEXCOORD0,
    out float4 o_color : COLOR)
{
    o_color = l_my;
}

/*
I have to admit here an unknowingness. GLSL does interpolate perspectively
correct (based on the depth the linear interpolation gets a correction), but I
do not know in which circumstances this applies to Cg. It may be possible that I
repeat the word linearly interpolated over and over again although it is not
always exactly true. Both the GLSL manual and the Cg manual only have the word
perspectively correction on one line, there is no explanation. If anyone has in
depth information about this I am happy if you share this knowledge.

Both GLSL and Cg support a keyword noproject to disable this correction. But
Panda3D currently does not support it.

http://www.opengl.org/registry/doc/GLSLangSpec.Full.1.20.8.pdf
http://developer.download.nvidia.com/cg/Cg_2.0/2.0.0015/Cg-2.0_May2008_ReferenceManual.pdf

The OpenGL function glHint has a parameter to enable or disable perspective
correction (GL_PERSPECTIVE_CORRECTION_HINT), but maybe that only applies to the
fixed function pipeline.

http://www.opengl.org/sdk/docs/man/xhtml/glHint.xml

As of OpenGL 2.1 perspective correction should always be enabled according to
the manual.

I bet that it depends on the GPU vendors daily mood, the moon phase and the
Google result to: &quot;number of horns on a unicorn multiplied by the answer to
life, the universe and everything&quot;.
*/

/*
First I like to explain why we need perspective correction. A scan line renderer
like todays GPUs are (in contrast to a ray tracer), transforms all three points
of a triangle from 3D space to a 2D screen. After the transformation e.g. the
linear interpolation of colors is calculated. Only if we transform a triangle to
our screen we know how much pixels the triangle will cover. If we like to
interpolate in 3D we may interpolate millions of position that are reduced to
one pixel if the triangle is far away, this is obviously infeasible. Open the
figures.svg of figures.png file and look at the figure 5.1. If you look at the
first image you can see a quad that consists of two triangles. You can look at
this image from two view points. First it is possible that is a perspective
plane in 3D, second it is a trapezoid in 2D. There are two yellow lines in the
image. This lines divide the trapezoid exactly in the center. Maybe you already
see a problem, this is only true in 2D. In 3D the center of the trapezoid is a
bit above the current center. Further on there are five marked intersections. We
need this numbers for the later images:

1: Exact 2D center for the top line.
2: Exact 2D center for the left line.
3: Exact 2D center for the right line.
4: Exact 2D center for the bottom line.
5: Exact 2D center for the line in the middle.

Now we start with the second image and assign some colors to the vertices. We
now interpolate this values manually at the intersection points:

1: 50% red 50% blue.
2: 100% red 0% blue.
3: 50% red 50% blue.
4: 0% red 100% blue.
5: 50% red 50% blue.

While 1 2 3 and 4 should be easy to calculate maybe 5 is not so obvious. But
because we now that the point is exactly at center between the top right vertex
and the bottom left vertex, the color must be the center between red and blue as
well.

In the third image you can see how this should look like. It looks nice, but it
is not correct, because the average of blue and red (50% red and 50% blue) lies
exactly in the center of the trapezoid and not in the center of the 3D plane we
have. The gradient looks nice because all colors on one horizontal have one and
the same color (point 1, 3 and 5 have the same color e.g.).

In the fourth image we rotate our plane. The only thing that changes are the
vertex colors. The interpolated colors are as follows this time:

1: 0% red 100% blue.
2: 50% red 50% blue.
3: 100% red 0% blue.
4: 50% red 50% blue.
5: 50% red 50% blue.

Point 5 has the same color as in the previous image. Because we have another
gradient now, all vertical lines should have the exact same color, but this is
not true. Point 2, 4 and 5 have the same color, but they are not on the same
line.

In the fifth image you can see the final result. Maybe it is not that obvious
but the green line, tries to show how the 50% line looks like.

You can reproduce this problem if you draw a rectangle yourself and apply the
perspective transformation on the vertices by yourselfe. The rectangle looks
like a trapezoid then. If you draw a trapezoid in Blender e.g. and assign a
texture with the following UV coordinates (of a grid like image) to the four
vertices: (0,0) (1,0) (0,1) (1,1) you can see the distortion more clearly. The
two files perspective-correction.blend and perspective-correction.jpg show you
the result more clearly. You can see one more fancy thing with this example. The
preview in Blender is renderer with OpenGL while the Blender itself has its own
renderer for production quality images. The internal renderer and OpenGL divide
a quad in two different ways into triangles. That is the reason why the vertical
line on the trapezoid does is twisted in two different directions.
*/
&lt;/pre&gt;</text>
    </revision>
  </page>
  <page>
    <title>Cg Tutorial Part 7</title>
    <ns>0</ns>
    <id>2302</id>
      <sha1>4clvzxx8twyk7f6pls2b4y3ifg53tfo</sha1>
    <revision>
      <id>7732</id>
      <timestamp>2012-03-10T07:09:03Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="8579">&lt;h2&gt;Cg Tutorial Part 7: Applying one texture to a model&lt;/h2&gt;

&lt;code python&gt;

&quot;&quot;&quot;
In this example we render each cube with one texture. The prerequisite is, that
we assign our object at least one texture. If we do not assign a texture here,
the shader cannot access it later. If you read this Python code first you can
see that we assign two textures, although on the visual output you can only see
only texture (remember 0.py). Assigning a texture to a NodePath is like
assigning a shader input. We need to assign an input, if we have shader that
needs this input. But only because there is a setShaderInput, does not mean we
have to care about it in the shader.
&quot;&quot;&quot;
#Lesson7.py

import sys

import direct.directbase.DirectStart
from panda3.core import Texture, TextureStage

base.setBackgroundColor(0.0, 0.0, 0.0)
base.disableMouse()

base.camLens.setNearFar(1.0, 50.0)
base.camLens.setFov(45.0)

camera.setPos(0.0, -20.0, 10.0)
camera.lookAt(0.0, 0.0, 0.0)

root = render.attachNewNode(&quot;Root&quot;)

textureArrow = loader.loadTexture(&quot;arrow.png&quot;)
textureArrow.setWrapU(Texture.WMClamp)
textureArrow.setWrapV(Texture.WMClamp)

&quot;&quot;&quot;
DIRTY
Try to increase the setSort parameter and look at the results. Somehow we can
influence the shader, nevertheless the cube is only textured with one texture.
&quot;&quot;&quot;
stageArrow = TextureStage(&quot;Arrow&quot;)
stageArrow.setSort(1)

textureCircle = loader.loadTexture(&quot;circle.png&quot;)
textureCircle.setWrapU(Texture.WMClamp)
textureCircle.setWrapV(Texture.WMClamp)

stageCircle = TextureStage(&quot;Circle&quot;)
stageCircle.setSort(2)

modelCube = loader.loadModel(&quot;cube.egg&quot;)

cubes = []
for x in [-3.0, 0.0, 3.0]:
    cube = modelCube.copyTo(root)
    cube.setPos(x, 0.0, 0.0)
    cubes += [ cube ]

shader = loader.loadShader(&quot;lesson7.sha&quot;)
root.setShader(shader)

&quot;&quot;&quot;
In this sample we assign all three cubes the same textures. Get another image
and try to assign one cube another texture.
&quot;&quot;&quot;
root.setTexture(stageArrow, textureArrow)
root.setTexture(stageCircle, textureCircle)

base.accept(&quot;escape&quot;, sys.exit)
base.accept(&quot;o&quot;, base.oobe)

def move(x, y, z):
    root.setX(root.getX() + x)
    root.setY(root.getY() + y)
    root.setZ(root.getZ() + z)

base.accept(&quot;d&quot;, move, [1.0, 0.0, 0.0])
base.accept(&quot;a&quot;, move, [-1.0, 0.0, 0.0])
base.accept(&quot;w&quot;, move, [0.0, 1.0, 0.0])
base.accept(&quot;s&quot;, move, [0.0, -1.0, 0.0])
base.accept(&quot;e&quot;, move, [0.0, 0.0, 1.0])
base.accept(&quot;q&quot;, move, [0.0, 0.0, -1.0])

run()

&lt;/code&gt;

&lt;pre class=&quot;codeblock&quot;&gt;
//Cg
/* lesson7.sha */

/*
Think of a 2D texture of something like a 2D array with values. We can use a 2D
texture for tinting meshes (as we do here), or for a function with two
parameters. If this function is extremely hard to calculate, this may indeed be
a good idea, so we can offload the work to a pre process. Textures often contain
a color with a R, G and B component. But it is possible that a texture contains
an additional alpha value, or only contains one value at all. Besides 2D
textures, there are 1D textures and 3D textures. One fragment/pixel on a texture
is often called a texel. UV coordinates address a texel on a 2D texture. It is
like if your home made RPG is only flat and needs no Z coordinate to position
your character, then you need only XY. XY in texture language means UV. If you
use a 3D texture there is an additional W parameter which leads to UVW
coordinates.
*/

/*
Maybe you remember that in the variable vtx_color, the current vertex color was.
Like vtx_color, there is a variable vtx_texcoord0 with the UV coordinates of the
first UV coordinate set. This UV coordinates are exactly the ones you can see in
the egg file. The egg file only has one set of UV coordinates, but it is
possible to specify more than one UV set. If you have two or more textures that
does not mean, we have to use more than one UV set, we can use one UV set for as
much textures we like (up to texture limit of the GPU and up to the limitations
older GPUs had). Like in the color sample we only assign the UV coordinate to
the variable l_my, or whatever we name it, and let it interpolate by the GPU.

One more thing about this UV sets. Maybe you think they are only useful for
textures, but think of this sets as additional properties of a vertex. The
designers maybe only thought that this UV sets are for texturing but you may use
them for any cool idea you have. UV coordinates are especially suited for that,
because you can have more than one, in contrast to a color where you only can
have one color (OpenGL has the possibility to use a secondary color, but as far
as I know Panda3D does not support it, because there is no need for it, in the
age of shaders).

You may ask: &quot;We do something about texturing, we have this UV set, but where is
the texture?&quot; Maybe you would not ask this question because you think that a
texture changes the color, so the fragment shader should care about the texture.
Per vertex texturing is non sense you may answer then and you are right. But as
already written you may abuse a texture for function evaluation. It may be
possible that this function has too many values, therefore our texture is too
large. Here it may possible that we can simplify the function and only create a
texture with some support values. This support values have to leave the vertex
shader and get linearly interpolated. This linear interpolation may lead to
inaccuracies, but hopefully they are good enough so no one can spot the
difference.
*/
void vshader(
    uniform float4x4 mat_modelproj,
    in float4 vtx_position : POSITION,
    in float2 vtx_texcoord0 : TEXCOORD0,
    out float2 l_my : TEXCOORD0,
    out float4 l_position : POSITION)
{
    l_position = mul(mat_modelproj, vtx_position);
    l_my = vtx_texcoord0;

    /*
    DIRTY
    If you add the following uniform to your program:

    uniform float4x4 mat_modelview,

    You have access to a matrix that only contains the modelview
    transformations, without the projection as with the modelproj matrix. If you
    calculate the texture coordinates based on this transformation (this is a
    form of texture generation), the texture should always be at the same
    location, move around the scene to see what happens exactly.
    */
    //l_my = mul(mat_modelview, vtx_position);
}

/*
Our fragment shader fetches the color from a texture and returns the color, so
the GPU can write it down to the color buffer.

To get a texel we need a texture and texture coordinate. The texture coordinate
is provided by the vertex shader, while the texture is provided through a
uniform. Besides the new data type sampler2D we have this new TEXUNIT0 register.
How do we now what is inside TEXUNIT0? Based on the sort order in the Python
code, Panda3D assigns the texture with the lowest number to TEXUNIT0, the
texture with the next hight number is then assigned TEXUNIT1 and so on. That is
the reason why you can switch the texture with the setSort method of a
TextureStage.

Finally there is this tex2D function. This function exists in multiple versions
(overloaded variants). The simplest one is where you have to specify a sampler2D
as first parameter and a float2 as second parameter, the one we use here. Based
on this input the GPU fetches a texel from the texture. How it is interpolated
depends on the settings on the texture unit which you have to apply in the
Python code. setWrapU and setWrapV are two examples (if you store function
values in texture then carefully chose the texture filtering options). Sometimes
it also depends on some graphic driver settings. Often graphic drivers have
often to override any application setting, in our case they do not care what
Panda3D or we like.

If you enable anisotropic filtering there are some hidden parameters to tex2D.
Especially for anisotropic filtering the results depends on the vendors
implementation. ATI and NVIDIA both harmlessly blamed each other for their GPUs
worse texture filtering capabilities.
*/
void fshader(
    uniform sampler2D tex_0 : TEXUNIT0,
    in float2 l_my : TEXCOORD0,
    out float4 o_color : COLOR)
{
    o_color = tex2D(tex_0, l_my);

    /*
    DIRTY
    Just to play with texture coordinates. Assign all fragments the same color
    from one specific 2D location in a texture. If you use the default texture
    that is assigned in the Python sample, then there is a black arrow in the
    middle of the texture. The UV coordinate for the texture center is (0.5,
    0.5). If you enable that line thus you only see a black screen.
    */
    //o_color = tex2D(tex_0, float2(0.5, 0.5));
    //o_color = tex2D(tex_0, float2(0.0, 0.5));
}

&lt;/pre&gt;</text>
    </revision>
  </page>
  <page>
    <title>Cg Tutorial Part 8</title>
    <ns>0</ns>
    <id>2303</id>
      <sha1>enh6g0d1dq2c6ppg9esuvolglnb98on</sha1>
    <revision>
      <id>7733</id>
      <timestamp>2012-03-10T07:09:49Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="3529">&lt;h2&gt;Cg Tutorial Part 8: Applying two textures to a model&lt;/h2&gt;

&lt;code python&gt;

&quot;&quot;&quot;
The Python code in this sample is exactly the same as in the last sample.
&quot;&quot;&quot;
#Lesson8.py

import sys

import direct.directbase.DirectStart
from panda3d.core import Texture, TextureStage

base.setBackgroundColor(0.0, 0.0, 0.0)
base.disableMouse()

base.camLens.setNearFar(1.0, 50.0)
base.camLens.setFov(45.0)

camera.setPos(0.0, -20.0, 10.0)
camera.lookAt(0.0, 0.0, 0.0)

root = render.attachNewNode(&quot;Root&quot;)

textureArrow = loader.loadTexture(&quot;arrow.png&quot;)
textureArrow.setWrapU(Texture.WMClamp)
textureArrow.setWrapV(Texture.WMClamp)

&quot;&quot;&quot;
DIRTY
Like in the previous example, increase the setSort parameter and see what
happens, the influence of the order depends on the applied shader. Sometimes you
can see a difference, sometimes not.
&quot;&quot;&quot;
stageArrow = TextureStage(&quot;Arrow&quot;)
stageArrow.setSort(1)

textureCircle = loader.loadTexture(&quot;circle.png&quot;)
textureCircle.setWrapU(Texture.WMClamp)
textureCircle.setWrapV(Texture.WMClamp)

stageCircle = TextureStage(&quot;Circle&quot;)
stageCircle.setSort(2)

modelCube = loader.loadModel(&quot;cube.egg&quot;)

cubes = []
for x in [-3.0, 0.0, 3.0]:
    cube = modelCube.copyTo(root)
    cube.setPos(x, 0.0, 0.0)
    cubes += [ cube ]

shader = loader.loadShader(&quot;lesson8.sha&quot;)
root.setShader(shader)

root.setTexture(stageArrow, textureArrow)
root.setTexture(stageCircle, textureCircle)

base.accept(&quot;escape&quot;, sys.exit)
base.accept(&quot;o&quot;, base.oobe)

def move(x, y, z):
    root.setX(root.getX() + x)
    root.setY(root.getY() + y)
    root.setZ(root.getZ() + z)

base.accept(&quot;d&quot;, move, [1.0, 0.0, 0.0])
base.accept(&quot;a&quot;, move, [-1.0, 0.0, 0.0])
base.accept(&quot;w&quot;, move, [0.0, 1.0, 0.0])
base.accept(&quot;s&quot;, move, [0.0, -1.0, 0.0])
base.accept(&quot;e&quot;, move, [0.0, 0.0, 1.0])
base.accept(&quot;q&quot;, move, [0.0, 0.0, -1.0])

run()

&lt;/code&gt;

&lt;pre class=&quot;codeblock&quot;&gt;
//Cg
/* lesson8.sha */

/*
The vertex shader has not changed. If you like to apply another UV set for the
second texture you have to pass the vtx_texcoord1 variable from the vertex
shader to the fragment shader.
*/
void vshader(
    uniform float4x4 mat_modelproj,
    in float4 vtx_position : POSITION,
    in float2 vtx_texcoord0 : TEXCOORD0,
    out float2 l_my : TEXCOORD0,
    out float4 l_position : POSITION)
{
    l_position = mul(mat_modelproj, vtx_position);
    l_my = vtx_texcoord0;
}

/*
With TEXUNIT1 we can access the second texture unit. How many texture unit you
can use depends on your GPU. The bad thing about this is that you need a
fallback mechanisms if you use more texture units than the GPU of your
applications users may have.
*/
void fshader(
    uniform sampler2D tex_0 : TEXUNIT0,
    uniform sampler2D tex_1 : TEXUNIT1,
    in float2 l_my : TEXCOORD0,
    out float4 o_color : COLOR)
{
    /*
    Apply both textures. This is same operation as if you modulate two textures
    with the fixed function pipline without using a shader. For this example,
    the sort order of the texture stages has no influence to the final result.
    */
    o_color = tex2D(tex_0, l_my) * tex2D(tex_1, l_my);

    /*
    DIRTY
    Here we play a bit and modify the arrow texture based on the red component
    of the circle texture (The circle texture only has gray colors, therefore it
    does not matter if you use R, G or B part).
    */
    //float4 arrow = tex2D(tex_0, l_my);
    //float4 circle = tex2D(tex_1, l_my);
    //if(circle.r &lt; 0.5) {
    //    o_color = arrow;
    //} else {
    //    o_color = float4(1.0, 1.0, 1.0, 1.0) - arrow;
    //}
}

&lt;/pre&gt;</text>
    </revision>
  </page>
  <page>
    <title>Cg Tutorial Part 9</title>
    <ns>0</ns>
    <id>2304</id>
      <sha1>3oyr3y0dhag3lagipkab308g8dhpatx</sha1>
    <revision>
      <id>7734</id>
      <timestamp>2012-03-10T07:10:49Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <text xml:space="preserve" bytes="8533">&lt;h2&gt;Cg Tutorial Part 9: Explaining details about diffuse lighting&lt;/h2&gt;

&lt;code python&gt;
#Lesson9.py

&quot;&quot;&quot;
Like 0.py we restart from scratch and create a basic example with one point
light, that only supports diffuse lighting. There is no shader attached to this
example. If you do not understand this sample then open the Panda3D manual and
try to understand e.g. the Disco-Lights sample.

When we talk about lighting we talk about an &quot;effect&quot; that we can see with our
eyes. Live is a game, just with better graphic. Lighting is still something you
may do your own research and invent a cool new idea, no one had before. We often
only approximate lighting and invent new terms that do not exist in reality e.g.
there is no specular light in real live. For better lighting we often need to
pre calculate some values in an often slow pre process. We start here only with
one basic lighting model: Diffuse Lighting.

The basic idea of diffuse lighting is: The steeper the angle between the light
and a surface, the less light particles can reach the surface. The following
figures show an example with a directional light and a wall.

1. 100% of the light reaches the wall.
2. ~50% of the light reaches the wall.
3. 0% of the light reaches the wall.

      |           /
1. -&gt; |    2. -&gt; /     3. -&gt; ---
      |         /

If no light reaches a wall, the wall cannot reflect any light particles and
therefore you cannot see anything. This idea is only one basic idea. This idea
e.g. says nothing about the fact that if a wall reflects some light, it may be
possible that this light reaches another wall, which may reflect this light
particles once more.

Given that there is one wall behind another wall:

   |    |
-&gt; |    |
   |    |

If we translate our idea to this situation, it means, that both walls got the
same amount of light, because the angle between the light surface and the light
source is equal for both walls. This is of course dead wrong, because the first
wall occludes the second wall, so there is more or less no light at all.

The default lighting model the fixed function pipeline offers to Panda3D has
tons of flaws, even though it helps to increase realism. Let us stick to this
mediocre lighting model for now (better lighting models are often extremely slow
and only with tricks you may use them in 60 FPS applications).

To calculate how much light reaches our triangle (or wall) we need a tool that
helps us to distinguish if a triangle looks toward a light source or not. One
possibility to do this is a surface normal. In the preceding examples we assumed
that the surface normal is perpendicular to the surface. This is not always
true, as we see later, therefore we like to define a normal at least for each
triangle (or face). When you have a look at the cube.egg once more you see that
for every polygon, a normal is specified. If Panda3D needs to triangulate the
model for the GPU it assigns every triangle, that belongs to the same polygon,
the same normal.

That is not the whole truth, in fact, the GPU likes to have a normal for every
vertex. Why this is a good idea is shown by another example. Open the enclosed
figures.svg or figures.png and look at figure 8-1. If we have a cube, there are
at least two possibilities to assign normals. The visual difference you may see
later is that the left cube has sharp edges, while the right cube has smooth
edges (on the right cube, the normals on each corner have a small gap in
between, this gap is only here to see that every vertex has a normal). Metal
like objects may have sharper edges while wooden objects may not. An artist may
influence how a model looks like (with lighting enabled) if he/she modifies the
normals. Back to our &quot;whole truth&quot; problem. As you can see it is impossible to
create a smooth cube if every polygon or triangle only has one normal. We need
at least one normal for every vertex.

The cube.egg model is an example of cube with sharp edges, while the
cube-smooth.egg model is an example of a cube with smooth edges. Try to see the
difference between this two files.

The fixed function pipeline of a GPU (that is the pipeline Panda3D uses if there
is no call to setShader or setAutoShader) is not that sophisticated. Better said
the GPUs were not powerful enough to calculate this very simple lighting model
per fragment/pixel, they only can calculate it per vertex. The larger your
triangles on your screen, the falser the result.

One more definition for diffuse lighting is, that it does not depend on the
viewers position. That is not true for all effects e.g. the &quot;output&quot; of a mirror
depends on the viewers position. Specular lighting simulates a mirror like
effect for lights and therefore depends on the viewers position.

Diffuse lighting is especially suited for rough surfaces, because of our
definition that the surfaces should distribute light in any direction,
independent of any other environmental effects.

Back to our problem: We have a surface normal, we have a light position and we
say that only this two things should matter. We now can calculate a direction
vector from the light to our triangle. Because it is a point light, that
distributes light in any direction, this assumption is correct. After this first
operation we calculate the angle between this direction and surface normal.
Based on this angle we can calculate how much diffuse light we have on a
triangle.

        |          |
1. -&gt; &lt;-|    2. -&gt; |-&gt;
        |          |

In example 1. we have 100% diffuse light while in the example 2. there is 0%
diffuse lighting.

There are two possibilities to calculate this angle. We do some trigonometry, or
we use the dot product. Both ideas are equivalent, but the second is faster to
calculate.

Read the following page to get in-depth information.

http://en.wikipedia.org/wiki/Dot_product

We will later see how to calculate exactly each of this steps. I only like to
introduce some concepts here.
&quot;&quot;&quot;

import sys
import math

import direct.directbase.DirectStart
from direct.interval.LerpInterval import LerpFunc
from panda3d.core import PointLight

base.setBackgroundColor(0.0, 0.0, 0.0)
base.disableMouse()

base.camLens.setNearFar(1.0, 50.0)
base.camLens.setFov(45.0)

camera.setPos(0.0, -20.0, 10.0)
camera.lookAt(0.0, 0.0, 0.0)

root = render.attachNewNode(&quot;Root&quot;)

&quot;&quot;&quot;
We set up a default point light here. You may modify the color of the light, but
in the next examples we assume, that the light has no attenuation and is white.

There is a dummy model attached to this node, to see where the light should be.
Because this light is parented to render, and we only enable light on the cubes,
this model does not influence the lighting nor is it lit by the light itself.
&quot;&quot;&quot;
pointlight = PointLight(&quot;Light&quot;)
light = render.attachNewNode(pointlight)
modelLight = loader.loadModel(&quot;misc/Pointlight.egg.pz&quot;)
modelLight.reparentTo(light)

&quot;&quot;&quot;
DIRTY
Replace cube.egg with cube-smooth.egg and try to understand why both outputs
differ.
&quot;&quot;&quot;
modelCube = loader.loadModel(&quot;cube.egg&quot;)

cubes = []
for x in [-3.0, 0.0, 3.0]:
    cube = modelCube.copyTo(root)
    cube.setPos(x, 0.0, 0.0)
    cube.setLight(light)
    cubes += [ cube ]

base.accept(&quot;escape&quot;, sys.exit)
base.accept(&quot;o&quot;, base.oobe)

&quot;&quot;&quot;
We move around our light. Because this basic application only supports per
vertex lighting you often can see some odd artifacts if only one vertex of a
face is lit.

The bounding box around all cubes ranges from (-4.0, -1.0, -1.0) to (4.0, 1.0,
1.0). Therefore we set the radius of the virtual sphere (the motion path of the
light) to something that is only a little bit larger than 4.0. This helps later
to see the visual difference from per vertex lighting to per pixel lighting.
&quot;&quot;&quot;
def animate(t):
    radius = 4.3
    angle = math.radians(t)
    x = math.cos(angle) * radius
    y = math.sin(angle) * radius
    z = math.sin(angle) * radius
    light.setPos(x, y, z)

def intervalStartPauseResume(i):
    if i.isStopped():
        i.start()
    elif i.isPaused():
        i.resume()
    else:
        i.pause()

interval = LerpFunc(animate, 10.0, 0.0, 360.0)

base.accept(&quot;i&quot;, intervalStartPauseResume, [interval])

def move(x, y, z):
    root.setX(root.getX() + x)
    root.setY(root.getY() + y)
    root.setZ(root.getZ() + z)

base.accept(&quot;d&quot;, move, [1.0, 0.0, 0.0])
base.accept(&quot;a&quot;, move, [-1.0, 0.0, 0.0])
base.accept(&quot;w&quot;, move, [0.0, 1.0, 0.0])
base.accept(&quot;s&quot;, move, [0.0, -1.0, 0.0])
base.accept(&quot;e&quot;, move, [0.0, 0.0, 1.0])
base.accept(&quot;q&quot;, move, [0.0, 0.0, -1.0])

run()

&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>Chickens</title>
    <ns>0</ns>
    <id>2064</id>
    <redirect title="Position and Rotation Intervals" />
      <sha1>htitpzan1wf3oqcsoy6lcj2h4gmi9fi</sha1>
    <revision>
      <id>4105</id>
      <timestamp>2007-02-17T09:10:36Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>[[Chickens]] moved to [[Position and Rotation Intervals]]: this article should be removed. so i renamed it so it can be used to store other stuff in.</comment>
      <text xml:space="preserve" bytes="45">#REDIRECT [[Position and Rotation Intervals]]</text>
    </revision>
  </page>
  <page>
    <title>Choosing a Texture Size</title>
    <ns>0</ns>
    <id>1235</id>
      <sha1>68febeblsdh6m37sl682ailjw9l9uzz</sha1>
    <revision>
      <id>7385</id>
      <timestamp>2011-11-29T12:00:13Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="5211">&lt;b&gt;Standard Texture Sizes&lt;/b&gt;

Most graphics hardware requires that your texture images always
be a size that is a power of two in each dimension.  That means you
can use any of the following choices for a texture size: 1, 2, 4, 8,
16, 32, 64, 128, 256, 512, 1024, 2048, or so on (but unless you have a
&lt;i&gt;really&lt;/i&gt; high-end card, you'll probably need to stop there).

The textures don't usually have to be &lt;i&gt;square:&lt;/i&gt; they don't have
to have the same size in both dimensions.  But each dimension does
usually have to be a power of two.  So 64 &amp;times; 128 is all
right, for instance, or 512 &amp;times; 32, or
256 &amp;times; 256.  But you can't make a texture image that is
200 &amp;times; 200 pixels, since 200 isn't a power of two.

By default, Panda3D will automatically rescale any texture image
down to the nearest smaller power of two when you read it from disk,
so you usually don't have to think about this--but your application
will load faster if you scale your textures properly in the first
place.

If you would like Panda3D to rescale your images up to the next larger power of two instead of down to the next smaller power of two, use:

&lt;code prc&gt;
textures-power-2 up
&lt;/code&gt;

In your config file.  The default is:

&lt;code prc&gt;
textures-power-2 down
&lt;/code&gt;

As of version 1.8.0, another mode was added which adds black borders as needed to frame the texture within a larger power-two texture. To enable this mode instead, use:

&lt;code prc&gt;
textures-power-2 pad
&lt;/code&gt;

In your config file.

It will then be up to your code to apply &lt;code&gt;texture.getTexScale()&lt;/code&gt; where needed. This mode does, of course, prevent using repeated textures.

Although you usually shouldn't use non power-of-two textures, for some things like GUI graphics it is not very uncommon to have them like that and let the game engine scale or pad them automatically.

Note that the size you choose for the texture image has
nothing to do with the size or shape of the texture image
onscreen--that's controlled by the size and shape of the polygon you
apply it to.  Making a texture image larger won't make it make it
appear larger onscreen, but it will tend to make it crisper and more
detailed.  Similarly, making a texture smaller will tend to make it
fuzzier.

&lt;b&gt;Padded Textures&lt;/b&gt;

Sometimes, you need to load data into a texture every frame.
The most common example is when you're playing a movie.  Let's say,
for example, that the movie is encoded at 640x480 at 30fps.  Neither
of those dimensions is a power-of-two. It would theoretically be
possible for Panda3D to rescale the image to 512x512, but it would
have to do it 30 times per second, which is too expensive to be
practical.

Instead, panda &lt;i&gt;pads&lt;/i&gt; the data.  Panda creates a 1024x512
texture, which is the smallest power-of-two size that can
hold a 640x480 movie.  It sticks the 640x480 movie
into the lower-left corner of the texture.  Then, it adds a black
border to the right edge and top edge of the movie, padding it
out to 1024x512.

From that point forward, it's just a texture with a movie in the
lower-left corner, and black bars on the upper and right sides.
However, if you use UV coordinates carefully, you can cause just
the movie to be displayed.  To do this, you need to know how big those
black bars are:

&lt;code python&gt;
padx = texture.getPadXSize()
pady = texture.getPadYSize()
&lt;/code&gt;

Panda3D only uses padded textures in a few very special cases:
1. When playing a non-power-of-two movie.
2. When using render-to-texture, and a non-power-of-two buffer.

&lt;b&gt;Nonstandard Texture Sizes&lt;/b&gt;

Some newer graphics cards can render textures that are not a power of
two.  This is generally not very useful for loading art from disk: after
all, game art is usually created in power-of-two sizes no matter what.
However, it is useful to avoid wasteful movie padding of the kind described
above.  If you have one of these cards and you want to enable the use
of non-power-of-two textures, you can put the following line in
your Config.prc:

&lt;code prc&gt;
textures-power-2 none
&lt;/code&gt;

You can also attempt to have panda detect your video card's capabilities automatically, using this command:

&lt;code prc&gt;
textures-auto-power-2 #t
&lt;/code&gt;

If this variable is true, then panda will wait until you open a window, and
then ask the window's driver if the driver supports non-power-of-two
textures.  If so, then the config variable &lt;code&gt;textures_power_2&lt;/code&gt; will automatically be adjusted.  In this way, you can configure Panda3D to use non-power-of-two textures if they are available.

Caution: there is a potential pitfall when using &lt;code&gt;textures-auto-power-2&lt;/code&gt;.  If you open a window that supports non-power-of-two textures, panda will switch into &lt;code&gt;textures-power-2 none&lt;/code&gt; mode.  If you then open a &lt;i&gt;second&lt;/i&gt; window using a different video card which doesn't support non-power-of-two textures, then panda will have no choice but to print an error message.

Note that some cards &lt;i&gt;appear&lt;/i&gt; to be able to render
non-power-of-two textures, but the driver is really just scaling the
textures at load time.  With cards like these, you're better off
letting Panda do the scaling, or dynamic textures may render
&lt;i&gt;very&lt;/i&gt; slowly.</text>
    </revision>
  </page>
  <page>
    <title>Class Reference</title>
    <ns>0</ns>
    <id>2212</id>
      <sha1>josl6o4pz8j1te2ur3b720wuxspe8tr</sha1>
    <revision>
      <id>4992</id>
      <timestamp>2008-03-14T21:51:45Z</timestamp>
      <contributor>
        <username>Treeform</username>
        <id>163</id>
      </contributor>
      <comment>crap only got the direct last time</comment>
      <text xml:space="preserve" bytes="149926">&lt;ul&gt;
&lt;li&gt;direct:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;actor:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Actor Actor]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DistributedActor DistributedActor]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;cluster:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;ClusterClient:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ClusterClient ClusterClient]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ClusterClientSync ClusterClientSync]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ClusterConfigItem ClusterConfigItem]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DisplayConnection DisplayConnection]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DummyClusterClient DummyClusterClient]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;ClusterMsgs:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ClusterMsgHandler ClusterMsgHandler]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ClusterServer ClusterServer]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;controls:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BattleWalker BattleWalker]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ControlManager ControlManager]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DevWalker DevWalker]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GhostWalker GhostWalker]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GravityWalker GravityWalker]&lt;/li&gt;
&lt;li&gt;InputState:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=InputState InputState]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=InputStateForceToken InputStateForceToken]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=InputStateToken InputStateToken]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=InputStateTokenGroup InputStateTokenGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=InputStateWatchToken InputStateWatchToken]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NonPhysicsWalker NonPhysicsWalker]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ObserverWalker ObserverWalker]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PhysicsWalker PhysicsWalker]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ShipPilot ShipPilot]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ShipPilot2 ShipPilot2]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SwimWalker SwimWalker]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;dcparser:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCArrayParameter DCArrayParameter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCAtomicField DCAtomicField]&lt;/li&gt;
&lt;li&gt;dcClass:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCClass DCClass]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCParameter DCParameter]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;dcClassParameter:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCClass DCClass]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCClassParameter DCClassParameter]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;dcDeclaration:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCClass DCClass]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCDeclaration DCDeclaration]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCSwitch DCSwitch]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;dcField:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCAtomicField DCAtomicField]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCClass DCClass]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCField DCField]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCMolecularField DCMolecularField]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCPacker DCPacker]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCParameter DCParameter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCSwitch DCSwitch]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;dcFile:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCClass DCClass]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCDeclaration DCDeclaration]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCField DCField]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCFile DCFile]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCKeyword DCKeyword]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCSwitch DCSwitch]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCTypedef DCTypedef]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;dcKeyword:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCKeyword DCKeyword]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCParameter DCParameter]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;dcKeywordList:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCKeyword DCKeyword]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCKeywordList DCKeywordList]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;dcMolecularField:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCAtomicField DCAtomicField]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCMolecularField DCMolecularField]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCParameter DCParameter]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCPackData DCPackData]&lt;/li&gt;
&lt;li&gt;dcPacker:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCClass DCClass]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCPacker DCPacker]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCSwitchParameter DCSwitchParameter]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;dcPackerCatalog:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCPacker DCPacker]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCPackerInterface DCPackerInterface]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCSwitchParameter DCSwitchParameter]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;dcPackerInterface:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCArrayParameter DCArrayParameter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCAtomicField DCAtomicField]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCClassParameter DCClassParameter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCField DCField]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCFile DCFile]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCMolecularField DCMolecularField]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCPackData DCPackData]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCPackerInterface DCPackerInterface]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCSimpleParameter DCSimpleParameter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCSwitchParameter DCSwitchParameter]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;dcParameter:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCArrayParameter DCArrayParameter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCClassParameter DCClassParameter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCParameter DCParameter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCSimpleParameter DCSimpleParameter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCTypedef DCTypedef]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;dcParserDefs:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCAtomicField DCAtomicField]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCClass DCClass]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCField DCField]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCFile DCFile]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCKeyword DCKeyword]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCPacker DCPacker]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCParameter DCParameter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCSwitch DCSwitch]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCSimpleParameter DCSimpleParameter]&lt;/li&gt;
&lt;li&gt;dcSwitch:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCField DCField]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCParameter DCParameter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCSwitch DCSwitch]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;dcSwitchParameter:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCSwitch DCSwitch]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCSwitchParameter DCSwitchParameter]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;dcTypedef:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCParameter DCParameter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCTypedef DCTypedef]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;deadrec:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SmoothMover SmoothMover]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;directdevices:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;DirectDeviceManager:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectAnalogs DirectAnalogs]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectButtons DirectButtons]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectDeviceManager DirectDeviceManager]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectDials DirectDials]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectTimecodeReader DirectTimecodeReader]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectTracker DirectTracker]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectFastrak DirectFastrak]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectJoybox DirectJoybox]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectRadamec DirectRadamec]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;directnotify:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectNotify DirectNotify]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Logger Logger]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Notifier Notifier]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RotatingLog RotatingLog]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;directtools:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectCameraControl DirectCameraControl]&lt;/li&gt;
&lt;li&gt;DirectGeometry:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LineNodePath LineNodePath]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectGrid DirectGrid]&lt;/li&gt;
&lt;li&gt;DirectLights:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectLight DirectLight]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectLights DirectLights]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;DirectManipulation:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectManipulationControl DirectManipulationControl]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ObjectHandles ObjectHandles]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;DirectSelection:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectBoundingBox DirectBoundingBox]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectNodePath DirectNodePath]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SelectedNodePaths SelectedNodePaths]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SelectionQueue SelectionQueue]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SelectionRay SelectionRay]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SelectionSegment SelectionSegment]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SelectionSphere SelectionSphere]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;DirectSession:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectSession DirectSession]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DisplayRegionContext DisplayRegionContext]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DisplayRegionList DisplayRegionList]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;directutil:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DeltaProfiler DeltaProfiler]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DistributedLargeBlobSender DistributedLargeBlobSender]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DistributedLargeBlobSenderAI DistributedLargeBlobSenderAI]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Mopath Mopath]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=WeightedChoice WeightedChoice]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;distributed:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AsyncRequest AsyncRequest]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CRCache CRCache]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CartesianGridBase CartesianGridBase]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ClientRepository ClientRepository]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ClientRepositoryBase ClientRepositoryBase]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ClockDelta ClockDelta]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConnectionRepository ConnectionRepository]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DelayDelete DelayDelete]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DistributedCartesianGrid DistributedCartesianGrid]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DistributedCartesianGridAI DistributedCartesianGridAI]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DistributedNode DistributedNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DistributedNodeAI DistributedNodeAI]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DistributedNodeUD DistributedNodeUD]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DistributedObject DistributedObject]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DistributedObjectAI DistributedObjectAI]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DistributedObjectBase DistributedObjectBase]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DistributedObjectGlobal DistributedObjectGlobal]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DistributedObjectGlobalAI DistributedObjectGlobalAI]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DistributedObjectGlobalUD DistributedObjectGlobalUD]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DistributedObjectOV DistributedObjectOV]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DistributedObjectUD DistributedObjectUD]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DistributedSmoothNode DistributedSmoothNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DistributedSmoothNodeAI DistributedSmoothNodeAI]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DistributedSmoothNodeBase DistributedSmoothNodeBase]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DoCollectionManager DoCollectionManager]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DoHierarchy DoHierarchy]&lt;/li&gt;
&lt;li&gt;DoInterestManager:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DoInterestManager DoInterestManager]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=InterestHandle InterestHandle]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=InterestState InterestState]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GridParent GridParent]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=InterestWatcher InterestWatcher]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NetMessenger NetMessenger]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=OldClientRepository OldClientRepository]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ParentMgr ParentMgr]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PyDatagram PyDatagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PyDatagramIterator PyDatagramIterator]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RelatedObjectMgr RelatedObjectMgr]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SampleObject SampleObject]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ServerRepository ServerRepository]&lt;/li&gt;
&lt;li&gt;cConnectionRepository:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CConnectionRepository CConnectionRepository]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=HTTPChannel HTTPChannel]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SocketStream SocketStream]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=URLSpec URLSpec]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;cDistributedSmoothNodeBase:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CConnectionRepository CConnectionRepository]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CDistributedSmoothNodeBase CDistributedSmoothNodeBase]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DCClass DCClass]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;fsm:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ClassicFSM ClassicFSM]&lt;/li&gt;
&lt;li&gt;FSM:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AlreadyInTransition AlreadyInTransition]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FSM FSM]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FSMException FSMException]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RequestDenied RequestDenied]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FourState FourState]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FourStateAI FourStateAI]&lt;/li&gt;
&lt;li&gt;SampleFSM:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ClassicStyle ClassicStyle]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NewStyle NewStyle]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ToonEyes ToonEyes]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=State State]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=StateData StateData]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;gui:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectButton DirectButton]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectCheckBox DirectCheckBox]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectCheckButton DirectCheckButton]&lt;/li&gt;
&lt;li&gt;DirectDialog:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectDialog DirectDialog]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=OkCancelDialog OkCancelDialog]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=OkDialog OkDialog]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RetryCancelDialog RetryCancelDialog]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=YesNoCancelDialog YesNoCancelDialog]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=YesNoDialog YesNoDialog]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectEntry DirectEntry]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectFrame DirectFrame]&lt;/li&gt;
&lt;li&gt;DirectGuiBase:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectGuiBase DirectGuiBase]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectGuiWidget DirectGuiWidget]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectLabel DirectLabel]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectOptionMenu DirectOptionMenu]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectScrollBar DirectScrollBar]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectScrolledFrame DirectScrolledFrame]&lt;/li&gt;
&lt;li&gt;DirectScrolledList:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectScrolledList DirectScrolledList]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectScrolledListItem DirectScrolledListItem]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectSlider DirectSlider]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectWaitBar DirectWaitBar]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=OnscreenGeom OnscreenGeom]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=OnscreenImage OnscreenImage]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=OnscreenText OnscreenText]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;http:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;http_bufferedreader:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page= ]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;ringbuffer_slide:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page= ]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;strtargetbuffer:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page= ]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;webAIInspector:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ClassInspector ClassInspector]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CodeInspector CodeInspector]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ComplexInspector ComplexInspector]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DictionaryInspector DictionaryInspector]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FunctionInspector FunctionInspector]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Inspector Inspector]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=InstanceInspector InstanceInspector]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=InstanceMethodInspector InstanceMethodInspector]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ModuleInspector ModuleInspector]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SequenceInspector SequenceInspector]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SliceInspector SliceInspector]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;interval:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;ActorInterval:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ActorInterval ActorInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LerpAnimInterval LerpAnimInterval]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;FunctionInterval:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AcceptInterval AcceptInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EventInterval EventInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Func Func]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FunctionInterval FunctionInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=HprInterval HprInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=HprScaleInterval HprScaleInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=IgnoreInterval IgnoreInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ParentInterval ParentInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PosHprInterval PosHprInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PosHprScaleInterval PosHprScaleInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PosInterval PosInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ScaleInterval ScaleInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Wait Wait]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=WrtParentInterval WrtParentInterval]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=IndirectInterval IndirectInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Interval Interval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=IntervalManager IntervalManager]&lt;/li&gt;
&lt;li&gt;LerpInterval:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LerpColorInterval LerpColorInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LerpColorScaleInterval LerpColorScaleInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LerpFunc LerpFunc]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LerpFunctionInterval LerpFunctionInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LerpHprInterval LerpHprInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LerpHprScaleInterval LerpHprScaleInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LerpNodePathInterval LerpNodePathInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LerpPosHprInterval LerpPosHprInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LerpPosHprScaleInterval LerpPosHprScaleInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LerpPosHprScaleShearInterval LerpPosHprScaleShearInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LerpPosInterval LerpPosInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LerpPosQuatInterval LerpPosQuatInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LerpPosQuatScaleInterval LerpPosQuatScaleInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LerpPosQuatScaleShearInterval LerpPosQuatScaleShearInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LerpQuatInterval LerpQuatInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LerpQuatScaleInterval LerpQuatScaleInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LerpScaleInterval LerpScaleInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LerpShearInterval LerpShearInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LerpTexOffsetInterval LerpTexOffsetInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LerpTexRotateInterval LerpTexRotateInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LerpTexScaleInterval LerpTexScaleInterval]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;MetaInterval:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MetaInterval MetaInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Parallel Parallel]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ParallelEndTogether ParallelEndTogether]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Sequence Sequence]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Track Track]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MopathInterval MopathInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ParticleInterval ParticleInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ProjectileInterval ProjectileInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SoundInterval SoundInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TestInterval TestInterval]&lt;/li&gt;
&lt;li&gt;cInterval:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CInterval CInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CIntervalManager CIntervalManager]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;cIntervalManager:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CIntervalManager CIntervalManager]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EventQueue EventQueue]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CLerpAnimEffectInterval CLerpAnimEffectInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CLerpInterval CLerpInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CLerpNodePathInterval CLerpNodePathInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CMetaInterval CMetaInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=HideInterval HideInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ShowInterval ShowInterval]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=WaitInterval WaitInterval]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;leveleditor:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;LevelEditor:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DNABaselineStyle DNABaselineStyle]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DNAFlatBuildingStyle DNAFlatBuildingStyle]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DNAWallStyle DNAWallStyle]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LevelAttribute LevelAttribute]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LevelEditor LevelEditor]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LevelEditorPanel LevelEditorPanel]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LevelStyleManager LevelStyleManager]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=OldLevelEditor OldLevelEditor]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VisGroupsEditor VisGroupsEditor]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;PieMenu:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PieMenu PieMenu]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TextPieMenu TextPieMenu]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MotionTrail MotionTrail]&lt;/li&gt;
&lt;li&gt;particles:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ForceGroup ForceGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GlobalForceGroup GlobalForceGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ParticleEffect ParticleEffect]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ParticleFloorTest ParticleFloorTest]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Particles Particles]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SpriteParticleRendererExt SpriteParticleRendererExt]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;physics:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FallTest FallTest]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RotationTest RotationTest]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;pyinst:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;Builder:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ArchiveTarget ArchiveTarget]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollectTarget CollectTarget]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ExeTarget ExeTarget]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FullExeTarget FullExeTarget]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=InstallTarget InstallTarget]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PYZTarget PYZTarget]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Target Target]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;archive:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Archive Archive]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ZlibArchive ZlibArchive]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;archive_rt:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Archive Archive]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ZlibArchive ZlibArchive]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;carchive:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CArchive CArchive]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CTOC CTOC]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;carchive_rt:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CArchive CArchive]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CTOC CTOC]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;icon:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GRPICONDIR GRPICONDIR]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GRPICONDIRENTRY GRPICONDIRENTRY]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ICONDIRENTRY ICONDIRENTRY]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ICONDIRHEADER ICONDIRHEADER]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=IconFile IconFile]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Structure Structure]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;imputil:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectoryImporter DirectoryImporter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FuncImporter FuncImporter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Importer Importer]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PackageArchive PackageArchive]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PackageArchiveImporter PackageArchiveImporter]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=lTOC lTOC]&lt;/li&gt;
&lt;li&gt;mkarchive:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MkImporter MkImporter]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;modulefinder:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Module Module]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ModuleFinder ModuleFinder]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;resource:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=archiveresource archiveresource]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=binaryresource binaryresource]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=dataresource dataresource]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=dirresource dirresource]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=moduleresource moduleresource]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=pkgresource pkgresource]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=pythonresource pythonresource]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=resource resource]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=scriptresource scriptresource]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=treeresource treeresource]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=zlibresource zlibresource]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;tocfilter:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirFilter DirFilter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ExtFilter ExtFilter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FileFilter FileFilter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ModFilter ModFilter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PatternFilter PatternFilter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PkgFilter PkgFilter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=StdLibFilter StdLibFilter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TypeFilter TypeFilter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=_ExtFilter _ExtFilter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=_Filter _Filter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=_NameFilter _NameFilter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=_PathFilter _PathFilter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=_PatternFilter _PatternFilter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=_TypeFilter _TypeFilter]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;showbase:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Audio3DManager Audio3DManager]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BufferViewer BufferViewer]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BulletinBoard BulletinBoard]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BulletinBoardWatcher BulletinBoardWatcher]&lt;/li&gt;
&lt;li&gt;ContainerLeakDetector:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CheckContainers CheckContainers]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ContainerLeakDetector ContainerLeakDetector]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FindContainers FindContainers]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Indirection Indirection]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NoDictKey NoDictKey]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ObjectRef ObjectRef]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PruneObjectRefs PruneObjectRefs]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ContainerReport ContainerReport]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CountedResource CountedResource]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectObject DirectObject]&lt;/li&gt;
&lt;li&gt;DistancePhasedNode:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BufferedDistancePhasedNode BufferedDistancePhasedNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DistancePhasedNode DistancePhasedNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EventGroup EventGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EventManager EventManager]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ExcelHandler ExcelHandler]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Factory Factory]&lt;/li&gt;
&lt;li&gt;GarbageReport:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FakeObject FakeObject]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GarbageLogger GarbageLogger]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GarbageReport GarbageReport]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GarbageReportScheduler GarbageReportScheduler]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Job Job]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=JobManager JobManager]&lt;/li&gt;
&lt;li&gt;LeakDetectors:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CppMemoryUsage CppMemoryUsage]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GarbageLeakDetector GarbageLeakDetector]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LeakDetector LeakDetector]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SceneGraphLeakDetector SceneGraphLeakDetector]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Loader Loader]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Messenger Messenger]&lt;/li&gt;
&lt;li&gt;MessengerLeakDetector:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MessengerLeakDetector MessengerLeakDetector]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MessengerLeakObject MessengerLeakObject]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;ObjectPool:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Diff Diff]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ObjectPool ObjectPool]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;ObjectReport:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ExclusiveObjectPool ExclusiveObjectPool]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ObjectReport ObjectReport]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=OnScreenDebug OnScreenDebug]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PhasedObject PhasedObject]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Pool Pool]&lt;/li&gt;
&lt;li&gt;PythonUtil:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ArgumentEater ArgumentEater]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Camera Camera]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ClassTree ClassTree]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DelayedCall DelayedCall]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DelayedFunctor DelayedFunctor]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Enum Enum]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EnumIter EnumIter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FrameDelayedCall FrameDelayedCall]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Functor Functor]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GoldenRectangle GoldenRectangle]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=HotkeyBreaker HotkeyBreaker]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=POD POD]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ParamObj ParamObj]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Queue Queue]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RefCounter RefCounter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ScratchPad ScratchPad]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SerialNumGen SerialNumGen]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Signature Signature]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Singleton Singleton]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SingletonError SingletonError]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Stack Stack]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=StackTrace StackTrace]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SubframeCall SubframeCall]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Sync Sync]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RandomNumGen RandomNumGen]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SfxPlayer SfxPlayer]&lt;/li&gt;
&lt;li&gt;ShadowDemo:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ShadowCaster ShadowCaster]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ShadowPlacer ShadowPlacer]&lt;/li&gt;
&lt;li&gt;ShowBase:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ShowBase ShowBase]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=WindowControls WindowControls]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;TaskThreaded:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TaskThread TaskThread]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TaskThreaded TaskThreaded]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ThreeUpShow ThreeUpShow]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Transitions Transitions]&lt;/li&gt;
&lt;li&gt;pandaSqueezeTool:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Loader Loader]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Squeezer Squeezer]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;showBase:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Camera Camera]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionTraverser CollisionTraverser]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsEngine GraphicsEngine]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;showutil:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Rope Rope]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;task:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;Task:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Task Task]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TaskManager TaskManager]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TaskPriorityList TaskPriorityList]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Timer Timer]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;tkpanels:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;AnimPanel:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ActorControl ActorControl]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AnimPanel AnimPanel]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectSessionPanel DirectSessionPanel]&lt;/li&gt;
&lt;li&gt;FSMInspector:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FSMInspector FSMInspector]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=StateInspector StateInspector]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;Inspector:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ClassInspector ClassInspector]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CodeInspector CodeInspector]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ComplexInspector ComplexInspector]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DictionaryInspector DictionaryInspector]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FunctionInspector FunctionInspector]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Inspector Inspector]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=InspectorWindow InspectorWindow]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=InstanceInspector InstanceInspector]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=InstanceMethodInspector InstanceMethodInspector]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ModuleInspector ModuleInspector]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SequenceInspector SequenceInspector]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SliceInspector SliceInspector]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MopathRecorder MopathRecorder]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NotifyPanel NotifyPanel]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ParticlePanel ParticlePanel]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Placer Placer]&lt;/li&gt;
&lt;li&gt;TaskManagerPanel:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TaskManagerPanel TaskManagerPanel]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TaskManagerWidget TaskManagerWidget]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;tkwidgets:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;AppShell:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AppShell AppShell]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TestAppShell TestAppShell]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;Dial:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AngleDial AngleDial]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Dial Dial]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DialWidget DialWidget]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;EntryScale:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EntryScale EntryScale]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EntryScaleGroup EntryScaleGroup]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;Floater:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Floater Floater]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FloaterGroup FloaterGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FloaterWidget FloaterWidget]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ProgressBar ProgressBar]&lt;/li&gt;
&lt;li&gt;SceneGraphExplorer:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SceneGraphExplorer SceneGraphExplorer]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SceneGraphExplorerItem SceneGraphExplorerItem]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;Slider:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Slider Slider]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SliderWidget SliderWidget]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;Tree:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TreeItem TreeItem]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TreeNode TreeNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;Valuator:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Valuator Valuator]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ValuatorGroup ValuatorGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ValuatorGroupPanel ValuatorGroupPanel]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;VectorWidgets:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ColorEntry ColorEntry]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Vector2Entry Vector2Entry]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Vector3Entry Vector3Entry]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Vector4Entry Vector4Entry]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VectorEntry VectorEntry]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=WidgetPropertiesDialog WidgetPropertiesDialog]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;dtool:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;dtoolbase:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;dtoolbase_cc:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ReferenceCount ReferenceCount]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NeverFreeMemory NeverFreeMemory]&lt;/li&gt;
&lt;li&gt;typeHandle:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TypeHandle TypeHandle]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TypedObject TypedObject]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;typeRegistry:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TypeHandle TypeHandle]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TypeRegistry TypeRegistry]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TypedObject TypedObject]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TypedObject TypedObject]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;dtoolutil:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DSearchPath DSearchPath]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ExecutionEnvironment ExecutionEnvironment]&lt;/li&gt;
&lt;li&gt;filename:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DSearchPath DSearchPath]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Filename Filename]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PandaSystem PandaSystem]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;prc:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConfigFlags ConfigFlags]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConfigPage ConfigPage]&lt;/li&gt;
&lt;li&gt;configPageManager:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConfigPage ConfigPage]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConfigPageManager ConfigPageManager]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConfigVariable ConfigVariable]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConfigVariableBase ConfigVariableBase]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConfigVariableBool ConfigVariableBool]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConfigVariableDouble ConfigVariableDouble]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConfigVariableFilename ConfigVariableFilename]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConfigVariableInt ConfigVariableInt]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConfigVariableList ConfigVariableList]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConfigVariableManager ConfigVariableManager]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConfigVariableSearchPath ConfigVariableSearchPath]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConfigVariableString ConfigVariableString]&lt;/li&gt;
&lt;li&gt;config_prc:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConfigVariableBool ConfigVariableBool]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GlobPattern GlobPattern]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NotifyCategory NotifyCategory]&lt;/li&gt;
&lt;li&gt;pnotify:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Notify Notify]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NotifyCategory NotifyCategory]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=StreamReader StreamReader]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=StreamWriter StreamWriter]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;makepanda:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;makepandacore:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Target Target]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;panda:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;audio:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AudioManager AudioManager]&lt;/li&gt;
&lt;li&gt;audioSound:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AudioManager AudioManager]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AudioSound AudioSound]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FilterProperties FilterProperties]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;chan:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AnimBundle AnimBundle]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AnimBundleNode AnimBundleNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AnimChannelBase AnimChannelBase]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AnimChannelMatrixDynamic AnimChannelMatrixDynamic]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AnimChannelMatrixXfmTable AnimChannelMatrixXfmTable]&lt;/li&gt;
&lt;li&gt;animChannelScalarDynamic:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AnimChannelScalarDynamic AnimChannelScalarDynamic]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PandaNode PandaNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TransformState TransformState]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AnimChannelScalarTable AnimChannelScalarTable]&lt;/li&gt;
&lt;li&gt;animControl:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AnimChannelBase AnimChannelBase]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AnimControl AnimControl]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PartBundle PartBundle]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AnimControlCollection AnimControlCollection]&lt;/li&gt;
&lt;li&gt;animGroup:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AnimBundle AnimBundle]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AnimGroup AnimGroup]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;auto_bind:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PandaNode PandaNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MovingPartBase MovingPartBase]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MovingPartMatrix MovingPartMatrix]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MovingPartScalar MovingPartScalar]&lt;/li&gt;
&lt;li&gt;partBundle:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AnimBundle AnimBundle]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PartBundle PartBundle]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PartBundleNode PartBundleNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TransformState TransformState]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PartBundleNode PartBundleNode]&lt;/li&gt;
&lt;li&gt;partGroup:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AnimChannelBase AnimChannelBase]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AnimControl AnimControl]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AnimGroup AnimGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BitArray BitArray]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PandaNode PandaNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PartBundle PartBundle]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PartGroup PartGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PartSubset PartSubset]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TransformState TransformState]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PartSubset PartSubset]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;char:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;character:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Character Character]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CharacterJointBundle CharacterJointBundle]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;characterJoint:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Character Character]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CharacterJoint CharacterJoint]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=JointVertexTransform JointVertexTransform]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;characterJointBundle:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Character Character]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CharacterJointBundle CharacterJointBundle]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CharacterJointEffect CharacterJointEffect]&lt;/li&gt;
&lt;li&gt;characterSlider:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CharacterSlider CharacterSlider]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CharacterVertexSlider CharacterVertexSlider]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CharacterVertexSlider CharacterVertexSlider]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=JointVertexTransform JointVertexTransform]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;collide:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionDSSolid CollisionDSSolid]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionEntry CollisionEntry]&lt;/li&gt;
&lt;li&gt;collisionFloorMesh:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionFloorMesh CollisionFloorMesh]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomNode GeomNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;collisionHandler:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionEntry CollisionEntry]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionHandler CollisionHandler]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionHandlerEvent CollisionHandlerEvent]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionHandlerFloor CollisionHandlerFloor]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionHandlerGravity CollisionHandlerGravity]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionHandlerPhysical CollisionHandlerPhysical]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionHandlerPusher CollisionHandlerPusher]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionHandlerQueue CollisionHandlerQueue]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionInvSphere CollisionInvSphere]&lt;/li&gt;
&lt;li&gt;collisionLevelStateBase:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionNode CollisionNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionSolid CollisionSolid]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionLine CollisionLine]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionNode CollisionNode]&lt;/li&gt;
&lt;li&gt;collisionParabola:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LensNode LensNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionPlane CollisionPlane]&lt;/li&gt;
&lt;li&gt;collisionPolygon:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionPolygon CollisionPolygon]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomNode GeomNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;collisionRay:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionRay CollisionRay]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LensNode LensNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;collisionRecorder:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionEntry CollisionEntry]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionRecorder CollisionRecorder]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionTraverser CollisionTraverser]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;collisionSegment:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionSegment CollisionSegment]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LensNode LensNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;collisionSolid:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionEntry CollisionEntry]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionHandler CollisionHandler]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionNode CollisionNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionSolid CollisionSolid]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionSphere CollisionSphere]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomNode GeomNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionSphere CollisionSphere]&lt;/li&gt;
&lt;li&gt;collisionTraverser:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionEntry CollisionEntry]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionNode CollisionNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionRecorder CollisionRecorder]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionTraverser CollisionTraverser]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionVisualizer CollisionVisualizer]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Geom Geom]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NodePath NodePath]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionTube CollisionTube]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionVisualizer CollisionVisualizer]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;cull:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;config_cull:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DSearchPath DSearchPath]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;drawCullHandler:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsStateGuardianBase GraphicsStateGuardianBase]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;device:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AnalogNode AnalogNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ButtonNode ButtonNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ClientBase ClientBase]&lt;/li&gt;
&lt;li&gt;clientDevice:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ClientBase ClientBase]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DialNode DialNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MouseAndKeyboard MouseAndKeyboard]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TrackerNode TrackerNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VirtualMouse VirtualMouse]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;dgraph:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;dataGraphTraverser:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DataGraphTraverser DataGraphTraverser]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DataNode DataNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PandaNode PandaNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;dataNode:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DataGraphTraverser DataGraphTraverser]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DataNode DataNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;dataNodeTransmit:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;display:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DisplayInformation DisplayInformation]&lt;/li&gt;
&lt;li&gt;displayRegion:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Camera Camera]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CullTraverser CullTraverser]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DisplayRegion DisplayRegion]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsOutput GraphicsOutput]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsPipe GraphicsPipe]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMImage PNMImage]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DisplaySearchParameters DisplaySearchParameters]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DrawableRegion DrawableRegion]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FrameBufferProperties FrameBufferProperties]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsBuffer GraphicsBuffer]&lt;/li&gt;
&lt;li&gt;graphicsDevice:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsDevice GraphicsDevice]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsPipe GraphicsPipe]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;graphicsEngine:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DisplayRegion DisplayRegion]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FrameBufferProperties FrameBufferProperties]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsEngine GraphicsEngine]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsPipe GraphicsPipe]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Texture Texture]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;graphicsOutput:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsOutput GraphicsOutput]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMImage PNMImage]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;graphicsPipe:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FrameBufferProperties FrameBufferProperties]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsBuffer GraphicsBuffer]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsOutput GraphicsOutput]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsPipe GraphicsPipe]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsStateGuardian GraphicsStateGuardian]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsWindow GraphicsWindow]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Texture Texture]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=WindowProperties WindowProperties]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;graphicsPipeSelection:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsPipeSelection GraphicsPipeSelection]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsWindow GraphicsWindow]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;graphicsStateGuardian:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DrawableRegion DrawableRegion]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsEngine GraphicsEngine]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsStateGuardian GraphicsStateGuardian]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsThreadingModel GraphicsThreadingModel]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsWindow GraphicsWindow]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ParasiteBuffer ParasiteBuffer]&lt;/li&gt;
&lt;li&gt;renderBuffer:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsStateGuardian GraphicsStateGuardian]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;stencilRenderStates:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsStateGuardian GraphicsStateGuardian]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=StencilRenderStates StencilRenderStates]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=WindowProperties WindowProperties]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;distort:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CylindricalLens CylindricalLens]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FisheyeLens FisheyeLens]&lt;/li&gt;
&lt;li&gt;nonlinearImager:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsEngine GraphicsEngine]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsOutput GraphicsOutput]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsStateGuardian GraphicsStateGuardian]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NonlinearImager NonlinearImager]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PSphereLens PSphereLens]&lt;/li&gt;
&lt;li&gt;projectionScreen:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Geom Geom]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ProjectionScreen ProjectionScreen]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;downloader:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;bioPtr:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=URLSpec URLSpec]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;chunkedStream:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=HTTPChannel HTTPChannel]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;decompressor:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Decompressor Decompressor]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Ramfile Ramfile]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DocumentSpec DocumentSpec]&lt;/li&gt;
&lt;li&gt;downloadDb:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DownloadDb DownloadDb]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Ramfile Ramfile]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=StreamReader StreamReader]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=StreamWriter StreamWriter]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Extractor Extractor]&lt;/li&gt;
&lt;li&gt;httpAuthorization:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=URLSpec URLSpec]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;httpChannel:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=HTTPChannel HTTPChannel]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=HTTPClient HTTPClient]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Ramfile Ramfile]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;httpClient:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Filename Filename]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=HTTPChannel HTTPChannel]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=HTTPClient HTTPClient]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=HTTPCookie HTTPCookie]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=HTTPDate HTTPDate]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=HTTPEntityTag HTTPEntityTag]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=HTTPEnum HTTPEnum]&lt;/li&gt;
&lt;li&gt;identityStream:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=HTTPChannel HTTPChannel]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MultiplexStream MultiplexStream]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Patcher Patcher]&lt;/li&gt;
&lt;li&gt;socketStream:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ISocketStream ISocketStream]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=OSocketStream OSocketStream]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SSReader SSReader]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SSWriter SSWriter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SocketStream SocketStream]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=URLSpec URLSpec]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;dxgsg8:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;dxGraphicsStateGuardian8:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Light Light]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;dxgsg9:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;dxGraphicsStateGuardian9:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Light Light]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;dxOcclusionQueryContext9:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsStateGuardian GraphicsStateGuardian]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;effects:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;lensFlareNode:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ClockObject ClockObject]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsStateGuardian GraphicsStateGuardian]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;egg:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggAnimData EggAnimData]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggAttributes EggAttributes]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggBin EggBin]&lt;/li&gt;
&lt;li&gt;eggBinMaker:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggBin EggBin]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggBinMaker EggBinMaker]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroup EggGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroupNode EggGroupNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggNode EggNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggComment EggComment]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggCompositePrimitive EggCompositePrimitive]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggCurve EggCurve]&lt;/li&gt;
&lt;li&gt;eggData:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BamCacheRecord BamCacheRecord]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggData EggData]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggExternalReference EggExternalReference]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggFilenameNode EggFilenameNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroup EggGroup]&lt;/li&gt;
&lt;li&gt;eggGroupNode:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BamCacheRecord BamCacheRecord]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DSearchPath DSearchPath]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroupNode EggGroupNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggMaterialCollection EggMaterialCollection]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggPolygon EggPolygon]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggTextureCollection EggTextureCollection]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggVertex EggVertex]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggVertexPool EggVertexPool]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroupUniquifier EggGroupUniquifier]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggLine EggLine]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggMaterial EggMaterial]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggMaterialCollection EggMaterialCollection]&lt;/li&gt;
&lt;li&gt;eggNameUniquifier:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggNameUniquifier EggNameUniquifier]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggNode EggNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggNamedObject EggNamedObject]&lt;/li&gt;
&lt;li&gt;eggNode:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroupNode EggGroupNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggNode EggNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggRenderMode EggRenderMode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggTextureCollection EggTextureCollection]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggNurbsCurve EggNurbsCurve]&lt;/li&gt;
&lt;li&gt;eggObject:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggObject EggObject]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggTransform EggTransform]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggPoint EggPoint]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggPolygon EggPolygon]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggPolysetMaker EggPolysetMaker]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggPoolUniquifier EggPoolUniquifier]&lt;/li&gt;
&lt;li&gt;eggPrimitive:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggPrimitive EggPrimitive]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggVertexPool EggVertexPool]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggRenderMode EggRenderMode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggSAnimData EggSAnimData]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggSurface EggSurface]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggSwitchCondition EggSwitchCondition]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggTable EggTable]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggTexture EggTexture]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggTextureCollection EggTextureCollection]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggTransform EggTransform]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggTriangleFan EggTriangleFan]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggTriangleStrip EggTriangleStrip]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggUserData EggUserData]&lt;/li&gt;
&lt;li&gt;eggUtilities:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggNode EggNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggVertex EggVertex]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;eggVertex:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroup EggGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggPrimitive EggPrimitive]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggVertex EggVertex]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggVertexPool EggVertexPool]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggVertexPool EggVertexPool]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggVertexUV EggVertexUV]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggXfmAnimData EggXfmAnimData]&lt;/li&gt;
&lt;li&gt;eggXfmSAnim:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggXfmAnimData EggXfmAnimData]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggXfmSAnim EggXfmSAnim]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;parserDefs:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroupNode EggGroupNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Mutex Mutex]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;egg2pg:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;animBundleMaker:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AnimBundle AnimBundle]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AnimBundleNode AnimBundleNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AnimChannelMatrixXfmTable AnimChannelMatrixXfmTable]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AnimChannelScalarTable AnimChannelScalarTable]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AnimGroup AnimGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroupNode EggGroupNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggNode EggNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggSAnimData EggSAnimData]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggTable EggTable]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggXfmSAnim EggXfmSAnim]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;characterMaker:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Character Character]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CharacterJointBundle CharacterJointBundle]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CharacterSlider CharacterSlider]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggBin EggBin]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroup EggGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroupNode EggGroupNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggNode EggNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggPrimitive EggPrimitive]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomNode GeomNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MovingPartBase MovingPartBase]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PandaNode PandaNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PartGroup PartGroup]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;deferredNodeProperty:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PandaNode PandaNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;eggLoader:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionNode CollisionNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionPlane CollisionPlane]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionPolygon CollisionPolygon]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CollisionSolid CollisionSolid]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggBin EggBin]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggMaterial EggMaterial]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggNode EggNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggNurbsCurve EggNurbsCurve]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggPolygon EggPolygon]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggPrimitive EggPrimitive]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggTable EggTable]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PolylightNode PolylightNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PortalNode PortalNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;eggRenderState:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggMaterial EggMaterial]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggPrimitive EggPrimitive]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggTexture EggTexture]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;load_egg_file:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BamCacheRecord BamCacheRecord]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;event:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;asyncTask:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AsyncTask AsyncTask]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AsyncTaskManager AsyncTaskManager]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AsyncTaskManager AsyncTaskManager]&lt;/li&gt;
&lt;li&gt;buttonEvent:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;buttonEventList:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ModifierButtons ModifierButtons]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Event Event]&lt;/li&gt;
&lt;li&gt;eventHandler:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EventHandler EventHandler]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EventQueue EventQueue]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;eventParameter:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EventParameter EventParameter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EventStoreTypedRefCount EventStoreTypedRefCount]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EventStoreValueBase EventStoreValueBase]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EventQueue EventQueue]&lt;/li&gt;
&lt;li&gt;pointerEvent:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;pointerEventList:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PointerEventList PointerEventList]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;express:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Buffer Buffer]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;datagramGenerator:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VirtualFile VirtualFile]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=HashVal HashVal]&lt;/li&gt;
&lt;li&gt;memoryInfo:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ReferenceCount ReferenceCount]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TypedObject TypedObject]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;memoryUsage:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ReferenceCount ReferenceCount]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Multifile Multifile]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Namable Namable]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NodeReferenceCount NodeReferenceCount]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PStatCollectorForwardBase PStatCollectorForwardBase]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Patchfile Patchfile]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PointerToVoid PointerToVoid]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ProfileTimer ProfileTimer]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Ramfile Ramfile]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ReferenceCount ReferenceCount]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TextEncoder TextEncoder]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TrueClock TrueClock]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TypedReferenceCount TypedReferenceCount]&lt;/li&gt;
&lt;li&gt;virtualFile:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VirtualFile VirtualFile]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VirtualFileList VirtualFileList]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VirtualFileSystem VirtualFileSystem]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VirtualFileComposite VirtualFileComposite]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VirtualFileList VirtualFileList]&lt;/li&gt;
&lt;li&gt;virtualFileMount:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VirtualFileSystem VirtualFileSystem]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VirtualFileSimple VirtualFileSimple]&lt;/li&gt;
&lt;li&gt;virtualFileSystem:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Multifile Multifile]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VirtualFileComposite VirtualFileComposite]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VirtualFileSystem VirtualFileSystem]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=WeakPointerToVoid WeakPointerToVoid]&lt;/li&gt;
&lt;li&gt;weakReferenceList:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=WeakPointerToVoid WeakPointerToVoid]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;framework:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;windowFramework:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AmbientLight AmbientLight]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectionalLight DirectionalLight]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DisplayRegion DisplayRegion]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsEngine GraphicsEngine]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsPipe GraphicsPipe]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;glstuff:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;glGraphicsStateGuardian_src:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Light Light]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PlaneNode PlaneNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;glOcclusionQueryContext_src:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsStateGuardian GraphicsStateGuardian]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;glxdisplay:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;glxGraphicsPipe:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FrameBufferProperties FrameBufferProperties]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;gobj:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;bufferContext:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BufferContext BufferContext]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PreparedGraphicsObjects PreparedGraphicsObjects]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;bufferContextChain:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BufferContext BufferContext]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;bufferResidencyTracker:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BufferContext BufferContext]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;geom:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Geom Geom]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomContext GeomContext]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PreparedGraphicsObjects PreparedGraphicsObjects]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;geomCacheEntry:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Geom Geom]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomPrimitive GeomPrimitive]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomCacheManager GeomCacheManager]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomContext GeomContext]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomEnums GeomEnums]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomLines GeomLines]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomLinestrips GeomLinestrips]&lt;/li&gt;
&lt;li&gt;geomMunger:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Geom Geom]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsStateGuardianBase GraphicsStateGuardianBase]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RenderState RenderState]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomPoints GeomPoints]&lt;/li&gt;
&lt;li&gt;geomPrimitive:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomPrimitive GeomPrimitive]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsStateGuardianBase GraphicsStateGuardianBase]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=IndexBufferContext IndexBufferContext]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PreparedGraphicsObjects PreparedGraphicsObjects]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomTriangles GeomTriangles]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomTrifans GeomTrifans]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomTristrips GeomTristrips]&lt;/li&gt;
&lt;li&gt;geomVertexAnimationSpec:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomVertexAnimationSpec GeomVertexAnimationSpec]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;geomVertexArrayData:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomVertexArrayData GeomVertexArrayData]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomVertexArrayDataHandle GeomVertexArrayDataHandle]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsStateGuardianBase GraphicsStateGuardianBase]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PreparedGraphicsObjects PreparedGraphicsObjects]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SimpleAllocatorBlock SimpleAllocatorBlock]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VertexBufferContext VertexBufferContext]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VertexDataBook VertexDataBook]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;geomVertexArrayFormat:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomVertexArrayData GeomVertexArrayData]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomVertexArrayFormat GeomVertexArrayFormat]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomVertexData GeomVertexData]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomVertexFormat GeomVertexFormat]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=InternalName InternalName]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;geomVertexColumn:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomVertexColumn GeomVertexColumn]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomVertexReader GeomVertexReader]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomVertexWriter GeomVertexWriter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TypedWritable TypedWritable]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;geomVertexData:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomVertexColumn GeomVertexColumn]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomVertexData GeomVertexData]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;geomVertexFormat:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomVertexData GeomVertexData]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomVertexFormat GeomVertexFormat]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomVertexReader GeomVertexReader]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomVertexRewriter GeomVertexRewriter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomVertexWriter GeomVertexWriter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=IndexBufferContext IndexBufferContext]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=InternalName InternalName]&lt;/li&gt;
&lt;li&gt;lens:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BoundingVolume BoundingVolume]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Lens Lens]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Material Material]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MaterialPool MaterialPool]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MatrixLens MatrixLens]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=OrthographicLens OrthographicLens]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PerspectiveLens PerspectiveLens]&lt;/li&gt;
&lt;li&gt;preparedGraphicsObjects:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomContext GeomContext]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsStateGuardianBase GraphicsStateGuardianBase]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=IndexBufferContext IndexBufferContext]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PreparedGraphicsObjects PreparedGraphicsObjects]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ShaderContext ShaderContext]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TextureContext TextureContext]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VertexBufferContext VertexBufferContext]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;queryContext:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PreparedGraphicsObjects PreparedGraphicsObjects]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SavedContext SavedContext]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Shader Shader]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ShaderContext ShaderContext]&lt;/li&gt;
&lt;li&gt;simpleAllocator:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SimpleAllocator SimpleAllocator]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SimpleAllocatorBlock SimpleAllocatorBlock]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;simpleLru:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SimpleLru SimpleLru]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SimpleLruPage SimpleLruPage]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SliderTable SliderTable]&lt;/li&gt;
&lt;li&gt;texture:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BamCacheRecord BamCacheRecord]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CullTraverser CullTraverser]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMImage PNMImage]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PreparedGraphicsObjects PreparedGraphicsObjects]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Texture Texture]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TextureContext TextureContext]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TextureContext TextureContext]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TexturePool TexturePool]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TextureStage TextureStage]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TransformBlend TransformBlend]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TransformBlendTable TransformBlendTable]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TransformTable TransformTable]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=UserVertexSlider UserVertexSlider]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=UserVertexTransform UserVertexTransform]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VertexBufferContext VertexBufferContext]&lt;/li&gt;
&lt;li&gt;vertexDataBlock:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VertexDataBlock VertexDataBlock]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VertexDataPage VertexDataPage]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;vertexDataBook:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VertexDataBlock VertexDataBlock]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VertexDataBook VertexDataBook]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;vertexDataPage:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VertexDataBlock VertexDataBlock]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VertexDataBook VertexDataBook]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VertexDataPage VertexDataPage]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VertexDataSaveFile VertexDataSaveFile]&lt;/li&gt;
&lt;li&gt;vertexSlider:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SliderTable SliderTable]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VertexSlider VertexSlider]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;vertexTransform:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TransformTable TransformTable]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VertexTransform VertexTransform]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VideoTexture VideoTexture]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;grutil:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CardMaker CardMaker]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FFMpegTexture FFMpegTexture]&lt;/li&gt;
&lt;li&gt;fisheyeMaker:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FisheyeMaker FisheyeMaker]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomVertexWriter GeomVertexWriter]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;frameRateMeter:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ClockObject ClockObject]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FrameRateMeter FrameRateMeter]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=HeightfieldTesselator HeightfieldTesselator]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LineSegs LineSegs]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MovieTexture MovieTexture]&lt;/li&gt;
&lt;li&gt;multitexReducer:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsOutput GraphicsOutput]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MultitexReducer MultitexReducer]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PandaNode PandaNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RenderState RenderState]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TransformState TransformState]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NodeVertexTransform NodeVertexTransform]&lt;/li&gt;
&lt;li&gt;pipeOcclusionCullTraverser:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsEngine GraphicsEngine]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsPipe GraphicsPipe]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsStateGuardian GraphicsStateGuardian]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PipeOcclusionCullTraverser PipeOcclusionCullTraverser]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;rigidBodyCombiner:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NodePath NodePath]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RigidBodyCombiner RigidBodyCombiner]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;gsgbase:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;graphicsStateGuardianBase:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AlphaTestAttrib AlphaTestAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AmbientLight AmbientLight]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AntialiasAttrib AntialiasAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ClipPlaneAttrib ClipPlaneAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ColorAttrib ColorAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ColorBlendAttrib ColorBlendAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ColorScaleAttrib ColorScaleAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ColorWriteAttrib ColorWriteAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CullFaceAttrib CullFaceAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DepthOffsetAttrib DepthOffsetAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DepthTestAttrib DepthTestAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DepthWriteAttrib DepthWriteAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectionalLight DirectionalLight]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DisplayRegion DisplayRegion]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FogAttrib FogAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Geom Geom]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomContext GeomContext]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomLines GeomLines]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomLinestrips GeomLinestrips]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomNode GeomNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomPoints GeomPoints]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomPrimitive GeomPrimitive]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomTriangles GeomTriangles]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomTrifans GeomTrifans]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomTristrips GeomTristrips]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomVertexArrayData GeomVertexArrayData]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomVertexData GeomVertexData]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsOutput GraphicsOutput]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsStateGuardianBase GraphicsStateGuardianBase]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsWindow GraphicsWindow]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=IndexBufferContext IndexBufferContext]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Lens Lens]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LightAttrib LightAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Material Material]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MaterialAttrib MaterialAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NodePath NodePath]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PointLight PointLight]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PreparedGraphicsObjects PreparedGraphicsObjects]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RenderModeAttrib RenderModeAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RenderState RenderState]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RescaleNormalAttrib RescaleNormalAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ShadeModelAttrib ShadeModelAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Shader Shader]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ShaderAttrib ShaderAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ShaderContext ShaderContext]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Spotlight Spotlight]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TexGenAttrib TexGenAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TexMatrixAttrib TexMatrixAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Texture Texture]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TextureAttrib TextureAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TextureContext TextureContext]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Thread Thread]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TransformState TransformState]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TransparencyAttrib TransparencyAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VertexBufferContext VertexBufferContext]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;lerp:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;lerp:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AutonomousLerp AutonomousLerp]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Lerp Lerp]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;lerpblend:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EaseInBlendType EaseInBlendType]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EaseInOutBlendType EaseInOutBlendType]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EaseOutBlendType EaseOutBlendType]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LerpBlendType LerpBlendType]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NoBlendType NoBlendType]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;lerpfunctor:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LerpFunctor LerpFunctor]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MultiLerpFunctor MultiLerpFunctor]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;linmath:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;lvecBase2:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;lvecBase3:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;lvecBase4:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MathNumbers MathNumbers]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;mathutil:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BoundingBox BoundingBox]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BoundingHexahedron BoundingHexahedron]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BoundingLine BoundingLine]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BoundingPlane BoundingPlane]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BoundingSphere BoundingSphere]&lt;/li&gt;
&lt;li&gt;boundingVolume:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BoundingBox BoundingBox]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BoundingHexahedron BoundingHexahedron]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BoundingLine BoundingLine]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BoundingPlane BoundingPlane]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BoundingSphere BoundingSphere]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BoundingVolume BoundingVolume]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FiniteBoundingVolume FiniteBoundingVolume]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeometricBoundingVolume GeometricBoundingVolume]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;fftCompressor:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FiniteBoundingVolume FiniteBoundingVolume]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeometricBoundingVolume GeometricBoundingVolume]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Mersenne Mersenne]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=OmniBoundingVolume OmniBoundingVolume]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PerlinNoise PerlinNoise]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PerlinNoise2 PerlinNoise2]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PerlinNoise3 PerlinNoise3]&lt;/li&gt;
&lt;li&gt;plane:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=StackedPerlinNoise2 StackedPerlinNoise2]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=StackedPerlinNoise3 StackedPerlinNoise3]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Triangulator Triangulator]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;mesadisplay:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;osMesaGraphicsPipe:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FrameBufferProperties FrameBufferProperties]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;movies:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;ffmpegAudio:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FfmpegAudio FfmpegAudio]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FfmpegAudioCursor FfmpegAudioCursor]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FfmpegAudioCursor FfmpegAudioCursor]&lt;/li&gt;
&lt;li&gt;ffmpegVideo:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FfmpegVideo FfmpegVideo]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FfmpegVideoCursor FfmpegVideoCursor]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FfmpegVideoCursor FfmpegVideoCursor]&lt;/li&gt;
&lt;li&gt;inkblotVideo:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=InkblotVideo InkblotVideo]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=InkblotVideoCursor InkblotVideoCursor]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=InkblotVideoCursor InkblotVideoCursor]&lt;/li&gt;
&lt;li&gt;movieAudio:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MovieAudio MovieAudio]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MovieAudioCursor MovieAudioCursor]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;movieAudioCursor:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MovieAudio MovieAudio]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MovieAudioCursor MovieAudioCursor]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;movieVideo:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MovieVideo MovieVideo]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MovieVideoCursor MovieVideoCursor]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;movieVideoCursor:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MovieVideo MovieVideo]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MovieVideoCursor MovieVideoCursor]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;nativenet:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Buffered_DatagramConnection Buffered_DatagramConnection]&lt;/li&gt;
&lt;li&gt;buffered_datagramwriter:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page= ]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;ringbuffer:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page= ]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Socket_Address Socket_Address]&lt;/li&gt;
&lt;li&gt;socket_ip:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Socket_IP Socket_IP]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Socket_TCP Socket_TCP]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Socket_TCP_Listen Socket_TCP_Listen]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Socket_UDP Socket_UDP]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Socket_UDP_Incoming Socket_UDP_Incoming]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Socket_UDP_Outgoing Socket_UDP_Outgoing]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Socket_TCP Socket_TCP]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Socket_TCP_Listen Socket_TCP_Listen]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Socket_UDP Socket_UDP]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Socket_UDP_Incoming Socket_UDP_Incoming]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Socket_UDP_Outgoing Socket_UDP_Outgoing]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;net:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;connection:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Connection Connection]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConnectionManager ConnectionManager]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NetDatagram NetDatagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Socket_IP Socket_IP]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;connectionListener:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConnectionListener ConnectionListener]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NetAddress NetAddress]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;connectionManager:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConnectionManager ConnectionManager]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConnectionReader ConnectionReader]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConnectionWriter ConnectionWriter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NetAddress NetAddress]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;connectionReader:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConnectionManager ConnectionManager]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConnectionReader ConnectionReader]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NetDatagram NetDatagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Socket_Address Socket_Address]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Socket_IP Socket_IP]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;connectionWriter:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConnectionManager ConnectionManager]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConnectionWriter ConnectionWriter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NetAddress NetAddress]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;datagramTCPHeader:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NetDatagram NetDatagram]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;datagramUDPHeader:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NetDatagram NetDatagram]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NetAddress NetAddress]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NetDatagram NetDatagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=QueuedConnectionListener QueuedConnectionListener]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=QueuedConnectionManager QueuedConnectionManager]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=QueuedConnectionReader QueuedConnectionReader]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RecentConnectionReader RecentConnectionReader]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;osxdisplay:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;osxGraphicsPipe:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMImage PNMImage]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;parametrics:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CubicCurveseg CubicCurveseg]&lt;/li&gt;
&lt;li&gt;curveFitter:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CurveFitter CurveFitter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=HermiteCurve HermiteCurve]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NurbsCurve NurbsCurve]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ParametricCurve ParametricCurve]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=HermiteCurve HermiteCurve]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NurbsCurve NurbsCurve]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NurbsCurveEvaluator NurbsCurveEvaluator]&lt;/li&gt;
&lt;li&gt;nurbsCurveInterface:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NurbsCurveInterface NurbsCurveInterface]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ParametricCurve ParametricCurve]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NurbsCurveResult NurbsCurveResult]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NurbsSurfaceEvaluator NurbsSurfaceEvaluator]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NurbsSurfaceResult NurbsSurfaceResult]&lt;/li&gt;
&lt;li&gt;parametricCurve:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=HermiteCurve HermiteCurve]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NurbsCurve NurbsCurve]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NurbsCurveInterface NurbsCurveInterface]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ParametricCurve ParametricCurve]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ParametricCurveCollection ParametricCurveCollection]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PiecewiseCurve PiecewiseCurve]&lt;/li&gt;
&lt;li&gt;ropeNode:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomVertexData GeomVertexData]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RopeNode RopeNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SheetNode SheetNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;particlesystem:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ArcEmitter ArcEmitter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BaseParticleEmitter BaseParticleEmitter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BaseParticleFactory BaseParticleFactory]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BaseParticleRenderer BaseParticleRenderer]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BoxEmitter BoxEmitter]&lt;/li&gt;
&lt;li&gt;colorInterpolationManager:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ColorInterpolationFunctionConstant ColorInterpolationFunctionConstant]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ColorInterpolationFunctionLinear ColorInterpolationFunctionLinear]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ColorInterpolationFunctionSinusoid ColorInterpolationFunctionSinusoid]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ColorInterpolationFunctionStepwave ColorInterpolationFunctionStepwave]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ColorInterpolationManager ColorInterpolationManager]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ColorInterpolationSegment ColorInterpolationSegment]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DiscEmitter DiscEmitter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomParticleRenderer GeomParticleRenderer]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LineEmitter LineEmitter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LineParticleRenderer LineParticleRenderer]&lt;/li&gt;
&lt;li&gt;particleSystem:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ParticleSystem ParticleSystem]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ParticleSystemManager ParticleSystemManager]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ParticleSystemManager ParticleSystemManager]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PointEmitter PointEmitter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PointParticleFactory PointParticleFactory]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PointParticleRenderer PointParticleRenderer]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RectangleEmitter RectangleEmitter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RingEmitter RingEmitter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SparkleParticleRenderer SparkleParticleRenderer]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SphereSurfaceEmitter SphereSurfaceEmitter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SphereVolumeEmitter SphereVolumeEmitter]&lt;/li&gt;
&lt;li&gt;spriteParticleRenderer:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NodePath NodePath]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SpriteAnim SpriteAnim]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SpriteParticleRenderer SpriteParticleRenderer]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TangentRingEmitter TangentRingEmitter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ZSpinParticleFactory ZSpinParticleFactory]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;pgraph:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;accumulatedAttribs:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PandaNode PandaNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AlphaTestAttrib AlphaTestAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AmbientLight AmbientLight]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AntialiasAttrib AntialiasAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AttribNodeRegistry AttribNodeRegistry]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AudioVolumeAttrib AudioVolumeAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AuxSceneData AuxSceneData]&lt;/li&gt;
&lt;li&gt;bamFile:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BamFile BamFile]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Filename Filename]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TypedWritable TypedWritable]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BillboardEffect BillboardEffect]&lt;/li&gt;
&lt;li&gt;camera:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Camera Camera]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DisplayRegion DisplayRegion]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ClipPlaneAttrib ClipPlaneAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ColorAttrib ColorAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ColorBlendAttrib ColorBlendAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ColorScaleAttrib ColorScaleAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ColorWriteAttrib ColorWriteAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CompassEffect CompassEffect]&lt;/li&gt;
&lt;li&gt;config_pgraph:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DSearchPath DSearchPath]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;cullBin:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomNode GeomNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsStateGuardianBase GraphicsStateGuardianBase]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PandaNode PandaNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RenderState RenderState]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TransformState TransformState]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CullBinAttrib CullBinAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CullBinEnums CullBinEnums]&lt;/li&gt;
&lt;li&gt;cullBinManager:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CullBinManager CullBinManager]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsStateGuardianBase GraphicsStateGuardianBase]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CullFaceAttrib CullFaceAttrib]&lt;/li&gt;
&lt;li&gt;cullHandler:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CullTraverser CullTraverser]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;cullResult:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CullTraverser CullTraverser]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsStateGuardianBase GraphicsStateGuardianBase]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RenderState RenderState]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TransformState TransformState]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;cullTraverser:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CullTraverser CullTraverser]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsStateGuardian GraphicsStateGuardian]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NodePath NodePath]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PandaNode PandaNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;cullTraverserData:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PandaNode PandaNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;cullableObject:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CullTraverser CullTraverser]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DecalEffect DecalEffect]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DepthOffsetAttrib DepthOffsetAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DepthTestAttrib DepthTestAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DepthWriteAttrib DepthWriteAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectionalLight DirectionalLight]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DrawMaskAttrib DrawMaskAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EventStorePandaNode EventStorePandaNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FadeLODNode FadeLODNode]&lt;/li&gt;
&lt;li&gt;findApproxLevelEntry:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NodePathCollection NodePathCollection]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;findApproxPath:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PandaNode PandaNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;fog:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Fog Fog]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TransformState TransformState]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FogAttrib FogAttrib]&lt;/li&gt;
&lt;li&gt;geomNode:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomNode GeomNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsStateGuardianBase GraphicsStateGuardianBase]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;geomTransformer:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomNode GeomNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=InternalName InternalName]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RenderState RenderState]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=InternalNameCollection InternalNameCollection]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LensNode LensNode]&lt;/li&gt;
&lt;li&gt;light:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsStateGuardianBase GraphicsStateGuardianBase]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Light Light]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NodePath NodePath]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PandaNode PandaNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LightAttrib LightAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LightLensNode LightLensNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LightNode LightNode]&lt;/li&gt;
&lt;li&gt;loader:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Loader Loader]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LoaderFileType LoaderFileType]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;loaderFileType:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BamCacheRecord BamCacheRecord]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LoaderFileType LoaderFileType]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LoaderOptions LoaderOptions]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;loaderFileTypeRegistry:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Filename Filename]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LoaderFileType LoaderFileType]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LoaderFileTypeRegistry LoaderFileTypeRegistry]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LoaderOptions LoaderOptions]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LODNode LODNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MaterialAttrib MaterialAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MaterialCollection MaterialCollection]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ModelFlattenRequest ModelFlattenRequest]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ModelLoadRequest ModelLoadRequest]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ModelNode ModelNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ModelPool ModelPool]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ModelRoot ModelRoot]&lt;/li&gt;
&lt;li&gt;nodePath:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Fog Fog]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GlobPattern GlobPattern]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=InternalNameCollection InternalNameCollection]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Light Light]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Material Material]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MaterialCollection MaterialCollection]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NodePath NodePath]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NodePathCollection NodePathCollection]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PolylightNode PolylightNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PreparedGraphicsObjects PreparedGraphicsObjects]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Shader Shader]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ShaderInput ShaderInput]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Texture Texture]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TextureCollection TextureCollection]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TextureStage TextureStage]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TextureStageCollection TextureStageCollection]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NodePathCollection NodePathCollection]&lt;/li&gt;
&lt;li&gt;nodePathLerps:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ColorLerpFunctor ColorLerpFunctor]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ColorScaleLerpFunctor ColorScaleLerpFunctor]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=HprLerpFunctor HprLerpFunctor]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=HprScaleLerpFunctor HprScaleLerpFunctor]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PosHprLerpFunctor PosHprLerpFunctor]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PosHprScaleLerpFunctor PosHprScaleLerpFunctor]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PosLerpFunctor PosLerpFunctor]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ScaleLerpFunctor ScaleLerpFunctor]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;pandaNode:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CullTraverser CullTraverser]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Light Light]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PandaNode PandaNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;pandaNodeChain:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PandaNode PandaNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PlaneNode PlaneNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PointLight PointLight]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PolylightEffect PolylightEffect]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PolylightNode PolylightNode]&lt;/li&gt;
&lt;li&gt;portalClipper:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NodePath NodePath]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PandaNode PandaNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PortalNode PortalNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PortalNode PortalNode]&lt;/li&gt;
&lt;li&gt;renderAttrib:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CullTraverser CullTraverser]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsStateGuardianBase GraphicsStateGuardianBase]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RenderAttrib RenderAttrib]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;renderEffect:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CullTraverser CullTraverser]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PandaNode PandaNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RenderEffect RenderEffect]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;renderEffects:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CullTraverser CullTraverser]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RenderEffects RenderEffects]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RenderModeAttrib RenderModeAttrib]&lt;/li&gt;
&lt;li&gt;renderState:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AudioVolumeAttrib AudioVolumeAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ClipPlaneAttrib ClipPlaneAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ColorAttrib ColorAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ColorScaleAttrib ColorScaleAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CullBinAttrib CullBinAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FogAttrib FogAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsStateGuardianBase GraphicsStateGuardianBase]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RenderState RenderState]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ShaderAttrib ShaderAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TexGenAttrib TexGenAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TextureAttrib TextureAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TransparencyAttrib TransparencyAttrib]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RescaleNormalAttrib RescaleNormalAttrib]&lt;/li&gt;
&lt;li&gt;sceneGraphAnalyzer:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Geom Geom]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomNode GeomNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomVertexArrayData GeomVertexArrayData]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomVertexData GeomVertexData]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomVertexFormat GeomVertexFormat]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PandaNode PandaNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SceneGraphAnalyzer SceneGraphAnalyzer]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Texture Texture]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;sceneGraphReducer:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PandaNode PandaNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SceneGraphReducer SceneGraphReducer]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SelectiveChildNode SelectiveChildNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SequenceNode SequenceNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ShadeModelAttrib ShadeModelAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ShaderAttrib ShaderAttrib]&lt;/li&gt;
&lt;li&gt;shaderGenerator:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AmbientLight AmbientLight]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DirectionalLight DirectionalLight]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LightAttrib LightAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PointLight PointLight]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ShaderAttrib ShaderAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Spotlight Spotlight]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ShaderInput ShaderInput]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ShaderPool ShaderPool]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ShowBoundsEffect ShowBoundsEffect]&lt;/li&gt;
&lt;li&gt;spotlight:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Spotlight Spotlight]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Texture Texture]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=StencilAttrib StencilAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SwitchNode SwitchNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TexGenAttrib TexGenAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TexMatrixAttrib TexMatrixAttrib]&lt;/li&gt;
&lt;li&gt;texProjectorEffect:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LensNode LensNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TexProjectorEffect TexProjectorEffect]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TextureAttrib TextureAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TextureCollection TextureCollection]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TextureStageCollection TextureStageCollection]&lt;/li&gt;
&lt;li&gt;transformState:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsStateGuardianBase GraphicsStateGuardianBase]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TransformState TransformState]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TransparencyAttrib TransparencyAttrib]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;pgui:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PGButton PGButton]&lt;/li&gt;
&lt;li&gt;pgButtonNotify:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PGButton PGButton]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PGEntry PGEntry]&lt;/li&gt;
&lt;li&gt;pgFrameStyle:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NodePath NodePath]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PGFrameStyle PGFrameStyle]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PandaNode PandaNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;pgItem:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AudioSound AudioSound]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ClipPlaneAttrib ClipPlaneAttrib]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MouseWatcherParameter MouseWatcherParameter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PGItem PGItem]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PGTop PGTop]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;pgItemNotify:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MouseWatcherParameter MouseWatcherParameter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PGItem PGItem]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PGMouseWatcherBackground PGMouseWatcherBackground]&lt;/li&gt;
&lt;li&gt;pgMouseWatcherGroup:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PGTop PGTop]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PGMouseWatcherParameter PGMouseWatcherParameter]&lt;/li&gt;
&lt;li&gt;pgMouseWatcherRegion:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PGItem PGItem]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PGScrollFrame PGScrollFrame]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PGSliderBar PGSliderBar]&lt;/li&gt;
&lt;li&gt;pgSliderBarNotify:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PGSliderBar PGSliderBar]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;pgTop:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsStateGuardian GraphicsStateGuardian]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PGTop PGTop]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;pgVirtualFrame:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PGVirtualFrame PGVirtualFrame]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TransformState TransformState]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PGWaitBar PGWaitBar]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;physics:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ActorNode ActorNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AngularEulerIntegrator AngularEulerIntegrator]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AngularForce AngularForce]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AngularIntegrator AngularIntegrator]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AngularVectorForce AngularVectorForce]&lt;/li&gt;
&lt;li&gt;baseForce:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BaseForce BaseForce]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ForceNode ForceNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;baseIntegrator:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Physical Physical]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ForceNode ForceNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LinearControlForce LinearControlForce]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LinearCylinderVortexForce LinearCylinderVortexForce]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LinearDistanceForce LinearDistanceForce]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LinearEulerIntegrator LinearEulerIntegrator]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LinearForce LinearForce]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LinearFrictionForce LinearFrictionForce]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LinearIntegrator LinearIntegrator]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LinearJitterForce LinearJitterForce]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LinearNoiseForce LinearNoiseForce]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LinearRandomForce LinearRandomForce]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LinearSinkForce LinearSinkForce]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LinearSourceForce LinearSourceForce]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LinearUserDefinedForce LinearUserDefinedForce]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LinearVectorForce LinearVectorForce]&lt;/li&gt;
&lt;li&gt;physical:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Physical Physical]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PhysicalNode PhysicalNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PhysicsManager PhysicsManager]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PhysicalNode PhysicalNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PhysicsCollisionHandler PhysicsCollisionHandler]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PhysicsManager PhysicsManager]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PhysicsObject PhysicsObject]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PhysicsObjectCollection PhysicsObjectCollection]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;pipeline:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConditionVar ConditionVar]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConditionVarDirect ConditionVarDirect]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConditionVarFull ConditionVarFull]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConditionVarFullDirect ConditionVarFullDirect]&lt;/li&gt;
&lt;li&gt;cycleData:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TypedWritable TypedWritable]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ExternalThread ExternalThread]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MainThread MainThread]&lt;/li&gt;
&lt;li&gt;mutexDirect:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MutexDirect MutexDirect]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Thread Thread]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;pmutex:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Mutex Mutex]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PythonThread PythonThread]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ReMutex ReMutex]&lt;/li&gt;
&lt;li&gt;reMutexDirect:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ReMutexDirect ReMutexDirect]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Thread Thread]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;reMutexHolder:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Thread Thread]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;thread:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Mutex Mutex]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ReMutex ReMutex]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Thread Thread]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;threadDummyImpl:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Thread Thread]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;threadPosixImpl:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Thread Thread]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;threadSimpleImpl:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Thread Thread]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;threadSimpleManager:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Thread Thread]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;threadWin32Impl:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Thread Thread]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;pnmimage:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;pnmBrush:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMBrush PNMBrush]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMImage PNMImage]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMFileType PNMFileType]&lt;/li&gt;
&lt;li&gt;pnmFileTypeRegistry:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMFileType PNMFileType]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMFileTypeRegistry PNMFileTypeRegistry]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;pnmImage:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMFileType PNMFileType]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMImage PNMImage]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;pnmImageHeader:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMFileType PNMFileType]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMImageHeader PNMImageHeader]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;pnmPainter:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMImage PNMImage]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMPainter PNMPainter]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;pnmtext:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;config_pnmtext:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DSearchPath DSearchPath]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FreetypeFont FreetypeFont]&lt;/li&gt;
&lt;li&gt;pnmTextMaker:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Filename Filename]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMImage PNMImage]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMTextMaker PNMTextMaker]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;pstatclient:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;pStatClient:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PStatClient PStatClient]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PStatCollector PStatCollector]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PStatThread PStatThread]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;pStatClientControlMessage:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;pStatClientImpl:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PStatClient PStatClient]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PStatCollector PStatCollector]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PStatThread PStatThread]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;pStatCollector:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PStatCollector PStatCollector]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Thread Thread]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;pStatCollectorDef:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PStatClient PStatClient]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PStatCollectorForward PStatCollectorForward]&lt;/li&gt;
&lt;li&gt;pStatFrameData:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PStatClient PStatClient]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;pStatProperties:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PStatClient PStatClient]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;pStatServerControlMessage:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;pStatThread:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PStatThread PStatThread]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Thread Thread]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;pStatTimer:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Thread Thread]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;putil:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;animInterface:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=AnimInterface AnimInterface]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BamCache BamCache]&lt;/li&gt;
&lt;li&gt;bamCacheRecord:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BamCacheRecord BamCacheRecord]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;bamReaderParam:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;bitArray:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BitArray BitArray]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SparseArray SparseArray]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ButtonHandle ButtonHandle]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ButtonRegistry ButtonRegistry]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CachedTypedWritableReferenceCount CachedTypedWritableReferenceCount]&lt;/li&gt;
&lt;li&gt;clockObject:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ClockObject ClockObject]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TimeVal TimeVal]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;config_util:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DSearchPath DSearchPath]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=CopyOnWriteObject CopyOnWriteObject]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Factory Factory]&lt;/li&gt;
&lt;li&gt;ioPtaDatagramFloat:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;ioPtaDatagramInt:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;ioPtaDatagramShort:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=KeyboardButton KeyboardButton]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LineStream LineStream]&lt;/li&gt;
&lt;li&gt;load_prc_file:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ConfigPage ConfigPage]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=HashVal HashVal]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ModifierButtons ModifierButtons]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MouseButton MouseButton]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MouseData MouseData]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NodeCachedReferenceCount NodeCachedReferenceCount]&lt;/li&gt;
&lt;li&gt;sparseArray:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BitArray BitArray]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SparseArray SparseArray]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=StringStream StringStream]&lt;/li&gt;
&lt;li&gt;timedCycle:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;typedWritable:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TypedWritable TypedWritable]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TypedWritableReferenceCount TypedWritableReferenceCount]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=UniqueIdAllocator UniqueIdAllocator]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=UpdateSeq UpdateSeq]&lt;/li&gt;
&lt;li&gt;vector_typedWritable:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TypedWritable TypedWritable]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=WritableConfigurable WritableConfigurable]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;recorder:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MouseRecorder MouseRecorder]&lt;/li&gt;
&lt;li&gt;recorderBase:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RecorderBase RecorderBase]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TypedWritable TypedWritable]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;recorderController:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RecorderBase RecorderBase]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RecorderController RecorderController]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;socketStreamRecorder:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=SocketStreamRecorder SocketStreamRecorder]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;skel:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=BasicSkel BasicSkel]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TypedSkel TypedSkel]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;text:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;config_text:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DSearchPath DSearchPath]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;dynamicTextFont:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DynamicTextFont DynamicTextFont]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NurbsCurveResult NurbsCurveResult]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;dynamicTextGlyph:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DynamicTextPage DynamicTextPage]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;dynamicTextPage:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DynamicTextFont DynamicTextFont]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DynamicTextPage DynamicTextPage]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=FontPool FontPool]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomTextGlyph GeomTextGlyph]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=StaticTextFont StaticTextFont]&lt;/li&gt;
&lt;li&gt;textAssembler:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TextEncoder TextEncoder]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TextGraphic TextGraphic]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TextFont TextFont]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TextGraphic TextGraphic]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TextNode TextNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TextProperties TextProperties]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TextPropertiesManager TextPropertiesManager]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;tform:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ButtonThrower ButtonThrower]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DriveInterface DriveInterface]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MouseInterfaceNode MouseInterfaceNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MouseSubregion MouseSubregion]&lt;/li&gt;
&lt;li&gt;mouseWatcher:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DisplayRegion DisplayRegion]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MouseWatcher MouseWatcher]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MouseWatcherParameter MouseWatcherParameter]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MouseWatcherGroup MouseWatcherGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MouseWatcherParameter MouseWatcherParameter]&lt;/li&gt;
&lt;li&gt;mouseWatcherRegion:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MouseWatcherParameter MouseWatcherParameter]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=MouseWatcherRegion MouseWatcherRegion]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Trackball Trackball]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Transform2SG Transform2SG]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;vrpn:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;vrpnAnalogDevice:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VrpnClient VrpnClient]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;vrpnButtonDevice:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VrpnClient VrpnClient]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VrpnClient VrpnClient]&lt;/li&gt;
&lt;li&gt;vrpnDialDevice:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VrpnClient VrpnClient]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;vrpnTrackerDevice:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=VrpnClient VrpnClient]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;pandaapp:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;indexify:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;fontSamples:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMTextMaker PNMTextMaker]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;indexImage:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMImage PNMImage]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMImageHeader PNMImageHeader]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMTextMaker PNMTextMaker]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;indexify:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMTextMaker PNMTextMaker]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;rollDirectory:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMTextMaker PNMTextMaker]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;pandatool:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;bam:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;bamInfo:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PandaNode PandaNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Texture Texture]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=TypedWritable TypedWritable]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;bamToEgg:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroup EggGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroupNode EggGroupNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggTexture EggTexture]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggVertexPool EggVertexPool]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomNode GeomNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomTriangles GeomTriangles]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GeomVertexData GeomVertexData]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LODNode LODNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PandaNode PandaNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RenderState RenderState]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Texture Texture]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;eggToBam:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsEngine GraphicsEngine]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsOutput GraphicsOutput]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GraphicsStateGuardian GraphicsStateGuardian]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PandaNode PandaNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=RenderState RenderState]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Texture Texture]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;converter:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;somethingToEggConverter:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggData EggData]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroupNode EggGroupNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;dxfegg:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;dxfToEggLayer:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroupNode EggGroupNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggVertex EggVertex]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;dxfprogs:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;eggToDXF:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroupNode EggGroupNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;eggToDXFLayer:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroupNode EggGroupNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggPolygon EggPolygon]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;egg-mkfont:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;eggMakeFont:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroup EggGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggVertexPool EggVertexPool]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMTextMaker PNMTextMaker]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;egg-optchar:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;eggOptchar:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroupNode EggGroupNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;vertexMembership:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroup EggGroup]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;egg-qtess:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;isoPlacer:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=NurbsSurfaceResult NurbsSurfaceResult]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;eggbase:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;eggMultiBase:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Filename Filename]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;eggReader:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMFileType PNMFileType]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;eggSingleBase:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggNode EggNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;eggcharbase:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;eggCharacterCollection:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggAttributes EggAttributes]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggTable EggTable]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;eggprogs:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;eggCrop:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroupNode EggGroupNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;eggMakeTube:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroup EggGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggVertex EggVertex]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggVertexPool EggVertexPool]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;eggTextureCards:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggVertex EggVertex]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggVertexPool EggVertexPool]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;eggToC:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggBin EggBin]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggNode EggNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggVertexPool EggVertexPool]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;flt:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;fltMaterial:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;fltRecord:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DatagramIterator DatagramIterator]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;fltegg:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;fltToEggConverter:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroupNode EggGroupNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggPrimitive EggPrimitive]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;fltToEggLevelState:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroup EggGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroupNode EggGroupNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;fltprogs:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;eggToFlt:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroup EggGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggPrimitive EggPrimitive]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggTexture EggTexture]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggTransform EggTransform]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggVertex EggVertex]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;lwo:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;iffInputFile:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;lwoegg:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;cLwoSurface:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggPrimitive EggPrimitive]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;maxegg:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;maxEggLoader:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggData EggData]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;maxLogger:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Logger Logger]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;maxNodeDesc:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroup EggGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggTable EggTable]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggXfmSAnim EggXfmSAnim]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;maxNodeTree:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggData EggData]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroupNode EggGroupNode]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;maxeggimport:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;maxEggLoader:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggData EggData]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;maya:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;mayaApi:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Filename Filename]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;mayaegg:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;mayaBlendDesc:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggSAnimData EggSAnimData]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggTable EggTable]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;mayaEggLoader:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggData EggData]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;mayaNodeDesc:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroup EggGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggTable EggTable]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggXfmSAnim EggXfmSAnim]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;mayaNodeTree:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggData EggData]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroupNode EggGroupNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggSAnimData EggSAnimData]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggTable EggTable]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggXfmSAnim EggXfmSAnim]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;mayaToEggConverter:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggData EggData]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroup EggGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggNurbsCurve EggNurbsCurve]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggPrimitive EggPrimitive]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggTable EggTable]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggVertexPool EggVertexPool]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggXfmSAnim EggXfmSAnim]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;palettizer:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;imageFile:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggTexture EggTexture]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMImage PNMImage]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;pal_string_utils:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMFileType PNMFileType]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;palettizer:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMFileType PNMFileType]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;sourceTextureImage:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMImageHeader PNMImageHeader]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;texturePlacement:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMImage PNMImage]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;textureProperties:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMFileType PNMFileType]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;textureReference:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggData EggData]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroupNode EggGroupNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggPrimitive EggPrimitive]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggTexture EggTexture]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Filename Filename]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;txaLine:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=PNMFileType PNMFileType]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;softegg:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;softNodeDesc:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroup EggGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggTable EggTable]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggXfmSAnim EggXfmSAnim]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;softNodeTree:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggData EggData]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroup EggGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroupNode EggGroupNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggTable EggTable]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggXfmSAnim EggXfmSAnim]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;softToEggConverter:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggData EggData]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroup EggGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggNurbsCurve EggNurbsCurve]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggPrimitive EggPrimitive]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggSAnimData EggSAnimData]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggTable EggTable]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggVertexPool EggVertexPool]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggXfmSAnim EggXfmSAnim]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;softprogs:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;softCVS:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Multifile Multifile]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;vrmlegg:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;indexedFaceSet:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggData EggData]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroup EggGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggVertexPool EggVertexPool]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LMatrix4d LMatrix4d]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;vrmlToEggConverter:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroup EggGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroupNode EggGroupNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=LMatrix4d LMatrix4d]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;xfile:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;xFileNode:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Filename Filename]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;xfileegg:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;xFileAnimationSet:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroup EggGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggTable EggTable]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggXfmSAnim EggXfmSAnim]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;xFileFace:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggPolygon EggPolygon]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;xFileMaker:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggBin EggBin]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggData EggData]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroup EggGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroupNode EggGroupNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggNode EggNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggVertexPool EggVertexPool]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;xFileMaterial:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggPrimitive EggPrimitive]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;xFileMesh:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroupNode EggGroupNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggPolygon EggPolygon]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggPrimitive EggPrimitive]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggVertex EggVertex]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;xFileNormal:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggPrimitive EggPrimitive]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggVertex EggVertex]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;xFileToEggConverter:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Datagram Datagram]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroup EggGroup]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggGroupNode EggGroupNode]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggMaterial EggMaterial]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggTexture EggTexture]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;xFileVertex:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggPrimitive EggPrimitive]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=EggVertex EggVertex]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;/ul&gt;
&lt;li&gt;ppremake:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DSearchPath DSearchPath]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=ExecutionEnvironment ExecutionEnvironment]&lt;/li&gt;
&lt;li&gt;filename:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=DSearchPath DSearchPath]&lt;/li&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=Filename Filename]&lt;/li&gt;
&lt;/ul&gt;
&lt;li&gt;[http://panda3d.net/apiref.php?page=GlobPattern GlobPattern]&lt;/li&gt;
&lt;/ul&gt;
&lt;/ul&gt;</text>
    </revision>
  </page>
  <page>
    <title>Classic Finite State Machine Usage</title>
    <ns>0</ns>
    <id>955</id>
      <sha1>n77f7pc4a31pb9ksty93zh0p1fpmikn</sha1>
    <revision>
      <id>4115</id>
      <timestamp>2007-02-17T13:39:07Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="24">This page is deprecated.</text>
    </revision>
  </page>
  <page>
    <title>Clearing Display Regions</title>
    <ns>0</ns>
    <id>2278</id>
      <sha1>16oh1cd5d9de4fydxll9ly09lvggqbp</sha1>
    <revision>
      <id>7668</id>
      <timestamp>2012-03-08T20:01:51Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="3196">When you have more than one DisplayRegion in a particular window, it is important to consider which of them, if any, you want to perform an explicit clear operation before drawing.

Clearing means to erase the contents of the window or DisplayRegion, and set it all to the background color.  Normally, you should perform a clear at the beginning of every frame, or you will be drawing the new frame on top of the contents of the previous frame.

The default is for clear to be performed by the GraphicsOutput (the window or buffer), before any DisplayRegions are drawn at all.  This is usually the best way to clear the window, because it is slightly faster to perform one big clear operation that resets the whole window at once, rather than clearing each DisplayRegion individually.  This particularly makes sense when your DisplayRegions don't overlap, and they all want to have the same background color, like this:

[[Image:QuadDR.jpg]]

However, when your DisplayRegions overlap, or when they each need to have a different background color, you may need to clear the DisplayRegions individually.  Consider the following example:

[[Image:DisplayRegion_3.jpg]]

Panda must draw this scene by first clearing the window to a gray background, then drawing the contents of the larger display region (with the panda), then clearing the smaller, nested display region to a black background, and then finally drawing the contents of the smaller display region.  ([[:Image:DisplayRegion_1.jpg|Click here]] to see the sample code that sets all this up.)

You can control the clear operations per DisplayRegion, as well as on the overall GraphicsOutput.  The following methods are defined for both DisplayRegions and GraphicsOutputs:

&lt;code python&gt;
win.setClearColorActive(flag)
win.setClearColor(VBase4(r, g, b, a))
&lt;/code&gt;

In the above, flag is a boolean flag--True or False, indicating whether this window or DisplayRegion should perform a clear to the background color.  If False, no clear will be performed.  If True, the color will be cleared before drawing, and the specific background color used will be specified by r, g, b, a.

In addition to clearing the color, you will also need to clear the depth or Z buffer.  This buffer is used to determine which objects are in front of other objects, and if you fail to clear it, some objects may not draw.  It has a similar interface:

&lt;code python&gt;
win.setClearDepthActive(flag)
win.setClearDepth(depthValue)
&lt;/code&gt;

The depthValue should almost always be 1.0, which is the default.

It is also possible to selectively clear the stencil buffer, and other auxiliary buffers, in a similar way.  See the generated API docs for more information.

==Sorting==

Note that when you are overlapping DisplayRegions, it becomes very important to specify the order in which the DisplayRegions should be drawn.  To do this, use setSort():

&lt;code python&gt;
dr.setSort(sortValue)
&lt;/code&gt;

The sortValue can be any integer number; the default is zero.  All DisplayRegions for a particular window will be drawn in order from smallest sort first to largest sort last.  If two DisplayRegions have the same sort value, the order in which they are drawn is undefined.</text>
    </revision>
  </page>
  <page>
    <title>Clicking on 3D Objects</title>
    <ns>0</ns>
    <id>1074</id>
      <sha1>pqr2rv9trse9ua8s9suglzgdm3orz7u</sha1>
    <revision>
      <id>7927</id>
      <timestamp>2013-04-09T19:00:29Z</timestamp>
      <contributor>
        <username>Croxis</username>
        <id>430</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="6168">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

&lt;p&gt;The simplest way to click on 3D objects in Panda3D is to use very simplistic collision detection coupled with event processing.&lt;/p&gt;

&lt;p&gt;First, after a &lt;code&gt;CollisonTraverser&lt;/code&gt; and a &lt;code&gt;CollisionHandler&lt;/code&gt; have been setup, attach a &lt;code&gt;CollisionRay&lt;/code&gt; node to the camera. This node will have its &lt;code&gt;[func]setFromCollideMask[/func]()&lt;/code&gt; set to &lt;code&gt;GeomNode[::][func]getDefaultCollideMask[/func]()&lt;/code&gt; in order to be as general as possible.&lt;/p&gt;

[python]
&lt;code python&gt;
pickerNode = CollisionNode('mouseRay')
pickerNP = camera.attachNewNode(pickerNode)
pickerNode.setFromCollideMask(GeomNode.getDefaultCollideMask())
pickerRay = CollisionRay()
pickerNode.addSolid(pickerRay)
myTraverser.addCollider(pickerNP, myHandler)
&lt;/code&gt;
[/python]
[cxx]
&lt;code cxx&gt;
PT(MouseWatcher) mouseWatcher;
PT(CollisionRay) pickerRay;
CollisionTraverser myTraverser = CollisionTraverser(&quot;ctraverser&quot;);
PT(CollisionHandlerQueue) myHandler;
PT(CollisionNode) pickerNode;
NodePath pickerNP;

pickerNode = new CollisionNode(&quot;mouseRay&quot;);
pickerNP = camera.attach_new_node (pickerNode);
pickerNode-&gt;set_from_collide_mask(GeomNode::get_default_collide_mask());
pickerRay = new CollisionRay();
pickerNode-&gt;add_solid(pickerRay);
myHandler = new CollisionHandlerQueue();
myTraverser.add_collider(pickerNP, myHandler);
&lt;/code&gt;
[/cxx]

&lt;p&gt;For any object that you want to be pickable you should add a flag to it. The easiest way is to use the &lt;code&gt;[func]setTag[/func]()&lt;/code&gt; function:&lt;/p&gt;

[python]
&lt;code python&gt;
object1.setTag('myObjectTag', '1')
object2.setTag('myObjectTag', '2')
&lt;/code&gt;
[/python]
[cxx]
&lt;code cxx&gt;
object1.set_tag(&quot;myObjectTag&quot;, &quot;1&quot;);
object2.set_tag(&quot;myObjectTag&quot;, &quot;2&quot;);
&lt;/code&gt;
[/cxx]

&lt;p&gt;The above example sets the tag &lt;code&gt;'myObjectTag'&lt;/code&gt; on two objects in your graph that you want to designate as pickable. We will check for the presence of this tag after we get the response back from the collision system. [python]Because [[Loading_Actors_and_Animations|Actors]] uses a different setup the collision system will return the geometry but not the NodePath. Use &lt;code&gt;object.setPythonTag('myObjectTag', 1)&lt;/code&gt; and &lt;code&gt;object.getPythonTag('myObjectTag')&lt;/code&gt; instead to return the nodepath of an Actor.[/python]&lt;/p&gt;

&lt;p&gt;Now assume that the function &lt;code&gt;[func]myFunction[/func]()&lt;/code&gt; is set up to be called for the &lt;code&gt;'mouse1'&lt;/code&gt; event. In &lt;code&gt;[func]myFunction[/func]()&lt;/code&gt; is where you call &lt;code&gt;[func]pickerRay.setFromLens[/func](origin, destX, destY)&lt;/code&gt;. This makes the ray's origin &lt;code&gt;origin&lt;/code&gt; and the ray's vector the direction from &lt;code&gt;origin&lt;/code&gt; to the point (&lt;code&gt;destX&lt;/code&gt;, &lt;code&gt;destY&lt;/code&gt;).&lt;/p&gt;

[python]
&lt;code python&gt;
def myFunction():
   # First we check that the mouse is not outside the screen.
   if base.mouseWatcherNode.hasMouse():
      # This gives up the screen coordinates of the mouse.
      mpos = base.mouseWatcherNode.getMouse()

      # This makes the ray's origin the camera and makes the ray point 
      # to the screen coordinates of the mouse.
      pickerRay.setFromLens(base.camNode, mpos.getX(), mpos.getY()) 
&lt;/code&gt;
[/python]
[cxx]
&lt;code cxx&gt;
void myFunction(){
   if (!mouseWatcher-&gt;has_mouse()){
      // The mouse is probably outside the screen.
      return;
   }
   // This gives up the screen coordinates of the mouse.
   LPoint2f mpos = mouseWatcher-&gt;get_mouse();

   // This makes the ray's origin the camera and makes the ray point 
   // to the screen coordinates of the mouse.
   pickerRay-&gt;set_from_lens(window-&gt;get_camera(0), mpos.get_x(), mpos.get_y());
}
&lt;/code&gt;
[/cxx]

&lt;p&gt;After this, you now call the traverser like any other collision, get the closest object and &quot;pick&quot; it.&lt;/p&gt;

&lt;!-- C++ editor should add a [cxx] version of the code below. --&gt;

[python]
&lt;code python&gt;
def myFunction():
   mpos = base.mouseWatcherNode.getMouse()
   pickerRay.setFromLens(base.camNode, mpos.getX(), mpos.getY())

   myTraverser.traverse(render)
   # Assume for simplicity's sake that myHandler is a CollisionHandlerQueue.
   if myHandler.getNumEntries() &gt; 0:
      # This is so we get the closest object
      myHandler.sortEntries()
      pickedObj = myHandler.getEntry(0).getIntoNodePath()
&lt;/code&gt;
[/python]

&lt;p&gt;The node returned by the collision system may not be the object itself, but might be just a part of the object. In particular, it will be one of the &lt;code&gt;GeomNodes&lt;/code&gt; that make up the object. (The &lt;code&gt;GeomNode&lt;/code&gt; class contains the visible geometry primitives that are used to define renderable objects in Panda3D.) Since your object might consist of more than one &lt;code&gt;GeomNode&lt;/code&gt;, what you probably would prefer to get is the &lt;code&gt;NodePath&lt;/code&gt; that represents the parent of all of these &lt;code&gt;GeomNodes&lt;/code&gt;; that is, the &lt;code&gt;NodePath&lt;/code&gt; that you set the &lt;code&gt;'myObjectTag'&lt;/code&gt; tag on above.&lt;/p&gt;

&lt;p&gt;You can use &lt;code&gt;[func]nodePath.findNetTag[/func]()&lt;/code&gt; to return the parent &lt;code&gt;NodePath&lt;/code&gt; that contains a specified tag.&lt;/p&gt;

&lt;p&gt;(There are also other, similar methods on &lt;code&gt;NodePath&lt;/code&gt; that can be used to query the tag specified on a parent node, such as &lt;code&gt;[func]getNetTag[/func]()&lt;/code&gt; and &lt;code&gt;[func]hasNetTag[/func]()&lt;/code&gt;. For simplicity, we shall restrict this example to &lt;code&gt;[func]findNetTag[/func]()&lt;/code&gt;.)&lt;/p&gt;

&lt;!-- C++ editor should remove the [python] tags from the next line after adding a corresponding [cxx] version of the code below it. --&gt;

[python]&lt;p&gt;Now you can edit &lt;code&gt;[func]myFunction[/func]()&lt;/code&gt; to look like this:&lt;/p&gt;[/python]

[python]
&lt;code python&gt;
def myFunction():
   mpos = base.mouseWatcherNode.getMouse()
   pickerRay.setFromLens(base.camNode, mpos.getX(), mpos.getY())

   myTraverser.traverse(render)
   # Assume for simplicity's sake that myHandler is a CollisionHandlerQueue.
   if myHandler.getNumEntries() &gt; 0:
      # This is so we get the closest object.
      myHandler.sortEntries()
      pickedObj = myHandler.getEntry(0).getIntoNodePath()
      pickedObj = pickedObj.findNetTag('myObjectTag')
      if not pickedObj.isEmpty():
         handlePickedObject(pickedObj)
&lt;/code&gt;
[/python]</text>
    </revision>
  </page>
  <page>
    <title>Clicking on 3D objects</title>
    <ns>0</ns>
    <id>2255</id>
    <redirect title="Clicking on 3D Objects" />
      <sha1>mkucmgq3vlztet3whlshf13fstnd4k1</sha1>
    <revision>
      <id>5375</id>
      <timestamp>2008-05-05T16:27:25Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[Clicking on 3D Objects]]</comment>
      <text xml:space="preserve" bytes="36">#REDIRECT [[Clicking on 3D Objects]]</text>
    </revision>
  </page>
  <page>
    <title>Clicking on 3d objects</title>
    <ns>0</ns>
    <id>2256</id>
    <redirect title="Clicking on 3D Objects" />
      <sha1>mkucmgq3vlztet3whlshf13fstnd4k1</sha1>
    <revision>
      <id>5376</id>
      <timestamp>2008-05-05T16:27:46Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[Clicking on 3D Objects]]</comment>
      <text xml:space="preserve" bytes="36">#REDIRECT [[Clicking on 3D Objects]]</text>
    </revision>
  </page>
  <page>
    <title>Client-Server Connection</title>
    <ns>0</ns>
    <id>2044</id>
      <sha1>ahh00g1bs7br467olm4k8p49sufduxv</sha1>
    <revision>
      <id>60519</id>
      <timestamp>2015-07-16T17:55:25Z</timestamp>
      <contributor>
        <username>Tzaeru</username>
        <id>22867</id>
      </contributor>
      <comment>Added Imports to code examples where they are first needed. Fixed inconsitencies between creating variables in local scope and trying to access them as instance members (i.e. removed bunch of selfs)</comment>
      <text xml:space="preserve" bytes="6026">The first step in network communication is to establish the client-server connection. This entails two sets of operations: one for the server side (which listens for incoming connections), and one for the client side (which establishes a connection to the server). Both of these processes are described below.

&lt;h2&gt;Preparing the server for connection&lt;/h2&gt;

An average Panda program acting as a server will need to create four classes:

* A QueuedConnectionManager, which handles the low-level connection processes, establishes connections, and handles unexpected network termination

* A QueuedConnectionListener, which waits for clients to request connection

* A QueuedConnectionReader, which buffers incoming data from an active connection

* A ConnectionWriter, which allows PyDatagrams to be transmitted out along an active connection

The first step is to instantiate these four classes.

&lt;code python&gt;
from panda3d.core import QueuedConnectionManager
from panda3d.core import QueuedConnectionListener
from panda3d.core import QueuedConnectionReader
from panda3d.core import ConnectionWriter

cManager = QueuedConnectionManager()
cListener = QueuedConnectionListener(cManager, 0)
cReader = QueuedConnectionReader(cManager, 0)
cWriter = ConnectionWriter(cManager,0)

activeConnections=[] # We'll want to keep track of these later
&lt;/code&gt;

This method of instantiation prepares the classes in single-thread mode, which that realtime communication requires them to be polled periodically.

To accept client connections, the server opens a special &quot;rendezvous&quot; socket at a specific port address. This port address must be known by both the client and the server. Additionally, a backlog is specified; this is the number of incoming connection requests that the connection will track before it starts rejecting connection attempts. The responsibility for managing the rendezvous socket is passed to the QueuedConnectionListener, and a task is spawned to periodically poll the listener.

&lt;code python&gt;
port_address=9099 #No-other TCP/IP services are using this port
backlog=1000 #If we ignore 1,000 connection attempts, something is wrong!
tcpSocket = cManager.openTCPServerRendezvous(port_address,backlog)

cListener.addConnection(tcpSocket)
&lt;/code&gt;


Since the network handlers we instantiated are polled, we'll create some tasks to do the polling.
&lt;code python&gt;
taskMgr.add(tskListenerPolling,&quot;Poll the connection listener&quot;,-39)
taskMgr.add(tskReaderPolling,&quot;Poll the connection reader&quot;,-40)
&lt;/code&gt;

When a connection comes in, the tskListenerPolling function below handles the incoming connection and hands it to the QueuedConnectionReader. The connection is now established.

&lt;code python&gt;
from panda3d.core import PointerToConnection
from panda3d.core import NetAddress

def tskListenerPolling(taskdata):
  if cListener.newConnectionAvailable():

    rendezvous = PointerToConnection()
    netAddress = NetAddress()
    newConnection = PointerToConnection()

    if cListener.getNewConnection(rendezvous,netAddress,newConnection):
      newConnection = newConnection.p()
      activeConnections.append(newConnection) # Remember connection
      cReader.addConnection(newConnection)     # Begin reading connection
  return Task.cont
&lt;/code&gt;

Once a connection has been opened, the QueuedConnectionReader may begin processing incoming packets. This is similar to the flow of the listener's task, but it is up to the server code to handle the incoming data.

&lt;code python&gt;
from panda3d.core import NetDatagram

def tskReaderPolling(taskdata):
  if cReader.dataAvailable():
    datagram=NetDatagram()  # catch the incoming data in this instance
    # Check the return value; if we were threaded, someone else could have
    # snagged this data before we did
    if cReader.getData(datagram):
      myProcessDataFunction(datagram)
  return Task.cont
&lt;/code&gt;

Note that the QueuedConnectionReader retrieves data from all clients connected to the server. The NetDatagram can be queried using NetDatagram.getConnection to determine which client sent the message.

If the server wishes to send data to the client, it can use the ConnectionWriter to transmit back along the connection.

&lt;code python&gt;
 # broadcast a message to all clients
myPyDatagram=myNewPyDatagram()  # build a datagram to send
for aClient in activeConnections:
  cWriter.send(myPyDatagram,aClient)
&lt;/code&gt;

Finally, the server may terminate a connection by removing it from the QueuedConnectionReader's responsibility. It may also deactivate its listener so that no more connections are received

&lt;code python&gt;
 # terminate connection to all clients

for aClient in activeConnections:
  cReader.removeConnection(aClient)
activeConnections=[]

 # close down our listener
cManager.closeConnection(tcpSocket)
&lt;/code&gt;

&lt;h2&gt;Connecting with a client&lt;/h2&gt;

The process the client undertakes to connect to a server is extremely similar to the process the server undertakes to receive connections. Like the server, a client instantiates a QueuedConnectionManager, QueuedConnectionReader, and ConnectionWriter. However, there are some differences in the process. 
In general, a client has no need to open a rendezvous socket or create a QueuedConnectionListener, since it will be doing the connecting itself. Instead, the client connects to a specific server by specifying the server's IP address and the correct socket ID.

&lt;code python&gt;
port_address=9099  # same for client and server

 # a valid server URL. You can also use a DNS name
 # if the server has one, such as &quot;localhost&quot; or &quot;panda3d.org&quot;
ip_address=&quot;192.168.0.50&quot;

 # how long until we give up trying to reach the server?
timeout_in_miliseconds=3000  # 3 seconds

myConnection=cManager.openTCPClientConnection(ip_address,port_address,timeout_in_miliseconds)
if myConnection:
  cReader.addConnection(myConnection)  # receive messages from server
&lt;/code&gt;

When the client has finished communicating with the server, it can close the connection.

&lt;code python&gt;
cManager.closeConnection(myConnection)
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>Clip Planes</title>
    <ns>0</ns>
    <id>2216</id>
      <sha1>llfbmmz81tbb5nhc0s0tqt8syuklw1t</sha1>
    <revision>
      <id>4940</id>
      <timestamp>2008-03-14T11:26:14Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="409">&lt;h2&gt;General Warning about Clip Planes&lt;/h2&gt;

Most drivers do a very poor job of implementing clip planes.  Furthermore, the way that clip planes combine with shaders can be unpredictable.  The use of clip planes is not recommended.  It is possible to emulate clip planes in a shader using the &lt;i&gt;discard&lt;/i&gt; instruction.

&lt;h2&gt;Incomplete Section&lt;/h2&gt;

Note: this section is incomplete.  It will be updated soon.</text>
    </revision>
  </page>
  <page>
    <title>Collision Bitmasks</title>
    <ns>0</ns>
    <id>956</id>
      <sha1>8rnosp8soe218i5f9o845ajk5bz1qwg</sha1>
    <revision>
      <id>7674</id>
      <timestamp>2012-03-08T20:15:42Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="4541">By default, every &quot;from&quot; object added to a CollisionTraverser will test for collisions with every other CollisionNode in the scene graph, and will not test for collisions with visible geometry.  For simple applications, this is sufficient, but often you will need more control.

This control is provided with the collide masks.  Every CollisionNode has two collide masks: a &quot;from&quot; mask, which is used when the CollisionNode is acting as a &quot;from&quot; object (i.e. it has been added to a [[Collision Traversers|CollisionTraverser]]), and an &quot;into&quot; mask, which is used when the node is acting as an &quot;into&quot; object (i.e. it is in the scene graph, and a from object is considering it for collisions).

In addition, visible geometry nodes--that is, GeomNodes--also have an &quot;into&quot; mask, so that visible geometry can serve as an &quot;into&quot; object also.  (However, only a CollisionNode can serve as a &quot;from&quot; object.)

Before the solids in a &quot;from&quot; CollisionNode are tested for collisions with another CollisionNode or with a GeomNode, the collide masks are compared.  Specifically, the &quot;from&quot; mask of the from object, and the &quot;into&quot; mask of the into object, are ANDed together.  If the result is not zero--meaning the two masks have at least one bit in common--then the collision test is attempted; otherwise, the two objects are ignored.

The collide masks are represented using a BitMask32 object, which is really just a 32-bit integer with some additional methods for getting and setting particular bits.

You can only set the from collide mask on a collision node, and you must set it directly on the node itself, not on the NodePath:

&lt;code python&gt;
nodePath.node().setFromCollideMask(BitMask32(0x10))
&lt;/code&gt;

However, the into collide mask may be set on the NodePath, for convenience; this recursively modifies the into collide mask for all the nodes at the given NodePath level and below.

&lt;code python&gt;
nodePath.setCollideMask(newMask, bitsToChange, nodeType)
&lt;/code&gt;

The parameter newMask specifies the new mask to apply.  The remaining parameters are optional; if they are omitted, then every node at nodePath level and below is assigned newMask as the new into collide mask.  However, if bitsToChange is specified, it represents the set of bits that are to be changed from the original; bits that are 0 in bitsToChange will not be modified at each node level.  If nodeType is specified, it should be a TypeHandle that represents the type of node that will be modified, e.g. &lt;code&gt;CollisionNode.getClassType()&lt;/code&gt; to affect only CollisionNodes.

Examples:

&lt;code python&gt;
nodePath.setCollideMask(BitMask32(0x10))
&lt;/code&gt;

This sets the into collide mask of nodePath, and all children of nodePath, to the value 0x10, regardless of the value each node had before.

&lt;code python&gt;
nodePath.setCollideMask(BitMask32(0x04), BitMask32(0xff))
&lt;/code&gt;

This replaces the lower 8 bits of nodePath and all of its children with the value 0x04, leaving the upper 24 bits of each node unchanged.

The default value for both from and into collide masks for a new CollisionNode can be retrieved by &lt;code&gt;CollisionNode.getDefaultCollideMask()&lt;/code&gt;, and the default into collide mask for a new GeomNode is &lt;code&gt;GeomNode.getDefaultCollideMask()&lt;/code&gt;.  Note that you can create a CollisionNode that collides with visible geometry by doing something like this:

&lt;code python&gt;
nodePath.node().setFromCollideMask(GeomNode.getDefaultCollideMask())
&lt;/code&gt;

The &lt;code&gt;NodePath.getCollideMask()&lt;/code&gt; function returns a union of all the collide masks for itself and its children. Since the &lt;code&gt;NodePath.setCollideMask()&lt;/code&gt; function is called recursively on its children, the following code can have a profound effect, even though it looks like it's doing nothing:

&lt;code python&gt;
nodePath.setCollideMask(nodePath.getCollideMask())
&lt;/code&gt;

The above code actually calculates the collide mask for its children, and sets all of its children to that same collide mask, wiping out what was there before.

If you need to have only entities with a certain collision mask to be able to collide with a model, it is helpful to open the model's egg file and see where the collisions are enabled (see [[Egg_Syntax]]). Then you would set the collide mask for only that child node, using &lt;code&gt;NodePath.find()&lt;/code&gt; (see [[NodePath]]). For example, to create a box into only &quot;ralph&quot; can collide:

&lt;code python&gt;
ralph=loader.loadModel(&quot;ralph&quot;)
ralph.setCollideMask(BitMask32.bit(0))
box=loader.loadModel(&quot;box&quot;)
box.find(&quot;**/Cube;+h&quot;).setCollideMask(BitMask32.bit(0))
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>Collision Detection</title>
    <ns>0</ns>
    <id>957</id>
      <sha1>ne1fvnlscod8fqwkdlybghzarv6x8fv</sha1>
    <revision>
      <id>2240</id>
      <timestamp>2005-05-08T23:09:08Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="779">Collision detection allows for two objects to bump into each other and react.  This includes not only sending messages for events, but also to keep the objects from passing through each other.  Collision detection is a very powerful tool for immersion, but it is somewhat complex.

There are two ways to go about collision detection.  One is to create special collision geometry, such as spheres and polygons, to determine collisions.  The other is to allow collisions against all geometry.  While the first is somewhat more complex and takes more effort to implement, it is much faster to execute and is a better long-term solution.  For quick-and-dirty applications, though, collision with geometry can be a fine solution.

This section of the manual will address both methods.</text>
    </revision>
  </page>
  <page>
    <title>Collision Detection with ODE</title>
    <ns>0</ns>
    <id>2287</id>
      <sha1>10k7ahb55u5ochal2jy4piprahn8n17</sha1>
    <revision>
      <id>7688</id>
      <timestamp>2012-03-09T09:53:05Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>new import system</comment>
      <text xml:space="preserve" bytes="11525">&lt;h2&gt;Collision Detection&lt;/h2&gt;
There are two types of collision detection: the kind that immediately makes the objects bounce back on a collision, and the kind that instead of making the objects bounce back immediately creates control joints instead. The latter is the method the Open Dynamics Engine uses. Normally, you would use near callbacks to make the control joints and have the objects bounce back. However, Panda3D has an autoCollide feature that automatically does these things for you.

These are the steps needed to have your objects collide with each other:
* Create an OdeSpace (explained below). Use &lt;code&gt;[func]setAutoCollideWorld[/func](world)&lt;/code&gt; to let the OdeSpace know in which world you want to collide things.
* Create an OdeJointGroup() to hold the contact joints. Use &lt;code&gt;space.[func]setAutoCollideJointGroup[/func]&lt;/code&gt; to let the space know in which OdeJointGroup you would like to store the contact joints.
* Configure the surface table for the world.
* Create ODE collision geometry for your bodies, e.g. OdeBoxGeom, OdePlaneGeom, etc. Be sure to set collide and category [[Collision Bitmasks|bitmasks]] on it using the &lt;code&gt;[func]setCollideBits[/func]&lt;/code&gt; and &lt;code&gt;[func]setCategoryBits[/func]&lt;/code&gt; methods. Assign it to your body using &lt;code&gt;geom.[func]setBody[/func](body)&lt;/code&gt;.
* In your simulation loop, call &lt;code&gt;space.[func]autoCollide[/func]()&lt;/code&gt; before you call &lt;code&gt;world.[func]quickStep[/func]&lt;/code&gt;.
* After using quickStep, you need to empty your OdeJointGroup using the &lt;code&gt;empty()&lt;/code&gt; method.

&lt;h2&gt;Spaces&lt;/h2&gt;
To be able to use collision detection, you will need to create an OdeSpace. There are three different kinds of space types you have to choose from, any one will work but each one is more optimized for a special kind of simulation.
* &lt;b&gt;OdeSimpleSpace&lt;/b&gt;. This is the most simple kind of space available. This does not perform any collision culling at all, that's why it is not preferred for a large number of objects. If you have a small amount of objects, however, you will most likely prefer an OdeSimpleSpace.
* If you have more objects and a larger scene, you will want to use the &lt;b&gt;OdeQuadTreeSpace&lt;/b&gt;. This uses a pre-allocated hierarchical grid-based AABB tree to quickly cull collision checks. It's exceptionally quick for large amounts of objects in landscape-shaped worlds.
* Finally, there's the &lt;b&gt;OdeHashSpace&lt;/b&gt;, which uses an internal data structure that records how each geom overlaps cells in one of several three dimensional grids. Each grid has cubical cells of side lengths 2**i, where i is an integer that ranges from a minimum to a maximum value. You can set this minimum and maximum value using the &lt;code&gt;[func]setMinLevel[/func]&lt;/code&gt; and &lt;code&gt;[func]setMaxLevel[/func]&lt;/code&gt; functions respectively, or you can use &lt;code&gt;[func]setLevels[/func]&lt;/code&gt; to set them all in one call.

&lt;h2&gt;Geometry&lt;/h2&gt;

Geometry are the collision solids that you place in a space. These collision solids are separate from panda's own collision solids but there are similar collision solid types. The general code for creating geometry is &lt;code&gt;OdeGeom(space, [parameters])&lt;/code&gt;, where space is the OdeSpace the geometry is being placed in. Parameters are dependent on which geometry solid you choose. The geometry types that you can choose from are:

&lt;table align='center' cellspacing='3' cellpadding='2' border='1'&gt;
&lt;tr&gt;&lt;th&gt;Geometry&lt;/th&gt;&lt;th&gt;Shape&lt;/th&gt;&lt;th&gt;Initialization Parameters&lt;/th&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;OdeBoxGeom&lt;/td&gt;&lt;td&gt;Box&lt;/td&gt;&lt;td&gt;&lt;code&gt;OdeBoxGeom(space, length, width, height)&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;OdeCappedCylinderGeom&lt;/td&gt;&lt;td&gt;Capsule&lt;/td&gt;&lt;td&gt;&lt;code&gt;OdeCappedCylinderGeom(space, radius, length)&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;OdeCylinderGeom&lt;/td&gt;&lt;td&gt;Cylinder&lt;/td&gt;&lt;td&gt;&lt;code&gt;OdeCylinderGeom(space, radius, length)&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;OdePlaneGeom&lt;/td&gt;&lt;td&gt;Infinite Plane&lt;/td&gt;&lt;td&gt;&lt;code&gt;OdePlaneGeom(space, Vec4(&lt;vector of plane normal&gt;))&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;OdeRayGeom&lt;/td&gt;&lt;td&gt;Finite Ray&lt;/td&gt;&lt;td&gt;&lt;code&gt;OdeRayGeom(space, ray_length)&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;OdeSphereGeom&lt;/td&gt;&lt;td&gt;Sphere&lt;/td&gt;&lt;td&gt;&lt;code&gt;OdeSphereGeom(space, radius)&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;OdeTriMeshGeom&lt;/td&gt;&lt;td&gt;3D Mesh&lt;/td&gt;&lt;td&gt;&lt;code&gt;OdeTriMeshGeom(space, OdeTriMeshData)&lt;/code&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

To set the position and direction of an OdeRayGeom, you must call &lt;code&gt;OdeRayGeom.set(Vec3(&lt;position&gt;), Vec3(&lt;direction&gt;))&lt;/code&gt;. The length of the direction vector is always set to the ray length specified during instantiation.

A trimesh geometry allows you to create collision geometry of an arbitrary shape from a 3d model. However collision detection with a trimesh is the most expensive and might be unreliable, for most applications you are better off approximating the shape with another collision solid. To get the OdeTriMeshGeom from a model requires two steps:

[python]&lt;code python&gt;
modelTrimesh = OdeTriMeshData(modelNodePath, True)
modelGeom = OdeTriMeshGeom(space, modelTrimesh)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
PT(OdeTriMeshData) modelTrimesh = new OdeTriMeshData(modelNodePath, true);
OdeTriMeshGeom modelGeom (space, modelTrimesh);
&lt;/code&gt;[/cxx]

If a geometry represents a physically dynamic object you can associate it with the dynamic body using &lt;code&gt;odeGeom.[func]setBody[/func](body)&lt;/code&gt;. This will automatically reposition the geometry with regard to the position of the related body in the OdeWorld.

&lt;h2&gt;Surfaces&lt;/h2&gt;

Sufaces define the material a geometry is made of and the Surface Table defines how materials react with each other setting the bounce, friction etc. To set up the surface system, you must first initialize the surface table which is done with &lt;code&gt;odeWorld.[func]initSurfaceTable[/func](numberOfSurfaces)&lt;/code&gt;

Once you have done that, you have to setup the parameters for collisions between two surfaces using &lt;code&gt;odeWorld.[func]setSurfaceEntry[/func](surfaceId1, surfaceId2, mu, bounce, bounce_vel, soft_erp, soft_cfm, slip, dampen)&lt;/code&gt; The surfaceId's start from 0 so if you initialized your surface table with 3 surfaces, the surface ID's are 0, 1, 2.

These are what the rest of the parameters mean:
* &lt;b&gt;mu&lt;/b&gt;: This is the [http://en.wikipedia.org/wiki/Coefficient_of_friction Coulomb friction coefficient]. It means how much friction the contact has, a value of 0.0 means there will be no friction at all, while a value of &lt;code&gt;OdeUtil[::][func]getInfinity[/func]()&lt;/code&gt; means the contact will never slip.
* &lt;b&gt;bounce&lt;/b&gt;: This is how bouncy the surface is. A value of 0.0 means it is not bouncy, a value of 1.0 gives a very bouncy surface.
* &lt;b&gt;bounce_vel&lt;/b&gt;: The minimum velocity a body must have before it bounces. If a body collides with a velocity lower than this value, it will not bounce off.
* &lt;b&gt;soft_erp&lt;/b&gt;: The error reduction parameter of the contact normal. This is used to simulate soft surfaces.
* &lt;b&gt;soft_cfm&lt;/b&gt;: The constraint force mixing parameter of the contact normal. This is used to simulate soft surfaces.
* &lt;b&gt;slip&lt;/b&gt;: The coefficient for the force-dependent slip. This makes it possible for bodies to slide past each other.
* &lt;b&gt;dampen&lt;/b&gt;: This is used to simulate a [http://en.wikipedia.org/wiki/Damping damping] effect.

If you have multiple surfaces, you need to tell ODE which surface belongs to which geometry. You can assign surfaces to your geometry using &lt;code&gt;odeSpace.[func]setSurfaceType[/func](geometry, surfaceId)&lt;/code&gt;

&lt;h2&gt;Collision Events&lt;/h2&gt;
In Panda3D 1.6 and above, it's possible to receive an event when a collision occurs. You need to set the name of the event by doing:
[python]&lt;code python&gt;space.setCollisionEvent(&quot;yourCollision&quot;)&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;space.set_collision_event(&quot;yourCollision&quot;);&lt;/code&gt;[/cxx]
You can then use this event name in an &lt;code&gt;accept()&lt;/code&gt; call. The parameter passed to the event is an OdeCollisionEntry, which holds all the geoms and contacts in the collision. See the API reference page for [http://panda3d.org/apiref.php?page=OdeCollisionEntry OdeCollisionEntry] for more details. The following code shows how it works (the methods used are not real):
&lt;code python&gt;# Setup collision event
def onCollision(entry):
  geom1 = entry.getGeom1()
  geom2 = entry.getGeom2()
  body1 = entry.getBody1()
  body2 = entry.getBody2()
  if (body1 and body1 == spear) or (body2 and body2 == spear):
    # Must have hit someone
    for p in entry.getContactPoints()
      particleSystem.drawBlood(p)

space.setCollisionEvent(&quot;ode-collision&quot;)
base.accept(&quot;ode-collision&quot;, onCollision)&lt;/code&gt;

&lt;h2&gt;Example&lt;/h2&gt;
This is an example of some random boxes falling down and colliding with the floor.
&lt;code python&gt;
from direct.directbase import DirectStart
from panda3d.ode import OdeWorld, OdeSimpleSpace, OdeJointGroup
from panda3d.ode import OdeBody, OdeMass, OdeBoxGeom, OdePlaneGeom
from panda3d.core import BitMask32, CardMaker, Vec4, Quat
from random import randint, random

# Setup our physics world
world = OdeWorld()
world.setGravity(0, 0, -9.81)

# The surface table is needed for autoCollide
world.initSurfaceTable(1)
world.setSurfaceEntry(0, 0, 150, 0.0, 9.1, 0.9, 0.00001, 0.0, 0.002)

# Create a space and add a contactgroup to it to add the contact joints
space = OdeSimpleSpace()
space.setAutoCollideWorld(world)
contactgroup = OdeJointGroup()
space.setAutoCollideJointGroup(contactgroup)

# Load the box
box = loader.loadModel(&quot;box&quot;)
# Make sure its center is at 0, 0, 0 like OdeBoxGeom
box.setPos(-.5, -.5, -.5)
box.flattenLight() # Apply transform
box.setTextureOff()

# Add a random amount of boxes
boxes = []
for i in range(randint(15, 30)):
  # Setup the geometry
  boxNP = box.copyTo(render)
  boxNP.setPos(randint(-10, 10), randint(-10, 10), 10 + random())
  boxNP.setColor(random(), random(), random(), 1)
  boxNP.setHpr(randint(-45, 45), randint(-45, 45), randint(-45, 45))
  # Create the body and set the mass
  boxBody = OdeBody(world)
  M = OdeMass()
  M.setBox(50, 1, 1, 1)
  boxBody.setMass(M)
  boxBody.setPosition(boxNP.getPos(render))
  boxBody.setQuaternion(boxNP.getQuat(render))
  # Create a BoxGeom
  boxGeom = OdeBoxGeom(space, 1, 1, 1)
  boxGeom.setCollideBits(BitMask32(0x00000002))
  boxGeom.setCategoryBits(BitMask32(0x00000001))
  boxGeom.setBody(boxBody)
  boxes.append((boxNP, boxBody))

# Add a plane to collide with
cm = CardMaker(&quot;ground&quot;)
cm.setFrame(-20, 20, -20, 20)
ground = render.attachNewNode(cm.generate())
ground.setPos(0, 0, 0); ground.lookAt(0, 0, -1)
groundGeom = OdePlaneGeom(space, Vec4(0, 0, 1, 0))
groundGeom.setCollideBits(BitMask32(0x00000001))
groundGeom.setCategoryBits(BitMask32(0x00000002))

# Set the camera position
base.disableMouse()
base.camera.setPos(40, 40, 20)
base.camera.lookAt(0, 0, 0)

# The task for our simulation
def simulationTask(task):
  space.autoCollide() # Setup the contact joints
  # Step the simulation and set the new positions
  world.quickStep(globalClock.getDt())
  for np, body in boxes:
    np.setPosQuat(render, body.getPosition(), Quat(body.getQuaternion()))
  contactgroup.empty() # Clear the contact joints
  return task.cont

# Wait a split second, then start the simulation  
taskMgr.doMethodLater(0.5, simulationTask, &quot;Physics Simulation&quot;)

run()
&lt;/code&gt;
In this example, we're creating a random amount of boxes with a random orientation and position, assigning collision solids to them, and adding a tuple of the [[NodePath]] and the body to a list. This way we can easily keep track of all the boxes and loop through them to copy over the positions from the OdeBody to Panda's NodePath in the simulation loop.</text>
    </revision>
  </page>
  <page>
    <title>Collision Entries</title>
    <ns>0</ns>
    <id>1164</id>
      <sha1>4znavz2ff6wmozh327o4cy5fkirnuyz</sha1>
    <revision>
      <id>5999</id>
      <timestamp>2009-07-19T13:43:14Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>fix typo</comment>
      <text xml:space="preserve" bytes="4912">For each collision detected, a new &lt;code&gt;CollisionEntry&lt;/code&gt; object is created.  This CollisionEntry stores all the information about the collision, including the two objects (nodes) involved in the collision, and the point of impact and the surface normal of the into object at that point.

The CollisionEntry object is passed to the event handler method by the &lt;code&gt;CollisionHandlerEvent&lt;/code&gt; and its derivatives; it is also the object stored in the queue of collisions maintained by the &lt;code&gt;CollisionHandlerQueue&lt;/code&gt;.

However you get a handle to CollisionEntry object, you can query it for information using the following methods:

[python]
&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;code&gt;entry.getFromNodePath()&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Returns the NodePath of the &quot;from&quot; object.  This NodePath will contain a CollisionNode.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;code&gt;entry.getIntoNodePath()&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Returns the NodePath of the &quot;into&quot; object.  This NodePath will contain a CollisionNode, or if the collision was made with visible geometry, a GeomNode.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;code&gt;entry.getFrom()&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Returns the actual CollisionSolid of the &quot;from&quot; object.  This is useful if there were more than one CollisionSolid in the &quot;from&quot; CollisionNode.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;code&gt;entry.getInto()&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Returns the actual CollisionSolid of the &quot;into&quot; object.  However, if the collision was made with visible geometry, there is no CollisionSolid, and this will be an invalid call.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;code&gt;entry.hasInto()&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Returns true if the collision was made into a CollisionSolid as opposed to visible geometry, and thus the above call will be valid.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;code&gt;entry.getSurfacePoint(nodePath)&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Returns the 3-D point of the collision, in the coordinate space of the supplied NodePath.  This point will usually be on the surface of the &quot;into&quot; object.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;code&gt;entry.getSurfaceNormal(nodePath)&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Returns the 3-D surface normal of the &quot;into&quot; object at the point of the collision, in the coordinate space of the supplied NodePath.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;code&gt;entry.getInteriorPoint(nodePath)&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Returns the 3-D point, within the interior of the &quot;into&quot; object, that represents the depth to which the &quot;from&quot; object has penetrated.&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;
[/python]


[cxx]
&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;code&gt;entry-&gt;get_from_nodePath()&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Returns the NodePath of the &quot;from&quot; object.  This NodePath will contain a CollisionNode.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;code&gt;entry-&gt;get_into_nodePath()&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Returns the NodePath of the &quot;into&quot; object.  This NodePath will contain a CollisionNode, or if the collision was made with visible geometry, a GeomNode.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;code&gt;entry-&gt;get_from()&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Returns the actual CollisionSolid of the &quot;from&quot; object.  This is useful if there were more than one CollisionSolid in the &quot;from&quot; CollisionNode.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;code&gt;entry-&gt;get_into()&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Returns the actual CollisionSolid of the &quot;into&quot; object.  However, if the collision was made with visible geometry, there is no CollisionSolid, and this will be an invalid call.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;code&gt;entry-&gt;has_into()&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Returns true if the collision was made into a CollisionSolid as opposed to visible geometry, and thus the above call will be valid.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;code&gt;entry-&gt;get_surface_point(nodePath)&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Returns the 3-D point of the collision, in the coordinate space of the supplied NodePath.  This point will usually be on the surface of the &quot;into&quot; object.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;code&gt;entry-&gt;get_surface_normal(nodePath)&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Returns the 3-D surface normal of the &quot;into&quot; object at the point of the collision, in the coordinate space of the supplied NodePath.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;code&gt;entry-&gt;get_interior_point(nodePath)&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Returns the 3-D point, within the interior of the &quot;into&quot; object, that represents the depth to which the &quot;from&quot; object has penetrated.&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;
[/cxx]

The three methods that return points or vectors all accept a NodePath as a parameter.  This can be any NodePath in the scene graph; it represents the coordinate space in which you expect to receive the answer.  For instance, to receive the point of intersection in the coordinate space of the &quot;into&quot; object, use:

[python]&lt;code python&gt;
point = collisionEntry.getSurfacePoint(collisionEntry.getIntoNodePath())
&lt;/code&gt;
[/python]

[cxx]
&lt;code cxx&gt;
point = collisionEntry-&gt;get_surface_point(collisionEntry-&gt;get_into_node_path());
&lt;/code&gt;
[/cxx]

If you wanted to put an axis at the point of the collision to visualize it, you might do something like this:

[python] &lt;code python&gt;
axis = loader.loadModel('zup-axis.egg')
axis.reparentTo(render)
point = collisionEntry.getSurfacePoint(render)
normal = collisionEntry.getSurfaceNormal(render)
axis.setPos(point)
axis.lookAt(point + normal)
&lt;/code&gt;
[/python]</text>
    </revision>
  </page>
  <page>
    <title>Collision Handlers</title>
    <ns>0</ns>
    <id>958</id>
      <sha1>0awcvtbqbm3c5kchq6km1dqavuthf5m</sha1>
    <revision>
      <id>60516</id>
      <timestamp>2015-06-19T19:25:00Z</timestamp>
      <contributor>
        <username>Tmo</username>
        <id>22866</id>
      </contributor>
      <minor/>
      <comment>fix C++ code for CollisionHandlerQueue</comment>
      <text xml:space="preserve" bytes="10115">You will need to create a CollisionHandler that specifies what to do when a collision event is detected. Each object can only have one collision handler associated with it. There are several possible kinds of CollisionHandler available.

&lt;h2&gt;CollisionHandlerQueue&lt;/h2&gt;

The simplest kind of CollisionHandler, this object simply records the collisions that were detected during the most recent traversal.  You can then iterate through the list using &lt;code&gt;queue.getNumEntries()&lt;/code&gt; and &lt;code&gt;queue.getEntry()&lt;/code&gt;:

[python]
&lt;syntaxhighlight lang=&quot;python&quot;&gt;
queue = CollisionHandlerQueue()
traverser.addCollider(fromObject, queue)
traverser.traverse(render)
for i in range(queue.getNumEntries()):
  entry = queue.getEntry(i)
  print entry
&lt;/syntaxhighlight&gt;
[/python]

[cxx]
&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
CollisionHandlerQueue *queue = new CollisionHandlerQueue();
CollisionTraverser traverser;
traverser.add_collider(fromObject,queue);
traverser.traverse(get_render());
for(i = 0; i&lt;queue-&gt;get_num_entries();i++)
{
            CollisionEntry *entry = queue-&gt;get_entry(i);
            cout &lt;&lt; *entry &lt;&lt; endl;
}
&lt;/syntaxhighlight&gt;
[/cxx]

By default, the [[Collision Entries]] appear in the queue in no particular order.  You can arrange them in order from nearest to furthest by calling &lt;code&gt;queue.sortEntries()&lt;/code&gt; after the traversal.

&lt;h2&gt;CollisionHandlerEvent&lt;/h2&gt;

This is another simple kind of CollisionHandler.  Rather than saving up the collisions, it generates a [[Event Handling|Panda event]] when collision events are detected.

There are three kinds of events that may be generated: the &quot;in&quot; event, when a particular object collides with another object that it didn't in the previous pass, the &quot;out&quot; event, when an object is no longer colliding with an object it collided with in the previous pass, and the &quot;again&quot; event, when an object is still colliding with the same object that it did in the previous pass.

For each kind of event, the CollisionHandlerEvent will construct an event name out of the names of the from and into objects that were involved in the collision.  The exact event name is controlled by a pattern string that you specify.  For instance:

[python]
&lt;code python&gt;
handler.addInPattern('%fn-into-%in')
handler.addAgainPattern('%fn-again-%in')
handler.addOutPattern('%fn-out-%in')
&lt;/code&gt;
[/python]

[cxx]
&lt;code cxx&gt;
C_handler.add_in_pattern(&quot;%fn-into-%in&quot;);
C_handler.add_again_pattern(&quot;%fn-into-%in&quot;);
C_handler.add_out_pattern(&quot;%fn-into-%in&quot;);
&lt;/code&gt;
[/cxx]

In the pattern string, the following sequences have special meaning:

&lt;table&gt;
&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;%fn&lt;/td&gt;
&lt;td&gt;the name of the &quot;from&quot; object's node&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;%in&lt;/td&gt;
&lt;td&gt;the name of the &quot;into&quot; object's node&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;%fs&lt;/td&gt;
&lt;td&gt;'t' if &quot;from&quot; is declared to be tangible, 'i' if intangible&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;%is&lt;/td&gt;
&lt;td&gt;'t' if &quot;into&quot; is declared to be tangible, 'i' if intangible&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;%ig&lt;/td&gt;
&lt;td&gt;'c' if the collision is into a CollisionNode, 'g' if it is an ordinary visible GeomNode&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;%(tag)fh&lt;/td&gt;
&lt;td&gt;generate event only if &quot;from&quot; node has the indicated tag&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;%(tag)fx&lt;/td&gt;
&lt;td&gt;generate event only if &quot;from&quot; node does not have the indicated tag&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;%(tag)ih&lt;/td&gt;
&lt;td&gt;generate event only if &quot;into&quot; node has the indicated tag&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;%(tag)ix&lt;/td&gt;
&lt;td&gt;generate event only if &quot;into&quot; node does not have the indicated tag&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;%(tag)ft&lt;/td&gt;
&lt;td&gt;the indicated tag value of the &quot;from&quot; node.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;%(tag)it&lt;/td&gt;
&lt;td&gt;the indicated tag value of the &quot;into&quot; node.&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

You may use as many of the above sequences as you like, or none, in the pattern string.  In the tag-based sequences, the parentheses around (tag) are literal; the idea is to write the name of the tag you want to look up, surrounded by parentheses.  The tag is consulted using the &lt;code&gt;nodePath.getNetTag()&lt;/code&gt; interface.

In any case, the event handler function that you write to service the event should receive one parameter (in addition to self, if it is a method): the [[Collision Entries|CollisionEntry]].  For example:

[python]&lt;code python&gt;
  class MyObject(DirectObject.DirectObject):
    def __init__(self):
      self.accept('car-into-rail', handleRailCollision)

    def handleRailCollision(self, entry):
      print entry
&lt;/code&gt;
[/python]

Note that all of the following versions of CollisionHandler also inherit from CollisionHandlerEvent, so any of them can be set up to throw events in the same way.

&lt;h2&gt;CollisionHandlerPusher&lt;/h2&gt;

This is the first of the more sophisticated handlers.  The CollisionHandlerPusher, in addition to inheriting all of the event logic from CollisionHandlerEvent, will automatically push back on its from object to keep it out of walls.  The visual effect is that your object will simply stop moving when it reaches a wall if it hits the wall head-on, or it will slide along the wall smoothly if it strikes the wall at an angle.

The CollisionHandlerPusher needs to have a handle to the NodePath that it will push back on, for each from object; you pass this information to &lt;code&gt;pusher.addCollider&lt;/code&gt;.  This should be the node that is actually moving.  This is often, but not always, the same NodePath as the CollisionNode itself, but it might be different if the CollisionNode is set up as a child of the node that is actually moving.

[python]&lt;code python&gt;
smiley = loader.loadModel('smiley.egg')
fromObject = smiley.attachNewNode(CollisionNode('colNode'))
fromObject.node().addSolid(CollisionSphere(0, 0, 0, 1))

pusher = CollisionHandlerPusher()
pusher.addCollider(fromObject, smiley)
&lt;/code&gt;
[/python]

[cxx]
&lt;code cxx&gt;
smiley = window-&gt;load_model(framework.get_models(),&quot;smiley.egg&quot;);
fromObject = smiley.attach_new_node(CollisionNode(&quot;colNode&quot;));
fromObject-&gt;add_solid(CollisionSphere(0,0,0,1));

pusher = new CollisionHandlerPusher();
pusher.add_collider(fromObject,smiley);
&lt;/code&gt;
[/cxx]


Don't be confused by the call to &lt;code&gt;pusher.addCollider&lt;/code&gt;; it looks a lot like the call to &lt;code&gt;traverser.addCollider&lt;/code&gt;, but it's not the same thing, and you still need to add the collider and its handler to the traverser:

[python]&lt;code python&gt;
traverser.addCollider(fromObject, pusher)
smiley.setPos(x, y, 0)
&lt;/code&gt;
[/python]

[cxx]
&lt;code cxx&gt;
CollisionTraverser traverser.add_collider(fromObject,pusher);
smiley-&gt;set_pos(x,y,0);
&lt;/code&gt;
[/cxx]

If you are using Panda's drive mode to move the camera around (or some other node), then you also need to tell the pusher about the drive node, by adding it into the &lt;code&gt;pusher.addCollider&lt;/code&gt; call:

[python]&lt;code python&gt;
fromObject = base.camera.attachNewNode(CollisionNode('colNode'))
fromObject.node().addSolid(CollisionSphere(0, 0, 0, 1))
pusher = CollisionHandlerPusher()
pusher.addCollider(fromObject, base.camera, base.drive.node())
&lt;/code&gt;
[/python]

[cxx]
&lt;code cxx&gt;
fromObject = cam.attach_new_node(CollisionNode(&quot;colNode&quot;))
fromObject-&gt;node().add_solid(CollisionSphere(0,0,0,1);
pusher = new CollisionHandlerPusher();
pusher.add_collider(fromObject,cam);
&lt;/code&gt;
[/cxx]

&lt;h2&gt;PhysicsCollisionHandler&lt;/h2&gt;

This kind of handler further specializes CollisionHandlerPusher to integrate with Panda's [[Physics Engine]].  It requires that the NodePath you pass as the second parameter to &lt;code&gt;pusher.addCollider&lt;/code&gt; actually contains an ActorNode, the type of node that is moved by forces in the physics system.

[python]&lt;code python&gt;
anp = render.attachNewNode(ActorNode('actor'))
fromObject = anp.attachNewNode(CollisionNode('colNode'))
fromObject.node().addSolid(CollisionSphere(0, 0, 0, 1))

pusher = PhysicsCollisionHandler()
pusher.addCollider(fromObject, anp)
&lt;/code&gt;
[/python]

[cxx]
&lt;code cxx&gt;
anp = window-&gt;get_render().attach_new_node(ActorNode(&quot;actor&quot;));
fromObject = anp.attach_new_node(CollisionNode(&quot;codeNode&quot;);
fromObject-&gt;node().add_solid(CollisionSphere(0,0,0,1))

pusher = new PhysicsCollisionHandler();
pusher.add_collider(fromObject , anp);
&lt;/code&gt;
[/cxx]

Whenever you have an ActorNode that you want to respond to collisions, we recommend that you use a PhysicsCollisionHandler rather than an ordinary CollisionHandlerPusher.  The PhysicsCollisionHandler will keep the object out of walls, just like the CollisionHandlerPusher does, but it will also update the object's velocity within the physics engine, which helps to prevent the physics system from becoming unstable due to large accumulated velocities.

&lt;h2&gt;CollisionHandlerFloor&lt;/h2&gt;

This collision handler is designed to serve one very specialized purpose: it keeps an object on the ground, or falling gently onto the ground, even if the floor is not level, without involving physics.

It is intended to be used with a &lt;code&gt;CollisionRay&lt;/code&gt; or &lt;code&gt;CollisionSegment&lt;/code&gt;.  The idea is that you attach a ray to your object, pointing downward, such that the topmost intersection the ray detects will be the floor your object should be resting on.  Each frame, the CollisionHandlerFloor simply sets your object's z value to the detected intersection point (or, if it is so configured, it slowly drops the object towards this point until it reaches it).

Using the CollisionHandlerFloor can be an easy way to simulate an avatar walking over uneven terrain, without having to set up a complicated physics simulation (or involve physics in any way).  Of course, it does have its limitations.

[python]&lt;code python&gt;
smiley = loader.loadModel('smiley.egg')
fromObject = smiley.attachNewNode(CollisionNode('colNode'))
fromObject.node().addSolid(CollisionRay(0, 0, 0, 0, 0, -1))

lifter = CollisionHandlerFloor()
lifter.addCollider(fromObject, smiley)
&lt;/code&gt;
[/python]

[cxx] 
&lt;code cxx&gt;
smiley = window-&gt;load_model(framework.get_models(), &quot;smiley.egg&quot;);
fromObject = smiley.attach_new_node(CollisionNode(&quot;colNode&quot;));
fromObject-&gt;node().add_solid(CollisionRay(0,0,0,0,0,-1));

lifter = new CollisionHandlerFloor();
lifter.add_collider(fromObject , smiley);

&lt;/code&gt;
[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Collision Solids</title>
    <ns>0</ns>
    <id>959</id>
      <sha1>7qoh8fukn3fppjcjfz7mvm8qso7p7fx</sha1>
    <revision>
      <id>60495</id>
      <timestamp>2015-05-13T13:43:29Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>Undo revision 6063 by [[Special:Contributions/Amith|Amith]] ([[User talk:Amith|talk]])</comment>
      <text xml:space="preserve" bytes="11250">The CollisionSolid is the fundamental object of the collision system.  CollisionSolids represent special invisible geometry that is created solely for the purpose of performing collision tests; these CollisionSolids are stored in the scene graph alongside the normal visible geometry.

The CollisionSolids are specifically optimized for performing collision tests quickly.  Collisions can be performed against visible geometry as well, but this is more expensive since visible geometry is not optimized for this sort of thing.

You can create CollisionSolids interactively in program code, or you can construct them in your modeling package and load them up from an egg or bam file along with the rest of your scene.

When you create a CollisionSolid interactively, you must also create a CollisionNode to hold the solid.  (When you load your CollisionSolids in from an egg file, the CollisionNodes are created for you.)  Often, a CollisionNode will be used to hold only one solid, but in fact a CollisionNode can contain any number of solids, and this is sometimes a useful optimization, especially if you have several solids that always move together as a unit.

[python]&lt;code python&gt;
cs = CollisionSphere(0, 0, 0, 1)
cnodePath = avatar.attachNewNode(CollisionNode('cnode'))
cnodePath.node().addSolid(cs)
&lt;/code&gt;[/python]

[cxx]
&lt;code cxx&gt;
PT(CollisionSphere) cs = new CollisionSphere();
cSphere_node= new CollisionNode(&quot;Sphere&quot;);
cSphere_node-&gt;add_solid(cs);
&lt;/code&gt;
[/cxx]

CollisionNodes are hidden by default, but they may be shown for debugging purposes:

[python]&lt;code python&gt;
cnodePath.show()
&lt;/code&gt;[/python]

[cxx]
&lt;code cxx&gt;
cSphere_node-&gt;show();
&lt;/code&gt;
[/cxx]

&lt;b&gt;Note&lt;/b&gt;: Be aware that the collision algorithm has only limited awareness of scaling transforms applied to CollisionSolids. If unequal scaling is applied between a &quot;from&quot; collider and an &quot;into&quot; collider, unexpected results may occur. In general, strive to have as few scaling transforms applied to your collision solids as possible.

There are several kinds of CollisionSolids available.

&lt;h2&gt;CollisionSphere&lt;/h2&gt;

The sphere is the workhorse of the collision system.  Spheres are the fastest primitives for any collision calculation; and the sphere calculation is particularly robust.  If your object is even vaguely spherical, consider wrapping a sphere around it.

Also, a sphere is a particularly good choice for use as a &quot;from&quot; object, because a sphere can reliably be tested for collision with most of the other solid types.  The &quot;from&quot; objects are the objects that are considered the active objects in the world; see [[Collision Traversers]].  A sphere is usually the best choice to put around the player's avatar, for instance.  The sphere also makes a good &quot;into&quot; object; it is the only object type that is a good choice for both &quot;from&quot; and &quot;into&quot; objects.

A sphere is defined in terms of a center and a radius.  Note that, like any object, the sphere's coordinates are defined in the sphere's own coordinate space, so that often the center is (0, 0, 0).

&lt;code python&gt;
sphere = CollisionSphere(cx, cy, cz, radius)
&lt;/code&gt;

&lt;h2&gt;CollisionTube&lt;/h2&gt;

A &quot;tube&quot; is a cylinder with hemispherical endcaps.  This shape is sometimes called a capsule in other collision systems.

The tube is good as an &quot;into&quot; object, for objects that are largely cylindrical.  It is not a very good choice for a &quot;from&quot; object, because not many intersection tests have been written from tubes into other shapes.

[[Image:Tube.jpg|A CollisionTube]]

A tube is defined with its two endpoints, and the cylindrical radius.

&lt;code python&gt;
tube = CollisionTube(ax, ay, az, bx, by, bz, radius)
&lt;/code&gt;

&lt;h2&gt;CollisionInvSphere&lt;/h2&gt;
The inverse sphere is a special-purpose solid that is rarely used, but occasionally it is very useful.  It is an inside-out sphere: the solid part of the sphere is on the outside.  Any object that is on the outside of the sphere is considered to be colliding with it; any object on the inside is not colliding.

Think of the inverse sphere as a solid mass that fills the whole universe in all directions, except for a bubble of space in the middle.  It's useful for constraining an object within a particular space, since nothing can get out of an inverse sphere.

&lt;code python&gt;
inv = CollisionInvSphere(cx, cy, cz, radius)
&lt;/code&gt;

&lt;h2&gt;CollisionPlane&lt;/h2&gt;

The CollisionPlane is an infinite plane extending in all directions.  It is not often used, but it can be useful in certain cases, for instance as a trigger placed below the ground to detect when an avatar has accidentally slipped through a crack in the world.  You can also build a box out of six planes to keep objects perfectly constrained within a rectangular region, similar to an inverse sphere; such a box is much more reliable than one constructed of six polygons.

The plane actually divides the universe into two spaces: the space behind the plane, which is all considered solid, and the space in front of the plane, which is all empty.  Thus, if an object is anywhere behind a plane, no matter how far, it is considered to be intersecting the plane.

A CollisionPlane is constructed using a Panda3D Plane object, which itself has a number of constructors, including the A, B, C, D plane equation, or a list of three points, or a point and a normal.

&lt;code python&gt;
plane = CollisionPlane(Plane(Vec3(0, 0, 1), Point3(0, 0, 0)))
&lt;/code&gt;

&lt;h2&gt;CollisionPolygon&lt;/h2&gt;

A CollisionPolygon is the most general of the collision solids, since it is easy to model any shape with polygons (especially using a modeling package).  However, it is also the most expensive solid, and the least robust--there may be numerical inaccuracies with polygons that allow collisions to slip through where they shouldn't.

Like a plane and a tube, a CollisionPolygon is only a good choice as an &quot;into&quot; object.  It doesn't support collision tests as a &quot;from&quot; object.

In general, if you must use CollisionPolygons to model your shape, you should use as few polygons as possible.  Use quads instead of triangles if possible, since two triangles take twice as much time to compute as a single quad.  This does mean that you need to ensure that your quads are perfectly coplanar.

You can also make higher-order polygons like five-sided and six-sided polygons or more, but you cannot make concave polygons.  If you create a concave or non-coplanar CollisionPolygon in your modeling package, Panda will automatically triangulate it for you (but this might result in a suboptimal representation, so it is usually better to subdivide a concave polygon by hand).

Unlike a plane, a CollisionPolygon is infinitely thin; an object is only considered to be colliding with the polygon while it is overlapping it.

When you create a CollisionPolygon interactively, you can only create triangles or quads (the higher-order polygons can only be loaded from an egg file).  Simply specify the three or four points to the constructor, in counter-clockwise order.

&lt;code python&gt;
quad = CollisionPolygon(Point3(0, 0, 0), Point3(0, 0, 1),
  Point3(0, 1, 1), Point3(0, 1, 0))
&lt;/code&gt;

&lt;h2&gt;CollisionRay&lt;/h2&gt;

The ray is a special collision solid that is useful only as a &quot;from&quot; object; since the object has no volume, nothing will collide &quot;into&quot; a ray.  The same is true for line, parabola, and segment listed below.

The CollisionRay represents an infinite ray that begins at a specific point, and stretches in one direction to infinity.

It is particularly useful for picking objects from the screen, since you can create a ray that starts at the camera's point of view and extends into the screen, and then determine which objects that ray is intersecting.  (In fact, there is a method on CollisionRay called &lt;code&gt;setFromLens()&lt;/code&gt; that automatically sets up the ray based on a 2-d onscreen coordinate; this is used by the &quot;picker&quot;.  See [[Clicking on 3D Objects]].)

The CollisionRay is also useful in conjunction with the CollisionHandlerFloor; see [[Collision Handlers]].

A CollisionRay is created by specifing an origin point, and a direction vector.  The direction vector need not be normalized.

&lt;code python&gt;
ray = CollisionRay(ox, oy, oz, dx, dy, dz)
&lt;/code&gt;

&lt;h2&gt;CollisionLine&lt;/h2&gt;

This is essentially the same as a CollisionRay, except it extends to infinity in both directions.  It is constructed with the same parameters, an origin point and a direction vector.

&lt;code python&gt;
line = CollisionLine(ox, oy, oz, dx, dy, dz)
&lt;/code&gt;

&lt;h2&gt;CollisionSegment&lt;/h2&gt;

A segment is another variant on the CollisionRay that does not extend to infinity, but only goes to a certain point and stops.  It is useful when you want to put a limit on how far the CollisionRay would otherwise reach.

A CollisionSegment is constructed by specifying the two end points.

&lt;code python&gt;
segment = CollisionSegment(ax, ay, az, bx, by, bz)
&lt;/code&gt;

&lt;h2&gt;CollisionParabola&lt;/h2&gt;

A parabola is another variant on the CollisionRay that bends.  It is useful when you want to test with arcs, such as a cannonball shot.

&lt;h2&gt;CollisionBox&lt;/h2&gt;

Finally, a box represents a cuboid. It consists of three pairs of rectangles, with adjacent sides meeting each other at a right angle. This can be employed where ever a necessity arises for using six intersecting planes. A box can be both a 'from' and 'into' object for the shapes specified in the chart.
A box can only be constructed as an Axis-Aligned Bounding Box (AABB). That is, each side of the box is parallel to one of the coordinate axes. Once constructed, all collision tests are performed on the box as though it was an Oriented-Bounding Box (OBB). 

There are two constructors for the Box. One of them specifies the center for the box as well as the distance of each of the sides from the center.

&lt;code python&gt;
box = CollisionBox(cx,cy,cz,dx,dy,dz)
or
box = CollisionBox(center,dx,dy,dz)
&lt;/code&gt;

The second form of constructor takes the two diagonally opposite end points of the AABB.
&lt;code python&gt;
box = CollisionBox(Point3(minx,miny,minz),Point3(maxx,maxy,maxz))
&lt;/code&gt;


&lt;h2&gt;Collision System Chart &lt;/h2&gt;
Here is a table of the Collision Solids that can be used as &quot;from&quot; and &quot;into&quot; objects in a Collision.

At noted above, with no volume CollisionRay, CollisionLine, CollisionParabola, CollisionSegment are only &quot;from&quot;, never &quot;into&quot; and hence not listed as columns in the table below.

At present, CollisionFloorMesh, CollisionInvSphere, CollisionPlane, CollisionPolygon, and CollisionTube are only &quot;into&quot; and never &quot;from&quot; and hence are not listed as rows in the table below. 

In the table below, the solid is listed without its &quot;Collision&quot; preface, e.g., &quot;Sphere&quot; instead of &quot;CollisionSphere&quot;, to save on space. 

{| border=&quot;1&quot;
| '''FROM/INTO''' || '''FloorMesh''' || '''InvSphere''' || '''Plane''' || '''Polygon''' || '''Sphere''' || '''Tube'''
|-
|| Line || ''' ''' || '''Yes''' || '''Yes''' || '''Yes''' || '''Yes''' || '''Yes'''
|-
|| Parabola || ''' ''' || ''' ''' || '''Yes''' || '''Yes''' || '''Yes''' || '''Yes'''
|-
|| Ray || '''Yes*''' || '''Yes''' || '''Yes''' || '''Yes''' || '''Yes''' || '''Yes'''
|-
|| Segment || ''' ''' || '''Yes''' || '''Yes''' || '''Yes''' || '''Yes''' || '''Yes'''
|-
|| Sphere || '''Yes''' || '''Yes''' || '''Yes''' || '''Yes''' || '''Yes''' || '''Yes'''
|}</text>
    </revision>
  </page>
  <page>
    <title>Collision Traversers</title>
    <ns>0</ns>
    <id>960</id>
      <sha1>os0xo1ympgqlwxrt8o1kagrtwit9ldd</sha1>
    <revision>
      <id>6090</id>
      <timestamp>2009-09-03T16:26:44Z</timestamp>
      <contributor>
        <username>ZeroByte</username>
        <id>170</id>
      </contributor>
      <text xml:space="preserve" bytes="3140">A CollisionTraverser object performs the actual work of checking all solid objects for collisions.  Normally, you will create a single CollisionTraverser object and assign it to &lt;code&gt;base.cTrav&lt;/code&gt;; this traverser will automatically be run every frame.  It is also possible to create additional CollisionTraversers if you have unusual needs; for instance, to run a second pass over a subset of the geometry.  If you create additional CollisionTraversers, you must run them yourself.

The CollisionTraverser maintains a list of the active objects in the world, sometimes called the &quot;colliders&quot; or &quot;from objects&quot;.  The remaining collidable objects in the world that are not added to a CollisionTraverser are the &quot;into objects&quot;.  Each of the &quot;from objects&quot; is tested for collisions with all other objects in the world, including the other from objects as well as the into objects.

Note that it is up to you to decide how to divide the world into &quot;from objects&quot; and &quot;into objects&quot;.  Typically, the from objects are the moving objects in the scene, and the static objects like walls and floors are into objects, but the collision system does not require this; it is perfectly legitimate for a from object to remain completely still while an into object moves into it, and the collision will still be detected.

It is a good idea for performance reasons to minimize the number of from objects in a particular scene.  For instance, the user's avatar is typically a from object; in many cases, it may be the only from object required--all of the other objects in the scene, including the walls, floors, and other avatars, might be simply into objects.  If your game involves bullets that need to test for collisions with the other avatars, you will need to make either the bullets or the other avatars be from objects, but probably not both.

In order to add a from object to the CollisionTraverser, you must first create a CollisionHandler that defines the action to take when the collision is detected; then you pass the NodePath for your from object, and its CollisionHandler, to &lt;code&gt;addCollider&lt;/code&gt;.

[python]
&lt;code python&gt;
traverser = CollisionTraverser('traverser name')
base.cTrav = traverser
traverser.addCollider(fromObject, handler)
&lt;/code&gt;
[/python]

[cxx]
&lt;code cxx&gt;
CollisionTraverser c_trav.add_collider(fromObject, handler);
&lt;/code&gt;
[/cxx]

&lt;i&gt;You only need to add the &quot;from&quot; objects to your traverser!&lt;/i&gt;  Don't try to add the &quot;into&quot; objects to the CollisionTraverser.  Adding an object to a CollisionTraverser makes it a &quot;from&quot; object.  On the other hand, every object that you put in the scene graph, whether it is added to a CollisionTraverser or not, is automatically an &quot;into&quot; object.

Note that all of your &quot;from&quot; objects are typically &quot;into&quot; objects too (because they are in the scene graph), although you may choose to make them not behave as into objects by setting their [[Collision Bitmasks|CollideMask]] to zero.

The CollisionTraverser can visually show the collisions that are occurring by using the following line of code:

[python]
&lt;code python&gt;
collisionTraverser.showCollisions(render)
&lt;/code&gt;
[/python]</text>
    </revision>
  </page>
  <page>
    <title>Color Spaces</title>
    <ns>0</ns>
    <id>51878</id>
      <sha1>3lg8m50xjdvmfcr8jqaprnp6viuw1k8</sha1>
    <revision>
      <id>60282</id>
      <timestamp>2014-10-07T21:34:25Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="11868">'''This page describes a future feature.  It is not currently available in any version of Panda3D.'''

== Introduction ==
By default, Panda3D and OpenGL (and most conventional graphics software) operate under the assumption that all input colors and output colors are in a linear color space.  This means that they assume that adding two colors together produces a color with their combined luminosity, and that multiplying a color with a scalar value ''n'' produces a color that is ''n'' times as bright.

However, these assumptions are wrong.  Historically, CRT monitors had a gamma of around 2.2, which means that the color values appear as if they were raised to the power of 2.2, so content produced was corrected for that gamma so that they could be viewed without the need for in-software gamma correction.

This practice was standardized in 1996 when the sRGB color space was established; it mimicked a gamma of 2.2 so that it could be viewed directly on CRT monitors.  When other display devices were produced, they typically had compensating circuitry so they could view the same imagery.  Today, almost all monitors are calibrated to the sRGB color space and the great majority of digital cameras shoot in sRGB.

Now, one might think that sRGB is merely an archaic artifact of the old days when we all had CRT monitors.  However, as it turns out, the human eye also has a very non-linear perception of color.  In particular, our eyes are better able to distinguish dark tones than they are able to distinguish bright tones.  So it is more efficient to store images as sRGB, which gives higher resolution for the darker tones, so that the images are more optimized for human consumption.

Usually, this all works out just fine: when you view an sRGB image in a browser or image viewer, it is sent to the monitor without need for gamma correction, and the monitor displays it with a gamma of 2.2.  However, there is a very important drawback:  our textures and framebuffers are '''''non-linear'''''.

This has an important implication for 3D lighting and blending calculations.  Since these involve linear calculations, the results will be &lt;i&gt;wrong&lt;/i&gt;.  This can be fairly dramatic!  A light that is supposed to attenuate a colour value to half brightness will actually cause it to appear at 0.22x brightness, which means that darker shades will appear far too dark, not to mention that the transition between light and dark will appear unnatural.

It is easy to dismiss these since the lighting in your scene may look just fine to you.  After all, you've probably adjusted all your light's attenuation to compensate for the darkness and you may find that you have to re-balance all your lights if you want to work with proper gamma-correction.  Plus, you may have to get used to the way lighting behaves if you're used to those old games that didn't account for gamma correction.

Your results may look fine, but they're still &lt;i&gt;wrong&lt;/i&gt;.  Until you properly account for gamma correction, lights in your applications won't behave the way they &lt;i&gt;should&lt;/i&gt;, or rather, as they do in real life.  This is especially important for realistic rendering techniques like physically based lighting - the closer you get to realistic lighting, the more obvious these lighting issues will become.

== Monitor Calibration ==
Of course, this all assumes that the monitor has been calibrated to the industry standard sRGB color space.  This may not always be the case.  Cheaper monitors may not have been calibrated correctly, or a monitor's gamma settings may have been altered.

Therefore, it is recommended that you not only let the user adjust the gamma in a settings menu, but it would be even better if there was a mechanism to let the user adjust the gamma based on test images.  One common approach is to show three instances of a certain glyph at different brightnesses, and let the user adjust the gamma until the brightness of the glyphs match, or until the visibility of the glyphs matches a certain expectation.

Use the following image to find out if your monitor is sRGB corrected.  Align the following image to the center of your monitor, then lean back and look at it straight-on.  The top half is finely black/white checkered, and its brightness will be exactly the midpoint between black and white.  The bottom half is what the midpoint of grey should look like when correctly calibrated.  If both halves appear to be at the same brightness, your monitor is correctly sRGB-calibrated.

http://rdb.name/srgb-calibration-strip.png

Be sure to view this image at exactly 100% magnification!  At any other magnification, the browser will perform gamma-naive scaling, and the top half will suddenly change to a dark grey.

== Correction Features ==
To correct this, we have to make sure that our lighting and blending operations happen in ''linear'' space.  These are the steps we have to do for that to happen:
* The texture values we sample must have been converted to linear space.
* The rendered pixels must be converted back to sRGB when displaying them on screen or writing them into the framebuffer.

Fortunately, modern graphics hardware has a range of facilities that make this easy for us, using two features available in both OpenGL and Direct3D: sRGB textures, and sRGB framebuffers.  The first means that a texture can be marked as being in the sRGB color space, which causes OpenGL to automatically convert the data to linear space when sampling the texture.  The second causes OpenGL to convert linear data back to sRGB when writing back into the frame buffer.  These two features go hand-in-hand; enabling one but not the other will cause results that will appear even more incorrect.

The nice thing is that these operations are implemented in silico, so they are virtually ''free'' on hardware that supports it.  It is supported in OpenGL 2 and Direct3D 9, although some vendors did not implement some things (like texture filtering) entirely in linear space; it is generally safe to assume that OpenGL 3 / Direct3D 10 hardware does it correctly.

The one thing that is not affected by color space conversion is flat colors.  This means that you may have to adjust the colors of your lights, fog, and background color after enabling sRGB frame buffers.  All colors in Panda3D are assumed to be in linear space.

=== sRGB Textures ===
As mentioned above, input textures need to be converted to linear space when they are sampled in order to have proper gamma corrections.  This simply means that all textures storing color data need to be flagged as being in the sRGB color space; the graphics hardware does the rest.

Keep in mind that this only applies to textures storing color data.  Normal maps and specular maps in particular do not store color data, and they are typically assumed to be linear.  &lt;b&gt;This also applies to any alpha channel&lt;/b&gt;, which is always linear, even if the red, green and blue channels are sRGB.

There are several ways to enable sRGB support on textures, depending on how those textures are loaded or created.

Firstly, when loading a texture in code, it is possible to specify the color space in the load call.  An extra &lt;code&gt;colorSpace&lt;/code&gt; keyword argument has been added to the &lt;code&gt;loader.loadTexture&lt;/code&gt; call:
&lt;syntaxhighlight lang=&quot;python&quot;&gt;
diffuseMap = loader.loadTexture(&quot;texture-diffuse.png&quot;, colorSpace=CS_srgb)
normalMap = loader.loadTexture(&quot;texture-normal.png&quot;, colorSpace=CS_linear)
&lt;/syntaxhighlight&gt;

This information can also be specified in an .egg file, using a syntax like the following:
&lt;syntaxhighlight&gt;
&lt;Texture&gt; tex {
  image.png
  &lt;Scalar&gt; color-space { linear }
}
&lt;/syntaxhighlight&gt;

Finally, there is the option to set the &lt;i&gt;default color space&lt;/i&gt;, which is used whenever color space information is omitted.  Simply setting the default color space to sRGB should cause all textures without otherwise specified color space information to be loaded as sRGB.  This can be done as follows:
&lt;syntaxhighlight&gt;
default-texture-color-space sRGB
&lt;/syntaxhighlight&gt;

The most recommended approach is to set the default color space to sRGB and only explicitly overriding this to linear when loading normal map or specular map textures.  This allows for easily turning off sRGB support by changing a single configuration variable, and also accounts for older model data or exporters that do not correctly respect color space settings.

When creating a texture procedurally, it is important to note that different formats are used for sRGB textures.  In the &lt;code&gt;setup_texture&lt;/code&gt; call, you should use one of the &lt;code&gt;F_srgb&lt;/code&gt;, &lt;code&gt;F_srgb_alpha&lt;/code&gt;, &lt;code&gt;F_sluminance&lt;/code&gt; or &lt;code&gt;F_sluminance_alpha&lt;/code&gt; formats.  These are 8-bit per channel formats of which the color components must be specified in the sRGB color space, whereas the alpha is always assumed to be linear.  There is no floating-point equivalent; when floating-point textures are desired, you should convert the data to a linear color space first.

The following setting enables driver support for sRGB textures:
&lt;syntaxhighlight&gt;
textures-srgb true
&lt;/syntaxhighlight&gt;
This setting is strongly recommended, and is in fact the default setting.  Panda3D can automatically convert textures from sRGB to linear space when the driver doesn't support sRGB textures or when this setting is disabled, but this comes at a cost: since linear textures do not optimally represent the range of colors perceived by the human eye, this is essentially a quality downgrade, and banding artifacts ''will'' be present when the texture is converted back to sRGB.  That's why you should usually leave this setting on unless you suspect a driver bug.

Mip map generation is automatically done in linear space by Panda3D on linear textures.  Since some AMD graphics cards I've tried have bugs causing them to perform the mip map generation in linear space (which causes them to appear too dark in the distance), Panda3D does not rely on driver generation of mipmaps by default.

'''Note:''' while some image formats (such as PNG) store color profile information, they are more often than not used incorrectly, and therefore Panda3D makes no attempt to interpret this metadata.

=== sRGB Framebuffers ===
The following Config.prc setting enables sRGB conversion on the main framebuffer:
&lt;syntaxhighlight&gt;
framebuffer-srgb true
&lt;/syntaxhighlight&gt;
It's that simple - from that point on, all colors will be converted from linear space to sRGB before showing up in the window.

Enabling sRGB on a buffer or window you create at run-time can be done using the following FrameBufferProperties setting:
&lt;syntaxhighlight lang=&quot;python&quot;&gt;
fbp = FrameBufferProperties()
fbp.set_srgb_color(True)
&lt;/syntaxhighlight&gt;

However, things get a bit more complicated when you have intermediate buffers.  It is important to always note which color space your image is in.  There are several cases to take into account here:
* A shadow, normal or other non-color buffer is always linear.  No sRGB is enabled.
* An intermediate buffer storing 8-bit color data should be sRGB.  Failure to do so will result in artifacts when converting the data back to sRGB for viewing.
* An intermediate buffer storing floating-point color data should be linear.  There is no point to the sRGB conversion.

When using post-processing passes, it may be tempting to enable sRGB correction only on the intermediate buffer and leaving it off when rendering the results into the window.  This is technically possible, but the issue with that is that the post-processing filter would not be working in linear space, which may cause them to show the wrong results.  Because sRGB conversion is practically free, we don't recommend this approach, but instead recommend to always enable sRGB support on the default window framebuffer using the above Config.prc variable.</text>
    </revision>
  </page>
  <page>
    <title>Color Write Masks</title>
    <ns>0</ns>
    <id>2224</id>
      <sha1>g3p1m3s8643au91ceubsxrhl9egpkpr</sha1>
    <revision>
      <id>6220</id>
      <timestamp>2009-10-12T12:03:54Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <text xml:space="preserve" bytes="1514">==Color Write Masks==

Color write masks enable you to block writes to the Red, Green, Blue, or Alpha channels of the framebuffer.  This is not a frequently-used capability, but it
does have a few applications:

* When using red-blue 3D glasses, you might want to render the red image, then the blue image.  (In fact, Panda uses this technique automatically when you set &lt;span class=&quot;code&quot;&gt;red-blue-stereo 1&lt;/span&gt; in your Config.prc file.)

* Battletech Battle Pods connect 3 black-and-white monitors to a single R,G,B video card output (really!)  With the help of color write masks, you could update an individual monitor.

* Sometimes, one wants to store data in the alpha-channel of the framebuffer. Using a color mask can avoid accidentally overwriting that data.

Using a color write-mask is not free.  During normal rendering, each pixel written to the frame buffer requires a memory write.  With a color-mask active, a memory read-modify-write cycle is needed, which is more expensive.

By default, color write masks are off.

==Turning on the Color Mask==

To enable writes to all the channels of the framebuffer, use this:

&lt;code python&gt;
bits = ColorWriteAttrib.CAlpha
bits |= ColorWriteAttrib.CRed
bits |= ColorWriteAttrib.CGreen
bits |= ColorWriteAttrib.CBlue
nodePath.setAttrib(ColorWriteAttrib.make(bits))
&lt;/code&gt;

To disable writes to one or more channels, omit that bit.  You can also use:

&lt;code python&gt;
nodePath.setAttrib(ColorWriteAttrib.make(ColorWriteAttrib.CAll))
&lt;/code&gt;

To enable all bits.</text>
    </revision>
  </page>
  <page>
    <title>Common Image Filters</title>
    <ns>0</ns>
    <id>2184</id>
      <sha1>38bgodm1sk5jg0jqh9otmua3d2w1tyf</sha1>
    <revision>
      <id>7559</id>
      <timestamp>2012-01-10T07:40:09Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>how are people supposed to know where to import it from?</comment>
      <text xml:space="preserve" bytes="7994">[cxx]&lt;b&gt;Note:&lt;/b&gt; Sorry, but the CommonFilters and FilterManager classes are implemented in Python and will not be of much use to C++ users.

[/cxx]&lt;h2&gt;Common Image Filters&lt;/h2&gt;

Note: the following information applies to Panda version 1.5.0 and beyond.
It does not apply to older versions of Panda3D.

The purpose of class CommonFilters is to make it easy to set up a number of
common image postprocessing operations.

Import the class like this:

&lt;code python&gt;
from direct.filter.CommonFilters import CommonFilters
&lt;/code&gt;

Currently, the image postprocessing
operations supported by class CommonFilters is:

# Bloom Filter - creates a glowing halo around bright objects.
# Cartoon Inker - draws black lines around 3D objects.
# Volumetric Lighting - screen-space method for casting god-rays (new in 1.6.0)
# Inverted Filter - inverts all colors (new in 1.6.0)
# Blur/Sharpen Filter - applies a generic blur or sharpen filter (new in 1.7.0)
# Ambient Occlusion - applies a screen-space ambient occlusion filter (new in 1.7.0)

We expect this list to grow rather substantially over the next year or so.


&lt;h2&gt;Basic Setup&lt;/h2&gt;

The first step is to create an object of class CommonFilters.  Pass in
a pointer to your window, and your 3D camera:

&lt;code python&gt;
filters = CommonFilters(base.win, base.cam)
&lt;/code&gt;

This will have no effect until you enable a filter (instructions below.)  Once
a filter is enabled, class CommonFilters will reconfigure the Panda3D rendering
as follows:

* It will render the scene into an offscreen buffer, using the camera you provided.
* It will remove the scene from the specified window, and replace it with a fullscreen quad.  
* The quad will be textured with the scene, plus a shader that implements whatever filter you have selected.

If all goes well, the net effect is that your scene will continue to appear
in your window, but it will be filtered as you specify.


&lt;h2&gt;What if the Video Card can't handle it?&lt;/h2&gt;

If the video card is not capable of implementing your filters, then all
filters will be removed and the filter-enabling function will return False.
Otherwise, filter-enabling functions will return True.


&lt;h2&gt;The Bloom Filter&lt;/h2&gt;

The bloom filter causes bright objects to have a glowing halo around them.  To enable a bloom filter, use &lt;code&gt;setBloom&lt;/code&gt;.  To disable, use &lt;code&gt;delBloom&lt;/code&gt;:

&lt;code python&gt;
filters.setBloom( ... options ...)
filters.delBloom()
&lt;/code&gt;

The bloom filter works as follows.  First, it renders the scene into a texture.  It also asks the renderer to render any glow-maps into the alpha channel of the texture.  After rendering the scene, it generates a second copy of the scene which has been darkened until only the brightest pixels are visible, and all the others go to black.  It then blurs that texture, yielding soft halos where the bright pixels used to be, and black everywhere else.  It then adds the soft halos back onto the scene in the window.

&lt;b&gt;Note:&lt;/b&gt; If you want to use glow maps to indicate which parts of the image should receive bloom, you should assign a nonzero value to the alpha value of the blend-weight parameter, and you should enable the [[shader generator]] for the models that have glow maps applied.

The bloom filter has many keyword parameters:

* blend - The bloom filter needs to measure the brightness of each pixel.  It does this by weighting the R,G,B, and A components.  Default weights: (0.3,0.4,0.3,0.0).  You should assign a nonzero weight to the alpha channel if you want the glow map to have an effect, or a value like (0, 0, 0, 1) if you only want your glow map to indicate which models should glow.

* mintrigger - Minimum brightness at which a halo is generated.  Default: 0.6

* maxtrigger - Maximum brightness at which the halo reaches peak intensity.  Default: 1.0

* desat - Degree to which the halo is desaturated.  Setting this to zero means the halo is the same color as the bright pixel.  Setting it to one means the halo is white.  Default: 0.6

* intensity - An adjustment parameter for the brightness of the halos.  Default: 1.0

* size - Adjusts the size of the halos.  Takes a string value: &quot;small&quot;, &quot;medium&quot;, or &quot;large&quot;.  The reason that this is a discrete value and not a continuous one is that the blur operation involves downsampling the original texture by a power of two.  Default: &quot;medium&quot;


&lt;h2&gt;The Cartoon Inking Filter&lt;/h2&gt;

The cartoon inking filter causes objects to have black lines around them.  To enable a cartoon inking filter, use &lt;code&gt;setCartoonInk&lt;/code&gt;.  To disable, use &lt;code&gt;delCartoonInk&lt;/code&gt;:

&lt;code python&gt;
filters.setCartoonInk( ... options ...)
filters.delCartoonInk()
&lt;/code&gt;

The cartoon inking filter works by rendering a camera-space normal into an
texture.  Then, a postprocessing filter does an edge-detect
algorithm on the camera-space normal texture.

The filter has the following keyword parameters:

* separation - Distance in pixels, controls the width of the ink line.  Default: 1 pixel.

* color - Color of the outline (new in 1.8.0). Default: (0, 0, 0, 1)


&lt;h2&gt;The Volumetric Lighting Filter&lt;/h2&gt;

The Volumetric Lighting filter makes objects cast visible light rays (also known as crepuscular rays, god rays or sunbeams) that can be occluded by visible geometry.  This is an easy way to easily create nice-looking light/sun effects.

&lt;code python&gt;
filters.setVolumetricLighting( ... options ...)
filters.delVolumetricLighting()
&lt;/code&gt;

The filter has the following keyword parameters:

* caster - NodePath that indicates the origin of the rays. Usually, you would pass your light, and create a sun billboard which is reparented to the light's NodePath.

* numsamples - Number of samples. The more samples you use, the slower the effect will be, but you will have smoother light rays. Note that using a fuzzy billboarded dot instead of a hard-edged sphere as light caster can help with smoothing the end result, too.  This value does &lt;b&gt;not&lt;/b&gt; need to be a power-of-two, it can be any positive number.  Default: 32

* density - This defines the length of the rays.  The default value of 5.0 is probably too high for many purposes, usually a value between 0.5 and 1.0 works best.  This also depends on the number of samples and exposure you've chosen, though.  Default: 5.0

* decay - Decay makes rays gradually decrease in brightness.  The default value of 0.1 is not well chosen and makes the rays very short!  Usually, this a value close to 1.0, like 0.98.  Default: 0.1

* exposure - Defines the brightness of the rays.  Default: 0.1


&lt;h2&gt;The Inverted Filter&lt;/h2&gt;

This filter simply inverts the colors of the image.

&lt;code python&gt;
filters.setInverted()
filters.delInverted()
&lt;/code&gt;

This filter has no parameters.


&lt;h2&gt;The Blur / Sharpen Filter&lt;/h2&gt;

This filter can apply a blur or sharpen effect to the image.

&lt;code python&gt;
filters.setBlurSharpen( ... options ...)
filters.delBlurSharpen()
&lt;/code&gt;

The filter has the following keyword parameters:

* amount - The amount of blurring, this is usually a value between 0.0 and 2.0.  You can take values smaller than 0.0 or larger than 2.0, but this usually gives ugly artifacts.  A value of 0.0 means maximum blur. A value of 1.0 does nothing, and if you go past 1.0, the image will be sharpened instead of blurred.  Default: 0.0

&lt;h2&gt;The Ambient Occlusion Filter&lt;/h2&gt;

This filter adds a simple screen-space ambient occlusion effect to the scene.

&lt;code python&gt;
filters.setAmbientOcclusion( ... options ...)
filters.delAmbientOcclusion()
&lt;/code&gt;

It is important that the viewing frustrum's near and far values fit the scene as tightly as possible.  Note that you need to do lots of tweaking to the parameters to get this filter to work for your particular situation.

The filter has the following keyword parameters:

* numsamples - The amount of samples used.  Default: 16

* radius - The sampling radius of the rotating kernel.  Default: 0.05

* amount - Default: 2.0

* strength - Default: 0.01

* falloff - Default: 0.000002</text>
    </revision>
  </page>
  <page>
    <title>Common Methods for Intervals, Sequences, and Parallels</title>
    <ns>0</ns>
    <id>961</id>
      <sha1>n77f7pc4a31pb9ksty93zh0p1fpmikn</sha1>
    <revision>
      <id>4113</id>
      <timestamp>2007-02-17T13:38:02Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="24">This page is deprecated.</text>
    </revision>
  </page>
  <page>
    <title>Common State Changes</title>
    <ns>0</ns>
    <id>962</id>
      <sha1>0l1pho9i1wvvihtccfh9n0ohgdnp53h</sha1>
    <revision>
      <id>6564</id>
      <timestamp>2010-01-24T09:57:37Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>Fixed wiki syntax usage error ([func][/code]); added &lt;code&gt; tags to a few in-line function references.</comment>
      <text xml:space="preserve" bytes="9222">&lt;h2&gt;Summary&lt;/h2&gt;

This page lists some of the most common changes you can make to a 3D node.
This page is really only a quick cheat-sheet summary: the 
detailed documentation for these operations comes later in the manual.

&lt;h2&gt;State Change Cheat Sheet&lt;/h2&gt;

Two of the most common changes are position and orientation.

[python]&lt;code python&gt;
myNodePath.setPos(X, Y, Z)
myNodePath.setHpr(Yaw, Pitch, Roll)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
myNodePath.set_pos(X, Y, Z);
myNodePath.set_hpr(Yaw, Pitch, Roll);
&lt;/code&gt;[/cxx]

By default in Panda3D, the X axis points to the right, the Y axis is forward, and Z is up.  An object's rotation is usually described using Euler angles called Heading, Pitch, and Roll (sometimes called Yaw, Pitch, and Roll in other packages)--these specify angle rotations in degrees.  (If you are more comfortable using quaternions, the &lt;code&gt;[func]setQuat[/func]()&lt;/code&gt; method can be used to specify the rotation as a quaternion.)

You can change an object's size, either uniformly, or with a different value of x, y, and z.

[python]&lt;code python&gt;
myNodePath.setScale(S)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
myNodePath.set_scale(S);
&lt;/code&gt;[/cxx]

Sometimes it is convenient to adjust a single component individually:

[python]&lt;code python&gt;
myNodePath.setX(X)
myNodePath.setY(Y)
myNodePath.setZ(Z)
myNodePath.setH(H)
myNodePath.setP(P)
myNodePath.setR(R)
myNodePath.setSx(SX)
myNodePath.setSy(SY)
myNodePath.setSz(SZ)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
myNodePath.set_x(X);
myNodePath.set_y(Y);
myNodePath.set_z(Z);
myNodePath.set_h(H);
myNodePath.set_p(P);
myNodePath.set_r(R);
myNodePath.set_sx(SX);
myNodePath.set_sy(SY);
myNodePath.set_sz(SZ);
&lt;/code&gt;[/cxx]

Or all at the same time:

[python]&lt;code python&gt;
myNodePath.setPosHprScale(X, Y, Z, H, P, R, SX, SY, SZ)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
myNodePath.set_pos_hpr_scale(X, Y, Z, H, P, R, SX, SY, SZ);
&lt;/code&gt;[/cxx]

You can also query the current transform information for any of the above:

[python]&lt;code python&gt;
myNodePath.getPos()
myNodePath.getX()
myNodePath.getY()
myNodePath.getZ()
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
myNodePath.get_pos();
myNodePath.get_x();
myNodePath.get_y();
myNodePath.get_z();
&lt;/code&gt;[/cxx]

Also, by using the functions &lt;code&gt;[func]setTag[/func]()&lt;/code&gt; and &lt;code&gt;[func]getTag[/func]()&lt;/code&gt; you can store your own information in key value pairs. For example:

[python]&lt;code python&gt;
myNodePath.setTag(&quot;Key&quot;, &quot;value&quot;)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
myNodePath.set_tag(&quot;Key&quot;, &quot;value&quot;);
&lt;/code&gt;[/cxx]
[python]You can also store Python objects as tags by using the &lt;code&gt;setPythonTag&lt;/code&gt; function with the same arguments.[/python]

As a more advanced feature, you may also set or query the position (or any of the above transform properties) of a particular NodePath with respect to another one.  To do this, specify the relative NodePath as the first parameter:

[python]&lt;code python&gt;
myNodePath.setPos(otherNodePath, X, Y, Z)
myNodePath.getPos(otherNodePath)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
myNodePath.set_pos(otherNodePath, X, Y, Z);
myNodePath.get_pos(otherNodePath);
&lt;/code&gt;[/cxx]

Putting a NodePath as the first parameter to any of the transform setters or getters makes it a relative operation.  The above &lt;code&gt;[func]setPos[/func]()&lt;/code&gt; means to set myNodePath to the position (X, Y, Z), relative to otherNodePath--that is, the position myNodePath would be in if it were a child of otherNodePath and its position were set to (X, Y, Z).  The &lt;code&gt;[func]getPos[/func]()&lt;/code&gt; call returns the position myNodePath would have if it were a child of otherNodePath.

It is also important to note that you can use the NodePath in its own relative sets and gets. This maybe helpful in situations where you are concerned with distances. For example:

[python]&lt;code python&gt;
# Move myNodePath 3 units forward in the x
myNodePath.setPos(myNodePath, 3, 0, 0)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
// Move myNodePath 3 units forward in the x
myNodePath.set_pos(myNodePath, 3, 0, 0);
&lt;/code&gt;[/cxx]

These relative sets and gets are a very powerful feature of Panda's scene graph, but they can also be confusing; don't worry if it doesn't make sense right now.

The &lt;code&gt;[func]lookAt[/func]()&lt;/code&gt; method rotates a model to face another object; that is, it rotates the first object so that its +Y axis points toward the second object.  Note that a particular model might or might not have been generated with the +Y axis forward, so this doesn't necessarily make a model &quot;look at&quot; the given object.

[python]&lt;code python&gt;
myNodePath.lookAt(otherObject)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
myNodePath.look_at(otherObject);
&lt;/code&gt;[/cxx]

Color changes are another common alteration. Values for color are floating point numbers from 0 to 1, 0 being black, 1 being white.

[python]&lt;code python&gt;
myNodePath.setColor(R, G, B, A)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
myNodePath.set_color(R, G, B, A);
&lt;/code&gt;[/cxx]

If models have textures, they may not be distinguishable or even visible at certain color settings. Setting the color to white may restore the visibility of the texture, but it is better to simply clear the current color settings.

[python]&lt;code python&gt;
myNodePath.clearColor()
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
myNodePath.clear_color();
&lt;/code&gt;[/cxx]

Note the fourth component of color is alpha.  This is usually used to indicate transparency, and it is usually 1.0 to indicate the object is not transparent.  If you set the alpha to a value between 0 and 1, you can fade the object to invisible.  However, in order for the alpha value to be respected, you must first enable transparency:

[python]&lt;code python&gt;
myNodePath.setTransparency(TransparencyAttrib.MAlpha)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
myNodePath.set_transparency(TransparencyAttrib::M_alpha);
&lt;/code&gt;[/cxx]

The parameter to &lt;code&gt;[func]setTransparency[/func]()&lt;/code&gt; is usually &lt;code&gt;TransparencyAttrib[::]M[python]A[/python][cxx]_a[/cxx]lpha&lt;/code&gt;, which is ordinary transparency.  You can also explicitly turn transparency off with &lt;code&gt;TransparencyAttrib[::]M[python]N[/python][cxx]_n[/cxx]one&lt;/code&gt;.  (Other transparency modes are possible, but that is a more advanced topic.  Some older code may pass just 0 or 1 for this parameter, but it is better to name the mode.)  If you don't explicitly enable transparency first, the alpha component of color may be ignored.  Be sure you don't enable transparency unnecessarily, since it does enable a more expensive rendering mode.

Setting an object's color completely replaces any color on the vertices.  However, if you have created a model with per-vertex color, you might prefer to modulate the object's color without losing the per-vertex color.  For this there is the &lt;code&gt;[func]setColorScale[/func]()&lt;/code&gt; variant, which multiples the indicated color values by the object's existing color:

[python]
&lt;code python&gt;
myNodePath.setColorScale(R, G, B, A)
&lt;/code&gt;
[/python]
[cxx]
&lt;code cxx&gt;
myNodePath.set_color_scale(R, G, B, A);
&lt;/code&gt;
[/cxx]

One use of &lt;code&gt;[func]setColorScale[/func]()&lt;/code&gt; is to apply it at the top of the scene graph (e.g. render) to darken the entire scene uniformly, for instance to implement a fade-to-black effect.

Since alpha is so important, there is also a method for scaling it without affecting the other color components:

[python]&lt;code python&gt;
myNodePath.setAlphaScale(SA)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
myNodePath.set_alpha_scale(SA);
&lt;/code&gt;[/cxx]

To temporarily prevent an object from being drawn on all cameras, use &lt;code&gt;hide()&lt;/code&gt; and &lt;code&gt;show()&lt;/code&gt;:

[python]&lt;code python&gt;
myNodePath.hide()
myNodePath.show()
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
myNodePath.hide();
myNodePath.show();
&lt;/code&gt;[/cxx]

If you want to hide an object for one camera but not another, you can use the &lt;code&gt;hide()&lt;/code&gt; and &lt;code&gt;show()&lt;/code&gt; commands in conjunction with the &lt;code&gt;camera.[func]setCameraMask[/func]()&lt;/code&gt; function:

[python]&lt;code python&gt;
camera1.node().setCameraMask(BitMask32.bit(0))
camera2.node().setCameraMask(BitMask32.bit(1))
myNodePath.hide(BitMask32.bit(0))
myNodePath.show(BitMask32.bit(1))
# Now myNodePath will only be shown on camera2...
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
camera1.node()-&gt;set_camera_mask(BitMask32::bit(0));
camera2.node()-&gt;set_camera_mask(BitMask32::bit(1));
myNodePath.hide(BitMask32::bit(0));
myNodePath.show(BitMask32::bit(1));
// Now myNodePath will only be shown on camera2...
&lt;/code&gt;[/cxx]

Please note that using hide/show without an argument will mess up any hide/shows with the argument (show(bit) will not undo a hide()...)  To hide an object from all cameras instead use &lt;code&gt;nodepath.hide(BitMask32[::][func]allOn[/func]())&lt;/code&gt;. [python]To set the camera mask for the default camera use base.cam, not base.camera, as base.camera is not an actual camera but a dummy node to hold cameras. [/python]Please see the camera section for information on how to set up multiple cameras.


Any object that is parented to the object that is hidden will also be hidden.

[python]If you have trouble to place, scale or rotate your nodes you can use the &lt;code&gt;place()&lt;/code&gt; function to bring up a small GUI which will help you. You need to have TkInter installed to use it.

&lt;code python&gt;
myNodePath.place()
&lt;/code&gt;[/python]</text>
    </revision>
  </page>
  <page>
    <title>Compas Effects</title>
    <ns>0</ns>
    <id>1078</id>
    <redirect title="Compass Effects" />
      <sha1>10v9csku8sub46tp1bh0sl2o78636vs</sha1>
    <revision>
      <id>2362</id>
      <timestamp>2005-05-01T01:09:42Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <comment>Compas Effects moved to Compass Effects</comment>
      <text xml:space="preserve" bytes="30">#REDIRECT [[Compass Effects]]
</text>
    </revision>
  </page>
  <page>
    <title>Compass Effects</title>
    <ns>0</ns>
    <id>963</id>
      <sha1>mbyzlepriyuijc3a7ahm206hj04snq9</sha1>
    <revision>
      <id>7436</id>
      <timestamp>2011-12-08T19:55:14Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>typo</comment>
      <text xml:space="preserve" bytes="1503">&lt;p&gt; A CompassEffect causes a node to inherit its rotation  (or pos or scale, if specified) from some other reference node in the graph, or more often from the root. &lt;/p&gt;

&lt;p&gt;In its purest form, a CompassEffect is used to keep the node's rotation fixed relative to the top of the scene graph, despite other transforms that may exist above the node. Hence the name: the node behaves like a magnetic compass, always pointing in the same  direction.&lt;/p&gt;

&lt;p&gt;As an couple of generalizing extensions, the  CompassEffect may also be set up to always orient its  node according to some other reference node than the root of the scene graph. Furthermore, it may  optionally adjust any of pos, rotation, or scale,  instead of necessarily rotation; and it may adjust individual pos and scale components. (Rotation may  not be adjusted on an individual component basis,  that's just asking for trouble.) &lt;/p&gt;

&lt;p&gt;Be careful when using the pos and scale modes. In these modes, it's possible for the CompassEffect to  move its node far from its normal bounding volume, causing culling to fail. If this is an issue, you  may need to explicitly set a large (or infinite) bounding volume on the effect node. &lt;/p&gt;

[python]&lt;code python&gt;
nodePath.setCompass()
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
nodePath.set_compass();
&lt;/code&gt;[/cxx]

&lt;p&gt;If a NodePath is supplied to the &lt;code&gt;[func]setCompass[/func]&lt;/code&gt; call, it indicates the node to which the rotation will be kept relative (which is &lt;code&gt;render&lt;/code&gt; by default).&lt;/p&gt;</text>
    </revision>
  </page>
  <page>
    <title>Compute Shaders</title>
    <ns>0</ns>
    <id>51875</id>
      <sha1>j8jlh0ash7y1zd2hf2zpqd90nxxv0m8</sha1>
    <revision>
      <id>60304</id>
      <timestamp>2014-12-21T13:49:10Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>add part about texture clear</comment>
      <text xml:space="preserve" bytes="15162">== Introduction ==

Panda3D 1.9.0 introduces a new feature: a type of general-purpose shader program that can be used to perform a wide variety of functions on the video card.  They are fundamentally different from other types of shaders in that they aren't assigned to a node and modify how the node is rendered, but are executed (''dispatched'') in a standalone fashion and perform an operation on an arbitrary set of data.  They may read from and write to texture images at will.  This is particularly useful for image processing or GPU-based particle algorithms, to name a few examples.

Compute shaders are only available on hardware supporting OpenGL 4.3, which includes NVIDIA GeForce 400 series and above and AMD Radeon HD 5000 series and above.

It is important to know that compute shaders are an advanced, low-level, and relatively recent feature.  This means that it is very easy to get strange and unexplainable results, including garbled texture data, or even video card crashes and system freezes in some cases.  Using them certainly requires a certain amount of expertise with graphics programming.  In many cases, similar results can be achieved with render-to-texture processes.

This page only aims to give a cursory overview of compute shaders where it is relevant to Panda3D's interfaces.  It is by no means a comprehensive manual covering everything about compute shaders.  In particular, image access concurrency, shared or coherent variables, and memory barriers are not covered here at all.  Please refer to the [http://www.opengl.org/wiki/Compute_Shader OpenGL documentation] for more information.

== Work groups ==

Normally, a regular shader is executed on a predetermined set of data (such as an amount of vertices or pixels), in which case the amount of shader invocations is known beforehand.  However, since compute shaders can operate on an arbitrary set of data, the amount of invocations has to be explicitly specified.

Compute shader invocations are divided up in batches called ''work groups'', which specify how many invocations happen simultaneously.  The different invocations in a work group may occur at the same time, but you should never rely on the different work groups being executed in a particular order or simultaneous to each other; this is up to the graphics driver to decide.

Although the local size of a work group is typically relatively small (you can count on 1024 total invocations within a single work group), you may invoke any number of these work groups.  The work group count is not hard-coded within the shader, but specified by the application.  One common workflow for an image processing shader is to divide up the image into tiles of fixed size, and then to specify in the application how many tiles are in the image to be processed.

The work group size and count are specified using a three-dimensional size value, so that it is conveniently possible to use compute shaders on sets of data with up to three physical dimensions, such as 3-D textures or cube maps.  However, the Z component of these values may be set to 1 if the shader is designed to operate on a 2-D set of data, and the Y component may be 1 if the shader is designed to work on a one-dimensional array.  The way this is specified merely determines how the coordinates are provided to the shader; in the end, what counts is the total number of invocations in the work group, which is equal to the product of these three numbers.

So, if you have an image processing shader that operates on a 512x512 image, you may set the local work group size in your shader to 16x16x1, whereas in your application, you would specify a work group count of 32x32x1 since there are 32 of these tiles in each of the X and Y directions.

== Example shader ==

A typical compute shader (GLSL) looks as follows.  All that the shader does is copy the contents of one texture to another, except that it swaps two channels.
&lt;syntaxhighlight lang=&quot;glsl&quot;&gt;
#version 430

// Set the number of invocations in the work group.
// In this case, we operate on the image in 16x16 pixel tiles.
layout (local_size_x = 16, local_size_y = 16) in;

// Declare the texture inputs
uniform readonly image2D fromTex;
uniform writeonly image2D toTex;

void main() {
  // Acquire the coordinates to the texel we are to process.
  ivec2 texelCoords = ivec2(gl_GlobalInvocationID.xy);

  // Read the pixel from the first texture.
  vec4 pixel = imageLoad(fromTex, texelCoords);

  // Swap the red and green channels.
  pixel.rg = pixel.gr;

  // Now write the modified pixel to the second texture.
  imageStore(toTex, texelCoords, pixel);
}
&lt;/syntaxhighlight&gt;

This page does not attempt to teach how to make GLSL compute shaders - please refer to the GLSL documentation for that information.

== Loading a compute shader ==

A compute shader is typically never combined with other types of shaders, and therefore, loading a compute shader happens via a special call.  At present, only GLSL compute shaders may be loaded.

[python]
&lt;syntaxhighlight lang=&quot;python&quot;&gt;
shader = Shader.load_compute(Shader.SL_GLSL, &quot;compute_shader.glsl&quot;)
&lt;/syntaxhighlight&gt;
[/python][cxx]
&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
PT(Shader) shader;
shader = Shader::load_compute(Shader::SL_GLSL, &quot;compute_shader.glsl&quot;);
&lt;/syntaxhighlight&gt;
[/cxx]

The call &lt;code&gt;make_compute&lt;/code&gt; can be used instead to load the shader from a string instead of a filename.

== Dispatching a compute shader ==

Since a compute shader is not applied to a model but may be invoked arbitrarily, there has to be a different interface for dispatching a compute shader.  Usually, you would do this by creating a &lt;code&gt;ComputeNode&lt;/code&gt; object, which is inserted into the scene graph.  When Panda3D encounters one of these nodes during the draw process, it will ask OpenGL to dispatch the compute shader assigned to that node for the given amount of work groups.

[python]
&lt;syntaxhighlight lang=&quot;python&quot;&gt;
# Create the node
node = ComputeNode(&quot;compute&quot;)

# We want to call it on a 512x512 image, keeping in
# mind that the shader has a work group size of 16x16.
node.add_dispatch(512 / 16, 512 / 16, 1)

# Put the node into the scene graph.
node_path = render.attach_new_node(node)

# Assign the shader and the shader inputs.
shader = Shader.load_compute(Shader.SL_GLSL, &quot;compute_shader.glsl&quot;)
node_path.set_shader(shader)
node_path.set_shader_input(&quot;fromTex&quot;, myTex1)
node_path.set_shader_input(&quot;toTex&quot;, myTex2)
&lt;/syntaxhighlight&gt;
[/python][cxx]
&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
PT(ComputeNode) node = new ComputeNode(&quot;compute&quot;);

// We want to call it on a 512x512 image, keeping in
// mind that the shader has a work group size of 16x16.
node-&gt;add_dispatch(512 / 16, 512 / 16, 1);

// Put the node into the scene graph.
NodePath node_path = render.attach_new_node(node);

// Assign the shader and the shader inputs.
PT(Shader) shader = Shader::load_compute(Shader::SL_GLSL, &quot;compute_shader.glsl&quot;);
node_path.set_shader(shader);
node_path.set_shader_input(&quot;fromTex&quot;, myTex1);
node_path.set_shader_input(&quot;toTex&quot;, myTex2);
&lt;/syntaxhighlight&gt;
[/cxx]

The ordering of nodes becomes especially important; you may not want a procedural texture to be rendered on another node before it is first generated using a compute shader, for example.  You may have to use cull bins or display regions in order to explicitly control when the &lt;code&gt;ComputeNode&lt;/code&gt; is encountered during the draw process.

Keep in mind that a ComputeNode is never culled away by default, since it is not associated with any geometry.  You may override this behaviour by assigning a custom BoundingVolume.

However, whereas the ComputeNode interface is useful for operations that are done every frame, it is not very useful for one-off calls, since it is cumbersome to add a node to the scene graph only to remove it again in the next frame.  For these use cases, there is a more lower-level operation to dispatch a compute shader:
[python]
&lt;syntaxhighlight lang=&quot;python&quot;&gt;
# Create a dummy node and apply the shader to it
shader = Shader.load_compute(Shader.SL_GLSL, &quot;compute_shader.glsl&quot;)
dummy = NodePath(&quot;dummy&quot;)
dummy.set_shader(shader)
dummy.set_shader_input(&quot;fromTex&quot;, myTex1)
dummy.set_shader_input(&quot;toTex&quot;, myTex2)

# Retrieve the underlying ShaderAttrib
sattr = dummy.get_attrib(ShaderAttrib)

# Dispatch the compute shader, right now!
base.graphicsEngine.dispatch_compute((32, 32, 1), sattr, base.win.get_gsg())
&lt;/syntaxhighlight&gt;
[/python][cxx]
&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
// Create a dummy node and apply the shader to it
PT(Shader) shader = Shader::load_compute(Shader::SL_GLSL, &quot;compute_shader.glsl&quot;);
NodePath dummy(&quot;dummy&quot;);
dummy.set_shader(shader);
dummy.set_shader_input(&quot;fromTex&quot;, myTex1);
dummy.set_shader_input(&quot;toTex&quot;, myTex2);

// Retrieve the underlying ShaderAttrib
CPT(ShaderAttrib) sattr = DCAST(ShaderAttrib,
  dummy.get_attrib(ShaderAttrib::get_class_type()));

// Our image has 32x32 tiles
LVecBase3i work_groups(512/16, 512/16, 1);

// Dispatch the compute shader, right now!
GraphicsEngine *engine = GraphicsEngine::get_global_ptr();
engine-&gt;dispatch_compute(work_groups, sattr, win-&gt;get_gsg());
&lt;/syntaxhighlight&gt;
[/cxx]

Keep in mind that each call to &lt;code&gt;dispatch_compute&lt;/code&gt; causes Panda3D to wait for the current frame to finish rendering.  This can be a very inefficient process, and you are not advised to use this method for operations that happen on a regular basis.

== Image access ==

Though it is still possible to use regular texture samplers, these aren't very well suited for many types of image processing.  Regular samplers take texture coordinates in a [0, 1] range, the extra filtering processes add an unnecessary overhead, and it is not possible to write back to textures using this interface.

However, there is a lower level method to read from and write to texture images.  As you have already seen in the example above, this can be done by using an &lt;code&gt;image2D&lt;/code&gt; declaration instead of &lt;code&gt;sampler2D&lt;/code&gt;, and instead of using the &lt;code&gt;texture&lt;/code&gt; family of functions to sample them, you would use &lt;code&gt;imageLoad&lt;/code&gt; and &lt;code&gt;imageStore&lt;/code&gt;, which now take integer texel coordinates.

On the application side, however, telling the shader which image to use still happens in the same way as usual, using the &lt;code&gt;set_shader_input&lt;/code&gt; function.  However, it is very important that the texture has a ''sized'' format, rather than a regular format:
[python]
&lt;syntaxhighlight lang=&quot;python&quot;&gt;
# WRONG
tex.set_format(Texture.F_rgba)

# RIGHT
tex.set_format(Texture.F_rgba8)

node_path.set_shader_input('fromTex', tex)
&lt;/syntaxhighlight&gt;
[/python][cxx]
&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
// WRONG
tex-&gt;set_format(Texture::F_rgba);

// RIGHT
tex-&gt;set_format(Texture::F_rgba8);

node_path.set_shader_input(&quot;fromTex&quot;, tex);
&lt;/syntaxhighlight&gt;
[/cxx]

At time of writing, it is only possible to access the first mipmap level.  It is not possible to automatically generate the other mipmap levels at the time of writing, so it is advised to turn mimpap filtering off for the relevant textures.  This is a feature we still mean to add.

Accessing depth textures is impossible via this interface.  It is not possible to write to them, and reading from them has to be done using a &lt;code&gt;sampler2D&lt;/code&gt; or &lt;code&gt;sampler2DShadow&lt;/code&gt; object.  You can use the &lt;code&gt;texelFetch&lt;/code&gt; function with samplers so that you can still use integer texel coordinates.

[http://www.opengl.org/wiki/Image_Load_Store#Atomic_operations Atomic image access] is only supported for textures with the integer &lt;code&gt;F_r32i&lt;/code&gt; format.  Atomic image operations are slower, but they come with an extra guarantee that no two invocations write or read from the image texel at the same time.

It should be noted that this low-level image interface is also supported for other types of shaders when write access to images is desired.

== Texture Clear ==

When using a compute shader to operate on a texture image, such as in procedural texture generation, you may require the texture data to be cleared to an initial value before it is used.  This is now possible using the &lt;code&gt;set_clear_color&lt;/code&gt; function, which specifies the color that Panda3D will clear the texture to.  This color is used in absence of actual image data.

[python]
&lt;syntaxhighlight lang=&quot;python&quot;&gt;
# Set up a texture for procedural generation.
tex = Texture(&quot;procedural-normal-map&quot;)
tex.setup_2d_texture(512, 512, Texture.T_unsigned_byte, Texture.F_rgb8)

# Set the initial color of the texture.
tex.set_clear_color((0.5, 0.5, 1.0, 0.0))
&lt;/syntaxhighlight&gt;
[/python][cxx]
&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
// Set up a texture for procedural generation.
PT(Texture) tex = new Texture(&quot;procedural-normal-map&quot;);
tex-&gt;setup_2d_texture(512, 512, Texture::T_unsigned_byte, Texture::F_rgb8);

// Set the initial color of the texture.
LColor clear_color(0.5f, 0.5f, 1.0f, 0.0f);
tex-&gt;set_clear_color(clear_color);
&lt;/syntaxhighlight&gt;
[/cxx]

The initial clear is implicit, but clearing a texture in a later frame requires explicit use of the &lt;code&gt;clear_image()&lt;/code&gt; function, which instructs Panda3D to clear the texture the next time it is used.  It also clears any RAM images that may have been associated with the texture (similar to &lt;code&gt;clear_ram_image()&lt;/code&gt;).

[python]
&lt;syntaxhighlight lang=&quot;python&quot;&gt;
# Tell Panda to fill the texture with a red color on the GPU.
tex.set_clear_color((1.0, 0.0, 0.0, 0.0))
tex.clear_image()
&lt;/syntaxhighlight&gt;
[/python][cxx]
&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
// Tell Panda to fill the texture with a red color on the GPU.
LColor clear_color(1.0f, 0.0f, 0.0f, 0.0f);
tex-&gt;set_clear_color(clear_color);
tex-&gt;clear_image();
&lt;/syntaxhighlight&gt;
[/cxx]

When doing this, it is recommended that you enable the use of immutable texture storage, which is an experimental feature that allows Panda3D to allocate the texture memory beforehand and perform more efficient initial clears.  It can be activated using the following configuration variable:

&lt;syntaxhighlight&gt;
gl-immutable-texture-storage true
&lt;/syntaxhighlight&gt;

== Memory barriers ==

Whenever you write to an image using an &lt;code&gt;image2D&lt;/code&gt; uniform, Panda3D assumes that the image has been modified by the shader.  Panda3D will automatically issue a memory barrier when the texture is used in a following operation, such as when the texture is used for rendering or bound to a different shader, to make sure that the reads and writes are synchronized.

Since Panda3D does not know whether you have actually written to the image or whether you have declared an image variable as &lt;code&gt;coherent&lt;/code&gt;, it may do this too often, causing slight performance degradation.  If you are confident that you don't need this feature, you may set &lt;code&gt;gl-enable-memory-barriers&lt;/code&gt; variable to &lt;code&gt;false&lt;/code&gt; in your Config.prc to disable this behavior.

Keep in mind that Panda3D's memory barriers only play a role when an image is modified by one shader and read by another; it does not affect reads and writes performed within the same shader.  It is still necessary to use the appropriate GLSL qualifiers and memory barrier commands for these purposes.</text>
    </revision>
  </page>
  <page>
    <title>Config.prc</title>
    <ns>0</ns>
    <id>2254</id>
    <redirect title="Configuring Panda" />
      <sha1>bjx9xgz4505fbrv3c4tyxdyfnetiarr</sha1>
    <revision>
      <id>5371</id>
      <timestamp>2008-05-05T10:41:42Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[Configuring Panda]]</comment>
      <text xml:space="preserve" bytes="31">#REDIRECT [[Configuring Panda]]</text>
    </revision>
  </page>
  <page>
    <title>Configuring Panda</title>
    <ns>0</ns>
    <id>2459</id>
    <redirect title="Configuring Panda3D" />
      <sha1>loi442jdu7ly20ah0kk2h0iaa9zfddv</sha1>
    <revision>
      <id>6610</id>
      <timestamp>2010-02-07T04:39:05Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>[[Configuring Panda]] moved to [[Configuring Panda3D]]: Panda3D is the name of the engine; not Panda.</comment>
      <text xml:space="preserve" bytes="33">#REDIRECT [[Configuring Panda3D]]</text>
    </revision>
  </page>
  <page>
    <title>Configuring Panda3D</title>
    <ns>0</ns>
    <id>931</id>
      <sha1>df6d86o6ei7kgb8k8lbgcdpbyza5wgd</sha1>
    <revision>
      <id>6903</id>
      <timestamp>2010-07-31T11:29:43Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <text xml:space="preserve" bytes="2721">In the &lt;i&gt;etc&lt;/i&gt; subdirectory, you will find a configuration file
&lt;i&gt;Config.prc&lt;/i&gt;.  This controls several of Panda's configuration options
- does it use OpenGL or DirectX, how much debugging output does it
print, and so forth.  The following table lists several of the most
commonly-used variables.

For a full documentation about Panda3D's configuration system, click [http://panda3d.cvs.sourceforge.net/*checkout*/panda3d/panda/src/doc/howto.use_config.txt here] to view the original documentation file.

To know about accessing config variables from within your code, please see [[Accessing Config Vars in a Program]].

To get a more complete list of variables, see the [[list of all config variables]].


{| border=&quot;1&quot; cellpadding=&quot;5&quot; cellspacing=&quot;0&quot;
! Variable
! Values
! Default
! Details
|-
| load-display
| pandagl&lt;br /&gt;pandadx9&lt;br /&gt;pandadx8&lt;br /&gt;tinydisplay
| pandagl
| Specifies which graphics GSG to use for rendering (OpenGL, Direct3D 8/9 or TinyPanda software rendering)
|-
| aux-display
| pandagl&lt;br /&gt;pandadx9&lt;br /&gt;pandadx8&lt;br /&gt;tinydisplay
| pandagl
| Specifies which graphics GSG to use if the GSG specified in load-display fails; May be specified multiple times to create multiple fallbacks.
|-
| win-size
| Number of pixels
| 640 480
| Specifies the size of the Panda3D window
|-
| win-origin
| Pixel offsets
| 50 50
| Specifies the offset of the Panda3D window
|-
| window-title
| Window title
| Panda
| Specifies the title of the Panda3D window
|-
| fullscreen
| #t&lt;br /&gt;#f
| #f
| Enables full-screen mode (true or false)
|-
| undecorated
| #t&lt;br /&gt;#f
| #f
| Removes border from window (true or false)
|-
| cursor-hidden
| #t&lt;br /&gt;#f
| #f
| Hides mouse cursor (true or false)
|-
| sync-video
| #t&lt;br /&gt;#f
| #t
| Limits the frame rate to monitor's capabilities
|-
| show-frame-rate-meter
| #t&lt;br /&gt;#f
| #f
| Shows the frame rate (in frames per second) at the upper right corner of the screen (true or false)
|-
| notify-level-[package]
| fatal&lt;br /&gt;error&lt;br /&gt;warning&lt;br /&gt;info&lt;br /&gt;debug&lt;br /&gt;spam
| info
| Sets notification levels for various Panda3D packages to control the amount of information printed during execution (fatal being least, spam being most)
|-
| model-path
| Path string
| see config file
| Adds specified path to the list of paths searched when loading a model
|-
| audio-library-name
| p3openal_audio&lt;br /&gt;p3fmod_audio&lt;br /&gt;p3miles_audio&lt;br /&gt;null
| p3openal_audio
| Loads the appropriate audio library
|-
| want-directtools
| #t&lt;br /&gt;#f
| #t&lt;br /&gt;line commented out
| Enables directtools, a suite of interactive object/camera manipulation tools
|-
| want-tk
| #t&lt;br /&gt;#f
| #t&lt;br /&gt;line commented out
| Enables support for using Tkinter/PMW (Python’s wrappers around Tk)
|}</text>
    </revision>
  </page>
  <page>
    <title>Controlling Panda Debugging Messages</title>
    <ns>0</ns>
    <id>1743</id>
    <redirect title="Log Messages" />
      <sha1>be0weu3yzb7ydljdr8zvz76pigqqje1</sha1>
    <revision>
      <id>3332</id>
      <timestamp>2006-04-28T16:38:12Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <comment>Controlling Panda Debugging Messages moved to Log Messages</comment>
      <text xml:space="preserve" bytes="26">#redirect [[Log Messages]]</text>
    </revision>
  </page>
  <page>
    <title>Controlling a Joint Procedurally</title>
    <ns>0</ns>
    <id>1061</id>
      <sha1>c156e8km7mzrjf5ezzx4exa6a3ls7j6</sha1>
    <revision>
      <id>7625</id>
      <timestamp>2012-03-08T17:34:14Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="2418">Sometimes one wishes to procedurally take control of a model's joint.  For example, if you wish to force a character model's eyes to follow the mouse, you will need to procedurally take control of the neck and head.  To achieve this, use &lt;i&gt;controlJoint&lt;/i&gt;.

&lt;code python&gt;
myNodePath = actor.controlJoint(None,&quot;modelRoot&quot;,&quot;Joint Name&quot;)
&lt;/code&gt;

This creates a dummy node.  Every frame, the transform is copied from the dummy node into the joint.  By setting the transform of the dummy node, you can control the joint.  Normally, one would want to use &lt;code&gt;setHpr&lt;/code&gt; to rotate the joint without moving it.  The dummy node is initialized in such a way that the joint is in its default location, the one specified in the model's egg file.

You must store a local (not global) transform in the dummy node.  In other words, the transform is relative to the joint's parent bone.  If you are controlling the forearm of a model, for instance, the transform will be relative to the upperarm.

The string &quot;modelRoot&quot; represents the name of the model node - the string &quot;modelRoot&quot; is usually the correct value.

The string &quot;Joint Name&quot; represents the name of the joint. Typically it would be something like &quot;Femur&quot;, or &quot;Neck&quot;, or &quot;L Finger1&quot;. This is usually set inside the modeling package. For example, in MAX, each object in the scene has a name, including the bones. If necessary, you can determine the joint names by scanning the egg file for strings like &lt;code&gt;&amp;lt;Joint&amp;gt; Femur&lt;/code&gt;.  You can also use the call &lt;code&gt;actor.listJoints()&lt;/code&gt; to show the complete hierarchy of joints.

&lt;h2&gt;Cautions and limitations&lt;/h2&gt;

Prior to Panda3D version 1.5, there were several important limitations to controlJoint().  These have been lifted as of Panda3D version 1.5.

&lt;ul&gt;
&lt;li&gt;In previous versions of Panda, controlJoint only worked when an animation is playing on the joint.  This is no longer true; controlJoint now takes effect whether an animation is playing or not.&lt;/li&gt;

&lt;li&gt;It used to be important to make all of your controlJoint() calls for a particular model before you made the first call to play(), loop(), or pose().  This is no longer necessary; you may call controlJoint() at any time.&lt;/li&gt;

&lt;li&gt;In previous versions of Panda, controlJoint could not be undone.  Beginning in Panda3D version 1.5, you may call releaseJoint(&quot;modelRoot&quot;, &quot;Joint Name&quot;) to undo a previous call to controlJoint().&lt;/li&gt;
&lt;/ul&gt;</text>
    </revision>
  </page>
  <page>
    <title>Controlling the Camera</title>
    <ns>0</ns>
    <id>937</id>
      <sha1>1u6gas67tp1ue0s5rjxbeo0j4smhyxg</sha1>
    <revision>
      <id>60219</id>
      <timestamp>2014-07-24T19:49:10Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="6322">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

== Default Camera Control System ==
&lt;p&gt;By default, Panda3D runs a task that allows you to move the camera using the mouse.[cxx] To enable it, use the following command: &lt;code cxx&gt;window-&gt;setup_trackball();&lt;/code&gt;[/cxx]&lt;/p&gt;

&lt;p&gt;The keys to navigate are:&lt;/p&gt;

{| class=&quot;wikitable sortable&quot; border=&quot;1&quot; cellpadding=&quot;5&quot; cellspacing=&quot;0&quot;
!width=&quot;150px&quot;|Key
!width=&quot;300px&quot;|Action
|-
| Left Button
| Pan left and right.
|-
| Right Button
| Move forwards and backwards.
|-
| Middle Button
| Rotate around the origin of the application.
|-
| Right and Middle Buttons
| Roll the point of view around the view axis.
|}

&lt;p&gt;Go ahead and try this camera control system. The problem with it is that it is sometimes awkward. It is not always easy to get the camera pointed in the direction we want.&lt;/p&gt;

== [[Tasks]] ==
=== Update the Code ===
&lt;p&gt;Instead, we are going to write a &lt;i&gt;task&lt;/i&gt; that controls the camera's position explicitly. A &lt;i&gt;task&lt;/i&gt; is nothing but a procedure that gets called every frame.  Update your code as follows:&lt;/p&gt;

[python]&lt;code python&gt;
from math import pi, sin, cos

from direct.showbase.ShowBase import ShowBase
from direct.task import Task

class MyApp(ShowBase):
    def __init__(self):
        ShowBase.__init__(self)

        # Load the environment model.
        self.environ = self.loader.loadModel(&quot;models/environment&quot;)
        # Reparent the model to render.
        self.environ.reparentTo(self.render)
        # Apply scale and position transforms on the model.
        self.environ.setScale(0.25, 0.25, 0.25)
        self.environ.setPos(-8, 42, 0)

        # Add the spinCameraTask procedure to the task manager.
        self.taskMgr.add(self.spinCameraTask, &quot;SpinCameraTask&quot;)

    # Define a procedure to move the camera.
    def spinCameraTask(self, task):
        angleDegrees = task.time * 6.0
        angleRadians = angleDegrees * (pi / 180.0)
        self.camera.setPos(20 * sin(angleRadians), -20.0 * cos(angleRadians), 3)
        self.camera.setHpr(angleDegrees, 0, 0)
        return Task.cont

app = MyApp()
app.run()
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;#include &quot;pandaFramework.h&quot;
#include &quot;pandaSystem.h&quot;

#include &quot;genericAsyncTask.h&quot;
#include &quot;asyncTaskManager.h&quot;

// The global task manager
PT(AsyncTaskManager) taskMgr = AsyncTaskManager::get_global_ptr(); 
// The global clock
PT(ClockObject) globalClock = ClockObject::get_global_clock();
// Here's what we'll store the camera in.
NodePath camera;

// This is our task - a global or static function that has to return DoneStatus.
// The task object is passed as argument, plus a void* pointer, containing custom data.
// For more advanced usage, we can subclass AsyncTask and override the do_task method.
AsyncTask::DoneStatus spinCameraTask(GenericAsyncTask* task, void* data) {
  // Calculate the new position and orientation (inefficient - change me!)
  double time = globalClock-&gt;get_real_time();
  double angledegrees = time * 6.0;
  double angleradians = angledegrees * (3.14 / 180.0);
  camera.set_pos(20*sin(angleradians),-20.0*cos(angleradians),3);
  camera.set_hpr(angledegrees, 0, 0);

  // Tell the task manager to continue this task the next frame.
  return AsyncTask::DS_cont;
}

int main(int argc, char *argv[]) {
    // Load the window and set its title.
    PandaFramework framework;
    framework.open_framework(argc, argv);
    framework.set_window_title(&quot;My Panda3D Window&quot;);
    WindowFramework *window = framework.open_window();
    // Get the camera and store it in a variable.
    camera = window-&gt;get_camera_group();

    // Load the environment model.
    NodePath environ = window-&gt;load_model(framework.get_models(), &quot;models/environment&quot;);
    // Reparent the model to render.
    environ.reparent_to(window-&gt;get_render());
    // Apply scale and position transforms to the model.
    environ.set_scale(0.25, 0.25, 0.25);
    environ.set_pos(-8, 42, 0);

    // Add our task.
    // If we specify custom data instead of NULL, it will be passed as the second argument
    // to the task function.
    taskMgr-&gt;add(new GenericAsyncTask(&quot;Spins the camera&quot;, &amp;spinCameraTask, (void*) NULL));
  
    // Run the engine.
    framework.main_loop();
    // Shut down the engine when done.
    framework.close_framework();
    return (0);
}&lt;/code&gt;[/cxx]

&lt;p&gt;The procedure &lt;code&gt;taskMgr[-&gt;]add()&lt;/code&gt; tells Panda3D's &lt;i&gt;task manager&lt;/i&gt; to call the procedure &lt;code&gt;spinCameraTask()&lt;/code&gt; every frame. This is a procedure that we have written to control the camera. As long as the procedure &lt;code&gt;spinCameraTask()&lt;/code&gt; returns the constant &lt;code&gt;[cxx]Async[/cxx]Task[::][cxx]DS_[/cxx]cont&lt;/code&gt;, the task manager will continue to call it every frame.&lt;/p&gt;

[cxx]&lt;p&gt;The object passed to &lt;code&gt;taskMgr-&gt;add&lt;/code&gt; is an &lt;code&gt;AsyncTask&lt;/code&gt; object. We can use &lt;code&gt;GenericAsyncTask&lt;/code&gt; to wrap a global function or static method around a task. We can also pass an additional &lt;code&gt;void*&lt;/code&gt; parameter that we can cast into a pointer of any data type we like, which is passed as argument to the task function. A GenericAsyncTask function must look like the following:&lt;/p&gt;

&lt;code cxx&gt;AsyncTask::DoneStatus your_task(GenericAsyncTask* task, void* data) {
  // Do your stuff here.

  // Tell the task manager to continue this task the next frame.
  // You can also pass DS_done if this task should not be run again.
  return AsyncTask::DS_cont;
}&lt;/code&gt;

&lt;p&gt;For more advanced usage, you can subclass AsyncTask and override the &lt;code&gt;do_task&lt;/code&gt; method to make it do what you want.&lt;/p&gt;[/cxx]

&lt;p&gt;In our code, the procedure &lt;code&gt;spinCameraTask()&lt;/code&gt; calculates the desired position of the camera based on how much time has elapsed. The camera rotates 6
degrees every second. The first two lines compute the desired orientation of the camera; first in degrees, and then in radians. The &lt;code&gt;[func]setPos[/func]()&lt;/code&gt; call actually sets the position of the camera. (Remember that Y is horizontal and Z is vertical, so the position is changed by animating X and Y while Z is left fixed at 3 units above ground level.) The &lt;code&gt;[func]setHpr[/func]()&lt;/code&gt; call actually sets the orientation.&lt;/p&gt;

=== Run the Program ===
&lt;p&gt;The camera should no longer be underground; and furthermore, it should now be rotating about the clearing:&lt;/p&gt;

[[Image:Tutorial2.jpg]]</text>
    </revision>
  </page>
  <page>
    <title>Controlling the Camera (CXX)</title>
    <ns>0</ns>
    <id>2089</id>
      <sha1>diery7vmdc2uc12exij67jfqcowz83n</sha1>
    <revision>
      <id>4985</id>
      <timestamp>2008-03-14T21:45:57Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="3463">Panda3D comes with a function that enables you to move
the camera using the mouse. To use this, insert:

&lt;pre class=&quot;codeblock&quot;&gt;
window-&gt;setup_trackball();
&lt;/pre&gt;

just before your call to the main loop.
The keys to navigate using this function are:

&lt;ul&gt;
&lt;li&gt;Left Button: pan left and right
&lt;li&gt;Right Button: move forwards and backwards
&lt;li&gt;Middle Button: rotate around the origin of the application
&lt;li&gt;Right and Middle Buttons: roll the point of view around the view axis
&lt;/ul&gt;

Go ahead and try this camera control system.  The
problem with this camera control system is that it is sometimes
awkward, it is not always easy to get the camera pointed in the
direction we want.

Instead, we want to have our camera position changed every frame. Because there is no basic implementation for [[tasks]] in C++ (yet), we have to write the main loop by ourselves. We can do this by making an infinite loop, in which the camera position gets updated and the function &lt;code&gt;framework.do_frame&lt;/code&gt; gets called. All this function does is rendering the current frame. It returns false if the window is terminated, and the main loop should stop.
Update your code as follows:

&lt;pre class=&quot;codeblock&quot;&gt;
#include &quot;pandaFramework.h&quot;
#include &quot;pandaSystem.h&quot;

PandaFramework framework;

int main(int argc, char *argv[]) {
    //open a new window framework
  framework.open_framework(argc, argv);
    //set the window title to My Panda3D Window
  framework.set_window_title(&quot;My Panda3D Window&quot;);
    //open the window
  WindowFramework *window = framework.open_window();
  NodePath cam = window-&gt;get_camera_group(); //get the camera and store it
    //load the environment model
  NodePath environ = window-&gt;load_model(framework.get_models(),&quot;models/environment&quot;);
  environ.reparent_to(window-&gt;get_render());
  environ.set_scale(0.25,0.25,0.25);
  environ.set_pos(-8,42,0);
    //do the main loop:
  ClockObject* clock; //create a clock object for time measurement
  clock=ClockObject::get_global_clock();
  Thread *current_thread = Thread::get_current_thread();
  while(framework.do_frame(current_thread)) {
    double time = clock-&gt;get_real_time(); //get the time in seconds
    double angledegrees = time * 6.0; //the angle of the camera in degrees
    double angleradians = angledegrees * (3.14 / 180.0); //in radians
    cam.set_pos(20*sin(angleradians),-20.0*cos(angleradians),3); //set the position
    cam.set_hpr(angledegrees, 0, 0); //set the hpr
  }
  //close the window framework
  framework.close_framework();
  return (0);
}

&lt;/pre&gt;

&lt;b&gt;Note:&lt;/b&gt; It is not possible to update the camera's position while the trackball is enabled. To have this code work, you must &lt;b&gt;not&lt;/b&gt; call the &lt;code&gt;setup_trackball()&lt;/code&gt; function.

The code in our home-made main loop calculates the desired position of
the camera based on how much time has elapsed. To get this time, we use Panda3D's global ClockObject. (It is sometimes convenient
to put these calculations in a separate function, but since we only have one
task now, it's not much of a problem.) The camera rotates 6
degrees every second.  The first two lines compute the desired
orientation of the camera, first in degrees, then in radians.  The &lt;code&gt;set_pos&lt;/code&gt; call actually sets the position of the camera.
The &lt;code&gt;set_hpr&lt;/code&gt; call actually sets the orientation.

The camera should no longer be underground, and
furthermore, the camera should now be rotating about the clearing:

[[Image:Tutorial2.jpg]]</text>
    </revision>
  </page>
  <page>
    <title>Converting Egg to Bam</title>
    <ns>0</ns>
    <id>964</id>
      <sha1>2y1m61s5j9rtweunjz4gsuwq0e4je24</sha1>
    <revision>
      <id>7717</id>
      <timestamp>2012-03-09T10:53:27Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="2159">Panda's native egg file format is human-readable.  This is convenient, but the files can get very large, and they can a little bit slow to load.  To accelerate loading, Panda supports a second native format, bam.  These files are smaller and are loaded very rapidly, but they cannot be viewed or edited in a text editor.  Also, bam files are specific to the version of Panda they are created with, so they are not a good choice for long-term storage of your models.

Texture pathnames in an egg file are first assumed to be relative to the egg file itself. If the texture is not found at that location, panda will search its model-path, which is specified in the panda config file.  When doing this, panda concatenates the directory which is part of the model-path to the entire string in the egg-file.  So if the model-path names the directory &quot;/d/stuff&quot;, and the texture-path in the egg file is &quot;mytextures/tex.png&quot;, then panda looks in &quot;/d/stuff/mytextures/tex.png.&quot;

Texture pathnames in a bam file may be stored relative to the bam file itself, relative to a directory on the model-path, or with a full pathname to the file, depending on the parameters given to the egg2bam program.

The program egg2bam is used to convert egg files to bam files.  Egg2bam will complain if the textures aren't present.  You must install the textures (into your model path) before you convert the bam file.  You can run the egg2bam program as follows:

&lt;pre class &quot;codeblock&quot;&gt;
egg2bam -ps rel -o bamFileName.bam eggFileName.egg
&lt;/pre&gt;

Here, &quot;-ps rel&quot; means to record the textures in the bam filename relative to the filename itself; if you use this option, you should ensure that you do not move the bam file later without also moving the textures.  (The default option is to assume the textures have already been installed along the model path, and record them relative to the model path.  If you use the default option, you should ensure the textures are already installed in their appropriate place, and the model-path is defined, before you run egg2bam.)

The egg2bam program accepts a number of other parameters that may be seen by running &lt;code&gt;egg2bam –h&lt;/code&gt;.</text>
    </revision>
  </page>
  <page>
    <title>Converting from 3D Studio Max</title>
    <ns>0</ns>
    <id>965</id>
      <sha1>ircfbhn1uo71vb9fuoku6xo3296mu0q</sha1>
    <revision>
      <id>6843</id>
      <timestamp>2010-04-29T18:25:57Z</timestamp>
      <contributor>
        <username>Sorcus</username>
        <id>239</id>
      </contributor>
      <text xml:space="preserve" bytes="7334">__TOC__


&lt;B&gt;NOTE: &lt;/B&gt; In Panda3D version 1.5.3, the max exporter was overhauled.  Versions prior to that were unstable.


The Max exporter understands only bone-based animation.  In other words, all animation must be done by moving bones around.  If you move anything else, the Max exporter may not notice!  Character studio bipeds work too --- they are indeed collections of bones.

Meshes must be connected to the bones using either the &lt;code&gt;skin&lt;/code&gt; or &lt;code&gt;physique&lt;/code&gt; modifiers.  Any other way of attaching the mesh to the bones will not work.  In particular, simply linking the mesh to the bone using the link tool will not work correctly.  Do not use the link tool to connect your meshes to your bones.  Use the physique or skin modifiers.

If all you want to do is drag a mesh around, then use the following method.  Create a single bone - it will look like a small diamond.  Put it in the middle of the mesh.  Skin the mesh, and connect it to the one bone.  Now you can drag the one bone around and the mesh will follow.

In Max, it is a little difficult to create a single bone, because the bone creation tool usually creates two.  After clicking to create a bone, look in the object list, and you'll see &quot;Bone01&quot;, &quot;Bone02&quot;, which proves that there are indeed two.  The easiest thing to do is to create the pair of bones, and then delete the second one by pressing the &quot;delete&quot; button.

&lt;h2&gt;Using the Exporter&lt;/h2&gt;

Before installing any plugins, you must install the visual studio runtime system.  To do so, execute &lt;i&gt;vcredist_x86-sp1.exe&lt;/i&gt; as administrator.  Then, to install the plugin, look in the panda3d &quot;plugins&quot; directory.  There, you will find the plugins, such as &lt;code&gt;maxegg5.dlo&lt;/code&gt;, &lt;code&gt;maxegg6.dlo&lt;/code&gt;, and &lt;code&gt;maxegg7.dlo&lt;/code&gt;.  These are for 3D Studio Max versions 5, 6, and 7 respectively.  Copy the correct file from the Panda3D plugins directory into the 3D Studio Max plugins directory, then, restart 3D Studio Max.

The exporter is somewhat unconventional in its design.  Max has a menu item &quot;File/Export&quot;.  Panda's egg format does &lt;i&gt;not&lt;/i&gt; show up in this menu.  Instead, Panda's exporter is a helper object.  This enables the exporter to save your export settings from one session to the next.

To export a scene, your first step is to create the necessary helper object. Go to the creation panel, select &quot;helper objects,&quot; choose &quot;exporters,&quot; and then click on the button to create a Panda3D export helper:

&lt;p align=&quot;center&quot;&gt;[[Image:maxexp1.jpg]]&lt;/p&gt;

Drop an egg exporter into the scene:

&lt;p align=&quot;center&quot;&gt;[[Image:maxexp2.jpg]]&lt;/p&gt;

Switch to the modify panel.  You will now be able to see the configuration settings that are stored in the export helper.

&lt;p align=&quot;center&quot;&gt;[[Image:maxexp3.jpg]]&lt;/p&gt;

The exporter can generate several egg files from a single scene.  The exporter therefore contains a list of egg files to generate.  To export this particular scene (the one with the blocky humanoid and the biped skeleton), we will create an egg containing the model and one containing the animation.  Click the &quot;add...&quot; button on the exporter's modify panel.  You will be prompted:

&lt;p align=&quot;center&quot;&gt;[[Image:maxexp4.jpg]]&lt;/p&gt;

I have filled in the file name, and I have selected the mesh I want to export. When I click &quot;OK,&quot; an egg file will be added to the list of eggs to generate. I then click the &quot;add...&quot; button again, and add another egg to the list:

&lt;p align=&quot;center&quot;&gt;[[Image:maxexp5.jpg]]&lt;/p&gt;

This time, I'm generating an animation egg.  I have listed the bones to export, and the range of animation frames.  Once I click OK, the modify panel for the egg exporter looks like this:

&lt;p align=&quot;center&quot;&gt;[[Image:maxexp6.jpg]]&lt;/p&gt;

When I click the &quot;export now&quot; button, the two egg files are generated, and I am asked whether or not I would like to pview them.

When you save your MAX file, the export helper will also be saved.  The next time you load it up, it will still remember which meshes go in which egg files.

&lt;h2&gt;Materials&lt;/h2&gt;
The different map types in the 3dsmax Standard material equal Panda ones followingly:
&lt;li /&gt;Diffuse Slot = Color
&lt;li /&gt;Bump Slot = Normal
&lt;li /&gt;Self-Illumination Slot = Glow
&lt;li /&gt;Specular Color Slot = Gloss
&lt;li /&gt;Opacity Slot = Modulate
&lt;br&gt;&lt;br&gt;

&lt;h2&gt;Max egger changes and additions(To be available in Panda3D 1.7.1 or later)&lt;/h2&gt;

There have been some minor but very noticeable changes to the way the Max egger handles collisions.  Although collision tagging was possible on a global level with the egger prior to now, it had some drawbacks, such as only one object would get tagged if the whole scene was exported.  To remedy this problem, the Panda SE team has implemented a method similar to the way Maya tags collision objects.  Every object in max has a User Defined properties box inside the per-object properties options. (to get it simply right click on any object and select Object Properties, User Defined is the far right tab).  


&lt;p align=&quot;center&quot;&gt;[[Image:OBJ_PROPS.JPG]]&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;[[Image:OBJECT_PROPERTIES.JPG]]&lt;/p&gt;
 
Every collision object in Panda has a Collision Solid Type and a Collision Flag.  To tag an object you have to type the &quot;&lt;solid type&gt; = 1&quot;. Where &lt;solid type&gt; is polyset, plane, etc.  Next you must specify a collision flag in the same manner (ex. descend = 1).  Be sure to note the all lowercase and spaces between the equals sign and the 1.  To remove any tag simply set the value of one to zero on both properties.  in order to speed up this process we've included a simple Maxscript utility called TagSelectedObjects.ms.  Simply run this either from the main program menu bar, or anywhere else in the program where you can run a Maxscript.  It will allow you to select any number of objects and tag them or remove any tags on the objects.   

&lt;p align=&quot;center&quot;&gt;[[Image:MAX_SCRIPT.JPG]]&lt;/p&gt;

Also included in this update is the ability to use Point Objects as locators (similar to Maya's locators).  Prior to now, an artist had to egg out a max scene using the model option and using joints as locators.  Now with the addition of point objects, an artist can use the static option and place locators for wherever a position needs to be stored.  NOTE: point objects do not get included in animated models, only in static ones.


&lt;h2&gt;Known Issues&lt;/h2&gt;
Currently, you have to use the option 'Export Entire Scene' when having animated models, otherwise the character hierarchy might not be exported correctly.

Also, in version 1.5.3, the 'both' option was broken. Instead, you had to export animations separately with the 'model' and 'anim' options. However, this has been fixed in 1.5.4.

Versions prior to 1.5.3 were unstable and it's not recommended to use them.

User interpretation regarding &quot;Pose&quot; versus the other export types (&quot;Model&quot;, &quot;Animation&quot;, &quot;Both&quot;) was not always correct.  Newer versions of the exporter will have &quot;Static&quot; rather than &quot;Pose&quot; in the interface, as the &quot;Static&quot; (formerly listed as &quot;Pose&quot;) type should be chosen for exporting an environment or static geometry, with the &quot;Model&quot; type chosen for exporting an animatable model with joints and vertex membership.  Using &quot;Static&quot; will generate an egg file without a &quot;Dart&quot; tag.  The &quot;Model&quot; export will produce a &quot;Dart&quot; tag in the egg file.  See [[Parsing_and_Generating_Egg_Files]] for more details.</text>
    </revision>
  </page>
  <page>
    <title>Converting from Blender</title>
    <ns>0</ns>
    <id>1062</id>
      <sha1>bcp6n0qbqkyndnuzxrhmgi5gxn41sy6</sha1>
    <revision>
      <id>60477</id>
      <timestamp>2015-03-15T13:27:24Z</timestamp>
      <contributor>
        <username>Frainfreeze</username>
        <id>22860</id>
      </contributor>
      <comment>Grammar edit.</comment>
      <text xml:space="preserve" bytes="3694">Currently, there are two ways to get data from Blender into Panda3D. The most popular is almost certainly the YABEE exporter.


&lt;h2&gt;Option 1: The Egg export Plugins for Blender&lt;/h2&gt;
There are several Blender plugins contributed by Panda3D users.

YABEE is an exporter for Blender 2.5, 2.6, 2.7 and should work with most recent versions of blender (2.73a at moment of writing). It's documented and feature complete. YABEE can export:
    Meshes
    UV layers
    Materials and textures (Partially)
    Armature (skeleton) animation
    ShapeKeys (morph) animation
    &lt;Tag&gt; and Collision options export through Blender's &quot;Game logic&quot; -&gt; &quot;properties&quot;
    Non cyclic NURBS Curves

https://github.com/09th/YABEE

If you observe any problem, or find a bug, you can report it on official thread that can be found here: http://www.panda3d.org/forums/viewtopic.php?f=2&amp;t=11441

---- 

Chicken is the old and no longer updated, but documented and feature complete exporter for Blender 2.4. It supports static meshes and armature animation, materials, vertex colors, alpha textures, tags, object types, etc. It also has advanced features such as automatic invocation of Panda tools (egg2bam, egg-optchar and pview) and Motion Extraction.
You can find it at http://sourceforge.net/projects/chicken-export/

----

Another exporter for Blender 2.4 that only supports static meshes can be found at http://xoomer.virgilio.it/glabro1/panda.html


&lt;h2&gt;Option 2: The &quot;X&quot; File format&lt;/h2&gt;

There exists a free plugin for Blender that can export &quot;X&quot; (DirectX native) file format.  Save the file from blender as an X file, then load it directly into Panda3D, which can read X file format.  Alternately, if you're concerned about long load times (panda has to translate the file at load time), then pre-convert the model from X to Egg to Bam using the conversion programs supplied with Panda3D (x2egg, egg2bam).  

Whenever you save a model in a non-native file format, you need to ask yourself: &quot;does this file format support everything I need?&quot;  For example, when you save out a model in 3DS file format, you automatically lose all bone and animation data, because the 3DS file format doesn't contain bone and animation data.  In the case of the X file format, you're in good shape: it's a fairly powerful file format, supporting vertices and triangles, bones and animation.

Note however, when an animated X file is converted to egg, the resulting egg file only plays the keyframes, but not whats supposed to be in between. For example, an animation could exist that should spawn 200 frames, gets sized down to about 40, and playback looks shakey.  This shakeyness happens because the X file format supports the concept of keyframes, with implicit frames interpolated between them.  The egg file format is explicit. An egg file must give all of the frames of an animation, even the frames that appear between &quot;keyframes&quot;. 

Therefore, a run of  x2egg with an X file that omits a lot of frames between keyframes, will product a shapekey animation.  The only solution is to ensure your X files are generated with all frames.  Testing of different X file exporters may be required.

Further, panda's native egg file format supports some esoteric things.  For example, it supports blend targets (morph animations) and motion path curves, which are not supported by the X file format.

&lt;i&gt;Caution: it has recently been discovered that there are two bugs in panda's X-file parser.  One, it is case-sensitive and it should not be.  Two, it does not handle hyphens in identifiers correctly.  These two bugs will be fixed in an upcoming version of Panda3D.  For information on temporary workarounds, search the forums.&lt;/i&gt;</text>
    </revision>
  </page>
  <page>
    <title>Converting from GMax</title>
    <ns>0</ns>
    <id>1145</id>
      <sha1>4ia6qawvpbbeoikwkafh1spb1iu4kgv</sha1>
    <revision>
      <id>5723</id>
      <timestamp>2009-03-20T01:01:23Z</timestamp>
      <contributor>
        <username>Masonsbro</username>
        <id>222</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="2971">To convert models to Panda from GMax, you must first convert models to .X format, and then load them into Panda as .X files, or convert them further using x2egg and/or egg2bam.

There is a fair amount of work involved in setting up the GMax-to-X converter, but once it is set up the conversion process is reportedly very easy.

&lt;h2&gt;Installation&lt;/h2&gt;

There are several plug-ins required to export .X files from gmax:

1. First download the ‘Gmax gamepack SDK’ found at this link: [http://www.microsoft.com/games/flightsimulator/fs2004_downloads_sdk.asp#gmax FlightSimulator exporter plugin]. Size is about 15Mb. Although only 3 files are actually needed, they are not available as separate downloads, so unfortunately you’ll need to download the whole thing.

2. Next, download programs '[http://hometown.aol.de/_ht_a/docmoriarty3/fs2002/en/mdlcommander_dl.html MDLCommander]' and '[http://thegreatptmd.tripod.com/ Middleman]'.

3. After download, you’ll see that the 'fs2004_sdk-gmax-setup' is an exe. If you install it in the default gmax directory, you’ll end up with a lot of extra stuff that you don’t need. So create a new folder somewhere on your hard drive and install it there.

4. When done, open the folder, go to gamepacks &gt; fs2004 &gt; plugins. And copy all 3 files: 'FSModelExp.dle', 'makemdl.exe' and 'makemdl.parts.xml' to your main ../gmax/plugins folder.

5. You need to rename two of the files. Right click on 'makemdl.exe' and rename it to to 'mkmdl.exe'. Then right click on 'makemdl.parts.xml' and rename it to 'mkmdl.parts.xml' (without the quotes).

6. Next, unzip 'MDLCommander.zip'. Then copy 'mdlcommander.exe' to your main ../gmax/plugins folder. This file also needs to be renamed. Right click on 'mdlcommander.exe' and rename it to 'makem.exe'.

7. Finally, unzip 'Middleman13beta3.zip'. Then copy 'makemdl.exe' to your main ../gmax/plugins folder. That’s it, you’re done!

&lt;h2&gt;Using&lt;/h2&gt;

To convert your gmax model to .X format: Go to ‘File &gt; Export’ and select ‘Flightsim Aircraft Object (.MDL) from the file type dropdown. Type in a filename and click Save. The Middleman dialog window should now appear. Click the ‘Options’ tab and check ‘SaveXFile’ (this saves the x file) and ‘nocompile’ (this tells mdlcommander to only create an .X file not mdl/bgl). Then click the GO button.

After a few seconds the dialog will close and your newly exported .X model should be in the directory where you saved it to.

&lt;h2&gt;Bugs in the Process&lt;/h2&gt;

The GMax converter writes slightly nonstandard .X files; it writes the name &quot;TextureFileName&quot; instead of &quot;TextureFilename&quot; for each texture reference.  It may also generate hyphens in identifiers.  Both of these can confuse the X file parser in Panda3D version 1.0.4 and earlier (this will be fixed in a future release of Panda).  In the meantime, the temporary workaround is to edit the .X file by hand to rename these strings to the correct case and remove hyphens.</text>
    </revision>
  </page>
  <page>
    <title>Converting from Maya</title>
    <ns>0</ns>
    <id>966</id>
      <sha1>d00jdpi96j4x7fpfuz8eoqm9dt6luub</sha1>
    <revision>
      <id>60298</id>
      <timestamp>2014-11-29T00:21:25Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>git</comment>
      <text xml:space="preserve" bytes="23921">This section talks about how to prepare a Maya model for export, and then
export it.  Since exporting is the very last step, the actual instructions
for the export process are last.

__TOC__

==Material Preparation==

Note: the information in this section is for Panda3D 1.5.0 and beyond.  It does not apply to older versions of Panda3D.

===Basic Texturing===

In order for the Panda3D to correctly export your textures, you must texture
your model in a manner that Panda3D understands.  In fact, you have to follow
a fairly strict formula in order for Panda3D to be able to make sense of your
scene.

Teaching how to use Maya is beyond the scope of this manual.  We assume that
you already know how to use maya, and especially the hypershade.  The only
purpose of this section is to show you what configurations are understood by
Panda3D.

The first step in texturing your model is to apply a &lt;code&gt;Phong&lt;/code&gt; shader.
This is the only kind of shader that Panda3D understands. You can apply a
phong shader using the Maya menus:

&lt;br&gt;&lt;br&gt;&lt;center&gt;[[Image:maya-tex-1.jpg]]&lt;/center&gt;&lt;br&gt;&lt;br&gt;

Next, tell maya that you want to control the color of the surface by clicking the color button:

&lt;br&gt;&lt;br&gt;&lt;center&gt;[[Image:maya-tex-2.jpg]]&lt;/center&gt;&lt;br&gt;&lt;br&gt;

Now create a file texture - this will control the color of the surface:

&lt;br&gt;&lt;br&gt;&lt;center&gt;[[Image:maya-tex-3.jpg]]&lt;/center&gt;&lt;br&gt;&lt;br&gt;

Set the filename.  Once you do this, you will be able to see your texture in Maya:

&lt;br&gt;&lt;br&gt;&lt;center&gt;[[Image:maya-tex-4.jpg]]&lt;/center&gt;&lt;br&gt;&lt;br&gt;

You now have a straightforward textured model that Panda3D can export.

===Advanced Texturing===

You may wish to use Panda's advanced texturing abilities: multitexturing,
normal maps, gloss maps, transparency, or glow maps.  To use these features,
you will need to access Maya's hypershade editor:

&lt;br&gt;&lt;br&gt;&lt;center&gt;[[Image:maya-hypershade.jpg]]&lt;/center&gt;&lt;br&gt;&lt;br&gt;

A straightforwardly textured model will look like this in the hypershade:

&lt;br&gt;&lt;br&gt;&lt;center&gt;[[Image:maya-hyper-1.jpg]]&lt;/center&gt;&lt;br&gt;&lt;br&gt;

To apply a normal map, create another file texture and connect the &quot;out color&quot;
of the normal map to the &quot;normal camera&quot; input of the phong shader.
The normal map must be a true normal map (you can recognize them by their
light blue color), not a bump map (which are black-and-white.)

&lt;br&gt;&lt;br&gt;&lt;center&gt;[[Image:maya-hyper-2.jpg]]&lt;/center&gt;&lt;br&gt;&lt;br&gt;

Unfortunately, there is a maya button to help you set up a bump map, but
what it creates is not correct for Panda3D.  If you use the button, you
end up with the following incorrect configuration.  So far as I know, the
only way to get the correct configuration (shown above) is to set it up
manually in the hypershade.  The incorrect configuration is:

&lt;br&gt;&lt;br&gt;&lt;center&gt;[[Image:maya-hyper-3.jpg]]&lt;/center&gt;&lt;br&gt;&lt;br&gt;

You may wish for parts of your model to be transparent.  This is a little
tricky, because Panda3D understands &quot;opacity maps,&quot; and maya understands
&quot;transparency maps,&quot; which are opposites of each other.  (In an opacity map,
white is opaque, in a transparency map, black is opaque.)  To set it up,
you will need to create a reverser-object:

&lt;br&gt;&lt;br&gt;&lt;center&gt;[[Image:maya-hyper-4.jpg]]&lt;/center&gt;&lt;br&gt;&lt;br&gt;

You may also wish to control which areas of the model are glossy, and
which are not.  Panda3D calls this a &quot;gloss map.&quot;  To do this, create a black-and-white image and connect it to the &quot;specularColor&quot; input of the
phong shader.  Note that it must be black-and-white, or Panda3D won't
understand it.

&lt;br&gt;&lt;br&gt;&lt;center&gt;[[Image:maya-hyper-5.jpg]]&lt;/center&gt;&lt;br&gt;&lt;br&gt;

You may also want to create glowing areas on your model.  Panda3D calls
this a &quot;glow map.&quot;  I have also heard it called a &quot;self-illumination map&quot;
or an &quot;incandescence map.&quot;  Create a black-and-white image and connect
it to the &quot;incandescence&quot; input of the phong shader:

&lt;br&gt;&lt;br&gt;&lt;center&gt;[[Image:maya-hyper-6.jpg]]&lt;/center&gt;&lt;br&gt;&lt;br&gt;

Creating a glow map will cause those parts of the model
which are glowing to be bright even when the light is dark.  However,
it will not by itself create a full-featured bloom effect.  To get that,
you need to use a bloom filter in your Panda3D program in conjunction
with the glow map.  There is a [[sample program|Sample Programs: Glow Filter]]
that demonstrates this process.

Finally, there is plain old multitexturing.  Create this structure in the hypershade, using a &quot;Layered Texture&quot; (NOT a &quot;Layered Shader!&quot;):

&lt;br&gt;&lt;br&gt;&lt;center&gt;[[Image:maya-hyper-8.jpg]]&lt;/center&gt;&lt;br&gt;&lt;br&gt;

This will cause the two textures to be multiplied, which is the simplest
form of multitexturing.  You can also obtain certain other effects by 
changing the settings of the Layered Texture, however, this functionality
is very incomplete at this time.  For the most part, you can only multiply.

===Merging Textures===

The Maya exporter may will try to merge textures.  For example,
if your model has an RGB color map, and a black-and-white opacity map,
then the exporter will consider loading them together as a single RGBA
texture.

In order to merge two textures, the following rules must be satisfied:

1. Their UV mappings must be identical.
2. Their filenames must have a common prefix.

By &quot;common prefix,&quot; I mean that the files &quot;house-color.jpg&quot; and &quot;house-opacity.jpg&quot; can be merged, because they both start with the common prefix &quot;house-&quot;.  A common prefix consists of a series of alphanumeric
characters followed by a dash.  If you do not want two files merged, 
use a different file naming convention.

==Flagging Objects From Maya==

The Maya exporter is able to automatically flag objects for collisions if the objects are flagged properly in Maya. There is a [https://raw.githubusercontent.com/panda3d/panda3d/master/pandatool/src/mayaprogs/eggImportOptions.mel MELscript] in the available in the source code that helps flag objects in Maya.

Installation
#Open up maya's script editor (Window&gt;General Editors&gt;Script Editor)
#Open the script in the editor and execute it (Ctrl+Enter or Script&gt;Execute)
#Type &quot;eggObjectFlags()&quot; at the script editor and select the text.
#Middle mouse drag the selection into your custom shelf.
#Optional: go to the shelf editor and give it a custom icon/name

Usage
#Select the objects that you want to tag and press the shelf script.
#Set the object type by going to the channel box of the object, there should be a new attribute called Egg Object TypesN.
#Set the object type to the desired value.

{|border=&quot;1&quot; cellpadding=&quot;5&quot;
||Object Type||Meaning
|-
||barrier || The geometry defined at this root and below defines an invisible
collision solid.
|-
||trigger || The geometry defined at this root and below defines an invisible trigger surface.
|-
||sphere || The geometry is replaced with the smallest collision sphere that will enclose it. Typically you model a sphere in polygons and put this flag on it to create a collision sphere of the same size.
|-
||tube || As in sphere, above, but the geometry is replaced with a collision tube (a capsule). Typically you will model a capsule or a cylinder in polygons.
|-
||bubble || A collision bubble is placed around the geometry, which is otherwise unchanged.
|-
||ghost || It means that the geometry beginning at this node and below should never be collided with--characters will pass through it.
|-
||backstage || It means that the geometry at this node and below should not be translated. This will normally be used on scale references and other modeling tools. 
|}

==Running the Exporter==

Maya's exporter can be run from the command prompt or via a graphical panel.  The command line utility is called &lt;i&gt;maya2egg&lt;/i&gt;.  There are multiple versions of it corresponding to different versions of maya.  For instance, the version to use for Maya 5.0 is &lt;i&gt;maya2egg5&lt;/i&gt;, for 6.0 its &lt;i&gt;maya2egg6&lt;/i&gt; and for 6.5 its &lt;i&gt;maya2egg65&lt;/i&gt;.

The following is an example of how to convert a file(maya binary .mb) if using Maya 6.0 through the command line.

&lt;p align=center&gt;[[Image:MayaCommandLineExport.png]]&lt;/p&gt;

The egg file will contain the filenames of the textures.  These texture pathnames will be stored as &lt;i&gt;relative&lt;/i&gt; paths, relative to the location of the egg file.  For example, let's say that the files are laid out like this:

&lt;pre class=&quot;codeblock&quot;&gt;
c:\My Models\Maya Files\Character.mb
c:\My Models\Egg Files\Character.egg
c:\My Models\Textures\Character.png
&lt;/pre&gt;

In that case, the command to export the model is:

&lt;pre class=&quot;codeblock&quot;&gt;
c:\
cd c:\My Models\
maya2egg -o &quot;Egg Files/Character.egg&quot; &quot;Maya Files/Character.mb&quot; 
&lt;/pre&gt;

Note that [[Panda Filename Syntax]] uses forward slashes, even under Windows, and this applies to the exporter as well. After doing this export, the character egg will contain the following texture reference:

&lt;pre class=&quot;codeblock&quot;&gt;
&quot;../Textures/Character.png&quot;
&lt;/pre&gt;

Again, notice that this pathname is relative to the egg file itself.  Many artists find it convenient to keep everything in the same directory, to avoid having to think about this.  This approach works fine.

The above conversion process will turn the character into a &lt;i&gt;static&lt;/i&gt; model. Models which are rigged (they have bones to help them animate), skinned (polygons attached to the bones/skeleton), and are animated need to use one of the following options:

&lt;pre class=&quot;codeblock&quot;&gt;
maya2egg -a model -o eggFileName.egg mayaFileName.mb 
maya2egg -a chan -o eggFileName.egg mayaFileName.mb 
maya2egg -a pose -o eggFileName.egg mayaFileName.mb 
maya2egg -a both -o eggFileName.egg mayaFileName.mb 
&lt;/pre&gt;

&lt;p&gt;The meanings of these options are:&lt;/p&gt;

&lt;table&gt;
&lt;tr&gt;&lt;td width=80&gt;-a model&lt;/td&gt;&lt;td&gt;Save only the skinned and boned model, ready for animation but with no animation attached. This is ideal for models with several event- or interaction-based animations.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;-a chan&lt;/td&gt;&lt;td&gt;Save only the animation data on the current model, but not the model itself. This is ideal applying animations to an already-existing model egg file that is ready to receive animation. A model may have several animation channels applied to it.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;-a pose&lt;/td&gt;&lt;td&gt;Save the model in the current key position of the animation applied to it. This position must be selected before choosing to export the file. This format does not save the animation.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;-a both&lt;/td&gt;&lt;td&gt;This will export the model and animation out as one file.&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;


There are many options to maya2egg.  For a complete list, run maya2egg with the &lt;i&gt;-h&lt;/i&gt; argument.

&lt;table class=&quot;code&quot;&gt;&lt;tr&gt;&lt;td&gt;
maya2egg -h
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;



==Using the New Maya2EGG GUI(To be available for Panda3D 1.7.1 or later) == 

Although the command line version of maya2egg (and the additional  optimization utilities such as egg2bam, egg-optchar, work well when used correctly, typically problems arise from a poor understanding of the command line options and requirements. This standalone tools application attempts to demystify some of those options and present them in a way an artist (rather than a programmer) can better understand. However, the application still requires the command line programs to be present in order to actually export or process any eggs or Maya files. Simply put, the application builds the command line arguments for you and can process multiple files in a sequence (better known as batch processing). After all, in most game pipelines models and animations have to be exported multiple times with no changes to their settings after minor tweaks within the 3D package. It should also be noted this tool currently only supports the maya2egg exporter, but since the other optimization tools operate on egg files they can be used with any egg file that has been correctly exported from any 3D package.

NOTE: The application was developed to work on Windows, Linux, and Mac OS. There are certain differences between how each operating system installs Panda , and how directory paths are represented. For the rest of this document Windows conventions are going to be used, because it is the operating system that the is most familiar. However, if there are significant differences between how you need to use the app in Linux of OSX the necessary steps can be provided to ensure the application working correctly.


'''SIMPLE MODE'''

&lt;p align=center&gt;[[Image:Egg_Gui_simple.jpg]]&lt;/p&gt;

For viewing the video tutorial click [http://vimeo.com/11445320 here]

This application presents two modes for exporting a model or animation from Maya. Upon opening the application the simple mode is presented show above. The simple mode tab is intended to do “one-off” or single file exports. It would be the same thing as typing the exporter command and options each time you wanted to export a model. To use simple mode follow these few steps:

:-Click the Save button next to the first text box labeled “Egg file to be written” and navigate to your intended export directory and name you r file. When you’ve finished this click OK.

:-Click the Choose button next to the text box labeled “Maya file to be exported” and select the .mb file that you would like to export.

:-Select the version of Maya you currently have on your system from the Maya Version drop-down box.

Now, before you click Run Export, you must decide if you want to export any animation from the file and if so what type. If you simply want a static model (usually used for props and game levels) select “none” in the Animation box. This will export only the geometry from your scene, excluding any joints or key frames. It should be noted that this type of model will not export any skinning data from Maya. However, it will still have a transform included which will allow it to be placed in a Panda3D world.

If you want to export a scene with joints and skinning data so that it can later accept any exported animation select “model “ from Animation box. This term can be slightly confusing initially, but once you realize we’re talking about what type of animation (if any) to export the distinction between “none” and “model” is slightly more clear. Remember, model doesn’t just mean polygon geometry, it implies that the model has joints and possibly a skin cluster in the scene file. It is meant to accept animation data from a separate file or to be animated by the programmer through code.

If you only want to export the animation data from a scene select “chan”. This will simply write out the key frames of your scene and what joints those key frames apply to into the egg file. This file is almost always used with a separate egg file that was egged out with the “model” option.

Lastly, if you want all the geometry, joints, and skinning data exported to your egg in one file select “both” from the Animation box. This file type is rarely used, but special cases exist. Most of the time you would want to keep the animation and geometry data in separate files. This allows you to load animations on the fly inside the engine without having to load the geometry data twice. Thus making your game load (and possibly run) faster.

Once you’ve figured out which type of animation you need to export in your egg file. Click Run Export. A pop-up window will show up and it will start writing the output from the command line tool that the application launched in the background. If your scene file does not export correctly, this text will let you know in most cases. It can be helpful in tracking down problems and be sure to copy and paste it to text file if things don’t work out so you can show your programmer or a member of the Panda community where things are going haywire. Also, since computers in general have not learned to interpret the intentions of a human without explicit instructions the egg file may not show up in the game correctly. In short the exporter may write a perfectly good egg file, but since something wasn’t quite right in your scene file in Maya, things may not turn out correctly when you Pview or import the egg into your game. This almost always has to do with the Maya file itself, NOT the exporter, so be sure to try and diagnose problems inside Maya first. A good place to start is the Common Problems section of this document. If there’s no answer there, post on the Panda3D forums. There are a number of experts and seasoned artists who have probably come across the same problems you have and can quickly get you back on track.


'''ADVANCED MODE'''

&lt;p align=center&gt;[[Image:Egg_Gui_advanced.jpg]]&lt;/p&gt;
For viewing the video tutorial click [http://vimeo.com/11445391 here]

In the beginning Simple Mode should cover the basics of single file exporting. However, once you’ve had to load the application a few times and enter the same settings over and over again, it’s probably time to move on to using the Advanced Mode Tab.

Aside from allowing you to have greater control over what specifically gets exported out of a particular Maya scene, this tab allows you to save these options and settings for later use. Also, since everyone has a different set of default exporter options and locations the application allows you to save and load a preferences XML file to load each time the application is launched.

The process for exporting from the Advanced Mode tab is largely the same as Simple Mode, but with a few wrinkles. First you should choose your Panda installation directory and Maya version from the Environment Options section. This location is the directory where you told Panda3D to install when running the installer. It is NOT the \bin directory where the maya2egg executable resides. This little wrinkle was necessary to allow multiple operating systems to use the application.

The last difference between Simple and Advanced mode for exporting a single file, is that it must be put into the batch list before it can be exported. The Batch List represents the order of the files that are about to be exported. To Add a Maya scene file with its export options to this list simply click Add To Batch (The other utilities in the Extra Utilities section have this same button for simplicity’s sake, but the main Add To Batch button deals solely with the maya2egg tool). After you’ve added any number of scene files with any of the available options to the Batch List you can then click Run Batch and the application will launch the exporter or utility command one by one until it has finished the entire list of items.

Another useful feature of the application is that it checks the modified date of every file used as an input for the given utility (ie the .mb file for an exporter batch command, and an egg file for egg2bam). This is handy if you have saved out an entire batch list of 20 files but only need to export the three files you actually changed. The exporter skips any unchanged files by default, but this behavior can be overridden by checking the “Override export changed files” checkbox next to the Run Batch button.

===Using the Egg-Palletize Tool===

For viewing the video tutorial click [http://vimeo.com/11445357 here]

Egg-palettize is an optimization tool in Panda for you to group your textures. You can have your textures placed in a single palette. In the advance mode of the GUI, choose the egg-palettize panel. This is the egg-palettize Tool.

&lt;p align=center&gt;[[Image:Pallettize_1.jpg]]&lt;/p&gt;

For using Egg pallettize for a single egg file select that option in the drop down list 

&lt;p align=center&gt;[[Image:Pallettize_2.jpg]]&lt;/p&gt;

First, specify the input egg file, the output texture file and the output egg file. The output texture file is where the palette will be put in. And the output egg file is the new egg with the new palette as the texture.
Before generating the egg palette, a .txa file should be generated with some attributes listed in the attribute panel.
Set palette size: Specify the size of the palette.
Imagetype: Image type of the palette.
Powertwo flag:   Specifies whether textures should be forced to a power of two  size when they are not placed within a palette. The default is false.

Set background color:  Specifies the background color of the generated palette images. The background color is the color of the palette images where nothing is used. The number  r, g, b, a channels are range from 0 to 255. The default color is black.

Margin:  This specifies the amount of default margin to apply to all textures that are placed within a palette image.  The margin is a number of additional pixels that are written around the texture image to help prevent color bleeding between neighboring images within the same palette.  The default is 2.

Coverage:  The 'coverage' of a texture refers to the fraction of the area in the texture image that is   actually used, according to the UV's that appear in the various egg files.  If a texture's   coverage is less than 1, only some of the texture image is used (and only this part will be written to the palette).  If the coverage is greater than 1, the texture repeats that number of times.  A repeating texture may still be palettized  by writing the required number of copies into the palette image, according to the coverage area. This attribute specifies the maximum coverage to allow for any texture before rejecting it from the palette.  It may be any floating-point number greater than zero.  Set this to 1 to avoid palettizing repeating textures altogether.

After setting all the attribute, click on Save Attributes button to save all the attributes to a .txa file. Last, add this to batch list, after clicking run batch, the palette will be generated.

Egg-palettize for multiple eggs

&lt;p align=center&gt;[[Image:Pallettize_3.jpg]]&lt;/p&gt;

Egg-palettize can also generate a palette image for multiple egg files to share. This palette image has all the textures of multiple egg files to be placed on it.
This panel is almost the same as the single egg one. Only for the input egg file can have multiple egg files put into it. Select a added egg file and click Remove button can remove that egg file. Click Remove All button can remove all the added egg files  
The output is a folder to put all the new eggs.
Attributes Panel is the same as the single egg one.


==Using the Graphical Front-End(Old)==

As of Panda3D 1.0.4, there is a graphical front-end to &lt;i&gt;maya2egg&lt;/i&gt;. To run the graphical Maya exporter, drag MayaPandaTool.mel from the panda plugins directory into the Maya workspace.

&lt;p align=center&gt;[[Image:MayaPandaToolLoad.png]]&lt;/p&gt;

The UI window(below) will appear.

&lt;p align=center&gt;[[Image:Maya-exporter.png]]&lt;/p&gt;

You can alternatively load the .mel file from the script editor.  To save space, the graphical tool does not have access to all of the features of the exporter.  It is designed for rapid verification of assets.  The features you can execute with the graphical tool are identical to the respective ones of the command line exporter listed below.

Or, you can integrate the UI interface to Maya.
There is a very convenient way to launch the MayaPandaTool, using Maya shelf to store the MEL script :
&lt;br&gt;[1] open the Script Editor :
&lt;br&gt;Window &gt; General Editors &gt; Script Editor
&lt;br&gt;[2] In Script Editor, load the MayaPandaTool MEL script :
&lt;br&gt;File &gt; Open Script
&lt;br&gt;[3] select the MEL text (press Ctrl+A)
&lt;br&gt;[4] using middle mouse button, drag the selected text onto the shelf
&lt;br&gt;[5] (optional) using Shelf Editor, you can change the image of Panda exporter icon to distinguish it from the others. 
&lt;p align=center&gt;[[Image:LaunchMPT.jpg]]&lt;/p&gt;

Anytime you need to open the Panda Exporter, just click the icon on the shelf.


&lt;u&gt;For Windows users :&lt;/u&gt;
&lt;br&gt;If you want a faster launch, you can put the MEL file on the QuickLaunch.
Press Ctrl while dragging the MEL file onto QuickLaunch bar. If you don't press Ctrl, the actual file dropped to QuickLaunch is only the shortcut to the MEL file.
&lt;br&gt;Anytime you need to open the Panda exporter, just drag it from QuickLaunch bar to the 3D window of Maya.</text>
    </revision>
  </page>
  <page>
    <title>Converting from Milkshape 3D</title>
    <ns>0</ns>
    <id>1063</id>
      <sha1>rzw1i4nzxsdylw28qyjozudb1a2chfi</sha1>
    <revision>
      <id>7504</id>
      <timestamp>2011-12-24T14:05:23Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>typos</comment>
      <text xml:space="preserve" bytes="3591">Currently, the best way to get data from Milkshape into Panda is to use X (DirectX native) file format.  Save the model as X from Milkshape, then load it directly into Panda, which can read X file format.  Alternately, if you're concerned about long load times (panda has to translate the file at load time), then pre-convert the model from X to Egg to Bam using the conversion programs supplied with Panda3D (x2egg, egg2bam).  

Note that Milkshape 3D contains &lt;i&gt;two&lt;/i&gt; X export plugins.  I have heard that one of them does not work correctly.  This may require some experimentation.

Whenever you save a model in a non-native file format, you need to ask yourself: &quot;does this file format support everything I need?&quot; For example, when you save out a model in 3DS file format, you automatically lose all bone and animation data, because the 3DS file format doesn't contain bone and animation data. In the case of the X file format, you're in good shape: it's a fairly powerful file format, supporting vertices and triangles, bones and animation.

However, egg file format supports some esoteric things. For example, it supports blend targets (morph animations), which are not supported by the X file format.



&lt;h2&gt; More Detailed explanations for MS3D users&lt;/h2&gt;

&lt;br&gt;You can use MS3D  to create X Files (both static or animated) to be converted by Panda3d x2eggconverter.
&lt;/br&gt;

In MS3D there is two Direct X .X exporter: Direct 8.0 and DirectX(JT).
So far i've managed to use only DirectX 8.0 File.
(DirectX JT got a lot more parameters and only a few combination of it seemed
to work but not on a predictable basis).
I'll talk only for animation with bones (not tested other ones).But this exporter work also for static meshes.

A) Before Exporting to .X you must ensure:
- no null material or null name in texture in your model 
(MS3D won't block you but will crashes during the export)
- no hyphen in your bones names (underscore is ok)
(No issue in MS3D but issue with panda converter).
- animation mode is NOT enabled

B) To export , use Direct 8.0 file export.
Select the required boxes. (Meshes, Materials ,Animations)
if you selected less than all checkboxes (material animations...) you will have to edit manually the x files to remove the last 1 or 2 &quot;}&quot; of the file .
before using X2egg to convert .
It's OK to leave default settings (Lock Root Bone and 1 as Frame offset).
Warning: Export can be very long in case of big models/animations.

C) Convert using X2egg converter

Warning:if you run X2egg without special args, you will need to have your textures also in the same directory than the x files.
Don't be surprised if .egg file size is 6 times your .X file size, it's pretty normal due to more explicit information in the .egg file format.
In case size is an issue, bamming the .egg file will reduce the size and optimize loading time.

Also , before converting to .egg , you can load your .x in pview to check everything is fine.

D)TIPS: depending if you make your models fully in MS3D or import it from Poser, you may find an issue : all animations applied to root bone instead of correct bone.
You can solve it in MS3D by regrouping all materials, export to HL SMD (1 or 2 ) then import again and export to .X.

NB: this have been written by a coder not an artist :-)

&lt;h2&gt;Bugs in the Process&lt;/h2&gt;

&lt;i&gt;Caution: at one time, it was discovered that there were two bugs in panda's X-file importer.  One, it was case-sensitive and it should not be.  Two, it did not handle hyphens in identifiers correctly.  It is unknown whether or not these bugs have been fixed.&lt;/i&gt;</text>
    </revision>
  </page>
  <page>
    <title>Converting from SoftImage</title>
    <ns>0</ns>
    <id>1144</id>
      <sha1>f49upt9xplmssxnkioplrrxt7tykp40</sha1>
    <revision>
      <id>4322</id>
      <timestamp>2007-05-26T15:39:37Z</timestamp>
      <contributor>
        <username>ThomasEgi</username>
        <id>111</id>
      </contributor>
      <comment>-removed spamlinks</comment>
      <text xml:space="preserve" bytes="46">WRITE ME: Add information about X file format.</text>
    </revision>
  </page>
  <page>
    <title>Converting from other Formats</title>
    <ns>0</ns>
    <id>1068</id>
      <sha1>8aj1j7t0srtr47w00itcbraonld7tb9</sha1>
    <revision>
      <id>7505</id>
      <timestamp>2011-12-24T14:06:27Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="558">There are several tools included with Panda that can convert various file formats into egg file format:

&lt;table class=&quot;code&quot;&gt;&lt;tr&gt;&lt;td&gt;
lwo2egg
&lt;br&gt;dxf2egg
&lt;br&gt;flt2egg
&lt;br&gt;vrml2egg
&lt;br&gt;x2egg
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

Note that Panda can load any of these file formats without conversion, doing so causes the conversion to occur at runtime. 

Also, be aware that many of these file formats are limited.  Most do not include bone or animation data.  Some do not store normals.  Currently the .x format is the only one of these that stores bones, joints and animations.</text>
    </revision>
  </page>
  <page>
    <title>Creating Geometry from Scratch</title>
    <ns>0</ns>
    <id>1127</id>
      <sha1>62biswfuvi27b1l7qcio2kq5jug8zmu</sha1>
    <revision>
      <id>60175</id>
      <timestamp>2014-06-22T13:18:22Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="6080">&lt;h2&gt;Creating Geometry of Your Own&lt;/h2&gt;
Making your own geometry on the fly can be broken down into 3 steps:
&lt;br&gt;1)Create a [[Vertices in Panda3D|GeomVertexData]] object to hold the vertices of your geometry. Add the data for all the vertices you will need.
&lt;br&gt;2)Create &lt;code&gt;GeomPrimitive&lt;/code&gt; objects and assign vertices to them
&lt;br&gt;3)Create a &lt;code&gt;Geom&lt;/code&gt; object with the object created in step 1 and add all the primitives you created. You can know put this Geom in a GeomNode and render the geometry.

The following sections explains these processes in detail.

&lt;h2&gt;The Geom and GeomPrimitive Class&lt;/h2&gt;

&lt;code&gt;GeomPrimitive&lt;/code&gt; is the base class for all the primary shapes that Panda can draw (GeomLines, GeomLinestrips, GeomPoints, GeomTriangles, GeomTrifans, and GeomTristrips). Any geometry that is rendered is broken down into these shapes.  You cannot mix objects of different fundamental types, for instance, GeomLines, GeomTriangles, and GeomPoints, in the same Geom; but you can (and should) put GeomTriangles, GeomTrifans, and GeomTristrips together, or GeomLines and GeomLinestrips together.

Each kind of GeomPrimitive constructor accepts a [[Vertices in Panda3D|UsageHint]] parameter.  The list of possible UsageHints is the same as that given for &lt;code&gt;GeomVertexData&lt;/code&gt; objects.

&lt;code&gt;GeomPrimitive&lt;/code&gt; objects keep track of what vertices to use by storing a list of integers. These integers tell the object which row in the &lt;code&gt;GeomVertexData&lt;/code&gt; object it will be associated with has the vertex it needs. This is why when you add a vertex to a &lt;code&gt;GeomPrimitive&lt;/code&gt; object, using  &lt;code&gt;addVertex(rowNum)&lt;/code&gt;, you have to supply the row of the vertex.

There are also some convenience functions built on top of &lt;code&gt;addVertex&lt;/code&gt;. &lt;code&gt;addConsecutiveVertices(int start, int vertNum)&lt;/code&gt; adds &lt;code&gt;vertNum&lt;/code&gt; vertices from the &lt;code&gt;GeomVertexData&lt;/code&gt; object starting from the row &lt;code&gt;start&lt;/code&gt;. There is also &lt;code&gt;addNextVertices(numAdd)&lt;/code&gt; which acts like &lt;code&gt;addConsecutiveVertices&lt;/code&gt; but uses the last vertex you have added as &lt;code&gt;start&lt;/code&gt;.

When you are done adding the vertices to a &lt;code&gt;GeomPrimitive&lt;/code&gt; object  for each primitive you must call the &lt;code&gt;closePrimitive()&lt;/code&gt; function. This makes sure that the number of vertices you have added to the primitive define it properly.  Note that each GeomPrimitive object can store more than one of its particular kind of primitive; for instance, you can store many triangles in a single GeomTriangles object, and many triangle strips in a single GeomTristrips.  You do this by adding all the vertex numbers in order, calling closePrimitive() after you have added the vertices for each primitive.

When this process is done you have to place these &lt;code&gt;GeomPrimitive&lt;/code&gt; objects in a &lt;code&gt;Geom&lt;/code&gt; object. You must pass the &lt;code&gt;GeomVertexData&lt;/code&gt; object to the &lt;code&gt;Geom&lt;/code&gt; constructor.  You can add many GeomPrimitives to a single Geom, but primitives in the same Geom object must take their vertices from the same GeomVertexData.  Furthermore, several Geom objects can share the same GeomVertexData object. You can add primitives to Geom objects by using &lt;code&gt;addPrimitive(myPrimitive)&lt;/code&gt; where myPrimitive is the &lt;code&gt;GeomPrimitive&lt;/code&gt; you want to add.

When the &lt;code&gt;Geom&lt;/code&gt; object is setup, you can now place it in a &lt;code&gt;GeomNode&lt;/code&gt; object and place it in the scene graph using &lt;code&gt;addGeom(myGeom)&lt;/code&gt; where &lt;code&gt;myGeom&lt;/code&gt; is the &lt;code&gt;Geom&lt;/code&gt; object you want to add.

Usage tip: modern PC graphics cards can render many thousands of triangles in a frame, but the PC bus can only handle a few hundred triangle &lt;i&gt;batches&lt;/i&gt; in a 60Hz frame.  In Panda, each GeomPrimitive is sent to the graphics card as a single batch, therefore, it is important to minimize the number of GeomPrimitive objects in your scene graph, and to put as many triangles as possible within a single GeomPrimitive--assuming they are all going to be onscreen at the same time anyway.  On the other hand, if you put too many unrelated triangles in the same GeomPrimitive, with both offscreen and onscreen triangles in the same primitive, then you will be wasting time drawing all of the offscreen triangles.  Finding the best balance point is difficult and depends on the quality of graphics hardware your application is targeting.  As a general rule of thumb, it is best to use as few GeomPrimitives as possible for small, atomic objects, but also to break up your scene into many individual objects (i.e. GeomNodes) that can easily be culled when they go offscreen.

An example to clarify things:
&lt;table class=&quot;code&quot;&gt;&lt;tr&gt;&lt;td&gt;
&amp;nbsp;#in this example, we'll show how to make a square from scratch
&lt;br&gt;#There is no &quot;GeomQuad&quot; class so we have to use two triangles.
&lt;br&gt;
&lt;br&gt;#step 1) create GeomVertexData and add vertex information
&lt;br&gt;format = GeomVertexFormat.getV3()
&lt;br&gt;vdata = GeomVertexData(&quot;vertices&quot;, format, Geom.UHStatic)
&lt;br&gt;vdata.setNumRows(4)
&lt;br&gt;
&lt;br&gt;vertexWriter = GeomVertexWriter(vdata, &quot;vertex&quot;)
&lt;br&gt;vertexWriter.addData3f(0,0,0)
&lt;br&gt;vertexWriter.addData3f(1,0,0)
&lt;br&gt;vertexWriter.addData3f(1,0,1)
&lt;br&gt;vertexWriter.addData3f(0,0,1)
&lt;br&gt;
&lt;br&gt;#step 2) make primitives and assign vertices to them
&lt;br&gt;tris=GeomTriangles(Geom.UHStatic)
&lt;br&gt;
&lt;br&gt;#have to add vertices one by one since they are not in order
&lt;br&gt;tris.addVertex(0)
&lt;br&gt;tris.addVertex(1)
&lt;br&gt;tris.addVertex(3)
&lt;br&gt;
&lt;br&gt;#indicates that we have finished adding vertices for the first triangle.
&lt;br&gt;tris.closePrimitive()
&lt;br&gt;
&lt;br&gt;#since the coordinates are in order we can use this convenience function.
&lt;br&gt;tris.addConsecutiveVertices(1,3) #add vertex 1, 2 and 3
&lt;br&gt;tris.closePrimitive()
&lt;br&gt;
&lt;br&gt;#step 3) make a Geom object to hold the primitives
&lt;br&gt;squareGeom=Geom(vdata)
&lt;br&gt;squareGeom.addPrimitive(tris)
&lt;br&gt;
&lt;br&gt;#now put squareGeom in a GeomNode. You can now position your geometry in the scene graph.
&lt;br&gt;squareGN=GeomNode(&quot;square&quot;)
&lt;br&gt;squareGN.addGeom(squareGeom)
&lt;br&gt;render.attachNewNode(squareGN)
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</text>
    </revision>
  </page>
  <page>
    <title>Creating Multifiles</title>
    <ns>0</ns>
    <id>2210</id>
      <sha1>ql5ilxditv5fd1yx5uv34d5hm10tyn3</sha1>
    <revision>
      <id>7690</id>
      <timestamp>2012-03-09T10:07:12Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>new import system and python code tags</comment>
      <text xml:space="preserve" bytes="11003">Multifiles archives are archive files that store game resources.  Think of it as a giant zip file that stores, optionally zips and encrypts your data files, but does not need to be extracted.

&lt;h2&gt;The multify program&lt;/h2&gt;
The multify console program creates such files. You can get information about the commandline parameters by running multify with the &lt;code&gt;-h&lt;/code&gt; option. This is how program describes itself:
&lt;pre class=&quot;codeblock&quot;&gt;
Usage: multify -[c|r|u|t|x] -f &lt;multifile_name&gt; [options] &lt;subfile_name&gt; ...
&lt;/pre&gt;

multify is used to store and extract files from a Panda Multifile.
This is similar to a tar or zip file in that it is an archive file that
contains a number of subfiles that may later be extracted.

Panda's VirtualFileSystem is capable of mounting Multifiles for direct
access to the subfiles contained within without having to extract them
out to independent files first.

The command-line options for multify are designed to be similar to those
for tar, the traditional Unix archiver utility.

&lt;h2&gt;Read Assets&lt;/h2&gt;

If you want to prepare to read assets from a Multifile directly, you can &quot;mount&quot; it into the virtual file system:

[python]
&lt;code python&gt;
from panda3d.core import VirtualFileSystem
from panda3d.core import Multifile
from panda3d.core import Filename

vfs = VirtualFileSystem.getGlobalPtr()
vfs.mount(Filename(&quot;foo.mf&quot;), &quot;.&quot;, VirtualFileSystem.MFReadOnly)
&lt;/code&gt;
[/python]
[cxx]
&lt;code cxx&gt;
VirtualFileSystem *vfs = VirtualFileSystem::get_global_ptr();
vfs-&gt;mount(&quot;./foo.mf&quot;, &quot;.&quot;, VirtualFileSystem::MF_read_only); 
&lt;/code&gt;
[/cxx]

If you want to read assets, you can mount a whole directory structure from a webserver. 

If your webserver hosts: 

&lt;pre class=&quot;codeblock&quot;&gt;
http://localhost/mydir/models/myfile.bam 
http://localhost/mydir/maps/mytexture.png 
&lt;/pre&gt;

Put this in your config.prc: 

&lt;pre class=&quot;codeblock&quot;&gt;
vfs-mount-url http://myserver/mydir /mydir 
model-path /mydir
&lt;/pre&gt;

Or, equivalently, write this Python code at startup: 

&lt;code python&gt;
vfs.mount(VirtualFileMountHTTP('http://myserver/mydir'), '/mydir', 0) 
getModelPath().appendDirectory('/mydir')
&lt;/code&gt;

and then you can load models like this in your Python code: 

&lt;code python&gt;
model = loader.loadModel('models/myfile.bam') 
texture = loader.loadTexture('maps/mytexture.png')
&lt;/code&gt;

If you want to prepare for reading and writing assets to a Multifile do the following. 

&lt;code python&gt;
from panda3d.core import VirtualFileSystem
from panda3d.core import Multifile
from panda3d.core import Filename

mf = Multifile()
mf.openReadWrite(&quot;models.mf&quot;)

vfs = VirtualFileSystem.getGlobalPtr()
if vfs.mount(mf, &quot;.&quot;, VirtualFileSystem.MFReadOnly):
  print 'mounted'
&lt;/code&gt;

If you want to prepare for reading and writing assets to a 'subdirectory' Multifile do the following. Note &quot;mysys&quot; must always be literally written in any python code. E.g. &quot;mysys/memfdir/mfbar2.txt&quot;

&lt;code python&gt;
from panda3d.core import VirtualFileSystem
from panda3d.core import Multifile
from panda3d.core import Filename

mf = Multifile()
mf.openReadWrite(&quot;models.mf&quot;)

vfs = VirtualFileSystem.getGlobalPtr()
if vfs.mount(mf, &quot;mysys&quot;, VirtualFileSystem.MFReadOnly):
  print 'mounted'
&lt;/code&gt;

If you are having problems loading from multifiles you can list the complete contents of your .mf file with a command like:

&lt;pre class=&quot;codeblock&quot;&gt;
multify -tvf mymultifile.mf
&lt;/pre&gt;

Doing a sanity inspection like this can be useful to ensure that your assets are in the right place within the multifile.

&lt;h2&gt;Multifile objects&lt;/h2&gt;
The Multifile class is designed for opening, reading and writing multifiles. You can open a new multifile by creating an instance of the class and calling the &lt;code&gt;openRead&lt;/code&gt; method:
&lt;code python&gt;
from panda3d.core import Multifile

mf = Multifile()
mf.openRead(&quot;foo.mf&quot;)
&lt;/code&gt;

The &lt;code&gt;openRead&lt;/code&gt; method opens the multifile as read-only. If you want to make changes to it and write it back to disk, you will need to use the &lt;code&gt;openReadWrite&lt;/code&gt; method. Also, there exists &lt;code&gt;openWrite&lt;/code&gt; to create a new multifile.

If you have made important structural changes to a Multifile, it is recommended to rewrite the multifile using the &lt;code&gt;repack()&lt;/code&gt; method. (This won't work if you've opened it using &lt;code&gt;openRead&lt;/code&gt;.) If you are uncertain about whether it has become suboptimal, you can call &lt;code&gt;needsRepack()&lt;/code&gt; which returns True if the Multifile is suboptimal and should be repacked.

To write it back to disk, you can use the &lt;code&gt;flush()&lt;/code&gt; method which flushes the changes you've made to the multifile back to disk, or the &lt;code&gt;close()&lt;/code&gt; method if you're done with the file.

To mount Multifile objects into the VirtualFileSystem without writing them to disk first, here's an example on how to mount them:
&lt;code python&gt;
yourMF = Multifile()
#... now do something with yourMF

vfs = VirtualFileSystem.getGlobalPtr()
vfs.mount(yourMF, &quot;.&quot;, VirtualFileSystem.MFReadOnly)
&lt;/code&gt;

&lt;h2&gt;Subfiles&lt;/h2&gt;
Files that are added to a multifile are called &lt;i&gt;subfiles&lt;/i&gt;. You can add existing files to a multifile object using the &lt;code&gt;addSubfile&lt;/code&gt; function. This function takes three arguments: the target filename, the existing source file and the compression level (1-9). There is also &lt;code&gt;updateSubfile&lt;/code&gt;, which does the same thing but if the file already exists, only updates it if the content is different.

There are several other methods which operate on subfiles, which you can find in the [http://panda3d.org/apiref.php?page=Multifile API Reference.]
Here are a few examples of working with subfiles:

&lt;code python&gt;
from panda3d.core import VirtualFileSystem
from panda3d.core import Multifile
from panda3d.core import Filename

m = Multifile()

# Add an existing real os file with compression level 6
m.openReadWrite(&quot;foo.mf&quot;)
m.addSubfile(&quot;bar.txt&quot;, Filename(&quot;/tmp/bar.txt&quot;), 6)
m.flush()

# Destroy the contents of the multifile
# Add an existing real os file to be the first multifile
m.openWrite(&quot;foo.mf&quot;)
m.addSubfile(&quot;bar.txt&quot;, Filename(&quot;/tmp/bar.txt&quot;), 6)
m.flush()

# Permanently re-order in ascending order the 
# directories and files in the multifile
m.openReadWrite(&quot;foo.mf&quot;)
m.repack()
m.flush()

# Open a multifile and replace the contents of the mulifile file
# with new contents
m = Multifile()
m.openReadWrite(&quot;foo.mf&quot;)
m.updateSubfile(&quot;bar.txt&quot;, Filename(&quot;/tmp/bar2.txt&quot;), 9)
m.flush()

# Open a multifile and extract all files smaller than 3kb
# New real os files are created with the contents of the multifile data
m = Multifile()
m.openRead(&quot;foo.mf&quot;)
for i in range(m.getNumSubfiles()):
  if m.getSubfileLength(i) &lt; 3 * 1024:
    m.extractSubfile(i, Filename(&quot;/tmp/&quot; + m.getSubfileName(i)))

# Find, print and remove a file named bar.txt
barIdx = m.findSubfile(&quot;bar.txt&quot;)
if barIdx != -1:
  # It returns -1 if it doesn't exist
  print m.readSubfile(barIdx)
  m.removeSubfile(barIdx)
m.flush()

m.close()

&lt;/code&gt;
[cxx]
&lt;code cxx&gt;
std::ostringstream os (std::ios::in | std::ios::out); 
std::istream is (os.rdbuf ()); 

os.write((char*)&amp;stuff, sizeof(stuff)); 

PT(Multifile) mf = new Multifile(); 
mf-&gt;open_write(fileName); 
mf-&gt;add_subfile(&quot;foo.mf&quot;, &amp;is,6); 
mf-&gt;flush(); 
mf-&gt;close(); 
&lt;/code&gt;[/cxx]

If the foo.mf file were to have a contained bar.egg.pz file, load the egg and use it similar to other model loading methods.
&lt;code python&gt;
nodepath = loader.loadModel(&quot;foo/bar&quot;)
&lt;/code&gt;

&lt;h2&gt;Stream-Based&lt;/h2&gt;
Multifile algorithms are stream-based and not random-based.
In a running game, from the output, if a message is received saying something similar to the words &lt;code&gt;seek error for offset&lt;/code&gt; then a file in the multifile is trying to be accessed by a random-based method.
For multifiles and fonts, an example of a random-based file is an .rgb file.
An alternative different from the use of an .rgb file is the use of a .ttf instead. An example follows.

&lt;pre class=&quot;codeblock&quot;&gt;
# models is the original directory
# models.mf it the new target multifile
multify -c -f models.mf -v models
&lt;/pre&gt;
In the game, from the multifile models.mf, load the .ttf file.
&lt;code python&gt;
font = loader.loadFont(&quot;models/arial.ttf&quot;)
&lt;/code&gt;


&lt;h2&gt;Encryption&lt;/h2&gt;
Multifiles can also encrypt your files with a password. To do so, you need to set the encryption flag and password using the &lt;code&gt;setEncryptionFlag&lt;/code&gt; and &lt;code&gt;setEncryptionPassword&lt;/code&gt; methods, before adding, extracting or reading multifiles. 

At the OS prompt, to create a password protected multifile and print out the contents do the following.

&lt;pre class=&quot;codeblock&quot;&gt;
# models is the original directory
# models.mf it the new target multifile
multify -c -f models.mf -ep &quot;mypass&quot; -v models
&lt;/pre&gt;

This code creates a multifile and adds an encrypted file to it:
&lt;code python&gt;
m = Multifile()
m.openReadWrite(&quot;foo.mf&quot;)
m.setEncryptionFlag(True)
m.setEncryptionPassword(&quot;foobar&quot;)

# Add a new file to the multifile
m.addSubfile(&quot;bar.txt&quot;, Filename(&quot;/tmp/bar.txt&quot;), 1)
m.flush()
m.close()
&lt;/code&gt;

You can read encrypted multifiles the same way:
&lt;code python&gt;
m = Multifile()
m.openRead(&quot;foo.mf&quot;)
m.setEncryptionFlag(True)
m.setEncryptionPassword(&quot;foobar&quot;)
# Prints the contents of the multifile
print m.readSubfile(&quot;bar.txt&quot;)
&lt;/code&gt;

At the OS prompt, to see the contents of a password protected multifile perform
&lt;pre class=&quot;codeblock&quot;&gt;
multify -tvf models.mf -p &quot;mypass&quot;
&lt;/pre&gt;


You can test the reading in a of password-protected multifile, followed by the mounting of the file using the following code.
&lt;code python&gt;
from panda3d.core import Multifile
mf = Multifile()
mf.openRead(&quot;models.mf&quot;)
mf.setEncryptionFlag(True)
mf.setEncryptionPassword(&quot;mypass&quot;)

from panda3d.core import VirtualFileSystem
vfs = VirtualFileSystem.getGlobalPtr()
if vfs.mount(mf, &quot;.&quot;, VirtualFileSystem.MFReadOnly):
   print 'mounted'
&lt;/code&gt;

When running the game, the following should be seen.
&lt;pre class=&quot;codeblock&quot;&gt;
mounted
&lt;/pre&gt;


You can check if a certain subfile is encrypted or not using the &lt;code&gt;isSubfileEncrypted&lt;/code&gt; method, which takes the subfile index as parameter.

It is possible to have a multifile where different subfiles have different encryption, but you will not be able to mount it with the VirtualFileSystem or use it with the multify tool. To mount an encrypted file using the VirtualFileSystem, pass the password as parameter to the &lt;code&gt;mount&lt;/code&gt; method:
[python]
&lt;code python&gt;
from panda3d.core import VirtualFileSystem, Filename
vfs = VirtualFileSystem.getGlobalPtr()
vfs.mount(Filename(&quot;foo.mf&quot;), &quot;.&quot;, vfs.MFReadOnly, &quot;foobar&quot;)
&lt;/code&gt;
[/python]
[cxx]
&lt;code cxx&gt;
VirtualFileSystem *vfs = VirtualFileSystem::get_global_ptr()
vfs-&gt;mount(&quot;./foo.mf&quot;, &quot;.&quot;, VirtualFileSystem::MF_read_only, &quot;foobar&quot;); 
&lt;/code&gt;
[/cxx]

To use encryption with the multify tool, run it with the &lt;code&gt;-e&lt;/code&gt; option, which will prompt for a password on the command line. Alternatively, if you also specify the &lt;code&gt;-p &quot;password&quot;&lt;/code&gt; option, you can specify it in the command instead of typing it at the prompt.</text>
    </revision>
  </page>
  <page>
    <title>Creating New MouseWatchers for Display Regions</title>
    <ns>0</ns>
    <id>2603</id>
      <sha1>eg13pwc5exoxm23rrv0ty4a7b6b55mh</sha1>
    <revision>
      <id>7667</id>
      <timestamp>2012-03-08T19:00:46Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="2658">When working with multiple display regions in a single window, it can be difficult to get accurate mouse interaction. base.mouseWatcherNode, the default MouseWatcher in Panda3D, reports the mouse coordinates for the entire window. To get mouse coordinates relative to a specific display region the MouseWatcher needs to be restricted to that region with the setDisplayRegion() method.

&lt;code python&gt;
myDR = base.win.makeDisplayRegion(0, 1, 0, 1)
base.mouseWatcherNode.setDisplayRegion(myDR)
&lt;/code&gt;

However, restricting the default MouseWatcher to a display region will prevent the mouse from being used outside of that region. For example, the image below shows two display regions, a 3D view in the top portion, and a menu in the bottom portion.
&lt;br&gt;
[[Image:DisplayRegionMouseWatcher.png]]
&lt;br&gt;
If base.mouseWatcherNode is restricted to the 3D view display region, the mouse won't interact with the menu buttons.

One way to get around this problem is to create a new MouseWatcher to handle the 3D view display region. By doing so, the mouse can interact with other display regions, such as the one containing the menu, and the program can still get accurate mouse coordinates for the 3D view display region for things like [[Clicking on 3D Objects|Clicking on 3D Objects]] which is discussed later in the manual.

Creating a new MouseWatcher and tying it to a display region is a three step process. First, the new MouseWatcher has to be created.

&lt;code python&gt;
myMouseWatcher = MouseWatcher()
# Creates a new mouse watcher 
&lt;/code&gt;

In order for the new MouseWatcher to do its job, it needs to receive information about the mouse from the system. This information comes from the MouseAndKeyboard object. To get the information, our new MouseWatcher needs to be a child of MouseAndKeyboard. We know that base.mouseWatcherNode is already a child of MouseAndKeyboard, so we can use that to our advantage to make our new MouseWatcher a child of it as well.

&lt;code python&gt;
base.mouseWatcher.getParent().attachNewNode(myMouseWatcher) 
# Gets MouseAndKeyboard, the parent of base.mouseWatcherNode
# that passes mouse data into MouseWatchers, 
# and attaches myMouseWatcher to it. 
&lt;/code&gt;

Now that our MouseWatcher is getting mouse information from the system, we just need to set it to the display region we want it to monitor.

&lt;code python&gt;
myMouseWatcher.setDisplayRegion(myDisplayRegion) 
# Restricts my MouseWatcher to my intended display region. 
&lt;/code&gt;

With that done, we can get accurate mouse coordinates within the display region from our new MouseWatcher.

&lt;code python&gt;
if(myMouseWatcher.hasMouse()):
  mpos = myMouseWatcher.getMouse()
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>Creating New Textures from Scratch</title>
    <ns>0</ns>
    <id>1128</id>
      <sha1>0procrddcodizp5qcejg9vwk12hnq4m</sha1>
    <revision>
      <id>7583</id>
      <timestamp>2012-02-11T20:03:17Z</timestamp>
      <contributor>
        <username>Eadthem</username>
        <id>561</id>
      </contributor>
      <minor/>
      <comment>fixed typo</comment>
      <text xml:space="preserve" bytes="5468">&lt;h2&gt;The PNMImage Class&lt;/h2&gt;
This class is how Panda3D handles regular images (.gif, .jpg, and the like). This class allows you to manipulate individual pixels of the image. You can load existing images using the function &lt;code&gt;read(fileName)&lt;/code&gt; where &lt;code&gt;filename&lt;/code&gt; is the path to the image file (in [[Panda Filename Syntax]]) wrapped in a &lt;code&gt;Filename &lt;/code&gt; object. Or, you can create a brand new image from scratch, by passing the x, y size to the constructor.
[python]
&lt;code python&gt;
myImage = PNMImage()
myImage.read(Filename(&quot;testImg.png&quot;))
myEmptyImage = PNMImage(256, 256)
&lt;/code&gt;
[/python]
[cxx]&lt;code cxx&gt;
PNMImage myImage;
myImage.read(Filename(&quot;testImg.png&quot;),PNMFileTypeRegistry::get_global_ptr()-&gt;get_type_from_extension(&quot;png&quot;),true);
&lt;/code&gt;[/cxx]

You can get the size of the image you have read using the &lt;code&gt;getXSize()&lt;/code&gt; and &lt;code&gt;getYSize()&lt;/code&gt; functions.  Although you cannot change the size of an image directly, you can rescale an image by filtering it into a larger or smaller PNMImage:

&lt;code python&gt;
fullSize = PNMImage(Filename(&quot;testImg.png&quot;))
reduced = PNMImage(256, 256)
reduced.gaussianFilterFrom(1.0, fullSize)
&lt;/code&gt;

You can get individual RGB values using the &lt;code&gt;getRed(x,y), getGreen(x,y), getBlue(x,y)&lt;/code&gt; or &lt;code&gt;getRedVal(x,y), getGreenVal(x,y), getBlueVal(x,y)&lt;/code&gt; where x and y tell what pixel to look at  (lower-left is 0,0 upper right is &lt;code&gt;getXSize()-1, getYSize()-1&lt;/code&gt; The difference between these functions is that the &lt;code&gt;get*Val&lt;/code&gt; functions return a number between 0 and 1 while the &lt;code&gt;get*&lt;/code&gt; functions return their value as an integer. For example, if your image uses 8-bit color calling &lt;code&gt;getGreenVal&lt;/code&gt; on a green pixel will return 255 and calling &lt;code&gt;getGreen&lt;/code&gt; will return 1. You can also get all the RGB information at the same time using &lt;code&gt;getXel(x,y)&lt;/code&gt; and &lt;code&gt;getXelVal(x,y)&lt;/code&gt; which return a 3 component vector with red in the x, green in the y, and blue in the z.

&lt;code python&gt;
# The pixel at 0,0 is red and we're using 8-bit color
myImage.getRedVal(0,0) # Returns 255
myImage.getRed(0,0) # Returns 1

colors = myImage.getXelVal(0,0) # Returns (255,0,0)
colorVal = myImage.getXel(0,0) # Returns (1,0,0)
&lt;/code&gt;

The functions for setting pixel information  are &lt;code&gt;setRed(x,y,value), setGreen(x,y, value), setBlue(x,y, value)&lt;/code&gt; or &lt;code&gt;setRedVal(x,y,value), setGreenVal(x,y, value), setBlueVal(x,y, value)&lt;/code&gt;. Theres still the same dichotomy as above when it comes to regular sets and using setvals. You can also use &lt;code&gt;setXel(x,y,colorVec)&lt;/code&gt; and &lt;code&gt;setXelVal(x,y, colorVec)&lt;/code&gt;. You can also fill an image with a color by using &lt;code&gt;fill(r,g,b)&lt;/code&gt; and &lt;code&gt;fillVal(r,g,b)&lt;/code&gt;.

&lt;code python&gt;
myImage.setGreenVal(0, 0, 255) # If pixel (0,0) was red before, now it is yellow (255,255,0)
myImage.setBlue(0, 0, 1) # Pixel (0,0) is now white

gray = Vec3(0.5, 0.5, 0.5)

# Both of these set the origin to gray
myImage.setXelVal(0, 0, gray * 255)
myImage.setXel(0, 0, gray)

# Makes every pixel red
myImage.fillVal(255, 0, 0)
# Makes every pixel green
myImage.fill(0, 1, 0)
&lt;/code&gt;

There are also gets and sets for the alpha channel using the same interface as above. However, if you use them on an image that doesn't have an alpha channel you will cause a crash. To see if an image has an alpha channel use &lt;code&gt;hasAlpha()&lt;/code&gt; which returns True if there is an alpha channel and False otherwise. You can add an alpha channel using &lt;code&gt;addAlpha()&lt;/code&gt;. You can also remove it using &lt;code&gt;removeAlpha()&lt;/code&gt;.

You can also make an image grayscale by using &lt;code&gt;makeGrayscale()&lt;/code&gt;. You can now use sets and gets for Gray too. Using &lt;code&gt;getGray*&lt;/code&gt; on a color image just returns the value in the blue channel. If you want to get the grayscale value of a pixel regardless of whether the image is a grayscale or a color image, you can use &lt;code&gt;getBright(x,y)&lt;/code&gt;, which works equally well on color or on grayscale images. If you want to weight the colors use &lt;code&gt;getBright(x,y, r,g,b)&lt;/code&gt; where r,g,b are the weights for their respective channels.

There are several other useful functions in the class this the API Reference for more information.

&lt;h2&gt;Getting the Image of a Texture&lt;/h2&gt;
The Panda &lt;code&gt;Texture&lt;/code&gt; class does not allow for pixel manipulation. However the &lt;code&gt;PNMImage&lt;/code&gt; class below does. Therefore, if you want to change the image in a &lt;code&gt;Texture&lt;/code&gt; object you must call its &lt;code&gt;store(myImage)&lt;/code&gt; which saves the image of the texture into &lt;code&gt;myImage&lt;/code&gt;.

&lt;code python&gt;
myImage = PNMImage()
myTexture = loader.loadTexture(&quot;myTex.jpg&quot;)

# After this call, myImage now holds the same image as the texture
myTexture.store(myImage)
&lt;/code&gt;

&lt;h2&gt;Loading a PNMImage Into a Texture&lt;/h2&gt;
Once you have changed all the data in the image you can now load it into a texture using the &lt;code&gt;Texture&lt;/code&gt; objects &lt;code&gt;load(myImage)&lt;/code&gt; function, where &lt;code&gt;myImage&lt;/code&gt; is the PNMImage to make the texture from.
&lt;code python&gt;
# Assume we already have myImage which is our modified PNMImage
myTexture=Texture()

# This texture now represents myImage
myTexture.load(myImage)

&lt;/code&gt;

Remember however, that most graphics cards require that the dimensions of  texture have to be a power of two. &lt;code&gt;PNMImage&lt;/code&gt; does not have this restriction and Panda will not automatically scale the image when you put it into a texture.</text>
    </revision>
  </page>
  <page>
    <title>Creating Windows and Buffers</title>
    <ns>0</ns>
    <id>2276</id>
      <sha1>etjl3bgghua1qmtl6dzscyndca093q3</sha1>
    <revision>
      <id>7666</id>
      <timestamp>2012-03-08T18:59:22Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tag</comment>
      <text xml:space="preserve" bytes="5307">Although Panda does provide the convenience function &lt;code&gt;base.openWindow()&lt;/code&gt; to create a new window, this function does a lot of things automatically for you and therefore takes away a lot of control.  The following discussion will focus instead on creating a window using the low-level interface, in order provide a clearer understanding of the actual class relationships.

In order to create a window, you will first need a &lt;b&gt;GraphicsEngine&lt;/b&gt; and a &lt;b&gt;GraphicsPipe&lt;/b&gt; object.  Both of these were discussed in more detail in previous pages.  Panda will typically create both of these for you at startup, and store them in &lt;code&gt;base.graphicsEngine&lt;/code&gt; and &lt;code&gt;base.pipe&lt;/code&gt;, respectively.

You will also need to create a &lt;b&gt;FrameBufferProperties&lt;/b&gt; object.  This defines important properties such as the number of bits you wish to allocate for red, green, and blue channels; as well as the number of bits for depth buffer; and whether you require a stencil buffer or special multisampling bits for antialiasing.  Your graphics card may be able to switch itself into one of several different configurations, and you can use the FrameBufferProperties to request certain properties that are more important to you.  Note, however, that there is no guarantee that the graphics card you are running on will be able to provide everything you ask for (but you can later ask what properties you actually got).  You can get a default FrameBufferProperties object using &lt;code&gt;FrameBufferProperties.getDefault()&lt;/code&gt;.  The default FrameBufferProperties has its settings already filled according to the Config.prc file variables; it is usually a good choice to use.

You will need to create a &lt;b&gt;WindowProperties&lt;/b&gt; object as well.  At a minimum, this defines the X, Y size of the window or buffer you want to create.  For an offscreen buffer, this is all it defines; but if you are creating a window, it also allows you to specify things like the window title, the placement onscreen, whether it should be user-resizable, and so on.  You can get a default WindowProperties object using &lt;code&gt;WindowProperties.getDefault()&lt;/code&gt;.  The default WindowProperties object has its settings filled in according to Config.prc file variables.  If you are creating an offscreen buffer, you may wish to use &lt;code&gt;WindowProperties.size(x, y)&lt;/code&gt; which creates a simple WindowProperties object that simply requests a buffer of size x y.

Once you have all of these objects, you can create a new window or buffer using the call graphicsEngine.makeOutput().  This is the fundamental method for creating a new GraphicsOutput; all of the other convenience functions like base.makeWindow() or win.makeTextureBuffer() eventually funnel down into this call.  This method accepts several parameters:

&lt;code python&gt;
base.graphicsEngine.makeOutput(pipe, name, sort, fbProps, winProps, flags, gsg, host)
&lt;/code&gt;

&lt;table&gt;

&lt;tr&gt;&lt;td&gt;&lt;code&gt;pipe&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;The GraphicsPipe to use to create this output, usually &lt;code&gt;base.pipe&lt;/code&gt;.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;&lt;code&gt;name&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;A string name to assign to this output.  Each window and buffer should have a name, which makes it easier for you to identify the object in a list.  This is an internal name only, and has nothing to do with the window title displayed above the window.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;&lt;code&gt;sort&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;The sort order of this output.  This determines the order in which the windows will be rendered, which is particularly important for offscreen buffers that are used to render to textures, which are in turn used in other windows or buffers.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;&lt;code&gt;fbProps&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;The FrameBufferProperties for this output.  If you intend to be sharing GSG's between multiple windows or buffers, it is usually important that they also share the same FrameBufferProperties.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;&lt;code&gt;winProps&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;The WindowProperties for this output.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;&lt;code&gt;flags&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;An integer value, a union of several possible bitmask options defined by the GraphicsPipe class.  This controls the type of GraphicsOutput we are requesting, for instance whether we want a window or buffer, or other exotic requirements.  Set this to GraphicsPipe.BFRequireWindow if you want to create a GraphicsWindow, or to GraphicsPipe.BFRefuseWindow if youw ant to create a GraphicsBuffer.  For more options, see the source code.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;&lt;code&gt;gsg&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;This parameter is optional, but if provided, it is a GSG to share with other windows or buffers.  You can get the GSG from an existing window or buffer with win.getGsg().  If you omit this parameter, a new GSG will be created.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;&lt;code&gt;host&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;This parameter is optional, but if provided, it is an already-existing host window or buffer.  This is useful when creating an offscreen buffer; it allows the creation of a &lt;b&gt;ParasiteBuffer&lt;/b&gt;, if necessary, instead of a true GraphicsBuffer object.  If you provide a host window, Panda will be able to return either a ParasiteBuffer or a GraphicsBuffer, according to what the graphics driver is best able to provide.&lt;/td&gt;&lt;/tr&gt;

&lt;/table&gt;

The return value of makeOutput() is either the new GraphicsWindow or GraphicsBuffer object, or None if it failed for some reason.</text>
    </revision>
  </page>
  <page>
    <title>Creating a Classic Finite State Machine</title>
    <ns>0</ns>
    <id>967</id>
      <sha1>n77f7pc4a31pb9ksty93zh0p1fpmikn</sha1>
    <revision>
      <id>4114</id>
      <timestamp>2007-02-17T13:38:48Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="24">This page is deprecated.</text>
    </revision>
  </page>
  <page>
    <title>Creating a New Node Class</title>
    <ns>0</ns>
    <id>1092</id>
      <sha1>2drhswne3mefkgazd5hct86jm6egazt</sha1>
    <revision>
      <id>2373</id>
      <timestamp>2005-05-04T03:51:36Z</timestamp>
      <contributor>
        <username>Hughperkins</username>
        <id>10</id>
      </contributor>
      <comment>copied and pasted from http://panda3d.org/forum/viewtopic.php?t=326, hope that is ok!</comment>
      <text xml:space="preserve" bytes="2848">== Summary ==

This page describes how to create a new node class, something like src/parametrics/sheetNode .

== Introduction ==

You might want to create a new node class if you wish to contribute a new type of renderable object to Panda.

Generally, you wont need to do this, because it will be easier and better to simply convert your object type into one of the existing Panda node types.

For example, if you wanted to be able to display MD2 animated meshes, it might be better to simply create a conversion utility to convert MD2 meshes into egg files.

== Creating a New Node Class ==

A node class will derive from PandaNode, which is the base class for all nodes.

It will specify its geometry to panda using a qpGeom class ([[Geom]]) class, in src/gobj/qpgeom.

There is some subtle stuff going on in the qpGeom structure. Each qpGeom has its own qpGeomVertexData, which is shared by all of the qpGeomPrimitive objects within the qpGeom. Thus, a qpGeomTristrips object (a kind of qpGeomPrimitive) can decompose itself into qpGeomTriangles (another kind of qpGeomPrimitive) simply by building a new index list, since it will still be within the same qpGeom, and will therefore be keeping the same qpGeomVertexData. 

In your routine, you will probably build up a qpGeomVertexData for all of your vertices, and then one or more qpGeomPrimitives (a single qpGeomTriangles object would be fine) to index into the vertices. Then add them both to a qpGeom, and wrap that up in a CullableObject which gets stored on the CullHandler. In the OpenGL analogy, a qpGeomVertexData corresponds to a glVertexPointer() call, and each qpGeomPrimitive is a glBegin(), glDrawElements(), glEnd(). 

If you can cache this qpGeom object across multiple frames, so much the better, but if you don't, that's ok too. Also note that the qp prefix is temporary and will eventually go away. 

For now, ignore the CData object you see everywhere; that's just a placeholder for when we add multithreaded pipeline support. It's a level of indirection that we will have to live with to support pipelining. In the meantime, just imagine that everything stored within the CData is actually stored on the class itself. 

All you really need to override in your PandaNode-derived class is has_cull_callback() and cull_callback(). 

To fit into Panda's run-time type system, you will also want to override init_type() and get_type(), following the examples of other nodes, and call init_type() sometime at startup. This is optional at this point. 

Once you get down the road a ways, you can start to think about overriding one of xform() or safe_to_flatten() to make nodePath.flattenLight() do the right thing, and write_datagram(), fillin(), and make_from_bam() if you want to be able to save your nodes in a bam file. But I wouldn't worry about either of these right now.</text>
    </revision>
  </page>
  <page>
    <title>Creating a hidden Window</title>
    <ns>0</ns>
    <id>1266</id>
      <sha1>5xhbhavakui45ylanhpxc4vfslxojop</sha1>
    <revision>
      <id>2545</id>
      <timestamp>2005-11-01T23:35:40Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="20">Section coming soon.</text>
    </revision>
  </page>
  <page>
    <title>Creating a normal Window</title>
    <ns>0</ns>
    <id>1265</id>
      <sha1>5xhbhavakui45ylanhpxc4vfslxojop</sha1>
    <revision>
      <id>2544</id>
      <timestamp>2005-11-01T23:35:28Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="20">Section coming soon.</text>
    </revision>
  </page>
  <page>
    <title>Creating and filling a GeomVertexData</title>
    <ns>0</ns>
    <id>1770</id>
      <sha1>ccrlk1b41j2qr70lnydbp93u28olf13</sha1>
    <revision>
      <id>60177</id>
      <timestamp>2014-06-22T14:22:03Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="7560">Once you have a [[GeomVertexFormat]], registered and ready to use, you can
use it to create a [[GeomVertexData|&lt;b&gt;GeomVertexData&lt;/b&gt;]].

[python]&lt;code python&gt;
vdata = GeomVertexData('name', format, Geom.UHStatic)
&lt;/code&gt;[/python]
[cxx]
Using a [[Defining your own GeomVertexFormat|custom vertex format]].
&lt;code cxx&gt;
PT(GeomVertexData) vdata;
vdata = new GeomVertexData(&quot;name&quot;, format, Geom::UH_static);
&lt;/code&gt;
Or using a [[Pre-defined_vertex_formats|Pre-defined vertex format]].
&lt;code cxx&gt;
PT(GeomVertexData) vdata;
vdata = new GeomVertexData(&quot;name&quot;, GeomVertexFormat::get_????(), Geom::UH_static);
&lt;/code&gt;
[/cxx]

The first parameter to the GeomVertexData constructor is the name of
the data, which is any arbitrary name you like.  This name is mainly
for documentation purposes; it may help you identify this vertex data
later.  You can leave it empty if you like.

The second parameter is the [[GeomVertexFormat]] to use for this
GeomVertexData.  The format specifies the number of arrays that will
be created for the data, the names and formats of the columns in each array, and the
number of bytes that need to be allocated for each row.

The third parameter is a usage hint, which tells Panda how often (if
ever) you expect to be modifying these vertices, once you have filled
them in the first time.  If you will be filling in the vertices once
(or only once in a while) and using them to render many frames
without changing them, you should use Geom.UHStatic.  The vast
majority of vertex datas are of this form.  Even GeomVertexDatas that
include vertex animation tables should usually be declared
Geom.UHStatic, since the vertex data itself will not be changing (even
though the vertices might be animating).

However, occasionally you might create a GeomVertexData whose vertices
you intend to adjust in-place every frame, or every few frames; in this case, you can specify
Geom.UHDynamic, to tell Panda not to make too much effort to cache the
vertex data.  This is just a performance hint; you're not required to
adhere to the usage you specify, though you may get better render
performance if you do.

If you are unsure about this third parameter, you should probably use
Geom.UHStatic.

Next, it is '''highly recommended''' that you set the number of rows you're going to write.  This is an optional step; Panda will resize the underlying table appropriately as you are adding new data, but this will cause every &lt;code&gt;add_dataXX()&lt;/code&gt; call to be ''much slower'' than if you had specified a number of rows.
[python]&lt;code python&gt;
vdata.setNumRows(4)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
vdata-&gt;set_num_rows(4);
&lt;/code&gt;[/cxx]

Now that you have created a GeomVertexData, you should create a number
of [[More about GeomVertexReader, GeomVertexWriter, and GeomVertexRewriter|GeomVertexWriters]], one for each column, to fill in the data.

[python]&lt;code python&gt;
vertex = GeomVertexWriter(vdata, 'vertex')
normal = GeomVertexWriter(vdata, 'normal')
color = GeomVertexWriter(vdata, 'color')
texcoord = GeomVertexWriter(vdata, 'texcoord')
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
GeomVertexWriter vertex, normal, color, texcoord;
vertex = GeomVertexWriter(vdata, &quot;vertex&quot;);
normal = GeomVertexWriter(vdata, &quot;normal&quot;);
color = GeomVertexWriter(vdata, &quot;color&quot;);
texcoord = GeomVertexWriter(vdata, &quot;texcoord&quot;);
&lt;/code&gt;[/cxx]

It is your responsibility to know which columns exist in the
GeomVertexFormat you have used.  It is legal to create a
GeomVertexWriter for a column that doesn't exist, but it will be an
error if you later attempt to use it to add data.

To add data, you can now iterate through your vertices and call one of
the addData methods on each GeomVertexWriter.

[python]&lt;code python&gt;
vertex.addData3f(1, 0, 0)
normal.addData3f(0, 0, 1)
color.addData4f(0, 0, 1, 1)
texcoord.addData2f(1, 0)

vertex.addData3f(1, 1, 0)
normal.addData3f(0, 0, 1)
color.addData4f(0, 0, 1, 1)
texcoord.addData2f(1, 1)

vertex.addData3f(0, 1, 0)
normal.addData3f(0, 0, 1)
color.addData4f(0, 0, 1, 1)
texcoord.addData2f(0, 1)

vertex.addData3f(0, 0, 0)
normal.addData3f(0, 0, 1)
color.addData4f(0, 0, 1, 1)
texcoord.addData2f(0, 0)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
vertex.add_data3f(1, 0, 0);
normal.add_data3f(0, 0, 1);
color.add_data4f(0, 0, 1, 1);
texcoord.add_data2f(1, 0);

vertex.add_data3f(1, 1, 0);
normal.add_data3f(0, 0, 1);
color.add_data4f(0, 0, 1, 1);
texcoord.add_data2f(1, 1);

vertex.add_data3f(0, 1, 0);
normal.add_data3f(0, 0, 1);
color.add_data4f(0, 0, 1, 1);
texcoord.add_data2f(0, 1);

vertex.add_data3f(0, 0, 0);
normal.add_data3f(0, 0, 1);
color.add_data4f(0, 0, 1, 1);
texcoord.add_data2f(0, 0);
&lt;/code&gt;[/cxx]

Each call to addData() adds a new row (vertex) to the vertex data, if
there is not already one there.  The above sample code creates the
following data table:

&lt;center&gt;&lt;table style=&quot;border-collapse: collapse&quot;&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;vertex&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;normal&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;color&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;texcoord&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td style=&quot;padding-right: 5pt&quot;&gt;0&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(1, 0, 0)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0, 1)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0, 1, 1)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(1, 0)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td style=&quot;padding-right: 5pt&quot;&gt;1&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(1, 1, 0)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0, 1)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0, 1, 1)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(1, 1)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td style=&quot;padding-right: 5pt&quot;&gt;2&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 1, 0)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0, 1)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0, 1, 1)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 1)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td style=&quot;padding-right: 5pt&quot;&gt;3&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0, 0)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0, 1)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0, 1, 1)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0)&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;

Note that there is no relationship between the different
GeomVertexWriters, other than the fact that they are operating on the
same table.  Each GeomVertexWriter maintains its own counter of its
current row.  This means you must fill in the data for every row of
each column, even if you don't care about writing the data for some
particular column on certain rows.  For instance, even if you want to
allow the default color for vertex 1 and 2, you must still call
color.addData4f() four times, in order to fill in the color value for
vertex 3.</text>
    </revision>
  </page>
  <page>
    <title>Creating multiple packages</title>
    <ns>0</ns>
    <id>2412</id>
      <sha1>rcv2mbjyt9a6u5dd09j9x9u1e636gnx</sha1>
    <revision>
      <id>6270</id>
      <timestamp>2009-10-21T00:00:36Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="529">
A pdef file can contain multiple package and/or p3d file definitions.  Each package named in a pdef file is created and placed in the output directory you specify with -i on the ppackage command line, and the contents.xml file at the root of the output directory is updated to describe all of the packages within.

You can also run ppackage multiple times, with a different pdef file each time, and specify the same output directory.  Each time, additional packages can be built, and the output directory is updated accordingly.</text>
    </revision>
  </page>
  <page>
    <title>Creating the GeomPrimitive objects</title>
    <ns>0</ns>
    <id>1771</id>
      <sha1>qsldyc7bua931bbymcjs1o5nrlmtr9n</sha1>
    <revision>
      <id>7160</id>
      <timestamp>2011-05-25T07:30:05Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <text xml:space="preserve" bytes="5735">Now that you have a [[GeomVertexData]] with a set of vertices, you can
create one or more [[GeomPrimitive|&lt;b&gt;GeomPrimitive&lt;/b&gt;]] objects that use the vertices in your
GeomVertexData.

In general, you do this by first creating a GeomPrimitive of the
appropriate type, and then calling addVertex() for each vertex in your
primitive, followed by closePrimitive() after each primitive is
complete.

Different GeomPrimitive types have different requirements for the
number of vertices per primitive.  Some always have a fixed amount of
vertices, like GeomTriangles, GeomLines and GeomPoints.  You should
simply add all of the vertices for these primitives.  Some people call
close_primitive after adding every primitive, but this is not strictly
necessary.
Other GeomPrimitive types have a variable number of vertices, like
GeomTristrips, GeomTrifans and GeomLinestrips.  Because you need to
tell Panda3D how many vertices are in every primitive, you should call
close_primitive() after adding every primitive.

For example:

[python]&lt;code python&gt;
prim = GeomTriangles(Geom.UHStatic)

prim.addVertex(0)
prim.addVertex(1)
prim.addVertex(2)
# thats the first triangle

# you can also add a few at once
prim.addVertices(2, 1, 3)

prim.addVertices(0, 5, 6)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
// In order for this to work you need to have included &quot;geomTriangles.h&quot;

PT(GeomTriangles) prim;
prim = new GeomTriangles(Geom::UH_static);

prim-&gt;add_vertex(0);
prim-&gt;add_vertex(1);
prim-&gt;add_vertex(2);
// thats the first triangle

// you can also add a few at once
prim-&gt;add_vertices(2, 1, 3);

prim-&gt;add_vertices(0, 5, 6);
&lt;/code&gt;[/cxx]

Note that the GeomPrimitive constructor requires one parameter, which
is a usage hint, similar to the usage hint required for the
[[GeomVertexData]] constructor.  Like that usage hint, this tells Panda
whether you will frequently adjust the vertex indices on this
primitive after it has been created.  Since it is very unusual to
adjust the vertex indices on a primitive (usually, if you intend to
animate the vertices, you would operate on the vertices, not these
indices), this is almost always Geom.UHStatic, even if the primitive
is associated with a dynamic GeomVertexData.  However, there may be
special rendering effects in which you actually do manipulate this
vertex index table in-place every few frames, in which case you should use
Geom.UHDynamic.  As with the GeomVertexData, this is only a
performance hint; you're not required to adhere to the usage you
specify.

If you are unsure about this parameter, you should use Geom.UHStatic.

The above sample code defines a GeomTriangles object that looks like
this:

&lt;center&gt;&lt;table style=&quot;border-collapse: collapse&quot;&gt;
&lt;tr&gt;
&lt;td style=&quot;padding-left: 64pt&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; text-align: center&quot;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; text-align: center&quot;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; text-align: center&quot;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; text-align: center&quot;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; text-align: center&quot;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; text-align: center&quot;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; text-align: center&quot;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; text-align: center&quot;&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; text-align: center&quot;&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;

The actual positions of the vertices depends on the values of the vertices numbered 0, 1, 2, 3, and 5 in the associated [[GeomVertexData]] (you will associate your GeomPrimitives with a GeomVertexData [[Putting your new geometry in the scene graph|in the next step]], when you attach the GeomPrimitives to a [[Geom]]).

Finally, there are a few handy shortcuts for adding multiple vertices
at once:

&lt;center&gt;&lt;table style=&quot;border-collapse: collapse&quot;&gt;

&lt;tr&gt;&lt;td style=&quot;border-top: 1px solid black; padding-right: 5pt&quot; width=&quot;40%&quot;&gt;
prim[python].[/python][cxx]-&gt;[/cxx][func]addVertices[/func](v1, v2)[;]&lt;br&gt;
prim[python].[/python][cxx]-&gt;[/cxx][func]addVertices[/func](v1, v2, v3)[;]&lt;br&gt;
prim[python].[/python][cxx]-&gt;[/cxx][func]addVertices[/func](v1, v2, v3, v4)[;]&lt;br&gt;
&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; padding-right: 5pt&quot;&gt;
Adds 2, 3, or 4 vertices in a single call.
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td style=&quot;border-top: 1px solid black; padding-right: 5pt&quot;&gt;
prim[python].[/python][cxx]-&gt;[/cxx][func]addConsecutiveVertices[/func](start, numVertices)[;]
&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; padding-right: 5pt&quot;&gt;
Adds &lt;i&gt;numVertices&lt;/i&gt; consecutive vertices, beginning at vertex &lt;i&gt;start&lt;/i&gt;.  For
instance, [func]addConsecutiveVertices[/func](5, 3) adds vertices 5, 6, 7.
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td style=&quot;border-top: 1px solid black; border-bottom: 1px solid black; padding-right: 5pt&quot;&gt;
prim[python].[/python][cxx]-&gt;[/cxx][func]addNextVertices[/func](numVertices)[;]
&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; border-bottom: 1px solid black; padding-right: 5pt&quot;&gt;
Adds &lt;i&gt;numVertices&lt;/i&gt; consecutive vertices, beginning with the next vertex
after the last vertex you added, or beginning at vertex 0 if these are the first vertices.  For instance, prim.addVertex(10)
adds vertex 10.  If you immediately call prim.addNextVertices(4), it
adds vertices 11, 12, 13, 14.
&lt;/td&gt;&lt;/tr&gt;

&lt;/table&gt;&lt;/center&gt;

None of the above shortcut methods calls closePrimitive() for you; it is still your responsibility to call closePrimitive() each time you add the appropriate number of vertices.</text>
    </revision>
  </page>
  <page>
    <title>Cube Map Support</title>
    <ns>0</ns>
    <id>1156</id>
      <sha1>1dkip6f4434wrbdq0aozt4b3uvuei4j</sha1>
    <revision>
      <id>4865</id>
      <timestamp>2008-03-13T03:21:30Z</timestamp>
      <contributor>
        <username>Admin</username>
        <id>1</id>
      </contributor>
      <text xml:space="preserve" bytes="24">this page is deprecated.</text>
    </revision>
  </page>
  <page>
    <title>Cube Maps</title>
    <ns>0</ns>
    <id>1230</id>
      <sha1>runrr9cki6va07bezy3dn5revg6md0d</sha1>
    <revision>
      <id>7640</id>
      <timestamp>2012-03-08T18:06:35Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="3625">There is one more special kind of texture map: the &lt;b&gt;cube map&lt;/b&gt;,
which is introduced in Panda3D version 1.1.  A cube map is similar to
a [[3-D Textures|3-D texture]], in that it requires 3-D texture
coordinates &lt;i&gt;(u, v, w)&lt;/i&gt;; also, a cube map is stored on disk as a
sequence of ordinary 2-D images.

But unlike a 3-D texture, which is defined by stacking up an arbitrary
number 2-D images like pancakes to fill up a volume, a cube map is
always defined with exactly six 2-D images, which are folded together
to make a cube.

The six images of a cube map are numbered from 0 to 5, and each image
corresponds to one particular face of the cube:

&lt;table&gt;
&lt;tr&gt;&lt;td&gt;image 0&lt;/td&gt;&lt;td&gt;The &lt;i&gt;+u&lt;/i&gt; (or &lt;i&gt;+x&lt;/i&gt;) face (right)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;image 1&lt;/td&gt;&lt;td&gt;The &lt;i&gt;-u&lt;/i&gt; (or &lt;i&gt;-x&lt;/i&gt;) face (left)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;image 2&lt;/td&gt;&lt;td&gt;The &lt;i&gt;+v&lt;/i&gt; (or &lt;i&gt;+y&lt;/i&gt;) face (forward)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;image 3&lt;/td&gt;&lt;td&gt;The &lt;i&gt;-v&lt;/i&gt; (or &lt;i&gt;-y&lt;/i&gt;) face (back)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;image 4&lt;/td&gt;&lt;td&gt;The &lt;i&gt;+w&lt;/i&gt; (or &lt;i&gt;+z&lt;/i&gt;) face (up)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;image 5&lt;/td&gt;&lt;td&gt;The &lt;i&gt;-w&lt;/i&gt; (or &lt;i&gt;-z&lt;/i&gt;) face (down)&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

By &lt;i&gt;+x&lt;/i&gt; face, we mean the face of the cube farthest along the
positive X axis.  In Panda3D's default Z-up coordinate system, this is
the &lt;i&gt;right&lt;/i&gt; face.  Similarly, the &lt;i&gt;-x&lt;/i&gt; face is the face
farthest along the negative X axis, or the &lt;i&gt;left&lt;/i&gt; face, and so on
for the Y and Z faces.  Since the coordinates of a texture map are
called &lt;i&gt;(u, v, w)&lt;/i&gt; instead of &lt;i&gt;(x, y, z)&lt;/i&gt;, it is technically
more correct to call these the &lt;i&gt;+u&lt;/i&gt; and &lt;i&gt;-u&lt;/i&gt; faces, though
it is often easier to think of them as &lt;i&gt;+x&lt;/i&gt; and &lt;i&gt;-x&lt;/i&gt;.

The faces are laid out according to the following diagram:

[[Image:Exploded cube map.png|The arrangement of the six faces of a cube map]]

Imagine that you cut out the above diagram and folded it into a cube.
You'd end up with something like this:

[[Image:Mapped cube map solid.png|A solid-mapped cube]]

Note that, when you hold the cube so that the axis indications for
each face are in the appropriate direction (as in the picture above),
several of the faces are upside-down or sideways.  That's because of
the way the graphics card manufacturers decided to lay out the cube
map faces (and also because of Panda3D's default coordinate system).
But in fact, it doesn't matter which way the faces are oriented, as
long as you always generate your cube map images the same way.

In some sense, a cube map is a kind of surface texture, like an
ordinary 2-D texture.  But in other sense, it is also volumetric like
a 3-D texture: every point within the 3-D texture coordinate space is
colored according to the face of the cube it comes closest to.  A sphere model with the cube map applied to it would pick up the same six faces:

[[Image:Mapped cube map.png|A wireframe cube, showing the internal mapped space]]

Note that, while a 3-D texture assigns a different pixel in the
texture to every &lt;i&gt;point&lt;/i&gt; within a volume, a cube map assigns a
different pixel in the texture to every &lt;i&gt;direction&lt;/i&gt; from the
center.

You can load a cube map from a series of six image files, very similar to the way you load a 3-D texture:

&lt;code python&gt;
tex = loader.loadCubeMap('cubemap_#.png')
&lt;/code&gt; 

As with a 3-D texture, the hash mark (&quot;#&quot;) in the filename will be
filled in with the image sequence number, which in the case of a cube
map will be a digit from 0 to 5.  The above example, then, will load
the six images &quot;cubemap_0.png&quot;, &quot;cubemap_1.png&quot;, &quot;cubemap_2.png&quot;,
&quot;cubemap_3.png&quot;, &quot;cubemap_4.png&quot;, and &quot;cubemap_5.png&quot;, and assemble
them into one cube map.</text>
    </revision>
  </page>
  <page>
    <title>CullFaceAttrib</title>
    <ns>0</ns>
    <id>2249</id>
    <redirect title="Backface Culling and Frontface Culling" />
      <sha1>294d9u6ldw8j3hncdczulwur379l1m0</sha1>
    <revision>
      <id>5338</id>
      <timestamp>2008-04-07T18:26:50Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[Backface Culling and Frontface Culling]]</comment>
      <text xml:space="preserve" bytes="52">#REDIRECT [[Backface Culling and Frontface Culling]]</text>
    </revision>
  </page>
  <page>
    <title>DC File</title>
    <ns>0</ns>
    <id>2496</id>
      <sha1>t1sdef4pycutx4zvf96invefp2aj6xm</sha1>
    <revision>
      <id>7568</id>
      <timestamp>2012-01-12T23:08:49Z</timestamp>
      <contributor>
        <username>PiratePanda</username>
        <id>522</id>
      </contributor>
      <text xml:space="preserve" bytes="9282">The .dc file defines what distributed objects, and their functions, are communicated across the network.

This is the direct.dc file, which defines the necessary functionality for the distributed objects bundled with panda3d.

The syntax is based on C++ as, at the time, Panda was C++ only.

Here is the complete example with line by line explanation to follow.

&lt;code python&gt;
// Comments are with two slashes
// Like C most lines must end with semicolons, except for the import statements

//keyword required;
keyword broadcast; 
keyword ram;       
//keyword db;
keyword p2p;
// keyword clsend;

// Currently unknown if these are implemented in the CMU distributed system.

// ownsend;
// airecv; // Special message to be received only by the AI, which will be described later. Not implimented
 
from direct.distributed import DistributedObject/AI
from direct.distributed import TimeManager/AI
from direct.distributed import DistributedNode/AI
from direct.distributed import DistributedSmoothNode/AI

struct BarrierData {
  uint16 context;
  string name;
  uint32 avIds[];
};

// The most fundamental class mapped to a python object.
dclass DistributedObject {
  // These are used to support DistributedObjectAI.beginBarrier() and
  // the matching DistributedObject.doneBarrier().  If you do not call
  // these functions, you don't care about these distributed methods.
  // (Actually, you probably don't care anyway.)
  setBarrierData(BarrierData data[]) broadcast ram;
  setBarrierReady(uint16 context);
  setLocation(uint32 parentId, uint32 zoneId) broadcast ram;
};

dclass TimeManager: DistributedObject {
  requestServerTime(uint8 context) p2p;
  serverTime(uint8 context, int32 timestamp);
};


// Inheritance of other dc definitions is allowed with the syntax: dclass NewObject: ParentObject {};
dclass DistributedNode: DistributedObject {
  setX(int16 / 10) broadcast ram;
  setY(int16 / 10) broadcast ram;
  setZ(int16 / 10) broadcast ram;
  setH(int16 % 360 / 10) broadcast ram;
  setP(int16 % 360 / 10) broadcast ram;
  setR(int16 % 360 / 10) broadcast ram;

  setPos: setX, setY, setZ;
  setHpr: setH, setP, setR;
  setPosHpr: setX, setY, setZ, setH, setP, setR;
  setXY: setX, setY;
  setXZ: setX, setZ;
  setXYH: setX, setY, setH;
  setXYZH: setX, setY, setZ, setH;
};

dclass DistributedSmoothNode: DistributedNode {
  // Component set pos and hpr functions.

  setComponentL(uint64) broadcast ram;
  setComponentX(int16 / 10) broadcast ram;
  setComponentY(int16 / 10) broadcast ram;
  setComponentZ(int16 / 10) broadcast ram;
  setComponentH(int16 % 360 / 10) broadcast ram;
  setComponentP(int16 % 360 / 10) broadcast ram;
  setComponentR(int16 % 360 / 10) broadcast ram;
  setComponentT(int16 timestamp) broadcast ram;

  // Composite set pos and hpr functions.  These map to combinations
  // of one or more of the above components.  They all include
  // setComponentT(), which must be called last.
  setSmStop: setComponentT;
  setSmH: setComponentH, setComponentT;
  setSmZ: setComponentZ, setComponentT;
  setSmXY: setComponentX, setComponentY, setComponentT;
  setSmXZ: setComponentX, setComponentZ, setComponentT;
  setSmPos: setComponentX, setComponentY, setComponentZ, setComponentT;
  setSmHpr: setComponentH, setComponentP, setComponentR, setComponentT;
  setSmXYH: setComponentX, setComponentY, setComponentH, setComponentT;
  setSmXYZH: setComponentX, setComponentY, setComponentZ, setComponentH, setComponentT;
  setSmPosHpr: setComponentX, setComponentY, setComponentZ, setComponentH, setComponentP, setComponentR, setComponentT;
  // special update if L (being location, such as zoneId) changes, send everything, intended to
  // keep position and 'location' in sync
  setSmPosHprL: setComponentL, setComponentX, setComponentY, setComponentZ, setComponentH, setComponentP, setComponentR, setComponentT;

  clearSmoothing(int8 bogus) broadcast;

  suggestResync(uint32 avId, int16 timestampA, int16 timestampB,
                int32 serverTimeSec, uint16 serverTimeUSec,
                uint16 / 100 uncertainty);
  returnResync(uint32 avId, int16 timestampB,
               int32 serverTimeSec, uint16 serverTimeUSec,
               uint16 / 100 uncertainty);
}; &lt;/code&gt;

&lt;h3&gt;Keywords&lt;/h3&gt;
&lt;code python&gt;//keyword required;
keyword broadcast;  
keyword ram;       
//keyword db;
keyword p2p;
//keyword clsend;

// Currently unknown if these are implemented in the CMU distributed system.
// ownsend;
// aireceive; &lt;/code&gt;

Keywords define the circumstances for propagating the data. They must be defined at the start of the file.
&lt;ol&gt;
&lt;li&gt;required: The parameters must be defined when generate() is called.
&lt;li&gt;broadcast: By default only the owner of the object will receive update messages. With the broadcast tag all copies of the object will receive the message. This will be the most frequently sued tag in most cases, leave off when you only want the owner of the object to receive a message such as a private chat, receiving gold, etd.
&lt;li&gt;ram: Normally the values sent over the wire will only be received by the interested clients, but a new client will not receive previously sent values. This is useful for things like chat. The values passed with a ram keyword will persist in memory and new clients will receive messages previously sent. This will be useful for things like position or names.
&lt;li&gt;db: Values stored into a database. This is currently not implemented in the CMU open source distributed system.
&lt;li&gt;p2p: Only the owner of the object will receive updates for this method. The clsend keyword is implicitly included with this keyword.
&lt;li&gt;clsend: Normally only the owner of the object is allowed to send updates. With this keyword, the method can be updated by any client.
&lt;li&gt;aireceive: Special message to be received only by the AI, which will be described later
&lt;/ol&gt;

&lt;h3&gt;Python Imports&lt;/h3&gt;
&lt;code python&gt;from direct.distributed import DistributedObject/AI
from direct.distributed import TimeManager/AI
from direct.distributed import DistributedNode/AI
from direct.distributed import DistributedSmoothNode/AI&lt;/code&gt;

Any python objects to be mapped for distributed networking should be imported here. A modified python syntax is used. In the first line DistributedObject.py and DistributedObjectAI.py will be mapped. The purpose for *AI.py files will be described in a later section.

&lt;h3&gt;Structs&lt;/h3&gt;
&lt;code python&gt;struct BarrierData {
  uint16 context;
  string name;
  uint32 avIds[];
};&lt;/code&gt;

You can define C-style structs in addition to the dclass (defined below).  This is really the same thing as a dclass, except it can be embedded in a message rather than created as an object in its own right.  The struct may or may not correspond with a Python class of the same name.  If the struct does have a Python representation, an instance of that class is created and passed in to functions that receive this kind of parameter; otherwise, a tuple with all of the fields is passed instead. 

&lt;h3&gt;Variable Types&lt;/h3&gt;
Due to the nature of the underlying datagram network system there are several fields, or containers, that can be used to transmit data. The &quot;smaller&quot; the package you can use, the less bandwidth used. Like C and unlike python the variables need to be typed.

Possible types are:
&lt;ol&gt;
&lt;li&gt;int8, int16, int32, and int64: Integer values and bit size and uint* for unsigned integers.
&lt;li&gt;float64: A C double, for floating point numbers
&lt;li&gt;string: An arbitrary string up to 64k in length. Obviously bandwidth intensive  so avoid for frequent communication
&lt;li&gt;char: Same as int8 but will be realized as a character
&lt;li&gt;blob: String but arbitrary byte sequence usually not intended for print or  something encoded that is too complicated for the normal dc system
&lt;li&gt;Structures can also be identified as well.
&lt;/ol&gt;

&lt;h3&gt;dclass&lt;/h3&gt;
&lt;code python&gt;dclass DistributedNode: DistributedObject {&lt;/code&gt;

Here the methods to be mapped in DistributedNode AND DistributedNodeAI are defined. Note that this inherits the definition of DistributedObject. Multiple inheritance is also allowed.

&lt;code python&gt;  setX(int16 / 10) broadcast ram;
  setY(int16 / 10) broadcast ram;
  setZ(int16 / 10) broadcast ram;&lt;/code&gt;

Here are three function definitions. When a DistributedNode receives a message with the name &quot;setX&quot;, DistributedNode.setX() will be called and the values passed to the function.

Syntax: functionName(container variable1 &lt;, container variable 2,...&gt;) &lt;parameters&gt;;

To conserve bandwidth when passing small float values it is possible to convert them into ints by multiplying them by the given value and dividing them again. int16 / 10 gives single point precision for values between -3276.7 to 3276.7. int16 / 100 will give two point precision for values between -327.67 and 327.67.

&lt;code python&gt;
  setH(int16 % 360 / 10) broadcast ram;
  setP(int16 % 360 / 10) broadcast ram;
  setR(int16 % 360 / 10) broadcast ram;

  setPos: setX, setY, setZ;
  setHpr: setH, setP, setR;
  setPosHpr: setX, setY, setZ, setH, setP, setR;
  setXY: setX, setY;
  setXZ: setX, setZ;
  setXYH: setX, setY, setH;
  setXYZH: setX, setY, setZ, setH;
};&lt;/code&gt;

These messages are composed of previously defined messages. The message &quot;setPos&quot; will contain the message &quot;setX&quot;, &quot;setY&quot;, &quot;setZ&quot; and their appropriate values.</text>
    </revision>
  </page>
  <page>
    <title>DSP Effects</title>
    <ns>0</ns>
    <id>1789</id>
      <sha1>1bdx5fu97z65y55esdroxcbydcdcf4l</sha1>
    <revision>
      <id>7647</id>
      <timestamp>2012-03-08T18:22:15Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>new import system</comment>
      <text xml:space="preserve" bytes="2431">DSP, or Digital Signal Processing, allows you to apply effect filters to your ingame audio. As of now, DSP effects are only available in Panda if you use the FMOD audio library. By default, Panda ships using the OpenAL audio library but FMOD can be enabled simply by editing [[Configuring_Panda|Config.prc]]. Please keep in mind that using FMOD in a commercial application will require purchasing a license.

You will need to change this line in your Config.prc: (some versions of Panda might already be set to FMOD)&lt;br&gt;
&lt;code&gt;
audio-library-name p3openal_audio
&lt;/code&gt;

To this:&lt;br&gt;
&lt;code&gt;
audio-library-name p3fmod_audio
&lt;/code&gt;

&lt;h2&gt;The FilterProperties Object&lt;/h2&gt;

Any DSP you add to your sound will require the use of &quot;FilterProperties&quot;, which is a list of filters and their coefficients. Start with this import:

&lt;code python&gt;
from panda3d.core import FilterProperties
&lt;/code&gt;

This will allow you to create lists of filters, like this one:

&lt;code python&gt;
fp = FilterProperties()
&lt;/code&gt;

This just adds a blank filter list. From here we can add whatever filter we'd like. To stay consistent with the example below, we'll add a reverb effect.

&lt;code python&gt;
fp.addReverb(0.6, 0.5, 0.1, 0.1, 0.1)
&lt;/code&gt;

All this really does is add this particular reverb to our filter list - sound is not yet affected. To apply these filters to our audio output, use:

&lt;code python&gt;
audioMgr.configureFilters(fp)
&lt;/code&gt;

where &lt;code&gt;audioMgr&lt;/code&gt; is an &lt;code&gt;AudioManager&lt;/code&gt; object, most likely &lt;code&gt;base.sfxManagerList[0]&lt;/code&gt; or &lt;code&gt;base.musicManager&lt;/code&gt;.

Depending on the sound you use, reverb may be very or only slightly noticeable; try using a quick sound at first, like a clap.

You can add more than just reverb to your sound. The full list of available filters is here:

http://panda3d.org/apiref.php?page=FilterProperties

Below is a sample program for adding a reverb effect:

&lt;code python&gt;
# This is just to ensure that we are using FMOD. In your application,
# please edit the Config.prc file that you distribute
from panda3d.core import loadPrcFileData
loadPrcFileData(&quot;&quot;, &quot;audio-library-name p3fmod_audio&quot;)

import direct.directbase.DirectStart
from panda3d.core import FilterProperties

mySound = loader.loadSfx(&quot;models/audio/sfx/GUI_rollover.wav&quot;)
mySound.setLoop(True)
mySound.play()

fp = FilterProperties()
fp.addReverb(0.6, 0.5, 0.1, 0.1, 0.1)
base.sfxManagerList[0].configureFilters(fp)

run()
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>Datagram Protocol</title>
    <ns>0</ns>
    <id>2043</id>
      <sha1>an9bgspuqvnnuua0h8g07dnzrqjron7</sha1>
    <revision>
      <id>3973</id>
      <timestamp>2006-11-03T04:26:51Z</timestamp>
      <contributor>
        <username>Fixer</username>
        <id>52</id>
      </contributor>
      <minor/>
      <comment>Extended description</comment>
      <text xml:space="preserve" bytes="576">Underpinning Panda's networking capabilities are the classes that compose the datagram protocol. These classes allow for developer-defined packets to be transmitted using either the UDP or TCP protocols. Panda's datagram layer can serve as a solid foundation for developing higher-level networking abstractions.

This section describes the classes used to establish a connection (QueuedConnectionManager,QueuedConnectionListener, QueuedConnectionReader, and ConnectionWriter), as well as the classes that transmit information (NetDatagram, PyDatagram, and PyDatagramIterator).</text>
    </revision>
  </page>
  <page>
    <title>Debugging</title>
    <ns>0</ns>
    <id>2195</id>
      <sha1>hgrq535rewqu1d8y1fy788j8d7gt07h</sha1>
    <revision>
      <id>4834</id>
      <timestamp>2008-03-12T20:48:57Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="96">This section documents the various debugging tools to use to find problems in a Panda3D program.</text>
    </revision>
  </page>
  <page>
    <title>Debugging and Performance Tuning</title>
    <ns>0</ns>
    <id>2056</id>
      <sha1>k4nwlxwp3h93y5r9mrwzjrb4c63f7hc</sha1>
    <revision>
      <id>4068</id>
      <timestamp>2007-02-15T14:09:52Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>created page</comment>
      <text xml:space="preserve" bytes="111">In this section you will learn how to debug your python game and how to tune up your performance, if it's slow.</text>
    </revision>
  </page>
  <page>
    <title>Defining your own GeomVertexFormat</title>
    <ns>0</ns>
    <id>1768</id>
      <sha1>ts6s4blssg6mk327gp6ypjwyj5zq3su</sha1>
    <revision>
      <id>60480</id>
      <timestamp>2015-03-16T10:50:07Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="4167">Before you can create any geometry in Panda3D, you must have a valid
[[GeomVertexFormat|&lt;b&gt;GeomVertexFormat&lt;/b&gt;]].  You can decide exactly which columns you want to
have in your format, by building the format up one column at a time.
(But you might be able to avoid this effort by taking advantage of one of the [[Pre-defined vertex formats|pre-defined formats]] listed on the next page.)

To build up your custom format, you need to first create an empty &lt;b&gt;GeomVertexArrayFormat&lt;/b&gt;,
and add columns one at a time by calling addColumn():
[python]
&lt;code python&gt;
array = GeomVertexArrayFormat()
array.addColumn(&quot;vertex&quot;, 3, Geom.NTFloat32, Geom.CPoint)
&lt;/code&gt;
[/python]
[cxx]
&lt;code cxx&gt;
PT(GeomVertexArrayFormat) array;
array = new GeomVertexArrayFormat();
array-&gt;add_column(InternalName::make(&quot;vertex&quot;), 3,
                  Geom::NT_float32, Geom::C_point);
&lt;/code&gt;
[/cxx]

The parameters to addColumn() are, in order, the column name, the
number of components, the numeric type, and the contents
specification.  See [[GeomVertexFormat]] for a detailed description of
each of these parameters and their appropriate values.  You may also
supply an optional fifth parameter, which specifies the byte offset
within the row at which the column's data begins; but normally you
should omit this to indicate that the column's data immediately
follows the previous column's data.

Note that the column name should be an &lt;b&gt;InternalName&lt;/b&gt; object, as
returned by a call to InternalName.make().  This is Panda's
mechanism for tokenizing a string name, to allow for fast name lookups
during rendering.  Other than this detail, the column name is really just an arbitrary string.

It is your responsibility to ensure that all of the parameters passed
to addColumn() are appropriate for the column you are defining.  The column data will be stored exactly as you specify.  When
rendering, Panda will attempt to convert the column data as it is stored to whatever format your graphics API (e.g. OpenGL or DirectX)
expects to receive.

For instance, to define a vertex format that includes a vertex
position and a (U, V) texture coordinate:

[python]
&lt;code python&gt;
array = GeomVertexArrayFormat()
array.addColumn(&quot;vertex&quot;, 3, Geom.NTFloat32, Geom.CPoint)
array.addColumn(&quot;texcoord&quot;, 2, Geom.NTFloat32, Geom.CTexcoord)
&lt;/code&gt;
[/python]
[cxx]
&lt;code cxx&gt;
PT(GeomVertexArrayFormat) array;
array = new GeomVertexArrayFormat();
array-&gt;add_column(InternalName::make(&quot;vertex&quot;), 3,
                  Geom::NT_float32, Geom::C_point);
array-&gt;add_column(InternalName::make(&quot;texcoord&quot;), 2,
                  Geom::NT_float32, Geom::C_texcoord);
&lt;/code&gt;
[/cxx]
Once you have defined the columns of your array, you should create a
GeomVertexFormat to hold the array:

[python]&lt;code python&gt;
format = GeomVertexFormat()
format.addArray(array)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
PT(GeomVertexFormat) unregistered_format;
unregistered_format = new GeomVertexFormat();
unregistered_format-&gt;add_array(array);
&lt;/code&gt;[/cxx]

If you want your format to consist of multiple different arrays, you
can create additional arrays and add them at this point as well.

Finally, before you can use your new format, you must &lt;i&gt;register&lt;/i&gt;
it.  Registering a format builds up the internal tables necessary to
use the vertex format for rendering.  However, once you have
registered a format, you can no longer add or remove columns, or
modify it in any way; if you want to make changes to the format after
this point, you'll have to start over with a new GeomVertexFormat
object.

[python]&lt;code python&gt;
format = GeomVertexFormat.registerFormat(format)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
CPT(GeomVertexFormat) format;
format = GeomVertexFormat::register_format(unregistered_format);
&lt;/code&gt;[/cxx]

You should always register a format with a syntax similar to the
above: that is, you should use the return value of registerFormat as
your new, registered format object, and discard the original format
object.  (The returned format object may be the same format object you
started with, or it may be a different object with an equivalent
meaning.  Either way, the format object you started with should be
discarded.)</text>
    </revision>
  </page>
  <page>
    <title>Dependencies</title>
    <ns>0</ns>
    <id>8968</id>
    <redirect title="Third-party dependencies and license info" />
      <sha1>snud3lvr48p2kmjwb01q81dhz2w6bto</sha1>
    <revision>
      <id>14458</id>
      <timestamp>2013-08-17T07:39:32Z</timestamp>
      <contributor>
        <username>Seb</username>
        <id>10198</id>
      </contributor>
      <comment>Seb moved page [[Dependencies]] to [[Third-party dependencies and license info]]: Dependencies page merged with license info page</comment>
      <text xml:space="preserve" bytes="55">#REDIRECT [[Third-party dependencies and license info]]</text>
    </revision>
  </page>
  <page>
    <title>Depth Test and Depth Write</title>
    <ns>0</ns>
    <id>2222</id>
      <sha1>0yv57idm43x3sd5ul0mw6w37kgi4pr7</sha1>
    <revision>
      <id>7628</id>
      <timestamp>2012-03-08T17:41:57Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="2498">&lt;h2&gt;Enabling or Disabling the Depth Buffer&lt;/h2&gt;

By default, depth buffer is enabled and functions normally.
It is possible to turn off the use of the depth buffer.  It is also
possible to alter the behavior of the depth buffer.

The most common thing to want to do is to disable the depth-write.  This
means that geometry will still be &lt;i&gt;tested&lt;/i&gt; against the depth buffer,
but it will not affect the depth buffer.  This is often used when rendering
objects such as particles that are transparent.  To disable or enable
the depth-write, use:

&lt;code python&gt;
nodePath.setDepthWrite(False)  # Disable
nodePath.setDepthWrite(True)   # Enable
&lt;/code&gt;

It may also be desirable to disable the depth-test.  This means that the
geometry pays no attention whatsoever to the contents of the depth-buffer.
This is often used for rendering things like heads-up displays, which
have no relation to the 3D depth of the scene.  To disable or enable the
depth-test, use:

&lt;code python&gt;
nodePath.setDepthTest(False)  # Disable
nodePath.setDepthTest(True)   # Enable
&lt;/code&gt;

One can remove these settings using &lt;code&gt;clearDepthTest&lt;/code&gt; and &lt;code&gt;clearDepthWrite&lt;/code&gt;.

&lt;h2&gt;Altering the Depth Buffer&lt;/h2&gt;

Occasionally, it is desirable to alter the functionality of the depth
buffer.  Normally, the depth buffer only renders things that are in front,
but it can be made to render things that are in back, or equal.  This
is rarely used,
but it can be important for certain unusual algorithms like shadow volumes.

To do this, you need to use the DepthTestAttrib directly, in one of the
following variants:

&lt;code python&gt;
nodePath.setAttrib(DepthTestAttrib.make(RenderAttrib.MNone))
nodePath.setAttrib(DepthTestAttrib.make(RenderAttrib.MNever))
nodePath.setAttrib(DepthTestAttrib.make(RenderAttrib.MLess))
nodePath.setAttrib(DepthTestAttrib.make(RenderAttrib.MEqual))
nodePath.setAttrib(DepthTestAttrib.make(RenderAttrib.MLessEqual))
nodePath.setAttrib(DepthTestAttrib.make(RenderAttrib.MGreater))
nodePath.setAttrib(DepthTestAttrib.make(RenderAttrib.MGreaterEqual))
nodePath.setAttrib(DepthTestAttrib.make(RenderAttrib.MNotEqual))
nodePath.setAttrib(DepthTestAttrib.make(RenderAttrib.MAlways))
&lt;/code&gt;

&lt;h2&gt;Depth Sorting&lt;/h2&gt;

When turning depth test off, it is sometimes desirable to use depth sorting
instead.  Depth sorting is controlled by the culling system, which can be
controlled by the CullBinAttrib.

&lt;h2&gt;Transparency&lt;/h2&gt;

Certain settings of the TransparencyAttrib can also affect the depth-test.</text>
    </revision>
  </page>
  <page>
    <title>DetectPanda3D.js</title>
    <ns>0</ns>
    <id>2417</id>
      <sha1>h8w57y456gwkrm0hjd1u3l7rqdsvn1x</sha1>
    <revision>
      <id>7317</id>
      <timestamp>2011-09-01T17:19:15Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="1836">There is a JavaScript function distributed with Panda, in the direct/src/directscripts directory, that can be used to determine whether the Panda3D plugin is installed at all.  You can use this script to redirect users to the appropriate page to install the plugin if necessary.

To use it, copy it to your web server and reference it in the &lt;head&gt; section of your HTML document like this:

&lt;code html4strict&gt;
&lt;script src=&quot;DetectPanda3D.js&quot; language=&quot;javascript&quot;&gt;&lt;/script&gt;
&lt;/code&gt;

Then elsewhere, presumably in the &lt;body&gt; section of your document, you can reference it like this:

&lt;code html4strict&gt;
&lt;script language=&quot;javascript&quot;&gt;
if (detectPanda3D()) {
   ... plugin installed
} else {
   ... plugin not installed
}
&lt;/script&gt;
&lt;/code&gt;

The function takes two optional parameters.  The first parameter, if specified, is the URL of another page to redirect to, and the second parameter should be True to redirect to the indicated URL if the plugin is found, or False to redirect if the plugin is not found.

For instance, to trigger an automatic redirect to another page if the plugin is not installed, pass that page's URL as the first parameter, and False as the second parameter, like this:

&lt;code html4strict&gt;
&lt;script language=&quot;javascript&quot;&gt;
detectPanda3D('http://my.host.net/needsPlugin.html', False);
&lt;/script&gt;
&lt;/code&gt;

Note that this JavaScript function only detects whether the plugin is installed; it cannot report the plugin version number, and even if the plugin is installed there is no guarantee that the plugin actually runs on this browser.  In order to test either of these, you have to use the plugin to embed a p3d file and query the resulting embedded object.

Note also that [[Embedding with RunPanda3D|RunPanda3D.js]] can also be used to do some simple plugin detection, using the noplugin_img and noplugin_href tags.</text>
    </revision>
  </page>
  <page>
    <title>DirectButton</title>
    <ns>0</ns>
    <id>968</id>
      <sha1>pj5u8fapw6fkoj6wvxkubotiwcblsv0</sha1>
    <revision>
      <id>7654</id>
      <timestamp>2012-03-08T18:41:39Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>new import system</comment>
      <text xml:space="preserve" bytes="5879">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

DirectButton is a DirectGui object that will respond to the mouse and can execute an arbitrary function when the user clicks on the object.  This is actually implemented by taking advantage of the &quot;state&quot; system supported by every DirectGui object.

Each DirectGui object has a predefined number of available &quot;states&quot;, and a current state.  This concept of &quot;state&quot; is completely unrelated to Panda's [[Finite State Machines|FSM]] object.  For a DirectGui object, the current state is simply as an integer number, which is used to select one of a list of different NodePaths that represent the way the DirectGui object appears in each state.  Each DirectGui object can therefore have a completely different appearance in each of its states.

Most types of DirectGui objects do not use this state system, and only have one state, which is state 0.  The DirectButton is presently the only predefined object that has more than one state defined by default.  In fact, DirectButton defines four states, numbered 0 through 3, which are called &lt;i&gt;ready, press, rollover,&lt;/i&gt; and &lt;i&gt;disabled,&lt;/i&gt; in that order.  Furthermore, the DirectButton automatically manages its current state into one of these states, according to the user's interaction with the mouse.

With a DirectButton, then, you have the flexibility to define four completely different NodePaths, each of which represents the way the button appears in a different state.  Usually, you want to define these such that the &lt;i&gt;ready&lt;/i&gt; state is the way the button looks most of the time, the &lt;i&gt;press&lt;/i&gt; state looks like the button has been depressed, the &lt;i&gt;rollover&lt;/i&gt; state is lit up, and the &lt;i&gt;disabled&lt;/i&gt; state is grayed out.  In fact, the DirectButton interfaces will set these NodePaths up for you, if you use the simple forms of the constructor (for instance, if you specify just a single text string to the &lt;code&gt;text&lt;/code&gt; parameter). 

Sometimes you want to have explicit control over the various states, for instance to display a different text string in each state.  To do this, you can pass a 4-tuple to the text parameter (or to many of the other parameters, such as relief or geom), where each element of the tuple is the parameter value for the corresponding state, like this:

&lt;code python&gt;
b = DirectButton(text = (&quot;OK&quot;, &quot;click!&quot;, &quot;rolling over&quot;, &quot;disabled&quot;))
&lt;/code&gt;

The above example would create a DirectButton whose label reads &quot;OK&quot; when it is not being touched, but it will change to a completely different label as the mouse rolls over it and clicks it.

Another common example is a button you have completely customized by painting four different texture maps to represent the button in each state.  Normally, you would convert these texture maps into an egg file using &lt;code&gt;egg-texture-cards&lt;/code&gt; like this:

&lt;code bash&gt;
egg-texture-cards -o button_maps.egg -p 240,240 button_ready.png button_click.png button_rollover.png button_disabled.png
&lt;/code&gt;

And then you would load up the that egg file in Panda and apply it to the four different states like this:

&lt;code python&gt;
maps = loader.loadModel('button_maps.egg')
b = DirectButton(geom = (maps.find('**/button_ready'),
                         maps.find('**/button_click'),
                         maps.find('**/button_rollover'),
                         maps.find('**/button_disabled')))
&lt;/code&gt;

You can also access one of the state-specific NodePaths after the button has been created with the interface &lt;code&gt;myButton.stateNodePath[stateNumber]&lt;/code&gt;.  Normally, however, you should not need to access these NodePaths directly.

The following are the DirectGui keywords that are specific to a DirectButton.  (These are in addition to the generic DirectGui keywords described on the [[DirectGUI|previous page]].)

&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Keyword&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Value&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;command&lt;/td&gt;&lt;td&gt;Command the button performs when clicked&lt;/td&gt;&lt;td&gt;Function&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;extraArgs&lt;/td&gt;&lt;td&gt;Extra arguments to the function specified in command&lt;/td&gt;&lt;td&gt;[Extra Arguments]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;commandButtons&lt;/td&gt;&lt;td&gt;Which mouse button must be clicked to do the command&lt;/td&gt;&lt;td&gt;LMB, MMB, or RMB&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;rolloverSound&lt;/td&gt;&lt;td&gt;The sound made when the cursor rolls over the button&lt;/td&gt;&lt;td&gt;AudioSound instance&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;clickSound&lt;/td&gt;&lt;td&gt;The sound made when the cursor clicks on the button&lt;/td&gt;&lt;td&gt;AudioSound instance&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;pressEffect&lt;/td&gt;&lt;td&gt;Whether or not the button sinks in when clicked&lt;/td&gt;&lt;td&gt;&lt;0 or 1&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;state&lt;/td&gt;&lt;td&gt;Whether or not the button is disabled&lt;/td&gt;&lt;td&gt;DGG.NORMAL or DGG.DISABLED&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;

Like any other [[DirectGui]] widget, you can change any of the properties by treating the element as a dictionary:
&lt;code python&gt;
button[&quot;state&quot;] = DGG.DISABLED
&lt;/code&gt;

&lt;h2&gt;Example&lt;/h2&gt;

&lt;code python&gt;
import direct.directbase.DirectStart
from direct.gui.OnscreenText import OnscreenText
from direct.gui.DirectGui import *

from panda3d.core import TextNode

# Add some text
bk_text = &quot;This is my Demo&quot;
textObject = OnscreenText(text = bk_text, pos = (0.95,-0.95), 
scale = 0.07,fg=(1,0.5,0.5,1),align=TextNode.ACenter,mayChange=1)

# Callback function to set  text
def setText():
        bk_text = &quot;Button Clicked&quot;
        textObject.setText(bk_text)

# Add button
b = DirectButton(text = (&quot;OK&quot;, &quot;click!&quot;, &quot;rolling over&quot;, &quot;disabled&quot;), scale=.05, command=setText)

# Run the tutorial
run()
&lt;/code&gt;

Note that you will not be able to set the text unless the mayChange flag is 1. This is an optimization, which is easily missed by newcomers.

When you are positioning your button, keep in mind that the button's vertical center is located at the base of the text.  For example, if you had a button with the word &quot;Apple&quot;, the vertical center would be aligned with the base of the letter &quot;A&quot;.</text>
    </revision>
  </page>
  <page>
    <title>DirectCheckButton</title>
    <ns>0</ns>
    <id>1141</id>
      <sha1>n09oohf5vhptoo2nwntgrj05lhv207h</sha1>
    <revision>
      <id>7655</id>
      <timestamp>2012-03-08T18:43:17Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>new import system</comment>
      <text xml:space="preserve" bytes="3306">DirectCheckButtons are similar to buttons, except they represent a binary state that is toggled when it is clicked.  Their usage is almost identical to regular buttons, except that the text area and box area can be modified separately.

&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Keyword&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Value&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;text_scale&lt;/td&gt;&lt;td&gt;Scale of the displayed text&lt;/td&gt;&lt;td&gt;(sx,sz)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;indicatorValue&lt;/td&gt;&lt;td&gt;The initial boolean state of the checkbox&lt;/td&gt;&lt;td&gt;0 or 1&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;boxImage&lt;/td&gt;&lt;td&gt;Image on the checkbox&lt;/td&gt;&lt;td&gt;Image Path&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;boxImageColor&lt;/td&gt;&lt;td&gt;Color of the image on the box&lt;/td&gt;&lt;td&gt;(R,G,B,A)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;boxImageScale&lt;/td&gt;&lt;td&gt;Scale of the displayed image&lt;/td&gt;&lt;td&gt;Number&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;boxPlacement&lt;/td&gt;&lt;td&gt;Position of the box relative to the text area&lt;/td&gt;&lt;td&gt;'left','right'&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;boxRelief&lt;/td&gt;&lt;td&gt;Relief appearance of the checkbox&lt;/td&gt;&lt;td&gt;DGG.SUNKEN or DGG.RAISED&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;boxBorder&lt;/td&gt;&lt;td&gt;Size of the border around the box&lt;/td&gt;&lt;td&gt;Number&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;command&lt;/td&gt;&lt;td&gt;Command the button performs when clicked(0 or 1 is passed, depending on the state)&lt;/td&gt;&lt;td&gt;Function&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;extraArgs&lt;/td&gt;&lt;td&gt;Extra arguments to the function specified in command&lt;/td&gt;&lt;td&gt;[Extra Arguments]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;commandButtons&lt;/td&gt;&lt;td&gt;Which mouse button must be clicked to do the command&lt;/td&gt;&lt;td&gt;LMB, MMB, or RMB&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;rolloverSound&lt;/td&gt;&lt;td&gt;The sound made when the cursor rolls over the button&lt;/td&gt;&lt;td&gt;Sound File Path&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;clickSound&lt;/td&gt;&lt;td&gt;The sound made when the cursor clicks on the button&lt;/td&gt;&lt;td&gt;Sound File Path&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;pressEffect&lt;/td&gt;&lt;td&gt;Whether or not the button sinks in when clicked&lt;/td&gt;&lt;td&gt;&lt;0 or 1&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;

&lt;h2&gt;Example&lt;/h2&gt;
&lt;code python&gt;
import direct.directbase.DirectStart
from direct.gui.OnscreenText import OnscreenText 
from direct.gui.DirectGui import *
from panda3d.core import *


# Add some text
bk_text = &quot;This is my Demo&quot;
textObject = OnscreenText(text = bk_text, pos = (0.95,-0.95), 
scale = 0.07,fg=(1,0.5,0.5,1),align=TextNode.ACenter,mayChange=1)

# Callback function to set  text 
def setText(status):
	if(status):
		bk_text = &quot;Checkbox Selected&quot;
	else:
		bk_text = &quot;Checkbox Not Selected&quot;
	textObject.setText(bk_text)

# Add button
b = DirectCheckButton(text = &quot;CheckButton&quot; ,scale=.05,command=setText)

# Run the tutorial
run()
&lt;/code&gt;


&lt;h2&gt;A note on programatically changing the indicatorValue&lt;/h2&gt;
If you programatically want to change the checkbutton's indicatorValue, you need to call &lt;code&gt;setIndicatorValue&lt;/code&gt; afterwards to update the checkbutton, like:
&lt;code python&gt;b[&quot;indicatorValue&quot;] = True
b.setIndicatorValue()&lt;/code&gt;

&lt;h2&gt;A note on boxImage and other box* keywords&lt;/h2&gt;

Just as DirectButton may be passed a 4-tuple of values to be used in the four button states, the box* keyword arguments may be supplied with multiple entries to denote the unchecked and checked state. To supply arguments to be used in the two states of the checkbox, construct a 3-tuple of values with a 'None' in the final entry, i.e. (unchecked, checked, None). For example, to set two different images for the unchecked and checked states:

&lt;code python&gt;
boxImage = (&quot;pathToDisabledImage.jpg&quot;, &quot;pathToEnabled.jpg&quot;, None)
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>DirectDialog</title>
    <ns>0</ns>
    <id>969</id>
      <sha1>la7lkuuve1didg9ihxgogaskzma8pyi</sha1>
    <revision>
      <id>7657</id>
      <timestamp>2012-03-08T18:44:57Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>new import system</comment>
      <text xml:space="preserve" bytes="3775">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

DirectDialog objects are popup windows to alert or interact with the user. It is invoked just like the other DirectGUI objects, but it also has some unique keywords. Integral to DirectDialog are dialogName, buttonTextList, buttonImageList, and buttonValueList. The dialogName should ideally be the name of the NodePath created to hold the object. The button lists contain the various properties of the buttons within the dialog box. No maximum number of buttons needs to be declared.

Panda3D contains a number of shortcuts for common dialog options.  For example, rather than specifying the rather common text list (&quot;Yes&quot;,&quot;No&quot;), there is a YesNoDialog that functions exactly like a normal dialog but has buttonTextList already defined.  The other similar dialogs are OkCancelDialog, OkDialog, RetryCancelDialog, and YesNoCancelDialog.
&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Keyword&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Value&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;dialogName&lt;/td&gt;&lt;td&gt;Name of the dialog&lt;/td&gt;&lt;td&gt;String&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;buttonTextList&lt;/td&gt;&lt;td&gt;List of text to show on each button&lt;/td&gt;&lt;td&gt;[Strings]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;buttonGeomList&lt;/td&gt;&lt;td&gt;List of geometry to show on each button&lt;/td&gt;&lt;td&gt;[NodePaths] &lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;buttonImageList&lt;/td&gt;&lt;td&gt;List of images to show on each button&lt;/td&gt;&lt;td&gt;[Image Paths]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;buttonValueList&lt;/td&gt;&lt;td&gt;List of values sent to dialog command for each button. If value is [] then the ordinal rank of the button is used as its value&lt;/td&gt;&lt;td&gt;[Numbers]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;buttonHotKeyList&lt;/td&gt;&lt;td&gt;Shortcut key for each button (the button must have focus)&lt;/td&gt;&lt;td&gt;[Characters]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;buttonSize&lt;/td&gt;&lt;td&gt;4-tuple used to specify custom size for each button (to make bigger then geom/text for example)&lt;/td&gt;&lt;td&gt;(Left,Right,Bottom,Top)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;topPad&lt;/td&gt;&lt;td&gt;Extra space added above text/geom/image&lt;/td&gt;&lt;td&gt;Number&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;midPad&lt;/td&gt;&lt;td&gt;Extra space added between text/buttons&lt;/td&gt;&lt;td&gt;Number&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;sidePad&lt;/td&gt;&lt;td&gt;Extra space added to either side of text/buttons&lt;/td&gt;&lt;td&gt;Number&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;buttonPadSF&lt;/td&gt;&lt;td&gt;Scale factor used to expand/contract button horizontal spacing&lt;/td&gt;&lt;td&gt;Number&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;command&lt;/td&gt;&lt;td&gt;Callback command used when a button is pressed. Value supplied to command depends on values in buttonValueList&lt;/td&gt;&lt;td&gt;Function&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;extraArgs&lt;/td&gt;&lt;td&gt;Extra arguments to the function specified in command&lt;/td&gt;&lt;td&gt;[Extra Arguments]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;fadeScreen&lt;/td&gt;&lt;td&gt;If 1, fades screen to black when the dialog appears&lt;/td&gt;&lt;td&gt;0 or 1&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;

&lt;h2&gt;YesNo Dialog Example&lt;/h2&gt;
&lt;code python&gt;
import direct.directbase.DirectStart
from direct.gui.OnscreenText import OnscreenText 
from direct.gui.DirectGui import *
from direct.task import Task
from direct.actor import Actor
from direct.interval.IntervalGlobal import *
from panda3d.core import *

#add some text
bk_text = &quot;DirectDialog- YesNoDialog Demo&quot;
textObject = OnscreenText(text = bk_text, pos = (0.85,0.85), 
scale = 0.07,fg=(1,0.5,0.5,1),align=TextNode.ACenter,mayChange=1)

#add some text
output = &quot;&quot;
textObject = OnscreenText(text = output, pos = (0.95,-0.95),
 scale = 0.07,fg=(1,0.5,0.5,1),align=TextNode.ACenter,mayChange=1)

#callback function to set  text 
def itemSel(arg):
	if(arg):
		output = &quot;Button Selected is: Yes&quot;
	else:
		output = &quot;Button Selected is: No&quot;
	textObject.setText(output)

#create a frame
dialog = YesNoDialog(dialogName=&quot;YesNoCancelDialog&quot;, text=&quot;Please choose:&quot;, command=itemSel)

base.camera.setPos(0,-20,0)
#run the tutorial
run()
&lt;/code&gt;

Note: the OkDialog causes an error if being created a second time after destroying it with myOkDialog.destroy() . To solve this you can use:
&lt;code python&gt;
myOkDialog.cleanup()
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>DirectEntry</title>
    <ns>0</ns>
    <id>1107</id>
      <sha1>hxwfg8u2asrh8m0lqrh4hvk917olcm8</sha1>
    <revision>
      <id>7658</id>
      <timestamp>2012-03-08T18:45:42Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>new import system</comment>
      <text xml:space="preserve" bytes="2875">The DirectEntry creates a field that accepts text entered by the user.  It provides a blinking cursor and support for backspace and the arrow keys.  It can accept either a single line of text, with a fixed width limit (it doesn't scroll), or it can accept multiple word-wrapped lines.  

&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Keyword&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Value&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;initialText&lt;/td&gt;&lt;td&gt;Initial text to load in the field&lt;/td&gt;&lt;td&gt;String&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;entryFont&lt;/td&gt;&lt;td&gt;Font to use for text entry&lt;/td&gt;&lt;td&gt;Font object&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;width&lt;/td&gt;&lt;td&gt;Width of field in screen units&lt;/td&gt;&lt;td&gt;Number&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;numLines&lt;/td&gt;&lt;td&gt;Number of lines in the field&lt;/td&gt;&lt;td&gt;Integer&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;cursorKeys&lt;/td&gt;&lt;td&gt;True to enable the use of cursor keys (arrow keys)&lt;/td&gt;&lt;td&gt;0 or 1&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;obscured&lt;/td&gt;&lt;td&gt;True to hide passwords, etc.&lt;/td&gt;&lt;td&gt;0 or 1&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;command&lt;/td&gt;&lt;td&gt;Function to call when enter is pressed(the text in the field is passed to the function)&lt;/td&gt;&lt;td&gt;Function&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;extraArgs&lt;/td&gt;&lt;td&gt;Extra arguments to the function specified in command&lt;/td&gt;&lt;td&gt;[Extra Arguments]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;rolloverSound&lt;/td&gt;&lt;td&gt;The sound made when the cursor rolls over the field&lt;/td&gt;&lt;td&gt;Sound File Path&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;clickSound&lt;/td&gt;&lt;td&gt;The sound made when the cursor inside the field&lt;/td&gt;&lt;td&gt;Sound File Path&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;focus&lt;/td&gt;&lt;td&gt;Whether or not the field begins with focus (focusInCommand is called if true)&lt;/td&gt;&lt;td&gt;0 or 1&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;backgroundFocus&lt;/td&gt;&lt;td&gt;If true, field begins with focus but with hidden cursor, and focusInCommand is not called&lt;/td&gt;&lt;td&gt;0 or 1&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;focusInCommand&lt;/td&gt;&lt;td&gt;Function called when the field gains focus&lt;/td&gt;&lt;td&gt;Function&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;focusInExtraArgs&lt;/td&gt;&lt;td&gt;Extra arguments to the function specified in focusInCommand&lt;/td&gt;&lt;td&gt;[Extra Arguments]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;focusOutCommand&lt;/td&gt;&lt;td&gt;Function called when the field loses focus&lt;/td&gt;&lt;td&gt;Function&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;focusOutExtraArgs&lt;/td&gt;&lt;td&gt;Extra arguments to the function specified in focusOutCommand&lt;/td&gt;&lt;td&gt;[Extra Arguments]&lt;/td&gt;&lt;/tr&gt;

&lt;/table&gt;&lt;/center&gt;

&lt;h2&gt;Example&lt;/h2&gt;
&lt;code python&gt;
import direct.directbase.DirectStart
from direct.gui.OnscreenText import OnscreenText 
from direct.gui.DirectGui import *
from panda3d.core import *

#add some text
bk_text = &quot;This is my Demo&quot;
textObject = OnscreenText(text = bk_text, pos = (0.95,-0.95), 
scale = 0.07,fg=(1,0.5,0.5,1),align=TextNode.ACenter,mayChange=1)

#callback function to set  text 
def setText(textEntered):
	textObject.setText(textEntered)

#clear the text
def clearText():
	b.enterText('')

#add button
b = DirectEntry(text = &quot;&quot; ,scale=.05,command=setText,
initialText=&quot;Type Something&quot;, numLines = 2,focus=1,focusInCommand=clearText)

#run the tutorial
run()
&lt;/code&gt;

This example implements a text entry widget typically seen in web pages.</text>
    </revision>
  </page>
  <page>
    <title>DirectFrame</title>
    <ns>0</ns>
    <id>970</id>
      <sha1>6w6vo63mv7byefpcf2xix41qmx0f9c2</sha1>
    <revision>
      <id>6717</id>
      <timestamp>2010-03-07T21:29:45Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>Typo; &quot;Frame&quot;-&gt;&quot;DirectFrame&quot;</comment>
      <text xml:space="preserve" bytes="2848">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

[python]
&lt;p&gt;A frame is a container object for multiple DirectGUI objects. This allows for the control over several objects that are reparented to the same frame.  When DirectGUI objects are parented to a frame, they will be positioned relative to the frame.&lt;/p&gt;

&lt;p&gt;DirectFrame has no unique keywords, since it is mostly used to arrange other objects.&lt;/p&gt;

&lt;p&gt;Like any other DirectGUI object, the DirectFrame is called as such:&lt;/p&gt;

&lt;code python&gt;
DirectFrame(keyword=value, keyword=value, ...)
&lt;/code&gt;

&lt;p&gt;For a basic frame, the most used keywords are &lt;code&gt;frameSize&lt;/code&gt;, &lt;code&gt;frameColor&lt;/code&gt; and &lt;code&gt;pos&lt;/code&gt;. For a full list of keywords available for this object you can click, see the [[DirectGUI]] page.&lt;/p&gt;

&lt;p&gt;As we established above, the most common keywords are:&lt;/p&gt;

&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Keyword&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Value&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;frameSize&lt;/td&gt;&lt;td&gt;Sets the size of the frame&lt;/td&gt;&lt;td&gt;(Left,Right,Bottom,Top)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;frameColor&lt;/td&gt;&lt;td&gt;sets the color of the object's frame&lt;/td&gt;&lt;td&gt;(R,G,B,A)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;pos&lt;/td&gt;&lt;td&gt;sets the position of the object&lt;/td&gt;&lt;td&gt;(X,Y,Z)&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;

&lt;p&gt;Now as an example let us make a single frame appear on the screen, for that the code would be the following:&lt;/p&gt;

&lt;code python&gt;
from direct.gui.DirectGui import DirectFrame

myFrame = DirectFrame(frameColor=(0, 0, 0, 1),
                      frameSize=(-1, 1, -1, 1),
                      pos=(1, -1, -1))
&lt;/code&gt;

&lt;p&gt;This will give you a black frame appearing at the lower right section of the Panda window.&lt;/p&gt;

&lt;p&gt;Keep in mind, if your screen is non-square you will see the background color you have set (or the default one if you have not set any) where there is no frame on screen.&lt;/p&gt;

&lt;p&gt;By default, as with any DirectGUI object, DirectFrame is reparented to aspect2d so the will stay fixed on-screen even when your camera moves. Newly created objects usually are drawn on top of already existing ones, unless you change it manually.&lt;/p&gt;

&lt;p&gt;Additionally you can position the frame using &lt;code&gt;setPos()&lt;/code&gt;. This works with other aspects like scale as well.&lt;/p&gt;

&lt;p&gt;The example above would change as follows:&lt;/p&gt;

&lt;code python&gt;
from direct.gui.DirectGui import DirectFrame

myFrame = DirectFrame(frameColor=(0, 0, 0, 1),
                      frameSize=(-1, 1, -1, 1))
myFrame.setPos(-0.5, 0, -0.5)
&lt;/code&gt;

&lt;p&gt;This will give us a black frame that is located at the lower left side of the screen.&lt;/p&gt;

&lt;p&gt;Usually one would decide on one of the ways to read and write values for DirectGUI objects a third way to access and change properties is the following:&lt;/p&gt;

&lt;code python&gt;
myDirectobject[&quot;yourKeyword&quot;] = value
&lt;/code&gt;
[/python]
[cxx]
&lt;!--Is this in PGUI (Incomplete Section) or not (Section Not Applicable)?--&gt;
[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>DirectGUI</title>
    <ns>0</ns>
    <id>971</id>
      <sha1>rj54ajci5or9nnc9frhz4ox3lfmb07k</sha1>
    <revision>
      <id>60473</id>
      <timestamp>2015-03-13T13:53:20Z</timestamp>
      <contributor>
        <username>Gczuczy</username>
        <id>21758</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="13648">[cxx]Since DirectGUI is implemented in Python, it is useless to c++ programmers.
However, there is another GUI system, PGui, that forms the foundation of DirectGUI and is in fact implemented in C++.&lt;br /&gt;
Let's take a look at some PGui functions.&lt;br /&gt;

&lt;b&gt;The PGui c++ modules&lt;/b&gt;&lt;br /&gt;

&lt;b&gt;[PGButton]&lt;/b&gt;&lt;br /&gt;
&lt;code cxx&gt;
#include &quot;PGButton.h&quot;
&lt;/code&gt;

with PGButton you can create a freely definable clickable button.&lt;br /&gt;
It can hold four different states:&lt;br /&gt;

ready     -&gt; The default state of an untouched button&lt;br /&gt;
pressed   -&gt; The pressed state (the user clicked on it)&lt;br /&gt;
roll over -&gt; When the user hovers over the button without clicking&lt;br /&gt;
inactive  -&gt; Disabled state&lt;br /&gt;

Example usage, creating a texture for each state:

&lt;code cxx&gt;
PT(PGButton) MyButton;
MyButton = new PGButton(&quot;MyButton&quot;);
MyButton-&gt;setup(&quot;Button&quot;,0.1);
PT(Texture) ButtonReady=TexturePool::load_texture(&quot;button.png&quot;);
PT(Texture) ButtonRollover=TexturePool::load_texture(&quot;button_active.png&quot;);
PT(Texture) ButtonPressed=TexturePool::load_texture(&quot;button_pressed.png&quot;);
PT(Texture) ButtonInactive=TexturePool::load_texture(&quot;button_inactive.png&quot;);

// PGFrameStyle is a powerful way to change the appearance of the button:
PGFrameStyle MyStyle=MyButton-&gt;get_frame_style(0); // frame_style(0): ready state
MyStyle.set_type(PGFrameStyle::T_flat);

MyStyle.set_texture(ButtonReady);    MyButton-&gt;set_frame_style(0,MyStyle);
MyStyle.set_texture(ButtonRollover); MyButton-&gt;set_frame_style(1,MyStyle);
MyStyle.set_texture(ButtonPressed);  MyButton-&gt;set_frame_style(2,MyStyle);
MyStyle.set_texture(ButtonInactive); MyButton-&gt;set_frame_style(3,MyStyle);

NodePath defbutNP = window-&gt;get_aspect_2d().attach_new_node(MyButton);
defbutNP.set_scale(0.1);

// Setup callback function
framework.define_key(MyButton-&gt;get_click_event(MouseButton::one() ), &quot;button press&quot;, &amp;GUI_Callback_Button_Clicked, MyButton);
&lt;/code&gt;

An example of a callback function:
&lt;code cxx&gt;
static void GUI_Callback_Button_Clicked(const Event *ev, void *data)
{
 PGButton* CurrentButton=(PGButton *)data;
 // Your action here
 printf(&quot;%s has been pressed.\n&quot;,CurrentButton-&gt;get_name().c_str());
}
&lt;/code&gt;

&lt;b&gt;[PGSliderBar]&lt;/b&gt;&lt;br/&gt;
&lt;code cxx&gt;
#include &quot;PGSliderBar.h&quot;
&lt;/code&gt;
A simple sliderbar.&lt;br/&gt;
This slider basically has four components:&lt;br/&gt;
The thumb button. This is the sliding part.&lt;br/&gt;
The slider. This is the 'rail' the thumb button slides along.&lt;br/&gt;
The left button. User can click on it to slide the thumb button to the left.&lt;br/&gt;
The right button. User can click on it to slide the thumb button to the right.&lt;br/&gt;
Using default initialisation, none of these components are textured.&lt;br/&gt;

&lt;code cxx&gt;
PT(PGSliderBar) Slider=new PGSliderBar(&quot;MySliderBar&quot;);
 
// Setup, feeding the constructor with (bool vertical,float lenght,float width,float bevel)
Slider-&gt;setup_slider(false,0.1,0.1,0); // 'rail' properties
Slider-&gt;set_range(0,1);
Slider-&gt;set_value(0.5);

// Setup scroll bar (the 'moving thumb button' including left and right button)
Slider-&gt;setup_scroll_bar(false,0.35,0.05,false);
NodePath SliderNP=window-&gt;get_aspect_2d().attach_new_node(Slider);
SliderNP.set_pos(0,0,0);
&lt;/code&gt;



(work in progress, more to come soon.)

[/cxx]

[python]

&lt;b&gt;The DirectGUI Python modules&lt;/b&gt;

Panda3D comes with a set of tools for the creation of a graphical interface for any program. The DirectGui system is used to create buttons, labels, text entries, and frames within the program. All of these items can be decorated with text, images, and 3D graphics. Commands may be associated with these items as well. Since these objects inherit from the NodePath class, anything done to a NodePath may be done to them, such as show()/hide(), setPos(), posInterval(), and so on. Also, since DirectGui objects are by default parented to the node aspect2d, they will stay on the screen no matter how the user navigates through the world.

You can specify the parent nodepath for any DirectGUI object using the parent= argument. You can use base.aspect2d for center-oriented pacement, and a2dTopLeft or a2dBottomRight respectively. The Y coordinate should be left 0, because it's useless in the 2D space. The Z coordinate goes from -1 to 1, and X depends on the aspect ratio, by the default 4:3 it's from -1.3333 to 1.3333. The other aspect2d variants don't scale the numbers, just offset them.

The direct-gui-edit option in the Config.prc file allows the user to use the middle mouse button to move around widgets, and resize them while holding the control key; this is very useful to lay a screen out during development.  If you need to turn this ability off for an individual object, set its &lt;code&gt;enableEdit&lt;/code&gt; keyword parameter to False.

All of the DirectGui objects are constructed in a similar way:

&lt;code python&gt;
from direct.gui.DirectGui import *
myObject = Directxxxxxx(keyword=value, keyword=value, ...)
&lt;/code&gt;

Each DirectGui object may contain any of four fundamental pieces that determine its appearance.  There may be an optional &lt;b&gt;text&lt;/b&gt;, an optional &lt;b&gt;geom&lt;/b&gt;, an optional &lt;b&gt;image&lt;/b&gt;, and an optional &lt;b&gt;frame&lt;/b&gt;.

A DirectGui's &lt;b&gt;text&lt;/b&gt; label may be any arbitrary text string, and whatever text string you supply is automatically created using the [[OnscreenText]] interface and centered on the object.  You can specify the text string using the &lt;code&gt;text&lt;/code&gt; keyword.  You can also specify further parameters to control the appearance or placement of the text using the form &lt;code&gt;text_parameter&lt;/code&gt;, where &lt;code&gt;parameter&lt;/code&gt; is any valid keyword to the [[OnscreenText]] constructor.

A DirectGui's &lt;b&gt;geom&lt;/b&gt; can be any NodePath that you design, to represent the appearance of the gui object.  Typically, this will be a model that you created via the program &lt;code&gt;egg-texture-cards&lt;/code&gt;. This little program takes a png or other picture and turns it into an egg. See [[Automatic_Texture_Animation]], for more details. Using this interface, you can completely customize the look of the DirectGui object to suit your needs.  You can specify the geom object using the &lt;code&gt;geom&lt;/code&gt; keyword, and like the text parameter, you can also control the geom's placement using keywords like &lt;code&gt;geom_parameter&lt;/code&gt;.

The &lt;b&gt;image&lt;/b&gt; is less often used.  It is the filename of a texture image (or an already-loaded Texture object).  It is intended for displaying a simple texture image for which you don't already have a model created via &lt;code&gt;egg-texture-cards&lt;/code&gt;.  A default card will be created to display this texture, with a bounding box of (-1, 0, -1) to (1, 0, 1); that is, a square with sides of length 2 units, centered on the origin.  You can position and scale this card with the keywords &lt;code&gt;image_pos&lt;/code&gt; and &lt;code&gt;image_scale&lt;/code&gt;. See also [[OnscreenImage]]

Finally, the DirectGui may have a &lt;b&gt;frame&lt;/b&gt; created for it.  This is typically a gray rectangular background with an optional bevel.  There are a handful of different frame styles; you can use the &lt;code&gt;relief&lt;/code&gt; keyword to select from one of the available styles; your choices are SUNKEN, RAISED, GROOVE, or RIDGE.  You can also specify &lt;code&gt;relief = None&lt;/code&gt; to avoid creating a frame polygon altogether (this is commonly done when you have specified your own geom object with the &lt;code&gt;geom&lt;/code&gt; keyword).

The overall size of the DirectGui object is controlled with the &lt;code&gt;frameSize&lt;/code&gt; keyword.  This is a four-tuple of floating-point numbers of the form (left, right, bottom, top), which specifies the bounding box region of the DirectGui object.  That is, the lower-left corner will be at position (left, 0, bottom), and the upper-right will be at (right, 0, top).  Note that these values represent coordinates from the origin of the frame.  Setting the frameSize to (-0.1, 0.1, -0.1, 0.1), for instance, will create a box, 0.2 units wide and 0.2 units in height, with 0,0 being the center of the frame located at &lt;code&gt;pos&lt;/code&gt; on the screen.

The &lt;code&gt;frameSize&lt;/code&gt; keyword is optional.  If you omit it, the default frameSize is computed based on the bounding box of the &lt;b&gt;text&lt;/b&gt;, &lt;b&gt;geom&lt;/b&gt;, and/or &lt;b&gt;image&lt;/b&gt; that you have specified.

The following is a list of keywords that are typically available to DirectGui objects of all kinds.  Individual kinds of DirectGUI objects may add more options to this list, but these keywords are not repeated on each of the following pages, for brevity:

&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Keyword&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Value&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;text&lt;/td&gt;&lt;td&gt;Text to be displayed on the object&lt;/td&gt;&lt;td&gt;String&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;text_bg&lt;/td&gt;&lt;td&gt;Background color of the text on the object&lt;/td&gt;&lt;td&gt;(R,G,B,A)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;text_fg&lt;/td&gt;&lt;td&gt;Color of the text&lt;/td&gt;&lt;td&gt;(R,G,B,A)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;text_pos&lt;/td&gt;&lt;td&gt;Position of the displayed text&lt;/td&gt;&lt;td&gt;(x,z)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;text_roll&lt;/td&gt;&lt;td&gt;Rotation of the displayed text&lt;/td&gt;&lt;td&gt;Number&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;text_scale&lt;/td&gt;&lt;td&gt;Scale of the displayed text&lt;/td&gt;&lt;td&gt;(sx,sz)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;text_*&lt;/td&gt;&lt;td&gt;Parameters to control the appearance of the text&lt;/td&gt;&lt;td&gt;Any keyword parameter appropriate to [[OnscreenText]].&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;frameSize&lt;/td&gt;&lt;td&gt;Size of the object&lt;/td&gt;&lt;td&gt;(Left,Right,Bottom,Top)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;frameVisibleScale&lt;/td&gt;&lt;td&gt;Relative scale of the visible frame to its clickable bounds. Useful for creating things like the paging region of a slider, which is visibly smaller than the acceptable click region (the height of the thumb).&lt;/td&gt;&lt;td&gt;(hscale, vscale)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;frameColor&lt;/td&gt;&lt;td&gt;Color of the object's &lt;b&gt;frame&lt;/b&gt;&lt;/td&gt;&lt;td&gt;(R,G,B,A)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;relief&lt;/td&gt;&lt;td&gt;Relief appearance of the &lt;b&gt;frame&lt;/b&gt;&lt;/td&gt;&lt;td&gt;SUNKEN, RAISED, GROOVE, RIDGE, FLAT, or None&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;invertedFrames&lt;/td&gt;&lt;td&gt;If true, switches the meaning of SUNKEN and RAISED&lt;/td&gt;&lt;td&gt;0 or 1&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;borderWidth&lt;/td&gt;&lt;td&gt;If relief is SUNKEN, RAISED, GROOVE, or RIDGE, changes the size of the bevel&lt;/td&gt;&lt;td&gt;(Width,Height)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;image&lt;/td&gt;&lt;td&gt;An &lt;b&gt;image&lt;/b&gt; to be displayed on the object&lt;/td&gt;&lt;td&gt;image filename or Texture object&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;image_pos&lt;/td&gt;&lt;td&gt;Position of the displayed image&lt;/td&gt;&lt;td&gt;(x,y,z)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;image_hpr&lt;/td&gt;&lt;td&gt;Rotation of the displayed image&lt;/td&gt;&lt;td&gt;(h,p,r)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;image_scale&lt;/td&gt;&lt;td&gt;Scale of the displayed image&lt;/td&gt;&lt;td&gt;(sx,sy,sz)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;geom&lt;/td&gt;&lt;td&gt;A &lt;b&gt;geom&lt;/b&gt; to represent the object's appearance&lt;/td&gt;&lt;td&gt;NodePath&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;geom_pos&lt;/td&gt;&lt;td&gt;Position of the displayed geom&lt;/td&gt;&lt;td&gt;(x,y,z)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;geom_hpr&lt;/td&gt;&lt;td&gt;Rotation of the displayed geom&lt;/td&gt;&lt;td&gt;(h,p,r)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;geom_scale&lt;/td&gt;&lt;td&gt;Scale of the displayed geom&lt;/td&gt;&lt;td&gt;(sx,sy,sz)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;parent&lt;/td&gt;&lt;td&gt;Parent to attach to&lt;/td&gt;&lt;td&gt;NodePath&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;pos&lt;/td&gt;&lt;td&gt;Position of the object&lt;/td&gt;&lt;td&gt;(X,Y,Z)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;hpr&lt;/td&gt;&lt;td&gt;Orientation of the object&lt;/td&gt;&lt;td&gt;(H,P,R)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;scale&lt;/td&gt;&lt;td&gt;Scale of the object&lt;/td&gt;&lt;td&gt;Number&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;pad&lt;/td&gt;&lt;td&gt;When frameSize is omitted, this determines the extra space around the &lt;b&gt;geom&lt;/b&gt; or &lt;b&gt;text&lt;/b&gt;'s bounding box by which to expand the default &lt;b&gt;frame&lt;/b&gt;&lt;/td&gt;&lt;td&gt;(Width,Height)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;state&lt;/td&gt;&lt;td&gt;The initial state of the object&lt;/td&gt;&lt;td&gt;NORMAL or DISABLED&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;frameTexture&lt;/td&gt;&lt;td&gt;Texture applied directly to the generated &lt;b&gt;frame&lt;/b&gt;&lt;/td&gt;&lt;td&gt;image filename or Texture object&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;enableEdit&lt;/td&gt;&lt;td&gt;Affects direct-gui-edit functionality&lt;/td&gt;&lt;td&gt;0 or 1&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;suppressKeys&lt;/td&gt;&lt;td&gt;If 1, suppresses triggers of global keyboard-related Panda events (not part of the GUI system)&lt;/td&gt;&lt;td&gt;0 or 1&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;suppressMouse&lt;/td&gt;&lt;td&gt;If 1, suppresses triggers of global mouse-related Panda events (e.g. camera controls)&lt;/td&gt;&lt;td&gt;0 or 1&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;sortOrder&lt;/td&gt;&lt;td&gt;Specifies render order for overlapping objects. Higher numbers are drawn in front of lower numbers.&lt;/td&gt;&lt;td&gt;Number&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;textMayChange&lt;/td&gt;&lt;td&gt;Whether the text of an object can be changed after creation&lt;/td&gt;&lt;td&gt;0 or 1&lt;/td&gt;&lt;/tr&gt;

&lt;/table&gt;&lt;/center&gt;

Remember that the axes for Panda3D use x for left and right, y for in and out of the screen, and z for up and down.  An object's &lt;b&gt;frame&lt;/b&gt; is always in the background of the object.  The &lt;b&gt;geom&lt;/b&gt;, if any, is shown in front of the frame, and &lt;b&gt;text&lt;/b&gt; is shown in front of the geom.

It is possible to change most of these values after object creation, using:

&lt;code python&gt;
myDirectObject['keyword'] = value
&lt;/code&gt;

Most properties can be updated in this way, although position and other transform-related values cannot be updated via the keyword parameters--attempts to update them will silently fail.  Instead, use the NodePath methods to change the object's transform.

Some types of updates, such as changing the text or the geom, may also change the size of the object.  If you change any of these properties after the object has been created, it is necessary to tell the object to re-determine its size:

&lt;code python&gt;
myDirectObject.resetFrameSize()
&lt;/code&gt;

If you don't do this, you may find, for example, that a button isn't clickable because it believes it has a zero-width frame.

To permanently remove a DirectGUI object, you should use the method:

&lt;code python&gt;
myDirectObject.destroy()
&lt;/code&gt;

It is not sufficient to simply call removeNode(), since the DirectGUI system adds a number of messenger hooks that need to be cleaned up.  However, if you have a hierarchy of DirectGUI objects, for instance a number of buttons parented to a frame, it is sufficient to call destroy() only on the topmost object; it will propagate downwards.

[/python]</text>
    </revision>
  </page>
  <page>
    <title>DirectGui</title>
    <ns>0</ns>
    <id>2090</id>
    <redirect title="DirectGUI" />
      <sha1>d0i9k0iewbgi4oux6szj6mdpcrs0wy2</sha1>
    <revision>
      <id>4253</id>
      <timestamp>2007-03-24T13:40:23Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>redirected</comment>
      <text xml:space="preserve" bytes="23">#REDIRECT [[DirectGUI]]</text>
    </revision>
  </page>
  <page>
    <title>DirectLabel</title>
    <ns>0</ns>
    <id>972</id>
      <sha1>gjplxs13dsj7alwhpq0gp5kei6mes5y</sha1>
    <revision>
      <id>2257</id>
      <timestamp>2005-08-11T19:11:18Z</timestamp>
      <contributor>
        <username>Ophilatry</username>
        <id>14</id>
      </contributor>
      <text xml:space="preserve" bytes="1018">Labels are like buttons, but they do not respond to mouse-clicks.  This means a DirectLabel is basically just a text string, and in that respect is similar to [[OnscreenText]], except that the DirectLabel integrates better with the rest of the DirectGUI system (and the constructor accepts more DirectGUI-like options).

If you are making a text label to appear on a DirectFrame or in conjunction with DirectGUI somehow, you should probably use a DirectLabel.  For all other uses of text, you would probably be better off using [[OnscreenText]] or a making a plain [[Text Node]] instead.

DirectLabel's only unique keyword can be used if you want to create a label with multiple states. If you set the value of activeState to a nonexistent state, the label will disappear, since the default state is undefined.
&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Keyword&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Value&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;activeState&lt;/td&gt;&lt;td&gt;The &quot;active&quot; or normal state of the label&lt;/td&gt;&lt;td&gt;Number&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;</text>
    </revision>
  </page>
  <page>
    <title>DirectOptionMenu</title>
    <ns>0</ns>
    <id>1137</id>
      <sha1>g31ngzlcpczwzn5bxoghiy07wdgm8b7</sha1>
    <revision>
      <id>7659</id>
      <timestamp>2012-03-08T18:46:57Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>new import system</comment>
      <text xml:space="preserve" bytes="4619">The DirectOptionMenu class models a popup menu with an arbitrary number of items.  It is composed of the menu bar, the popup marker, and the popup menu itself.  The popup menu appears when the menu is clicked on and disappears when the user clicks again; if the click was inside the popup, the selection changes.  By default, the text on the menu changes to whatever item is currently selected.  The attributes that affect the appearance of the menu bar don't apply to the popup.  Make sure to specify the items option or it may crash.


&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Keyword&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Value&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;textMayChange&lt;/td&gt;&lt;td&gt;Whether the text on the menu changes with the selection&lt;/td&gt;&lt;td&gt;0 or 1&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;initialitem&lt;/td&gt;&lt;td&gt;The index of the item that appears next to the cursor when the popup appears&lt;/td&gt;&lt;td&gt;Number&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;items&lt;/td&gt;&lt;td&gt;List of items in the popup menu&lt;/td&gt;&lt;td&gt;[Strings]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;command&lt;/td&gt;&lt;td&gt;Function called when an item is selected (the item is passed in as a parameter)&lt;/td&gt;&lt;td&gt;Function&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;commandButtons&lt;/td&gt;&lt;td&gt;Which mouse button must be clicked to open the popup&lt;/td&gt;&lt;td&gt;LMB, MMB, or RMB&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;extraArgs&lt;/td&gt;&lt;td&gt;Extra arguments to the function specified in command&lt;/td&gt;&lt;td&gt;[Extra Arguments]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;highlightColor&lt;/td&gt;&lt;td&gt;Color of highlighted text&lt;/td&gt;&lt;td&gt;(R,G,B,A)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;highlightScale&lt;/td&gt;&lt;td&gt;Scale of highlighted text&lt;/td&gt;&lt;td&gt;(Width,Height)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;rolloverSound&lt;/td&gt;&lt;td&gt;The sound made when the cursor rolls over the button&lt;/td&gt;&lt;td&gt;Sound File Path&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;clickSound&lt;/td&gt;&lt;td&gt;The sound made when the cursor clicks on the button&lt;/td&gt;&lt;td&gt;Sound File Path&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;popupMarkerBorder&lt;/td&gt;&lt;td&gt;Use width to change the size of the border around the popup marker&lt;/td&gt;&lt;td&gt;(Width,Height)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;popupMarker_image&lt;/td&gt;&lt;td&gt;Set the state images of the popupMarker&lt;/td&gt;&lt;td&gt;(see directButton: image)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;popupMarker_scale&lt;/td&gt;&lt;td&gt;Set the scale of the popupMarker&lt;/td&gt;&lt;td&gt;scale=x  or scale=(x,y,z)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;popupMarker_pos&lt;/td&gt;&lt;td&gt;Set the poition of the popupMarker relative to the parent optionMenu&lt;/td&gt;&lt;td&gt;pos=(x,y,z)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;popupMarker_relief&lt;/td&gt;&lt;td&gt;Set the relief value of the popupMarker, the depth of the beveled edge&lt;/td&gt;&lt;td&gt;relief=x (for int value) or relief=None (for no relief)&lt;/td&gt;&lt;/tr&gt;

&lt;/table&gt;&lt;/center&gt;

&lt;h2&gt;Example&lt;/h2&gt;
&lt;code python&gt;
import direct.directbase.DirectStart
from direct.gui.OnscreenText import OnscreenText 
from direct.gui.DirectGui import *
from panda3d.core import *

# Add some text
bk_text = &quot;DirectOptionMenu Demo&quot;
textObject = OnscreenText(text = bk_text, pos = (0.85,0.85), 
scale = 0.07,fg=(1,0.5,0.5,1),align=TextNode.ACenter,mayChange=1)

# Add some text
output = &quot;&quot;
textObject = OnscreenText(text = output, pos = (0.95,-0.95),
 scale = 0.07,fg=(1,0.5,0.5,1),align=TextNode.ACenter,mayChange=1)

# Callback function to set  text 
def itemSel(arg):
	output = &quot;Item Selected is: &quot;+arg
	textObject.setText(output)

# Create a frame
menu = DirectOptionMenu(text=&quot;options&quot;, scale=0.1,items=[&quot;item1&quot;,&quot;item2&quot;,&quot;item3&quot;],initialitem=2,
highlightColor=(0.65,0.65,0.65,1),command=itemSel)

# Run the tutorial
run()
&lt;/code&gt;

This is a simple demonstration of the DirectOptionMenu.

&lt;h2&gt;Dynamic Updating of a Menu&lt;/h2&gt;
&lt;code python&gt;
import direct.directbase.DirectStart
from direct.gui.OnscreenText import OnscreenText 
from direct.gui.DirectGui import *
from panda3d.core import *

# Add some text
bk_text = &quot;DirectOptionMenu Demo&quot;
textObject = OnscreenText(text = bk_text, pos = (0.85,0.85), 
scale = 0.07,fg=(1,0.5,0.5,1),align=TextNode.ACenter,mayChange=1)

# Add some text
output = &quot;&quot;
textObject = OnscreenText(text = output, pos = (0.95,-0.95), 
scale = 0.07,fg=(1,0.5,0.5,1),align=TextNode.ACenter,mayChange=1)

# Callback function to set text
def itemSel(arg):
	if(arg != &quot;Add&quot;): #no need to add an element
		output = &quot;Item Selected is: &quot;+arg
		textObject.setText(output)
	else: #add an element
		tmp_menu = menu['items']
		new_item = &quot;item&quot;+str(len(tmp_menu))
		tmp_menu.insert(-1,new_item) #add the element before add
		menu['items'] = tmp_menu	
		#set the status message
		output = &quot;Item Added is: &quot;+new_item
		textObject.setText(output)

# Create a frame
menu = DirectOptionMenu(text=&quot;options&quot;, scale=0.1,items=[&quot;item1&quot;,&quot;item2&quot;,&quot;item3&quot;,&quot;Add&quot;],
initialitem=2,highlightColor=(0.65,0.65,0.65,1),command=itemSel,textMayChange=1)

# Procedurally select a item
menu.set(0)

# Run the tutorial
run()
&lt;/code&gt;

In this example we add an item to the menu whenever the Add item is selected.</text>
    </revision>
  </page>
  <page>
    <title>DirectRadioButton</title>
    <ns>0</ns>
    <id>2261</id>
      <sha1>8ofu0rs68f4ziuey1vdw8zwlg226dwb</sha1>
    <revision>
      <id>7656</id>
      <timestamp>2012-03-08T18:44:00Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <text xml:space="preserve" bytes="3722">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt; 
&lt;b&gt;This feature is only available in Panda3D versions 1.5.3 and higher&lt;/b&gt;

DirectRadioButtons are similar to check buttons, except only one button is selected when it is clicked.  Their usage is almost identical to regular buttons, except that the text area and box area can be modified separately.

&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Keyword&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Value&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;text_scale&lt;/td&gt;&lt;td&gt;Scale of the displayed text&lt;/td&gt;&lt;td&gt;(sx,sz)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;indicatorValue&lt;/td&gt;&lt;td&gt;The initial boolean state of the radiobutton&lt;/td&gt;&lt;td&gt;0 or 1&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;variable&lt;/td&gt;&lt;td&gt;The variable whose value will be set by radiobutton. Since we can not use call by reference for int or string variables in python, I used a list insteads.&lt;/td&gt;&lt;td&gt;define a list and pass it&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;value&lt;/td&gt;&lt;td&gt;The value to be set to the variable. Since we are using a list, we can define multiple values. But the length of value list must be same as length of variable list.&lt;/td&gt;&lt;td&gt;a list of values&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;others&lt;/td&gt;&lt;td&gt;The list of radio button instances sharing same variable. This must be set by using setOthers() after all radiobutton is created.&lt;/td&gt;&lt;td&gt;a list of radioButton instances&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;boxImage&lt;/td&gt;&lt;td&gt;BG Image of the radio button&lt;/td&gt;&lt;td&gt;Image Path&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;boxImageColor&lt;/td&gt;&lt;td&gt;Color of the BG image&lt;/td&gt;&lt;td&gt;(R,G,B,A)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;boxImageScale&lt;/td&gt;&lt;td&gt;Scale of the BG image&lt;/td&gt;&lt;td&gt;Number&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;boxGeom&lt;/td&gt;&lt;td&gt;FG Image on the radio button&lt;/td&gt;&lt;td&gt;Image Path&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;boxGeomColor&lt;/td&gt;&lt;td&gt;Color of the FG image&lt;/td&gt;&lt;td&gt;(R,G,B,A)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;boxGeomScale&lt;/td&gt;&lt;td&gt;Scale of the FG image&lt;/td&gt;&lt;td&gt;Number&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;boxPlacement&lt;/td&gt;&lt;td&gt;Position of the box relative to the text area&lt;/td&gt;&lt;td&gt;'left','right', 'above', 'below', 'center'&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;boxBorder&lt;/td&gt;&lt;td&gt;Size of the border around the box&lt;/td&gt;&lt;td&gt;Number&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;command&lt;/td&gt;&lt;td&gt;Command the button performs when clicked (In version 1.6 and higher, no parameter is passed unless extraArgs are defined. Before, a single argument was passed by default.)&lt;/td&gt;&lt;td&gt;Function&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;extraArgs&lt;/td&gt;&lt;td&gt;Extra arguments to the function specified in command&lt;/td&gt;&lt;td&gt;[Extra Arguments]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;commandButtons&lt;/td&gt;&lt;td&gt;Which mouse button must be clicked to do the command&lt;/td&gt;&lt;td&gt;LMB, MMB, or RMB&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;rolloverSound&lt;/td&gt;&lt;td&gt;The sound made when the cursor rolls over the button&lt;/td&gt;&lt;td&gt;Sound File Path&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;clickSound&lt;/td&gt;&lt;td&gt;The sound made when the cursor clicks on the button&lt;/td&gt;&lt;td&gt;Sound File Path&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;pressEffect&lt;/td&gt;&lt;td&gt;Whether or not the button sinks in when clicked&lt;/td&gt;&lt;td&gt;&lt;0 or 1&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;

&lt;h2&gt;Example&lt;/h2&gt;
&lt;code python&gt;
import direct.directbase.DirectStart
from direct.gui.OnscreenText import OnscreenText 
from direct.gui.DirectGui import *
from panda3d.core import *

v = [0]
# Add some text
bk_text = &quot;This is my Demo&quot;
textObject = OnscreenText(text = bk_text, pos = (0.95,-0.95), 
scale = 0.07,fg=(1,0.5,0.5,1),align=TextNode.ACenter,mayChange=1)

# Callback function to set  text 
def setText(status=None):
    bk_text = &quot;CurrentValue : %s&quot;%v
    textObject.setText(bk_text)

# Add button
buttons = [
    DirectRadioButton(text = 'RadioButton0', variable=v, value=[0], scale=0.05, pos=(-0.4,0,0), command=setText),
    DirectRadioButton(text = 'RadioButton1', variable=v, value=[1], scale=0.05, pos=(0,0,0), command=setText),
    DirectRadioButton(text = 'RadioButton2', variable=v, value=[2], scale=0.05, pos=(0.4,0,0), command=setText)
]

for button in buttons:
    button.setOthers(buttons)

# Run the tutorial
run()
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>DirectScrollBar</title>
    <ns>0</ns>
    <id>1166</id>
      <sha1>9flezx1dev300ygw65w1z2iby5fhfef</sha1>
    <revision>
      <id>6718</id>
      <timestamp>2010-03-07T21:39:11Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>Fixes, tags, code clean-up, screenshot suppression.</comment>
      <text xml:space="preserve" bytes="4190">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

[python]
&lt;p&gt;A DirectScrollBar is similar to the &quot;scroll bar&quot; widget commonly used by the user to page through a large document.  DirectScrollBar is available beginning in Panda3D 1.1.  It consists of a long trough, a thumb that slides along the trough, and a pair of buttons on either side of the trough to scroll one line at a time.  A DirectScrollBar can be oriented either vertically or horizontally.&lt;/p&gt;

&lt;p&gt;The DirectScrollBar is similar in function to [[DirectSlider]], but it is specifically designed for scrolling through a large window.  In fact, a pair of DirectScrollBars is used to implement the [[DirectScrolledFrame]], which manages this scrolling functionality automatically.  (Because DirectScrolledFrame exists, you will probably not need to create a DirectScrollBar directly, unless you have some custom purpose that requires a scroll bar.)&lt;/p&gt;

&lt;p&gt;DirectScrollBar has many things in common with [[DirectSlider]].  Like [[DirectSlider]], the normal DirectGui parameters such as frameSize, geom, and relief control the look of the trough.  You can control the look of the thumb by prefixing each of these parameters with the prefix &quot;thumb_&quot;, e.g. &lt;code&gt;thumb_frameSize&lt;/code&gt;; similarly, you can control the look of the two scroll buttons by prefixing these with &quot;incButton_&quot; and &quot;decButton_&quot;.  You can retrieve or set the current position of the thumb with &lt;code&gt;myScrollBar['value']&lt;/code&gt;.&lt;/p&gt;

&lt;table border=1 cellpadding=1 cellspacing=0&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Keyword&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Value&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;value&lt;/td&gt;&lt;td&gt;Initial position of the thumb&lt;/td&gt;&lt;td&gt;Default is 0&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;range&lt;/td&gt;&lt;td&gt;The (min, max) range of the thumb&lt;/td&gt;&lt;td&gt;Default is (0, 1)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;pageSize&lt;/td&gt;&lt;td&gt;The amount to jump the thumb when the user clicks left or right, (up or down if the scrollbar is vertical), of the thumb; this also controls the width of the thumb when resizeThumb is True&lt;/td&gt;&lt;td&gt;Default is 0.1&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;scrollSize&lt;/td&gt;&lt;td&gt;The amount to move the thumb when the user clicks once on either scroll button&lt;/td&gt;&lt;td&gt;Default is 0.01&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;orientation&lt;/td&gt;&lt;td&gt;The orientation of the scroll bar&lt;/td&gt;&lt;td&gt;DGG.HORIZONTAL or DGG.VERTICAL&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;manageButtons&lt;/td&gt;&lt;td&gt;Whether to automatically adjust the buttons when the scroll bar's frame is changed&lt;/td&gt;&lt;td&gt;True or False&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;resizeThumb&lt;/td&gt;&lt;td&gt;Whether to adjust the width of the thumb to reflect the ratio of pageSize to the overall range; requires manageButtons to be True as well&lt;/td&gt;&lt;td&gt;True or False&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;command&lt;/td&gt;&lt;td&gt;Function called when the position of the thumb changes (takes no arguments)&lt;/td&gt;&lt;td&gt;Function&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;extraArgs&lt;/td&gt;&lt;td&gt;Extra arguments to the function specified in command&lt;/td&gt;&lt;td&gt;[Extra Arguments]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;thumb_geom, thumb_relief, thumb_text, thumb_frameSize, etc.&lt;/td&gt;&lt;td&gt;Parameters to control the look of the thumb&lt;/td&gt;&lt;td&gt;Any parameters appropriate to [[DirectButton]]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;incButton_geom, incButton_relief, incButton_text, incButton_frameSize, etc.&lt;/td&gt;&lt;td&gt;Parameters to control the look of the lower or right scroll button&lt;/td&gt;&lt;td&gt;Any parameters appropriate to [[DirectButton]]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;decButton_geom, decButton_relief, decButton_text, decButton_frameSize, etc.&lt;/td&gt;&lt;td&gt;Parameters to control the look of the upper or left scroll button&lt;/td&gt;&lt;td&gt;Any parameters appropriate to [[DirectButton]]&lt;/td&gt;&lt;/tr&gt;

&lt;/table&gt;

&lt;p&gt;Here is a small example on how to create the scrollbar:&lt;/p&gt;
&lt;code python&gt;
from direct.gui.DirectGui import DirectScrollBar

mybar = DirectScrollBar(range=(0, 100), value=50, pageSize=3, orientation= DGG.VERTICAL)
mybar.setPos(-1, 0, -0.5)
&lt;/code&gt;

&lt;p&gt;This will give you a scrollbar at the lower left side of the screen. If you want to parent the scrollbar to a determined frame, you add the keyword &lt;b&gt;parent&lt;/b&gt; to the set of keyboards like so:&lt;/p&gt;

&lt;code python&gt;
mybar = DirectScrollBar(parent=myframe, range=(0,100), value=50, pageSize=3, orientation= DGG.VERTICAL)
mybar.setPos(-1, 0, -0.5)
&lt;/code&gt;
[/python]
[cxx]
&lt;!--Is this in PGUI (Incomplete Section) or not (Section Not Applicable)?--&gt;
[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>DirectScrolledFrame</title>
    <ns>0</ns>
    <id>1167</id>
      <sha1>bxtinouvc27zjzzhxtouhjppxvaem3g</sha1>
    <revision>
      <id>6057</id>
      <timestamp>2009-08-01T10:23:56Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>code tags</comment>
      <text xml:space="preserve" bytes="3050">The DirectScrolledFrame is a special variant of DirectFrame that allows the user to page through a larger frame than would otherwise fit onscreen.  The DirectScrolledFrame consists of a small onscreen frame which is actually a window onto a potentially much larger virtual canvas; the user can scroll through this canvas through the use of one or two [[DirectScrollBar|DirectScrollBars]] on the right and bottom of the frame.  DirectScrolledFrame is available beginning with Panda3D version 1.1.

The &lt;code&gt;frameSize&lt;/code&gt; parameter controls the size and placement of the visible, onscreen frame; use the &lt;code&gt;canvasSize&lt;/code&gt; parameter to control the size of the larger virtual canvas.

You can then parent any widgets you like to the NodePath returned by &lt;code&gt;myFrame.getCanvas()&lt;/code&gt;.  The DirectGui items you attach to this canvas NodePath will be visible through the small window; you should position them within the virtual canvas using values within the coordinate range you established via the &lt;code&gt;canvasSize&lt;/code&gt; parameter.

By default, the scroll bars are automatically created with the DirectScrolledFrame and will be hidden automatically when they are not needed (that is, if the virtual frame size is equal to or smaller than the onscreen frame size).  You can adjust either frame size at runtime and the scroll bars will automatically adjust as needed.  If you would prefer to manage the scroll bars yourself, you can set one or both of &lt;code&gt;manageScrollBars&lt;/code&gt; and &lt;code&gt;autoHideScrollBars&lt;/code&gt; to False.

&lt;table border=1 cellpadding=1 cellspacing=0&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Keyword&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Value&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;canvasSize&lt;/td&gt;&lt;td&gt;Extents of the virtual canvas&lt;/td&gt;&lt;td&gt;(Left, right, bottom, top)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;frameSize&lt;/td&gt;&lt;td&gt;Extents of the actual visible frame&lt;/td&gt;&lt;td&gt;(Left, right, bottom, top)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;manageScrollBars&lt;/td&gt;&lt;td&gt;Whether to automatically position and scale the scroll bars to fit along the right and bottom of the frame&lt;/td&gt;&lt;td&gt;True or False&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;autoHideScrollBars&lt;/td&gt;&lt;td&gt;Whether to automatically hide one or both scroll bars when not needed&lt;/td&gt;&lt;td&gt;True or False&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;scrollBarWidth&lt;/td&gt;&lt;td&gt;Specifies the width of both scroll bars at construction time&lt;/td&gt;&lt;td&gt;Default is 0.08&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;verticalScroll_relief, verticalScroll_frameSize, etc.&lt;/td&gt;&lt;td&gt;Parameters to control the look of the vertical scroll bar&lt;/td&gt;&lt;td&gt;Any parameters appropriate to [[DirectScrollBar]]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;horizontalScroll_relief, horizontalScroll_frameSize, etc.&lt;/td&gt;&lt;td&gt;Parameters to control the look of the horizontal scroll bar&lt;/td&gt;&lt;td&gt;Any parameters appropriate to [[DirectScrollBar]]&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

As a very small and simple example on how to use this element we have a simple scrolled frame on the middle of the screen:

&lt;code python&gt;
from direct.gui.DirectGui import *
import direct.directbase.DirectStart

myframe = DirectScrolledFrame(canvasSize = (-2,2,-2,2), frameSize = (-.5,.5,-.5,.5)) 
myframe.setPos(0, 0, 0)

run()
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>DirectScrolledList</title>
    <ns>0</ns>
    <id>1143</id>
      <sha1>il13r9mmj2a3qtw8w7dwb3vo0yuu6wk</sha1>
    <revision>
      <id>7660</id>
      <timestamp>2012-03-08T18:48:17Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>new import system</comment>
      <text xml:space="preserve" bytes="5185">DirectScrolledLists create a list of DirectGuiWidgets.  Each object is created individually and can then be added to the list.  Some useful methods are:
&lt;code python&gt;
addItem(item, refresh)
getItemIndexForItemID(self, itemID)
getSelectedIndex(self) 
getSelectedText(self)
removeItem(self, item, refresh)
scrollBy(self, delta)  
scrollTo(self, index, centered) 
scrollToItemID(self, itemID, centered)  
selectListItem(self, item)  
&lt;/code&gt;

In the above methods, item is a new item, either a string or a DirectGUI element, and itemID is an arbitrary identification number for each item (but not necessarily a zero-based index number). The itemID for a new item is the return value of addItem().  The centered parameter is a boolean; if true, the list scrolls so that the given index is centered, otherwise it scrolls so that the index is on top of the list.

The items option should either be a list of DirectGUI items or of strings.  If strings are used, the itemMakeFunction (and possibly itemMakeExtraArgs) option should be defined to point to a function that will take the supplied string, the index, and the extra args as parameters and return a DirectGUI object to insert into the list.  If items is a list of strings and itemMakeFunction is not specified, it will create a list of DirectLabels.  itemMakeFunction is redundant if a list of DirectGUI objects is passed into items to begin with.  

DirectScrolledLists come with two scroll buttons for navigating through the list.  By default, they both start at (0,0,0) relative to the list with size 0, and their positions and size need to be set explicitly.  You can set any of the values except relief appearance as you initialize the list:

&lt;code python&gt;
myScrolledList = DirectScrolledList(incButton_propertyName = value,
decButton_propertyName = value)
&lt;/code&gt;

incButton scrolls forward through the list; decButton backward.  Note that this only works for initialization.  To change a property of the scroll buttons later in the program, you must use:

&lt;code python&gt;
myScrolledList.incButton['propertyName'] = value
myScrolledList.decButton['propertyName'] = value
&lt;/code&gt;

Unlike the first method, this does not work with NodePath options like position; use setPos(...) for that. 

For example, the following creates a scrolled list and resizes and moves the buttons appropriately.

&lt;code python&gt;
myScrolledList = DirectScrolledList(
   incButton_pos= (.5,0,0), incButton_text = &quot;Inc&quot;,
   decButton_pos= (-.5,0,0), decButton_text = &quot;Dec&quot;)
myScrolledList.incButton['frameSize'] = (0, 0.2, 0, 0.2)
myScrolledList.decButton['frameSize'] = (0, 0.2, 0, 0.2)
myScrolledList.incButton['text_scale'] = .2
myScrolledList.decButton['text_scale'] = .2
&lt;/code&gt;

&lt;br&gt;&lt;br&gt;

&lt;table border=1 cellpadding=1 cellspacing=0&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Keyword&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Value&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;command&lt;/td&gt;&lt;td&gt;Function called when the list is scrolled&lt;/td&gt;&lt;td&gt;Function&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;extraArgs&lt;/td&gt;&lt;td&gt;Extra arguments to the function specified in command&lt;/td&gt;&lt;td&gt;[Extra Arguments]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;text_scale&lt;/td&gt;&lt;td&gt;Scale of the displayed text&lt;/td&gt;&lt;td&gt;(sx,sz)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;items&lt;/td&gt;&lt;td&gt;List of the objects to appear in the ScrolledList&lt;/td&gt;&lt;td&gt;[DirectGUI items] or [Strings]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;numItemsVisible&lt;/td&gt;&lt;td&gt;Number of items visible at a time&lt;/td&gt;&lt;td&gt;Number&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;forceHeight&lt;/td&gt;&lt;td&gt;Forces the height of the list to be a given number&lt;/td&gt;&lt;td&gt;Number&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;itemMakeFunction&lt;/td&gt;&lt;td&gt;Function that makes DirectGUI items out of strings&lt;/td&gt;&lt;td&gt;Function&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;itemMakeExtraArgs&lt;/td&gt;&lt;td&gt;Extra arguments to the function in itemMakeFunction&lt;/td&gt;&lt;td&gt;[Extra Arguments]&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;


A small example on how to use it:
&lt;code python&gt;
from direct.directbase import DirectStart
from direct.gui.DirectGui import *
from panda3d.core import *

b1 = DirectButton(text = (&quot;Button1&quot;, &quot;click!&quot;, &quot;roll&quot;, &quot;disabled&quot;),
                  text_scale=0.1, borderWidth = (0.01, 0.01),
                  relief=2)

b2 = DirectButton(text = (&quot;Button2&quot;, &quot;click!&quot;, &quot;roll&quot;, &quot;disabled&quot;),
                  text_scale=0.1, borderWidth = (0.01, 0.01),
                  relief=2)

l1 = DirectLabel(text = &quot;Test1&quot;, text_scale=0.1)
l2 = DirectLabel(text = &quot;Test2&quot;, text_scale=0.1)
l3 = DirectLabel(text = &quot;Test3&quot;, text_scale=0.1)

numItemsVisible = 4
itemHeight = 0.11

myScrolledList = DirectScrolledList(
    decButton_pos= (0.35, 0, 0.53),
    decButton_text = &quot;Dec&quot;,
    decButton_text_scale = 0.04,
    decButton_borderWidth = (0.005, 0.005),

    incButton_pos= (0.35, 0, -0.02),
    incButton_text = &quot;Inc&quot;,
    incButton_text_scale = 0.04,
    incButton_borderWidth = (0.005, 0.005),

    frameSize = (0.0, 0.7, -0.05, 0.59),
    frameColor = (1,0,0,0.5),
    pos = (-1, 0, 0),
    items = [b1, b2],
    numItemsVisible = numItemsVisible,
    forceHeight = itemHeight,
    itemFrame_frameSize = (-0.2, 0.2, -0.37, 0.11),
    itemFrame_pos = (0.35, 0, 0.4),
    )

myScrolledList.addItem(l1)
myScrolledList.addItem(l2)
myScrolledList.addItem(l3)

for fruit in ['apple', 'pear', 'banana', 'orange']:
    l = DirectLabel(text = fruit, text_scale=0.1)
    myScrolledList.addItem(l) 


run()
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>DirectSlider</title>
    <ns>0</ns>
    <id>1165</id>
      <sha1>oaiowq851ml8workue8q4m7dtfqf0f9</sha1>
    <revision>
      <id>6017</id>
      <timestamp>2009-07-29T13:49:21Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>cleanup</comment>
      <text xml:space="preserve" bytes="2064">Use a DirectSlider to make a slider, a widget that allows the user to select a value between a bounded interval.  DirectSlider is available beginning in Panda3D 1.1.

A DirectSlider consists of a long bar, by default horizontal, along with a &quot;thumb&quot;, which is a special button that the user may move left or right along the bar.  The normal DirectGui parameters such as frameSize, geom, and relief control the look of the bar; to control the look of the thumb, prefix each of these parameters with the prefix &quot;thumb_&quot;, e.g. &lt;code&gt;thumb_frameSize&lt;/code&gt;.

If you want to get (or modify) the current value of the slider (by default, the range is between 0 and 1), use &lt;code&gt;mySlider['value']&lt;/code&gt;.

&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Keyword&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Value&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;value&lt;/td&gt;&lt;td&gt;Initial value of the slider&lt;/td&gt;&lt;td&gt;Default is 0&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;range&lt;/td&gt;&lt;td&gt;The (min, max) range of the slider&lt;/td&gt;&lt;td&gt;Default is (0, 1)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;pageSize&lt;/td&gt;&lt;td&gt;The amount to jump the slider when the user clicks left or right of the thumb&lt;/td&gt;&lt;td&gt;Default is 0.1&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;orientation&lt;/td&gt;&lt;td&gt;The orientation of the slider&lt;/td&gt;&lt;td&gt;HORIZONTAL or VERTICAL&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;command&lt;/td&gt;&lt;td&gt;Function called when the value of the slider changes (takes no arguments)&lt;/td&gt;&lt;td&gt;Function&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;extraArgs&lt;/td&gt;&lt;td&gt;Extra arguments to the function specified in command&lt;/td&gt;&lt;td&gt;[Extra Arguments]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;thumb_geom, thumb_relief, thumb_text, thumb_frameSize, etc.&lt;/td&gt;&lt;td&gt;Parameters to control the look of the thumb&lt;/td&gt;&lt;td&gt;Any parameters appropriate to DirectButton&lt;/td&gt;&lt;/tr&gt;

&lt;/table&gt;

&lt;h2&gt;Example&lt;/h2&gt;

&lt;code python&gt;
import direct.directbase.DirectStart
from direct.gui.DirectGui import *

def showValue():
    print slider['value']

slider = DirectSlider(range=(0,100), value=50, pageSize=3, command=showValue)

run()
&lt;/code&gt;

&quot;range&quot; sets values between 0 and 100
&quot;value&quot; sets initial value to 50
&quot;pageSize&quot; sets the step between mouseclicks to 3 (approximately)
&quot;command&quot; calls the showValue-function implemented above</text>
    </revision>
  </page>
  <page>
    <title>DirectSliderBar</title>
    <ns>0</ns>
    <id>1140</id>
      <sha1>n77f7pc4a31pb9ksty93zh0p1fpmikn</sha1>
    <revision>
      <id>4120</id>
      <timestamp>2007-02-17T13:51:00Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="24">This page is deprecated.</text>
    </revision>
  </page>
  <page>
    <title>DirectStart</title>
    <ns>0</ns>
    <id>2476</id>
    <redirect title="ShowBase" />
      <sha1>5aexqugqc59dpjom7mth457bb1oa3mz</sha1>
    <revision>
      <id>6704</id>
      <timestamp>2010-02-28T23:16:34Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>[[DirectStart]] moved to [[ShowBase]]: The article was already 99% covering ShowBase, and DirectStart is nothing more than a jump-starter for ShowBase.</comment>
      <text xml:space="preserve" bytes="22">#REDIRECT [[ShowBase]]</text>
    </revision>
  </page>
  <page>
    <title>DirectWaitBar</title>
    <ns>0</ns>
    <id>1142</id>
      <sha1>5b82442xou9v23l0jy99m08v1p6oz50</sha1>
    <revision>
      <id>7661</id>
      <timestamp>2012-03-08T18:49:01Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>new import system</comment>
      <text xml:space="preserve" bytes="2380">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

DirectWaitBars are similar to status bars; use them to indicate a slow process gradually completing (e.g. a loading screen).  It has various options for both the background bar and the loading bar that fills up as the process progresses.  You can call finish() to automatically fill up the bar, or use:
&lt;code python&gt;myWaitBar['value'] = number&lt;/code&gt;
to set the value (it ranges from 0 to 100 by default).
&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Keyword&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Value&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;value&lt;/td&gt;&lt;td&gt;Initial value of the loading bar (from 0 to 100)&lt;/td&gt;&lt;td&gt;Number&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;range&lt;/td&gt;&lt;td&gt;The maximum value of the loading bar&lt;/td&gt;&lt;td&gt;Number&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;barColor&lt;/td&gt;&lt;td&gt;The color of the loading bar&lt;/td&gt;&lt;td&gt;(R,G,B,A)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;barTexture&lt;/td&gt;&lt;td&gt;An image to be display on the loading bar&lt;/td&gt;&lt;td&gt;image filename or Texture object&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;barRelief&lt;/td&gt;&lt;td&gt;The relief appearance of the loading bar&lt;/td&gt;&lt;td&gt;SUNKEN or RAISED&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;barBorderWidth&lt;/td&gt;&lt;td&gt;If barRelief is SUNKEN, RAISED, GROOVE, or RIDGE, changes the size of the loading bar's bevel&lt;/td&gt;&lt;td&gt;(Width,Height)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;relief&lt;/td&gt;&lt;td&gt;The relief appearance of the background bar&lt;/td&gt;&lt;td&gt;SUNKEN or RAISED&lt;/td&gt;&lt;/tr&gt;

&lt;/table&gt;&lt;/center&gt;

&lt;h2&gt;Example&lt;/h2&gt;
&lt;code python&gt;
import direct.directbase.DirectStart
from direct.gui.OnscreenText import OnscreenText 
from direct.gui.DirectGui import *
from panda3d.core import *

# Add some text
bk_text = &quot;This is my Demo&quot;
textObject = OnscreenText(text = bk_text, pos = (0.95,-0.95), 
scale = 0.07,fg=(1,0.5,0.5,1),align=TextNode.ACenter,mayChange=1)

# Callback function to set text
def incBar(arg):
	bar['value'] +=	arg
	text = &quot;Progress is:&quot;+str(bar['value'])+'%'
	textObject.setText(text)

# Create a frame
frame = DirectFrame(text = &quot;main&quot;, scale = 0.001)
# Add button
bar = DirectWaitBar(text = &quot;&quot;, value = 50, pos = (0,.4,.4))

# Create 4 buttons
button_1 = DirectButton(text=&quot;+1&quot;,scale=0.05,pos=(-.3,.6,0), command=incBar,extraArgs = [1])
button_10 = DirectButton(text=&quot;+10&quot;,scale=0.05,pos=(0,.6,0), command=incBar,extraArgs = [10])
button_m1 = DirectButton(text=&quot;-1&quot;,scale=0.05,pos=(0.3,.6,0), command=incBar,extraArgs = [-1])
button_m10 = DirectButton(text=&quot;-10&quot;,scale=0.05,pos=(0.6,.6,0), command=incBar,extraArgs = [-10])

# Run the tutorial
run()
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>Disney Video Lectures</title>
    <ns>0</ns>
    <id>973</id>
      <sha1>3p5odph0ktyuak49ff38qnev00k4dpg</sha1>
    <revision>
      <id>5610</id>
      <timestamp>2008-11-18T19:39:02Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="2878">&lt;p&gt;David Rose, from Walt Disney VR Studio, occasionally holds classes based on the fundamentals and working of Panda3D. Below are a few of these lectures.

&lt;ul&gt;
	&lt;li&gt;[http://video.google.com/videoplay?docid=-3062788944994284554&amp;hl=en Characters Part I] Recorded October 8, 2003. Eggs, Characters and Actors, but audio quality is very poor.
	&lt;li&gt;[http://video.google.com/videoplay?docid=-1586200015760444650&amp;hl=en Characters Part II] Recorded October 22, 2003. This is a recap of character animation in Panda3D.
	&lt;li&gt;[http://video.google.com/videoplay?docid=-7958937369732071881&amp;hl=en PStats] Recorded February 24, 2004. Demonstrating the use of Panda's built-in performance analysis tool.
	&lt;li&gt;[http://video.google.com/videoplay?docid=5009786393476731454&amp;hl=en Threading] Recorded March 26, 2008. The current state-of-the-art in multiprogramming in Panda.
	&lt;li&gt;[http://video.google.com/videoplay?docid=-3032355519509216354&amp;hl=en Windows, Buffers, and Cameras] Recorded April 9, 2008. Fundamentals of managing windows and offscreen buffers, and connecting them up to cameras for rendering.
	&lt;li&gt;[http://video.google.com/videoplay?docid=7093299406745614529&amp;hl=en Scene Graph] Recorded April 2, 2008. Fundamentals of Panda's scene graph, tricks you can do with it, and how it is implemented.
	&lt;li&gt;[http://video.google.com/videoplay?docid=59098437095671394&amp;hl=en DistributedObjects] Recorded April 16, 2008. How to use Panda's DistributedObject system, for the Python developer.
	&lt;li&gt;[http://video.google.com/videoplay?docid=-4547040139284563409&amp;hl=en DistributedObjects and the OTP Server] Recorded April 23, 2008. Panda's DistributedObject system, and how it relates to the VR Studio's OTP Server.
	&lt;li&gt;[http://video.google.com/videoplay?docid=-6551816888913680536&amp;hl=en The OTP Server] Recorded April 30, 2008. What's inside the VR Studio's OTP Server (not part of Panda).
	&lt;li&gt;[http://video.google.com/videoplay?docid=2633778230802753163&amp;hl=en The PRC System] Recorded May 7, 2008. All about Panda's run-time configuration system.
	&lt;li&gt;[http://video.google.com/videoplay?docid=8524155402201040926&amp;hl=en Collisions] Recorded May 14, 2008. How to use Panda's built-in collision system, and how it works.
	&lt;li&gt;[http://video.google.com/videoplay?docid=922496949308495232&amp;hl=en egg-palettize] Recorded May 21, 2008. How to use egg-palettize, and why you'd want to.
	&lt;li&gt;[http://video.google.com/videoplay?docid=8716922590223131644&amp;hl=en interrogate] Recorded June 4, 2008. How interrogate works to generate Panda's Python/C++ interface.
	&lt;li&gt;[http://video.google.com/videoplay?docid=6429726243770234547&amp;hl=en ODE in Panda] Recorded June 18, 2008. How Panda's built-in ODE integration is intended to be used.
	&lt;li&gt;[http://video.google.com/videoplay?docid=53318334729655998&amp;hl=en Inside an Actor] Recorded July 2, 2008. How the Actor class is implemented, and how to use it.
&lt;/ul&gt;
&lt;/p&gt;</text>
    </revision>
  </page>
  <page>
    <title>Display Regions</title>
    <ns>0</ns>
    <id>2273</id>
      <sha1>irdftm59y6501oza83uqhz4hqiuo9yi</sha1>
    <revision>
      <id>7386</id>
      <timestamp>2011-11-30T14:46:04Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <comment>Add C++ versions</comment>
      <text xml:space="preserve" bytes="4116">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;
A new window can't render anything until it has at least one DisplayRegion.  A DisplayRegion is necessary to associate a camera with the window.

A DisplayRegion is a rectangular area of the window that contains the rendered scene, as viewed by one particular camera.  Usually, you create just one DisplayRegion that covers the entire window, although you can create as many different smaller regions as you like, each one displaying the output from a different camera.

&lt;table&gt;&lt;tr&gt;
&lt;td&gt;&lt;div&gt;[[Image:DisplayRegion_1.jpg]]&lt;br&gt;&lt;center&gt;A single display region&lt;/center&gt;&lt;/div&gt;&lt;/td&gt;
&lt;td&gt;&lt;div&gt;[[Image:DisplayRegion_2.jpg]]&lt;br&gt;&lt;center&gt;Two display regions&lt;/center&gt;&lt;/div&gt;&lt;/td&gt;
&lt;td&gt;&lt;div&gt;[[Image:DisplayRegion_3.jpg]]&lt;br&gt;&lt;center&gt;Another arrangement of two regions&lt;/center&gt;&lt;/div&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

You can create a DisplayRegion with the [func]makeDisplayRegion[/func]() call on a window:

[python]&lt;code python&gt;
displayRegion = win.makeDisplayRegion()
displayRegion = win.makeDisplayRegion(left, right, bottom, top)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
PT(DisplayRegion) displayRegion = win.make_display_region();
PT(DisplayRegion) displayRegion = win.make_display_region(left, right, bottom, top);
&lt;/code&gt;[/cxx]

The first example creates a DisplayRegion that fills the entire window, while the second example specifies the size and placement of the DisplayRegion within the window.  The ranges of left, right, bottom, top are from 0 to 1, where 0 is the left and bottom of the window, and 1 is the right and top of the window.  (Note that this is different from the range of the render2d screen coordinates, which ranges from -1 to 1 instead of 0 to 1.)  For instance, the right panel of the second example above was created with the call &lt;code&gt;win.[func]makeDisplayRegion[/func](0.5, 1, 0, 1)&lt;/code&gt;.

A new DisplayRegion won't render anything until it has been associated with a camera.  Each DisplayRegion may have just one camera associated with it (although a particular camera may be associated with more than one DisplayRegion).

A Camera is a kind of PandaNode, so you can simply create one and wrap a NodePath around it:
[python]&lt;code python&gt;
camNode = Camera('cam')
camNP = NodePath(camNode)
displayRegion.setCamera(camNP)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
PT(Camera) camNode = new Camera(&quot;cam&quot;);
NodePath camNP(camNode);
displayRegion-&gt;set_camera(camNP);
&lt;/code&gt;[/cxx]
Once you have a Camera, you need to decide where to attach it to the scene graph.  If you parent it to base.camera, it will inherit the transform of that node and so it will move with the system trackball controls, if enabled, and will view the scene that base.camera is attached to (usually render).  The default Camera that Panda creates is attached to base.camera.
[python]&lt;code python&gt;
# View render, as seen by the default camera
camNP.reparentTo(base.camera)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
// View render, as seen by the default camera
camNP.reparent_to(windowFramework-&gt;get_camera_group());
&lt;/code&gt;[/cxx]

If you wish your new Camera to view a completely different scene, you can set up a new scene graph simply by creating a new NodePath to be the root, and then reparent your Camera into that new scene graph.  Then, your camera will render whatever models you put into the same scene graph.  In this case, since your camera is not a child of base.camera, it will be up to you to position the camera and the models correctly relative to each other.
[python]&lt;code python&gt;
# View some other scene, unrelated to render
render2 = NodePath('render2')  # the string parameter is important
camNP.reparentTo(render2)
env = loader.loadModel('environment.egg')
env.reparentTo(render2)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
// View some other scene, unrelated to render
NodePath render2(&quot;render2&quot;);  // the string parameter is important
camNP.reparent_to(render2);
NodePath env = windowFramework-&gt;load_model(render2, &quot;environment.egg&quot;);
&lt;/code&gt;[/cxx]

&lt;h3&gt;Example code&lt;/h3&gt;&lt;p&gt;[[:Image:DisplayRegion_1.jpg|Click here]] to see the sample code that sets all this up (it also reveals where &lt;b&gt;win&lt;/b&gt; comes from.)&lt;/p&gt;</text>
    </revision>
  </page>
  <page>
    <title>Distributed Networking</title>
    <ns>0</ns>
    <id>2495</id>
      <sha1>6267svfwr8szgrda8xor0fy44v0yn0a</sha1>
    <revision>
      <id>6884</id>
      <timestamp>2010-06-25T15:56:15Z</timestamp>
      <contributor>
        <username>Croxis</username>
        <id>430</id>
      </contributor>
      <text xml:space="preserve" bytes="620">Distributed Networking is Panda3D's high level network API. When a distributed object is created all interested clients will automatically create a copy of that object. Updates to the object will automatically propagate to the copies.

The distributed network is composed of several layers: the dc file which defines the communication, ServerRepositories which handle inter client communication, ClientRepositories which interact and manage the distributed objects, and the distributed objects themselves.

The documentation on these features is still in development. Read the forums for the most up-to-date information.</text>
    </revision>
  </page>
  <page>
    <title>Distributing Panda3D Applications</title>
    <ns>0</ns>
    <id>2390</id>
      <sha1>61vb9unis3r4e8bduyinijfjq1paomg</sha1>
    <revision>
      <id>60531</id>
      <timestamp>2015-07-23T11:39:07Z</timestamp>
      <contributor>
        <username>Sal</username>
        <id>22868</id>
      </contributor>
      <comment>more info</comment>
      <text xml:space="preserve" bytes="553">Beginning in Panda3D version 1.7.0, Panda provides a packaging and distribution system designed to make it very easy to distribute your Panda3D application to the world, either embedded within a web page or distributed as a standalone application.

If you are using an older version of Panda3D or do not wish to use the packaging and distribution system that Panda3D provides for whatever reason then you can use [http://www.panda3d.org/manual/index.php/Building_an_installer_using_packpanda packpanda] or any other similar tool for Python/C++ programs.</text>
    </revision>
  </page>
  <page>
    <title>Distributing Panda Applications</title>
    <ns>0</ns>
    <id>2464</id>
    <redirect title="Distributing Panda3D Applications" />
      <sha1>hsv89zqsnpuwaxeitnopsno3kh6ljsy</sha1>
    <revision>
      <id>6620</id>
      <timestamp>2010-02-07T04:42:07Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>[[Distributing Panda Applications]] moved to [[Distributing Panda3D Applications]]: Panda3D is the name of the engine; not Panda.</comment>
      <text xml:space="preserve" bytes="47">#REDIRECT [[Distributing Panda3D Applications]]</text>
    </revision>
  </page>
  <page>
    <title>Distributing as a self-contained installer</title>
    <ns>0</ns>
    <id>2404</id>
      <sha1>6s0ld496v0xg5tf43cxeevvboajo7q2</sha1>
    <revision>
      <id>7573</id>
      <timestamp>2012-01-22T13:18:14Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="5263">It is possible to distribute your p3d file as a fully
self-contained application.  You can use your p3d file to generate a
custom installer, and distribute this installer to your users.  The
installer will produce a fully-self-contained application that doesn't
require the user to install the Panda3D plugin separately.  The user
never needs to know that he/she is running Panda3D at all.

This can be done using the &lt;code&gt;pdeploy&lt;/code&gt; utility.  It has the
ability generate a graphical installer for every known platform, so you
will never need to boot a different operating system just to generate an
installer for that platform.  However, note that pdeploy requires an
internet connection to run.

For information about command-line options, you can invoke:
&lt;code bash&gt;pdeploy -h&lt;/code&gt;
This will print the help text for pdeploy, along with information about
every supported command-line option.

&lt;h2&gt;Generating an installer&lt;/h2&gt;
You can create a graphical installer for your game using a command similar to:
&lt;code bash&gt;pdeploy -s -N &quot;My Cool Game&quot; -v 1.0.0 myCoolGame.p3d installer&lt;/code&gt;
This will create various subdirectories in the current directory, one for every platform, containing graphical installers that install your game.  (You can specify a custom output directory with the &lt;b&gt;-o&lt;/b&gt; option.)  The Panda3D libraries are not packed with the installer, but they will be automatically downloaded when the game is ran for the first time.

The &lt;b&gt;-s&lt;/b&gt; option ensures a self-contained installer is created that does not require an internet connection to run.  The resulting installers will also contain the Panda3D libraries and will be larger.  In case you want to produce much lighter installers that do not contain the Panda3D libraries themselves, simply omit the &lt;b&gt;-s&lt;/b&gt; option.  In this case, the game will automatically download the latest stable version of the Panda3D libraries and install it into the user's cache directory on launch (only the first time, though, or when there are updates available).

By default, pdeploy will generate an installer for every known platform.  You can also specify a custom set of platforms, by adding the &lt;b&gt;-P&lt;/b&gt; option followed by the platform name.  You may repeat &lt;b&gt;-P&lt;/b&gt; as many times as necessary.
To generate an installer only for the current platform, use the &lt;b&gt;-c&lt;/b&gt; option. If &lt;b&gt;-c&lt;/b&gt; is provided, any &lt;b&gt;-P&lt;/b&gt; options are ignored.

You can also let pdeploy pass custom tokens to the application, as described in [[Advanced object tags]]. You can simply pass tokens to pdeploy using the &lt;b&gt;-t token=value&lt;/b&gt; option, and you may repeat the -t option as many times as you need.

In Panda3D versions 1.8 and above, you can let pdeploy generate a custom icon for the installed game.  Use and repeat the &lt;b&gt;-i&lt;/b&gt; option to pass several image files of different square sizes, which will be combined into a single icon file by pdeploy.  To support all platforms, it is recommended to supply images of the sizes 16x16, 32x32, 48x48, 128x128, 256x256, and 512x512, but you may omit the latter two or three sizes if you cannot provide images in that resolution.
It is recommended to use .png images for correct transparency.

When running the resulting game, the window will be placed in the center of the screen, unless explicitly overridden in the application.  You can pass a custom height and width for the window using the 'width' and 'height' tokens.

&lt;b&gt;Note:&lt;/b&gt; Even though most of the informational command-line arguments are optional, it is highly recommended to specify as many of them as possible, to provide the most accurate description for your application.

&lt;h3&gt;Example&lt;/h3&gt;
This fictional example shows how to use pdeploy and commonly-used options.  (You may want to omit the &lt;b&gt;-P&lt;/b&gt; options to generate for every platform.)  This is a single command, line breaks are merely added to avoid this manual page from stretching.
&lt;code bash&gt;pdeploy -s -n coolgame -N &quot;My Cool Game&quot; -v 1.0.0 -a com.cool_company -A &quot;Cool Company&quot;
-e packager@cool_company.com -l &quot;Modified BSD License&quot;
-L bsd.txt -t width=800 -t height=600
-i icon16.png -i icon32.png -i icon48.png -i icon128.png 
-P linux_amd64 -P win32 -P osx_i386 coolGame.p3d installer&lt;/code&gt;

&lt;h2&gt;Generating a standalone executable&lt;/h2&gt;
Instead of a graphical installer, pdeploy also has the ability to generate a standalone executable.  It works similar to tools like py2exe, but is designed to embed .p3d games.  This will not require a Panda3D installation to run - instead, when running it, it will automatically download and install the Panda3D libraries.  The pdeploy command-line looks like this:
&lt;code bash&gt;pdeploy myCoolGame.p3d standalone&lt;/code&gt;
Like when generating an installer, you can use the &lt;b&gt;-c&lt;/b&gt; and &lt;b&gt;P&lt;/b&gt; options to specify a custom set of platforms to generate for, &lt;b&gt;-o&lt;/b&gt; to specify a custom output directory, and &lt;b&gt;-t&lt;/b&gt; to pass custom tokens.

Note that the resulting executable will have some dependencies, such as the X11 libraries on Unix, and the Visual C++ 2008 runtime on Windows.  It will not run if those libraries are not present on the system.  You should use the &quot;installer&quot; option, as explained above, for a fully self-contained installer that contains the dependent libraries.</text>
    </revision>
  </page>
  <page>
    <title>Distributing via the web</title>
    <ns>0</ns>
    <id>2395</id>
      <sha1>dtscw4cbq78ik6kot92f7llis6fxe89</sha1>
    <revision>
      <id>6648</id>
      <timestamp>2010-02-08T20:32:40Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="261">One of the big advantages of packaging your application into a p3d
file is that it is possible to embed that p3d file into a web page, so
that your application can be run by simply visiting a particular web
address.  The following pages describe this technique.</text>
    </revision>
  </page>
  <page>
    <title>Downloading a File</title>
    <ns>0</ns>
    <id>2258</id>
      <sha1>0e3ptfpslv90hhh4jp968t9prum2cyc</sha1>
    <revision>
      <id>6321</id>
      <timestamp>2009-11-06T15:55:23Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>code tags</comment>
      <text xml:space="preserve" bytes="1185">To download a file while the game is running without blocking the connections one has to use HTTPClient and HTTPChannel objects. This will allow the file to be downloaded in the background using the downloadTask task.

&lt;code python&gt;
self.http = HTTPClient()
self.channel = self.http.makeChannel(True)
self.channel.beginGetDocument(DocumentSpec('http://my.url/'))
self.rf = Ramfile()
self.channel.downloadToRam(self.rf)
taskMgr.add(self.downloadTask, 'download')

def downloadTask(self, task):
    if self.channel.run():
        # Still waiting for file to finish downloading.
        return task.cont
    if not self.channel.isDownloadComplete():
        print &quot;Error downloading file.&quot;
        return task.done
    data = self.rf.getData()
    print &quot;got data:&quot;
    print data
    return task.done 
&lt;/code&gt;

You can also download to file 
&lt;code python&gt;
channel.downloadToFile(Filename(fileName))
&lt;/code&gt;

The file channel can be quarried for further information while the game is running to get the current download state.
&lt;code python&gt;
mbDownloaded = self.channel.getBytesDownloaded()/1024/1024
percentDownloaded = 100.*self.channel.getBytesDownloaded()/channel.getFileSize()
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>Draft A New Panda General Interface</title>
    <ns>0</ns>
    <id>2519</id>
    <redirect title="P2/General Interface" />
      <sha1>o0of0e1ky0w3nq4e22rays2r4upx72b</sha1>
    <revision>
      <id>6976</id>
      <timestamp>2010-12-18T22:13:04Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>[[Draft A New Panda General Interface]] moved to [[P2/General Interface]]</comment>
      <text xml:space="preserve" bytes="34">#REDIRECT [[P2/General Interface]]</text>
    </revision>
  </page>
  <page>
    <title>Dynamic Cube Maps</title>
    <ns>0</ns>
    <id>1232</id>
      <sha1>jbtzquvn9bd9gw0f8ry082gijuxh7j9</sha1>
    <revision>
      <id>6553</id>
      <timestamp>2010-01-21T12:53:32Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>Suppressed screenshots; added &lt;p&gt; tags inside the &lt;table&gt; to make &lt;code&gt; tags look cleaner in it.</comment>
      <text xml:space="preserve" bytes="6555">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;
[python]
&lt;p&gt;Since the six faces of a cube map are really just six different views of a scene from the same point, it's possible to generate a cube map automatically by rendering these six different views at runtime.&lt;/p&gt;

&lt;p&gt;This is really just a form of offscreen rendering to a texture. Instead of rendering just one 2-D texture image, though, rendering a dynamic cube map means rendering six different 2-D images, one for each face of a cube map texture.&lt;/p&gt;

&lt;p&gt;Panda3D makes this easy for you. To start rendering a dynamic cube map, simply call:&lt;/p&gt;
&lt;code python&gt;
rig = NodePath('rig')
buffer = base.win.makeCubeMap(name, size, rig)
&lt;/code&gt;
&lt;p&gt;This will return an offscreen &lt;code&gt;GraphicsBuffer&lt;/code&gt; that will be used to render the cube map. The three required parameters to &lt;code&gt;[func]makeCubeMap[/func]()&lt;/code&gt; are:&lt;/p&gt;

&lt;center&gt;
&lt;table border=1 cellpadding=1 cellspacing=0&gt;
&lt;tr&gt;
&lt;td&gt;&lt;p&gt;&lt;code&gt;name&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;An arbitrary name to assign to the cube map and its associated &lt;code&gt;GraphicsBuffer&lt;/code&gt;. This can be any string.&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;p&gt;&lt;code&gt;size&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;The size in pixels of one side of the cube. Many graphics cards require this size to be a power of two. Some cards don't &lt;i&gt;require&lt;/i&gt; a power of two, but will perform very slowly if you give anything else.&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;p&gt;&lt;code&gt;rig&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;The camera rig node. This should be a new &lt;code&gt;NodePath&lt;/code&gt;. It will be filled in with six cameras. See below.&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/center&gt;

&lt;p&gt;There are also additional, optional parameters to &lt;code&gt;[func]makeCubeMap[/func]()&lt;/code&gt;:&lt;/p&gt;

&lt;center&gt;
&lt;table border=1 cellpadding=1 cellspacing=0&gt;
&lt;tr&gt;
&lt;td&gt;&lt;p&gt;&lt;code&gt;cameraMask&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;This specifies the &lt;code&gt;DrawMask&lt;/code&gt; that is associated with the cube map's cameras. This is an advanced Panda3D feature that can be used to hide or show certain objects specifically for the cube map cameras.&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;p&gt;&lt;code&gt;toRam&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;This is a boolean flag that, when True, indicates the texture image will be made available in system RAM, instead of leaving it only in texture memory. The default is False. Setting it True is slower, but may be necessary if you want to write out the generated cube map image to disk.&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/center&gt;

&lt;p&gt;Note that we passed a new &lt;code&gt;NodePath&lt;/code&gt;, called &lt;code&gt;rig&lt;/code&gt; in the above example, to the &lt;code&gt;[func]makeCubeMap[/func]()&lt;/code&gt; call. This &lt;code&gt;NodePath&lt;/code&gt; serves as the &quot;camera rig&quot;; the &lt;code&gt;[func]makeCubeMap[/func]()&lt;/code&gt; method will create six cameras facing in six different directions, and attach them all to the camera rig. Thus, you can parent this rig into your scene and move it around as if it were a six-eyed camera. Normally, for environment maps, you would parent the rig somewhere within your shiny object so it can look out of the shiny object and see the things that should be reflected in it.&lt;/p&gt;

&lt;p&gt;The actual cube map itself be retrieved with the call:&lt;/p&gt;

&lt;code python&gt;
tex = buffer.getTexture()
&lt;/code&gt;

&lt;p&gt;You can apply the texture to geometry as in the [[Environment Mapping with Cube Maps|previous example]]. You should use the &lt;code&gt;MWorldCubeMap&lt;/code&gt; mode to generate texture coordinates for your geometry since the camera rig will have a [[Compass Effects|CompassEffect]] on it to keep it unrotated with respect to &lt;code&gt;render&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;When you are done with the cube map, you should remove its buffer (and stop the cube map from continuing to render) by calling:&lt;/p&gt;

&lt;code python&gt;
base.graphicsEngine.removeWindow(buffer)
&lt;/code&gt;

&lt;p&gt;As a complete example, here is how we might load up a dynamic cube map environment on our teapot and move the teapot down the street to show off the dynamic reflections:&lt;/p&gt;

&lt;code python&gt;
scene = loader.loadModel('bvw-f2004--streetscene/street-scene.egg')
scene.reparentTo(render)
scene.setZ(-2)

teapot = loader.loadModel('teapot.egg')
teapot.reparentTo(render)

rig = NodePath('rig')
buffer = base.win.makeCubeMap('env', 64, rig)
rig.reparentTo(teapot)

teapot.setTexGen(TextureStage.getDefault(), TexGenAttrib.MWorldCubeMap)
teapot.setTexture(buffer.getTexture())

zoom = teapot.posInterval(5, VBase3(20, 0, 0), startPos=VBase3(-20, 0, 0))
zoom.loop()
&lt;/code&gt;

&lt;h2&gt;A word of caution&lt;/h2&gt;

&lt;p&gt;When you render a dynamic cube map, don't forget that you are re-rendering your scene &lt;i&gt;six times&lt;/i&gt; every frame in addition to the main frame render. If you are not careful, and if you have a complex scene, then you could easily end up reducing your frame rate by a factor of seven.&lt;/p&gt;

&lt;p&gt;It is a good idea to limit the amount of geometry that you render in the cube map. One simple way to do this is to ensure that the [[Lenses and Field of View|far plane]] on the cube map cameras is set relatively close in. Since all of the cube map cameras share the same lens, you can adjust the near and far plane of all of the cameras at once like this:&lt;/p&gt;

&lt;code python&gt;
lens = rig.find('**/+Camera').node().getLens()
lens.setNearFar(1, 100)
&lt;/code&gt;

&lt;p&gt;It is especially important when you are using cube maps that you structure your scene graph hierarchically and divide it up spatially so that Panda3D's view-frustum culling can do an effective job of eliminating the parts of the scene that are behind each of the six cameras. (Unfortunately, the street-scene model used in the above example is not at all well-structured, so the example performs very poorly on all but the highest-end hardware.)&lt;/p&gt;

&lt;p&gt;It's also usually a good idea to keep the cube map size (the &lt;code&gt;size&lt;/code&gt; parameter to &lt;code&gt;[func]makeCubeMap[/func]()&lt;/code&gt;) no larger than it absolutely has to be to get the look you want.&lt;/p&gt;

&lt;p&gt;You can also take advantage of the &lt;code&gt;DrawMask&lt;/code&gt; to hide things from the cube cameras that are not likely to be important in the reflections. The documentation for this advanced feature of Panda3D will be found in another section of the manual (which, as of the time of this writing, has yet to be written).&lt;/p&gt;

&lt;p&gt;Finally, you can temporarily disable the cube map rendering from time to time if you know the environment won't be changing for a little while. The cube map will retain its last-rendered image. You can do this with &lt;code&gt;[func]buffer.setActive[/func](0)&lt;/code&gt;. Use &lt;code&gt;[func]buffer.setActive[/func](1)&lt;/code&gt; to re-activate it.&lt;/p&gt;
[/python]

[cxx]
&lt;h2&gt;Incomplete Section&lt;/h2&gt;

&lt;p&gt;Note: this section is incomplete. It will be updated soon.&lt;/p&gt;
[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Dynamic Obstacles</title>
    <ns>0</ns>
    <id>2594</id>
      <sha1>o85um2ot8hc0qf7ht7dt7ujoabgfhpc</sha1>
    <revision>
      <id>7708</id>
      <timestamp>2012-03-09T10:32:01Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <comment>Panda's &quot;direct&quot; package has nothing to do with &quot;DirectX&quot;</comment>
      <text xml:space="preserve" bytes="8953">&lt;b&gt;DYNAMIC OBSTACLES :&lt;/b&gt;


{{#ev:youtube|8BZ_3gua5Bs}}


-----


In PandAI, use it via :

&lt;code python&gt;
addDynamicObstacle(NodePath obstacle);
&lt;/code&gt;


-----


&lt;b&gt;The code for this tutorial :&lt;/b&gt;

&lt;code python&gt;
# This tutorial provides an example of creating a character
# and having it walk around using PandAI and dynamic obstacle
# pathfinding

import direct.directbase.DirectStart
from panda3d.core import *
from direct.showbase.DirectObject import DirectObject
#for intervals
from direct.interval.IntervalGlobal import *
#for FSM
from direct.fsm import FSM
from direct.fsm import State
#for tasks
from direct.task import Task
#for Actors
from direct.actor.Actor import Actor
#for math
import math
import random
#for system commands
import random, sys, os, math
#for directGUI
from direct.gui.DirectGui import *
from direct.gui.OnscreenText import OnscreenText

#for Pandai
from panda3d.ai import *

#************************GLOBAL**********************************************
speed = 0.2
turnspeed = 3.5

# Figure out what directory this program is in.
MYDIR=os.path.abspath(sys.path[0])
MYDIR=Filename.fromOsSpecific(MYDIR).getFullpath()

font = loader.loadFont(&quot;cmss12&quot;)

# Function to put instructions on the screen.
def addInstructions(pos, msg):
    return OnscreenText(text=msg, style=1, fg=(1,1,1,1), font = font,
                        pos=(-1.3, pos), align=TextNode.ALeft, scale = .05)

# Function to put title on the screen.
def addTitle(text):
    return OnscreenText(text=text, style=1, fg=(1,1,1,1), font = font,
                        pos=(1.3,-0.95), align=TextNode.ARight, scale = .07)

class World(DirectObject):

    def __init__(self):
        
        self.keyMap = {&quot;left&quot;:0, &quot;right&quot;:0, &quot;forward&quot;:0}
        
        #base.disableMouse()
        base.cam.setPosHpr(0,-210,135,0,327,0)
        self.done = []
        for i in range(4):
            self.done.append(False)
        self.toggle = False
        self.firstTime = False

        self.title = addTitle(&quot;Pandai Tutorial: Dynamic Avoidance of Moving Obstacles&quot;)
        self.inst1 = addInstructions(0.95, &quot;[ESC]: Quit&quot;)
        self.inst2 = addInstructions(0.90, &quot;[Arrow Keys]: Move the blue Ralph&quot;)
        self.inst3 = addInstructions(0.85, &quot;Try and move the blue Ralph in the path of the other Ralphs&quot;)

        self.loadModels()
        self.setAI()
       
    def loadModels(self):

        self.environ1 = loader.loadModel(&quot;models/skydome&quot;)      
        self.environ1.reparentTo(render)
        self.environ1.setPos(0,0,0)
        self.environ1.setScale(1)
        
        self.environ2 = loader.loadModel(&quot;models/skydome&quot;)      
        self.environ2.reparentTo(render)
        self.environ2.setP(180)
        self.environ2.setH(270)
        self.environ2.setScale(1)

        self.environ = loader.loadModel(&quot;models/plane_demo1&quot;)      
        self.environ.reparentTo(render)
        self.environ.setPos(0,0,0)
               
        self.Target = Actor(&quot;models/ralph&quot;,
                                     {&quot;run&quot;:&quot;models/ralph-run&quot;,
                                      &quot;walk&quot;:&quot;models/ralph-walk&quot;})
        self.Target.setColor(0,0,1)
        self.Target.setPos(60,-60,0)
        self.Target.setScale(2)
        self.Target.reparentTo(render)
        self.Target.loop(&quot;run&quot;)
        self.Targetforward = NodePath(&quot;Targetforward&quot;)
        self.Targetforward.setPos(0,-1,0)
        self.Targetforward.reparentTo(self.Target)   
                      
        # Create the main character, Ralph
        self.ralph = []
        self.positions = []
        self.positions_new = []
        for i in range(4):
            self.ralph.append(Actor(&quot;models/ralph&quot;,
                                     {&quot;run&quot;:&quot;models/ralph-run&quot;,
                                      &quot;walk&quot;:&quot;models/ralph-walk&quot;}))
            self.ralph[i].reparentTo(render)
            self.ralph[i].setScale(2)

            self.positions.append(NodePath(str(i)))
            self.positions_new.append(NodePath(str(i)))
            if(i&lt;2):
                self.ralph[i].setPos(Vec3(-61,-34 + (i * 40),0))
            else:
                self.ralph[i].setPos(Vec3(61,-34 + ((i-2) * 40),0))

            self.positions.append(NodePath(str(i)))
            self.positions_new.append(NodePath(str(i)))

        self.positions[0].setPos(Vec3(-61,-34 + ((0) * 40),0))
        self.positions[1].setPos(Vec3(-53,-34 + ((1) * 40),0))
        self.positions[2].setPos(Vec3(53,-44 + ((0) * 40),0))
        self.positions[3].setPos(Vec3(61,-24 + ((1) * 40),0))

        self.positions_new[0].setPos(Vec3(61,-44 + ((0) * 40),0))
        self.positions_new[1].setPos(Vec3(53,-44 + ((1) * 40),0))
        self.positions_new[2].setPos(Vec3(-53,-24 + ((0) * 40),0))
        self.positions_new[3].setPos(Vec3(-61,-24 + ((1) * 40),0))
                
           
    def setAI(self):
        #Creating AI World
        self.AIworld = AIWorld(render)
        
        #self.accept(&quot;enter&quot;, self.setMove)
        #movement
        self.accept(&quot;arrow_left&quot;, self.setKey, [&quot;left&quot;,1])
        self.accept(&quot;arrow_right&quot;, self.setKey, [&quot;right&quot;,1])
        self.accept(&quot;arrow_up&quot;, self.setKey, [&quot;forward&quot;,1])
        self.accept(&quot;arrow_left-up&quot;, self.setKey, [&quot;left&quot;,0])
        self.accept(&quot;arrow_right-up&quot;, self.setKey, [&quot;right&quot;,0])
        self.accept(&quot;arrow_up-up&quot;, self.setKey, [&quot;forward&quot;,0])
        
        self.AIchar = []
        self.AIbehaviors = []
        for i in range(4):
            self.AIchar.append(AICharacter(&quot;ralph&quot;,self.ralph[i], 60, 0.05, 25 - (5 * random.random())))
            self.AIworld.addAiChar(self.AIchar[i])
            self.AIbehaviors.append(self.AIchar[i].getAiBehaviors())
            self.AIbehaviors[i].initPathFind(&quot;models/navmesh.csv&quot;)
                   
        #AI World update        
        taskMgr.add(self.AIUpdate,&quot;AIUpdate&quot;)
        
        taskMgr.add(self.Mover, &quot;mover&quot;)
        
        self.setMove(1)

        
    def setMove(self, type):
        if(type == 1):
            for i in range(4):
                if(i==0):
                    self.AIbehaviors[i].pathFindTo(self.positions_new[0], &quot;addPath&quot;)
                    self.AIbehaviors[i].addDynamicObstacle(self.ralph[2])   
                if(i==1):
                    self.AIbehaviors[i].pathFindTo(self.positions_new[1], &quot;addPath&quot;)
                    self.AIbehaviors[i].addDynamicObstacle(self.ralph[3])
                if(i==2):
                    self.AIbehaviors[i].pathFindTo(self.positions_new[2], &quot;addPath&quot;)
                if(i==3):
                    self.AIbehaviors[i].pathFindTo(self.positions_new[3], &quot;addPath&quot;)
                if(self.firstTime == False):
                    self.AIbehaviors[i].addDynamicObstacle(self.Target)                    
                self.ralph[i].loop(&quot;run&quot;)
                
            self.firstTime = True
        
        if(type == 2):
            for i in range(4):
                if(i==0):
                    self.AIbehaviors[i].pathFindTo(self.positions[0], &quot;addPath&quot;)
                if(i==1):
                    self.AIbehaviors[i].pathFindTo(self.positions[1], &quot;addPath&quot;)
                if(i==2):
                    self.AIbehaviors[i].pathFindTo(self.positions[2], &quot;addPath&quot;)
                if(i==3):
                    self.AIbehaviors[i].pathFindTo(self.positions[3], &quot;addPath&quot;)

                    
                self.ralph[i].loop(&quot;run&quot;)
            
     #to update the AIWorld    
    def AIUpdate(self,task):
        self.AIworld.update()
        for i in range(4):
            #print(str(i) + &quot; &quot; + self.AIbehaviors[i].behaviorStatus(&quot;pathfollow&quot;))
            if(self.AIbehaviors[i].behaviorStatus(&quot;pursue&quot;) == &quot;done&quot; or 
               self.AIbehaviors[i].behaviorStatus(&quot;pursue&quot;) == &quot;paused&quot;):
                self.done[i] = True
            
        j = 0
        for i in range(4):
            if(self.done[i] == True):
                j = j+1
             
        if(j==4):
            self.toggle = not self.toggle
            if(self.toggle == True):
                self.setMove(2)
            else:
                self.setMove(1)
            for i in range(4):
                self.done[i] = False
                   
        return Task.cont
 
    def setKey(self, key, value):
        self.keyMap[key] = value
        
    def Mover(self,task):
        startPos = self.Target.getPos()

        if (self.keyMap[&quot;left&quot;]!=0):
            self.Target.setH(self.Target.getH() + turnspeed)
        if (self.keyMap[&quot;right&quot;]!=0):
            self.Target.setH(self.Target.getH() - turnspeed)
        if (self.keyMap[&quot;forward&quot;]!=0):
            forwardvector = self.Targetforward.getPos(render)-startPos
            self.Target.setPos(startPos + forwardvector * speed)
            
        return Task.cont
 
w = World()
run()

&lt;/code&gt;


-----


&lt;b&gt;The full working demo can be downloaded at :&lt;/b&gt;

https://sites.google.com/site/etcpandai/documentation/pathfinding/DynamicObstacleDemo.zip?attredirects=0&amp;d=1</text>
    </revision>
  </page>
  <page>
    <title>Egg File Syntax</title>
    <ns>0</ns>
    <id>1159</id>
    <redirect title="Parsing and Generating Egg Files" />
      <sha1>3xiezkzv6myl4t335wyhchbdyi6bcve</sha1>
    <revision>
      <id>2440</id>
      <timestamp>2005-08-04T19:43:22Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <comment>Egg File Syntax moved to Parsing and Generating Egg Files</comment>
      <text xml:space="preserve" bytes="47">#REDIRECT [[Parsing and Generating Egg Files]]
</text>
    </revision>
  </page>
  <page>
    <title>Egg Syntax</title>
    <ns>0</ns>
    <id>2236</id>
      <sha1>b8b771qtl2cu5w7azcuox12674r4f6r</sha1>
    <revision>
      <id>60299</id>
      <timestamp>2014-11-29T00:37:28Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>Git</comment>
      <text xml:space="preserve" bytes="16218">'''The Egg Syntax'''

This is a condensed version of the Egg Syntax document, incorporating only syntax definitions in common use. For complete documentation, please see the [https://raw.githubusercontent.com/panda3d/panda3d/master/panda/src/doc/eggSyntax.txt Egg Syntax] documentation from the Panda3D source code repository.

__TOC__

== General Syntax ==

Egg files consist of a series of sequential and hierarchically-nested entries. In general, the syntax of each entry is:

  &lt;Entry-type&gt; name { contents }

Comment text should be enclosed in quotation marks:

  &lt;Comment&gt; { text }

== Local Information Entries ==

These nodes contain information relevant to the current level of nesting only.

  &lt;Scalar&gt; name { value }

Scalars are attributes of the entry the Scalar is in. Name is the attribute name with value as the contents of that attribute.

== Global Information Entries ==

These nodes contain information relevant to the file as a whole. They can be nested along with geometry nodes, but this nesting is irrelevant and the only significant placement rule is that they should appear before they are referenced.

=== Coordinate System ===

  &lt;CoordinateSystem&gt; { string }

This entry indicates the coordinate system used in the egg file; the egg loader will automatically make a conversion if necessary.  The following strings are valid: Y-up, Z-up, Y-up-right, Z-up-right, Y-up-left, or Z-up-left.  (Y-up is the same as Y-up-right, and Z-up
is the same as Z-up-right.)

=== Textures ===

This describes a texture file that can be referenced later with &lt;TRef&gt; { name }.

&lt;pre class=&quot;codeblock&quot;&gt;
&lt;Texture&gt; name {
  filename
  [scalars]
}
&lt;/pre&gt;

==== Texture Scalars====

This is not a complete list of texture attributes. Please refer to the full document for all scalars and their value definitions

  &lt;Scalar&gt; alpha-file { alpha-filename }
  &lt;Scalar&gt; alpha-file-channel { channel }
  &lt;Scalar&gt; format { format-definition }
  &lt;Scalar&gt; type { texture-type }
  &lt;Scalar&gt; envtype { environment-type }
  &lt;Scalar&gt; tex-gen { mode }
  &lt;Scalar&gt; stage-name { name }
  &lt;Scalar&gt; uv-name { name }
  &lt;Scalar&gt; rgb-scale { scale }
  &lt;Scalar&gt; alpha-scale { scale }
  &lt;Scalar&gt; alpha { alpha-type }
  &lt;Transform&gt; { transform-definition }

=== Materials ===

This defines a set of material attributes that may later be referenced with &lt;MRef&gt; { name }.

&lt;pre class=&quot;codeblock&quot;&gt;
&lt;Material&gt; name {
  [scalars]
}
&lt;/pre&gt;

==== Material Scalars ====

  &lt;Scalar&gt; diffr { number }
  &lt;Scalar&gt; diffg { number }
  &lt;Scalar&gt; diffb { number }
  &lt;Scalar&gt; diffa { number }
  &lt;Scalar&gt; ambr { number }
  &lt;Scalar&gt; ambg { number }
  &lt;Scalar&gt; ambb { number }
  &lt;Scalar&gt; amba { number }
  &lt;Scalar&gt; emitr { number }
  &lt;Scalar&gt; emitg { number }
  &lt;Scalar&gt; emitb { number }
  &lt;Scalar&gt; emita { number }
  &lt;Scalar&gt; specr { number }
  &lt;Scalar&gt; specg { number }
  &lt;Scalar&gt; specb { number }
  &lt;Scalar&gt; speca { number }
  &lt;Scalar&gt; shininess { number }
  &lt;Scalar&gt; local { flag }

=== Vertex Pool ===

A vertex pool is a set of vertices.  All geometry is created by referring to vertices by number in a particular vertex pool.  There may be one or several vertex pools in an egg file, but all vertices that make up a single polygon must come from the same vertex pool. The body of a &lt;VertexPool&gt; entry is simply a list of one or more &lt;Vertex&gt; entries, as follows:

&lt;pre class=&quot;codeblock&quot;&gt;
&lt;VertexPool&gt; name {
  &lt;Vertex&gt; number1 {
  }
  &lt;Vertex&gt; numer2 {
  }
  ...
}
&lt;/pre&gt;

==== Vertices ====

A &lt;Vertex&gt; entry is only valid within a vertex pool definition. The number is the index by which this vertex will be referenced. It is optional; if it is omitted, the vertices are implicitly numbered consecutively beginning at one.  If the number is supplied, the vertices need not be consecutive.

The vertex's coordinates are always given in world space, regardless of any transforms before the vertex pool or before the referencing geometry. If the vertex is referenced by geometry under a transform, the egg loader will do an inverse transform to move the vertex into the proper coordinate space without changing its position in world space.  One exception is geometry under an &lt;Instance&gt; node; in this case the vertex coordinates are given in the space of the &lt;Instance&gt; node.  (Another exception is a &lt;DynamicVertexPool&gt;; see below.)

&lt;pre class=&quot;codeblock&quot;&gt;
  &lt;Vertex&gt; number {
    x y z [w]
    [attributes]
  }
&lt;/pre&gt;

===== Vertex Attributes =====

  &lt;Normal&gt; { x y z [morph-list] }
  &lt;RGBA&gt; { r g b a [morph-list] }
  &lt;UV&gt; [name] { u v [w] [tangent] [binormal] [morph-list] }
  &lt;Dxyz&gt; target { x y z }

== Geometry Entries ==

Geometry entries reference Vertex pool entries to generate renderable geometry
for Panda to use.

=== Polygons ===

A polygon consists of a sequence of vertices from a single vertex pool. Vertices are identified by pool-name and index number within the pool; indices is a list of vertex numbers within the given vertex pool.  Vertices are listed in counterclockwise order. Although the vertices must all come from the same vertex pool, they may have been assigned to arbitrarily many different joints regardless of joint connectivity (there is no &quot;straddle-polygon&quot; limitation). See Joints, below.

The polygon syntax is quite verbose, and there isn't any way to specify a set of attributes that applies to a group of polygons--the attributes list must be repeated for each polygon.  This is why egg files tend to be very large.

&lt;pre class=&quot;codeblock&quot;&gt;
&lt;Polygon&gt; name { 
    [attributes] 
    &lt;VertexRef&gt; { 
        indices 
        &lt;Ref&gt; { pool-name } 
    } 
}&lt;/pre&gt;

==== Polygon Attributes ====

  &lt;TRef&gt; { texture-name }
  &lt;Texture&gt; { filename }
  &lt;MRef&gt; { material-name }
  &lt;Normal&gt; { x y z [morph-list] }
  &lt;RGBA&gt; { r g b a [morph-list] }
  &lt;BFace&gt; { boolean-value }
  &lt;Scalar&gt; bin { bin-name }
  &lt;Scalar&gt; draw_order { number }
  &lt;Scalar&gt; visibility { hidden | normal }

== Grouping Entries ==

A &lt;Group&gt; node is the primary means of providing structure to the egg file.  Groups can contain vertex pools and polygons, as well as other groups.  The egg loader translates &lt;Group&gt; nodes directly into PandaNodes in the scene graph (although the egg loader reserves the right to arbitrarily remove nodes that it deems unimportant--see the &lt;Model&gt; flag, below to avoid this).  In addition, the following entries can be given specifically within a &lt;Group&gt; node to specify attributes of the group.

&lt;pre class=&quot;codeblock&quot;&gt;
&lt;Group&gt; name {
  [attributes]
  [scalars]
  [SwitchCondition]
  [Tag]
  [Collide]
  [ObjectType]
}
&lt;/pre&gt;

=== Grouping Attributes ===

  &lt;DCS&gt; { boolean-value }
  &lt;DCS&gt; { dcs-type }
  &lt;Model&gt; { boolean-value }
  &lt;Dart&gt; { boolean-value }
  &lt;Switch&gt; { boolean-value }

=== Group Scalars ===

  &lt;Scalar&gt; fps { frame-rate }
  &lt;Scalar&gt; bin { bin-name }
  &lt;Scalar&gt; draw_order { number }
  &lt;Scalar&gt; visibility { hidden | normal }
  &lt;Scalar&gt; decal { boolean-value }
  &lt;Scalar&gt; decalbase { boolean-value }
  &lt;Scalar&gt; collide-mask { value }
  &lt;Scalar&gt; from-collide-mask { value }
  &lt;Scalar&gt; into-collide-mask { value }
  &lt;Scalar&gt; blend { mode }
  &lt;Scalar&gt; blendop-a { mode }
  &lt;Scalar&gt; blendop-b { mode }
  &lt;Scalar&gt; blendr { red-value }
  &lt;Scalar&gt; blendg { green-value }
  &lt;Scalar&gt; blendb { blue-value }
  &lt;Scalar&gt; blenda { alpha-value }

=== Other Group Attributes ===

==== Billboard ====

  &lt;Billboard&gt; { type }

This entry indicates that all geometry defined at or below this group level is part of a billboard that will rotate to face the
camera.  Type is either &quot;axis&quot; or &quot;point&quot;, describing the type of rotation.

Billboards rotate about their local axis.  In the case of a Y-up file, the billboards rotate about the Y axis; in a Z-up file, they rotate about the Z axis.  Point-rotation billboards rotate about the origin.

There is an implicit &lt;Instance&gt; around billboard geometry.  This means that the geometry within a billboard is not specified in world coordinates, but in the local billboard space.  Thus, a vertex drawn at point 0,0,0 will appear to be at the pivot point of the billboard, not at the origin of the scene.

==== SwitchCondition ====

  &lt;SwitchCondition&gt; {
     &lt;Distance&gt; { 
        in out [fade] &lt;Vertex&gt; { x y z }
     }
  }

The subtree beginning at this node and below represents a single level of detail for a particular model.  Sibling nodes represent the additional levels of detail.  The geometry at this node will be visible when the point (x, y, z) is closer than &quot;in&quot; units, but further than &quot;out&quot; units, from the camera.  &quot;fade&quot; is presently ignored.

==== Tag ====

  &lt;Tag&gt; key { value }

This attribute defines the indicated tag (as a key/value pair), retrievable via NodePath::get_tag() and related interfaces, on this node.

==== Collide ====

  &lt;Collide&gt; name { type [flags] }

This entry indicates that geometry defined at this group level is actually an invisible collision surface, and is not true geometry. The geometry is used to define the extents of the collision surface.  If there is no geometry defined at this level, then a child is searched for with the same collision type specified, and its geometry is used to define the extent of the collision surface (unless the &quot;descend&quot; flag is given; see below).

    Valid types so far are:

    Plane
    
      The geometry represents an infinite plane.  The first polygon
      found in the group will define the plane.

    Polygon

      The geometry represents a single polygon.  The first polygon is
      used.

    Polyset

      The geometry represents a complex shape made up of several
      polygons.  This collision type should not be overused, as it
      provides the least optimization benefit.

    Sphere

      The geometry represents a sphere.  The vertices in the group are
      averaged together to determine the sphere's center and radius.

    InvSphere

      The geometry represents an inverse sphere.  This is the same as
      Sphere, with the normal inverted, so that the solid part of an
      inverse sphere is the entire world outside of it.  Note that an
      inverse sphere is in infinitely large solid with a finite hole
      cut into it.

    Tube

      The geometry represents a tube.  This is a cylinder-like shape
      with hemispherical endcaps; it is sometimes called a capsule or
      a lozenge in other packages.  The smallest tube shape that will
      fit around the vertices is used.


    The flags may be any zero or more of:

    event

      Throws the name of the &lt;Collide&gt; entry, or the name of the
      surface if the &lt;Collide&gt; entry has no name, as an event whenever
      an avatar strikes the solid.  This is the default if the
      &lt;Collide&gt; entry has a name.

    intangible

      Rather than being a solid collision surface, the defined surface
      represents a boundary.  The name of the surface will be thrown
      as an event when an avatar crosses into the interior, and
      name-out will be thrown when an avatar exits.

    descend

      Instead of creating only one collision object of the given type,
      each group descended from this node that contains geometry will
      define a new collision object of the given type.  The event
      name, if any, will also be inherited from the top node and
      shared among all the collision objects.

    keep
 
      Don't discard the visible geometry after using it to define a
      collision surface; create both an invisible collision surface
      and the visible geometry.

    level

      Stores a special effective normal with the collision solid that
      points up, regardless of the actual shape or orientation of the
      solid.  This can be used to allow an avatar to stand on a
      sloping surface without having a tendency to slide downward.

==== ObjectType ====

  &lt;ObjectType&gt; { type }

This is a short form to indicate one of several pre-canned sets of attributes.  Type may be any word, and a Config definition will be searched for by the name &quot;egg-object-type-word&quot;, where &quot;word&quot; is the type word.  This definition may contain any arbitrary egg syntax to be parsed in at this group level.

    A number of predefined ObjectType definitions are provided:

    barrier

      This is equivalent to &lt;Collide&gt; { Polyset descend }.  The
      geometry defined at this root and below defines an invisible
      collision solid.

    trigger

      This is equivalent to &lt;Collide&gt; { Polyset descend intangible }.
      The geometry defined at this root and below defines an invisible
      trigger surface.

    sphere

      Equivalent to &lt;Collide&gt; { Sphere descend }.  The geometry is
      replaced with the smallest collision sphere that will enclose
      it.  Typically you model a sphere in polygons and put this flag
      on it to create a collision sphere of the same size.

    tube

      Equivalent to &lt;Collide&gt; { Tube descend }.  As in sphere, above,
      but the geometry is replaced with a collision tube (a capsule).
      Typically you will model a capsule or a cylinder in polygons.

    bubble

      Equivalent to &lt;Collide&gt; { Sphere keep descend }.  A collision
      bubble is placed around the geometry, which is otherwise
      unchanged.

    ghost

      Equivalent to &lt;Scalar&gt; collide-mask { 0 }.  It means that the
      geometry beginning at this node and below should never be
      collided with--characters will pass through it.

    backstage

      This has no equivalent; it is treated as a special case.  It
      means that the geometry at this node and below should not be
      translated.  This will normally be used on scale references and
      other modeling tools.

    There may also be additional predefined egg object types not
    listed here; see the *.pp files that are installed into the etc
    directory for a complete list.

  &lt;Transform&gt; { transform-definition }
  &lt;VertexRef&gt; { indices &lt;Ref&gt; { pool-name } }

== Joint Nodes ==

&lt;pre class=&quot;codebase&quot;&gt;
&lt;Joint&gt; name {
  [transform]
  [ref-list]
  [joint-list]
}
&lt;/pre&gt;

A joint is a highly specialized kind of grouping node.  A tree of joints is used to specify the skeletal structure of an animated character.

A joint may only contain one of three things.  It may contain a &lt;code&gt;&lt;Transform&gt;&lt;/code&gt; entry, as above, which defines the joint's unanimated (rest) position; it may contain lists of assigned vertices or CV's; and it may contain other joints.

A tree of &lt;Joint&gt; nodes only makes sense within a character definition, which is created by applying the &lt;DART&gt; flag to a group. See &lt;DART&gt;, above.

The vertex assignment is crucial.  This is how the geometry of a character is made to move with the joints.  The character's geometry is actually defined outside the joint tree, and each vertex must be assigned to one or more joints within the tree.

This is done with zero or more &lt;VertexRef&gt; entries per joint, as the following:

  &lt;VertexRef&gt; { indices [&lt;Scalar&gt; membership { m }] &lt;Ref&gt; { pool-name } }

This is syntactically similar to the way vertices are assigned to polygons. Each &lt;VertexRef&gt; entry can assign vertices from only one vertex pool (but there may be many &lt;VertexRef&gt; entries per joint). Indices is a list of vertex numbers from the specified vertex pool, in an arbitrary order.

The membership scalar is optional.  If specified, it is a value between 0.0 and 1.0 that indicates the fraction of dominance this joint has over the vertices.  This is used to implement soft-skinning, so that each vertex may have partial ownership in several joints.

The &lt;VertexRef&gt; entry may also be given to ordinary &lt;Group&gt; nodes. In this case, it treats the geometry as if it was parented under the group in the first place.  Non-total membership assignments are meaningless.

== Bundle and Table entries ==

A table is a set of animated values for joints.  A tree of tables with the same structure as the corresponding tree of joints must be defined for each character to be animated.  Such a tree is placed under a &lt;Bundle&gt; node, which provides a handle within Panda to the tree as a whole.

Bundles may only contain tables; tables may contain more tables, bundles, or any one of the following (&lt;Scalar&gt; entries are optional, and default as shown):

&lt;pre class=&quot;codeblock&quot;&gt;
&lt;S$Anim&gt; name { 
  &lt;Scalar&gt; fps { 24 }
  &lt;V&gt; { values }
}
&lt;/pre&gt;</text>
    </revision>
  </page>
  <page>
    <title>Email certificates</title>
    <ns>0</ns>
    <id>2402</id>
      <sha1>bg621rnknqmxkfimhsrpeodkrsdd1k0</sha1>
    <revision>
      <id>6247</id>
      <timestamp>2009-10-17T15:51:07Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="1699">You can also use a personal email certificate to sign your p3d files.
When you do this, and the user is shown your certificate, he/she will
be told &quot;This application has been signed by
yourname@youraddress.net,&quot; which reassures the user of your personal
identity.

An email certificate is sometimes called an S/MIME certificate,
because it can be used to send encrypted and signed email via the
international S/MIME standard.

This kind of certificate may be most appropriate for a p3d file
produced by an individual or by a small group.  Signing a p3d file
with your own email address is a very personal touch.

You can obtain an email certificate from numerous sources.  Many
companies charge a nominal fee for an email certificate intended for
corporate use, but some companies also offer a completely cost-free
email certificate for personal use, typically with a 1-year expiration
date.  (The expiration date is a nuisance, but not a limit.  You can replace it with a new certificate when it expires.)

The process to obtain an email certificate can be a bit convoluted.
Usually, you will fill out a form at the company's website, receive an
email to confirm your email address, click on a link in the email,
then download the certificate into your browser.  Once it has been
installed in your browser, you can find the certificate under the
Preferences menus, and save it (as a &quot;backup&quot;) to a pkcs12 file on
disk, with the .p12 extension.  Then you can convert it to a pem file
using openssl, with the command sequence:

&lt;code bash&gt;
openssl pkcs12 -in mycert.p12 -out mycert.pem -nodes
&lt;/code&gt;

Typically, the public key and private key will be combined in the same
file.  Keep this file safe.</text>
    </revision>
  </page>
  <page>
    <title>Embedded Text Properties</title>
    <ns>0</ns>
    <id>1712</id>
      <sha1>d29ml776s288a6ui7ymfb6z9l0kklmb</sha1>
    <revision>
      <id>7653</id>
      <timestamp>2012-03-08T18:40:07Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="3166">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

It's possible to change text properties in the middle of a paragraph.  To do this, you must first define the different kinds of text properties you might want to change to, and give each one a name; then you can embed special characters in your text string to switch these predefined text properties in and out.

&lt;h2&gt;Defining your text properties&lt;/h2&gt;

You can create any number of &lt;code&gt;TextProperties&lt;/code&gt; objects.  Each of these can store a different set of text properties, any of the text properties that you can set directly on a TextNode.  These include the per-character attributes such as font, color, shadow, and slant, as well as per-line formatting properties such as alignment and wordwrap.

&lt;code python&gt;
tpRed = TextProperties()
tpRed.setTextColor(1, 0, 0, 1)
tpSlant = TextProperties()
tpSlant.setSlant(0.3)
tpRoman = TextProperties()
tpRoman.setFont(cmr12)
&lt;/code&gt; 

You can set as many or as few different attributes on any one TextProperties object as you like.  Only the attributes you specify will be applied to the text string; any attributes you don't mention will remain unchanged when you apply the TextProperties.  In the above example, applying the tpRed structure to a particular text string will only change the text color to red; other properties, such as slant, shadow, and font, will remain whatever they were previously.  Similarly for tpSlant, which only changes the slant, and tpRoman, which only changes the font.

&lt;h2&gt;Registering the new TextProperties objects&lt;/h2&gt;

You will need a pointer to the global &lt;code&gt;TextPropertiesManager&lt;/code&gt; object:

&lt;code python&gt;
tpMgr = TextPropertiesManager.getGlobalPtr()
&lt;/code&gt; 

After you have created your TextProperties objects, you must register each one with the TextPropertiesManager, under a unique name:

&lt;code python&gt;
tpMgr.setProperties(&quot;red&quot;, tpRed)
tpMgr.setProperties(&quot;slant&quot;, tpSlant)
tpMgr.setProperties(&quot;roman&quot;, tpRoman)
&lt;/code&gt;

&lt;h2&gt;Referencing the TextProperties in text strings&lt;/h2&gt;

Now you're ready to put the special characters in your text string to activate these mode changes.  To do this, you will use the special character '\1', or the ASCII 0x01 character.  You use the \1 character twice, as a kind of quotation mark before and after the name you have used above to register your TextProperties object, e.g. '\1red\1' to activate tpRed, or '\1slant\1' to activate tpSlant.

The sequence '\1red\1' acts as a &lt;em&gt;push&lt;/em&gt; operation.  It applies tpRed to the current text properties, but also remembers the previous properties.  To go back to the previous properties, use the character '\2' by itself.  You can nest property changes like this; each '\2' will undo the most recent '\1name\1' that is still in effect.

The following text string:

&lt;code python&gt;
text.setText(&quot;Every day in \1slant\1every way\2 I'm \1red\1getting \1roman\1better \1slant\1and\2 better.\2\2&quot;)
&lt;/code&gt;

Looks like this:

[[Image:Text attrib.png|Every day in every way I'm getting better and better]]

You can use these special characters in any Panda construct that generates text, including TextNode, OnscreenText, and any DirectGui object.</text>
    </revision>
  </page>
  <page>
    <title>Embedding with RunPanda3D</title>
    <ns>0</ns>
    <id>2397</id>
      <sha1>a61hkog922j2a4xyn9hde49mzj5o5s0</sha1>
    <revision>
      <id>7315</id>
      <timestamp>2011-09-01T05:02:22Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="2550">Using nested &lt;object&gt; elements is a straightforward way to embed your
p3d file, but it does have two disadvantages.  Specifically, (1) it
requires you to specify all of the options twice, which promotes
errors; and (2) it doesn't work if you need to specify an &quot;id&quot;
attribute to access your embedded plugin object via JavaScript,
because you can't specify the same &quot;id&quot; attribute to two different
&lt;object&gt; elements.

There's another alternative that solves both problems, using
JavaScript.  Of course, this requires that your end-users will have
JavaScript enabled, but this is common; and your web page may have
this requirement anyway if you are planning to control your p3d
application via JavaScript.

There's a JavaScript file called RunPanda3D.js that is distributed
with the Panda3D source.  You'll find it in the directory
direct/src/directscripts.  Simply copy this JavaScript file to your
web host, and reference it in your web page like this:

&lt;code html4strict&gt;
&lt;head&gt;
... other head content ...
&lt;script src=&quot;RunPanda3D.js&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;
... other head content ...
&lt;/head&gt;
&lt;body&gt;
... other body content ...
&lt;script type=&quot;text/javascript&quot;&gt;
P3D_RunContent('data', 'myapp.p3d', 'id', 'myapp_id',
    'width', '640', 'height', '480')
}
&lt;/script&gt;
... other body content ...
&lt;/body&gt;
&lt;/code&gt;

That is, you must include a reference to RunPanda3D.js within the
&lt;head&gt; part of your web page; and you include a call to the function
P3D_RunContent() within the &lt;body&gt; part of your web page.

P3D_RunContent() will generate the appropriate form of the &lt;object&gt;
element for whichever browser the user is currently running: either
the Internet Explorer form, or the non-Internet Explorer form.  The
object element is generated via document.write(), wherever the call to
P3D_RunContent() appears within your web page.

The parameters to P3D_RunContent() must be given in pairs: of each two
parameters, the first parameter is the keyword, and the second
parameter is the value.  This is equivalent to a keyword=&quot;value&quot; pair
appearing in the &lt;object&gt; element.  For instance, the above call would
generate an &lt;object&gt; element something like this:

&lt;code html4strict&gt;
&lt;object data=&quot;myapp.p3d&quot; id=&quot;myapp_id&quot; width=&quot;640&quot; height=&quot;480&quot;&gt;
&lt;/object&gt;
&lt;/code&gt;

(though it will also add either classid or type, according to the type
of browser the user is running.)

Using P3D_RunContent() also adds two additional [[Splash window tags]], noplugin_img and noplugin_href.  These tags are not available if you embed using the &lt;object&gt; syntax directly.</text>
    </revision>
  </page>
  <page>
    <title>Embedding with an object element</title>
    <ns>0</ns>
    <id>2396</id>
      <sha1>f02x8ifvvl84p01p6x3aouu6hysmst1</sha1>
    <revision>
      <id>6708</id>
      <timestamp>2010-03-04T19:13:55Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="2968">There are two different syntaxes for embedding a p3d file in a web
page.  Internet Explorer requires one particular syntax, and every
other browser in the world requires another syntax, similar but
slightly different.  Fortunately, it is possible to write a single web
page that supports both syntaxes at the same time.

This discussion assumes you are comfortable with writing HTML code in
a web page.  If you are unfamiliar with HTML syntax, we recommend you
study a brief tutorial on writing web pages using HTML before
continuing.

For Internet Explorer, you must use the &lt;object&gt; element to embed a
p3d file, with code like this:

&lt;code html4strict&gt;
&lt;object width=&quot;640&quot; height=&quot;480&quot;
  classid=&quot;CLSID:924B4927-D3BA-41EA-9F7E-8A89194AB3AC&quot;&gt;
    &lt;param name=&quot;data&quot; value=&quot;myapp.p3d&quot;&gt;
&lt;/object&gt;
&lt;/code&gt;

Note that the width and height are specified as attributes to the
&lt;object&gt; element.  The classid string is literal, and must always be the
exact string shown above; this is the string that identifies the
Panda3D plugin.  The URL of the p3d file to be launched should be
specified as an attribute of the nested &lt;param&gt; element, as shown
above.

For other browsers, you also use the &lt;object&gt; element, but it looks a
little bit different:

&lt;code html4strict&gt;
&lt;object width=&quot;640&quot; height=&quot;480&quot;
  type=&quot;application/x-panda3d&quot; data=&quot;myapp.p3d&quot;&gt;
&lt;/object&gt;
&lt;/code&gt;

In non-Internet Explorer browsers, you identify the Panda3D plugin
with the string type=&quot;application/x-panda3d&quot;, instead of with the
classid string used by Internet Explorer.  Also, the URL of the p3d
file is specified as an attribute of the &lt;object&gt; element, instead of
in a nested &lt;param&gt; element.

In order to design a web page that works on any browser--and you
should always design web pages that do--you can embed one &lt;object&gt;
element within the other.  This works because if a browser encounters
an &lt;object&gt; element that it doesn't understand, it is supposed to load
whatever is within that &lt;object&gt;'s nested scope, which might be
another &lt;object&gt; element.  So, for instance, the above examples could
be written like this:

&lt;code html4strict&gt;
&lt;object width=&quot;640&quot; height=&quot;480&quot;
  type=&quot;application/x-panda3d&quot; data=&quot;myapp.p3d&quot;&gt;
    &lt;object width=&quot;640&quot; height=&quot;480&quot;
      classid=&quot;CLSID:924B4927-D3BA-41EA-9F7E-8A89194AB3AC&quot;&gt;
        &lt;param name=&quot;data&quot; value=&quot;myapp.p3d&quot;&gt;
    &lt;/object&gt;
&lt;/object&gt;
&lt;/code&gt;

The outer &lt;object&gt; element is the non-Internet Explorer version, and
in case that isn't understood (for instance, because the user is
running Internet Explorer), then it will fall to the inner &lt;object&gt;
element instead, which is the Internet Explorer version.

We recommend putting the non-Internet Explorer version on the outside,
because some versions of Safari seem to get confused if they encounter
the Internet Explorer version first.

Note that there are additional, optional attributes that may be
provided to either form of the &lt;object&gt; tag.  These are discussed in
[[Advanced object tags]].</text>
    </revision>
  </page>
  <page>
    <title>Enabling physics on a node</title>
    <ns>0</ns>
    <id>1779</id>
      <sha1>qnskxfltqqnvvs93n60wt3c0q2di3gu</sha1>
    <revision>
      <id>7683</id>
      <timestamp>2012-03-08T20:32:51Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="1565">The ActorNode is the component of the physics system that tracks interactions and applies them to a model. The calculations factor in the amount of time elapsed between frames, so the physics will be robust against changes in framerate.

To enable a node for physics, attach it to an ActorNode.  An ActorNode's position and orientation can be updated automatically by the physics system, and so any children of the ActorNode will inherit that position and orientation as well.

(Do not confuse ActorNode with the [[Actors and Characters|Actor]] class, which is used to play animations.  They are completely unrelated classes with similar names.)

When an ActorNode is created, it must be associated with a PhysicsManager. The PhysicsManager will handle the physics calculations every frame and update the ActorNode with any changes. Panda provides a default physics manager, base.physicsMgr, which will often be suitable for most applications.

&lt;code python&gt;
node = NodePath(&quot;PhysicsNode&quot;)
node.reparentTo(render)
an = ActorNode(&quot;jetpack-guy-physics&quot;)
anp = node.attachNewNode(an)
base.physicsMgr.attachPhysicalNode(an)
jetpackGuy = loader.loadModel(&quot;models/jetpack_guy&quot;)
jetpackGuy.reparentTo(anp)
&lt;/code&gt;

Now, the &quot;jetpackGuy&quot; model will be updated every frame with the physics applied to it.

The ActorNode also serves as a repository for the PhysicsObject that describes the physical properties (i.e. mass) of the object. To modify these properties, use the getPhysicsObject call.

&lt;code python&gt;
an.getPhysicsObject().setMass(136.077)   # about 300 lbs
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>Enhanced Mouse Navigation</title>
    <ns>0</ns>
    <id>974</id>
      <sha1>3amfjrhilc9xt4w9rlcyu8lwprrqe0p</sha1>
    <revision>
      <id>2259</id>
      <timestamp>2005-06-09T16:59:27Z</timestamp>
      <contributor>
        <username>Ophilatry</username>
        <id>14</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="4296">Enhanced mouse navigation is only available when 'Direct Tools' are enabled.  Information on enabling 'Direct Tools' is available in the [[Panda Tools]] section.

Direct Tools gives more functionality to the middle mouse button. First, clicking the middle mouse button changes the pivot point it uses to rotate around the environment. The middle mouse button will also move the camera depending on where the cursor is on the screen.

&lt;center&gt;[[Image:directtools2.jpg]]&lt;/center&gt;

&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;Middle Mouse Click&lt;/td&gt;&lt;td&gt;Sets pivot point for rotating around the world&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Middle Mouse + Middle Region&lt;/td&gt;&lt;td&gt;Move camera parallel to ground&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Shift + Middle Mouse + Middle Region&lt;/td&gt;&lt;td&gt;Move camera vertically&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Middle Mouse + Edge Region&lt;/td&gt;&lt;td&gt;Rotate camera around pivot point&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Middle Mouse + Corner Region&lt;/td&gt;&lt;td&gt;Roll camera around pivot point&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Shift + Middle Mouse + Edge Region&lt;/td&gt;&lt;td&gt;Changes pitch of the camera&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;

The left mouse button is now used to select and manipulate objects in the environment. Once an object is selected, it may be moved and rotated.

&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;Left Mouse Click&lt;/td&gt;&lt;td&gt;Select an object&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Left Mouse + Middle Region&lt;/td&gt;&lt;td&gt;Move object vertically&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Shift + Left Mouse + Middle Region&lt;/td&gt;&lt;td&gt;Move object parallel to ground&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Left Mouse + Edge Region&lt;/td&gt;&lt;td&gt;Rotate object around its pivot point&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Left Mouse + Corner Region&lt;/td&gt;&lt;td&gt;Roll object around its pivot point&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Control + Left Mouse&lt;/td&gt;&lt;td&gt;Rescale the model&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;
&lt;p&gt;Direct Tools uses a large number of hot keys for camera control, rendering styles, and object control. The full list is in the table below.&lt;/p&gt;
&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Camera Control&lt;/b&gt;&lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;td&gt;&lt;b&gt;Render Style&lt;/b&gt;&lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;+&lt;/td&gt;&lt;td&gt;Zoom in&lt;/td&gt;&lt;td&gt;Shift + A&lt;/td&gt;&lt;td&gt;Show all&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;-&lt;/td&gt;&lt;td&gt;Zoom out&lt;/td&gt;&lt;td&gt;Control + F&lt;/td&gt;&lt;td&gt;Flash selected&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;Front view (relative to render)&lt;/td&gt;&lt;td&gt;B&lt;/td&gt;&lt;td&gt;Toggle backface&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;Back view (relative to render)&lt;/td&gt;&lt;td&gt;L&lt;/td&gt;&lt;td&gt;Toggle lights&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;Right view (relative to render)&lt;/td&gt;&lt;td&gt;T&lt;/td&gt;&lt;td&gt;Toggle texture&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4&lt;/td&gt;&lt;td&gt;Left view (relative to render)&lt;/td&gt;&lt;td&gt;W&lt;/td&gt;&lt;td&gt;Toggle wireframe&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;Top view (relative to render)&lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;6&lt;/td&gt;&lt;td&gt;Bottom view (relative to render)&lt;/td&gt;&lt;td&gt;&lt;b&gt;Direct Controls&lt;/b&gt;&lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;7&lt;/td&gt;&lt;td&gt;¾ view (relative to render)&lt;/td&gt;&lt;td&gt;Delete&lt;/td&gt;&lt;td&gt;Delete selected object&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;8&lt;/td&gt;&lt;td&gt;Roll view about axis relative to camera’s axis&lt;/td&gt;&lt;td&gt;Escape&lt;/td&gt;&lt;td&gt;Delete all&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;9&lt;/td&gt;&lt;td&gt;Rotate around hot point&lt;/td&gt;&lt;td&gt;Page Down&lt;/td&gt;&lt;td&gt;Move down selected object’s hierarchy&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;Rotate around hot point&lt;/td&gt;&lt;td&gt;Page Up&lt;/td&gt;&lt;td&gt;Move up selected object’s hierarchy&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;C&lt;/td&gt;&lt;td&gt;Center on hot point&lt;/td&gt;&lt;td&gt;Tab&lt;/td&gt;&lt;td&gt;Toggle widget mode&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;F&lt;/td&gt;&lt;td&gt;Fit on hot point&lt;/td&gt;&lt;td&gt;Shift + F&lt;/td&gt;&lt;td&gt;Grow widget to fit current window&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;H&lt;/td&gt;&lt;td&gt;Move to (0,0,0)&lt;/td&gt;&lt;td&gt;I&lt;/td&gt;&lt;td&gt;Plant selected object at cursor intersection point&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Shift + L&lt;/td&gt;&lt;td&gt;Toggle camera pivot point lock&lt;/td&gt;&lt;td&gt;M&lt;/td&gt;&lt;td&gt;Move widget in front of camera&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;N&lt;/td&gt;&lt;td&gt;Select next possible camera COA (along last intersection ray)&lt;/td&gt;&lt;td&gt;P&lt;/td&gt;&lt;td&gt;Set active parent to selected object&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;U&lt;/td&gt;&lt;td&gt;Orbit upright camera about hot point&lt;/td&gt;&lt;td&gt;R&lt;/td&gt;&lt;td&gt;WRT reparent selected to active parent&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Shift + U&lt;/td&gt;&lt;td&gt;Upright camera&lt;/td&gt;&lt;td&gt;Shift + R&lt;/td&gt;&lt;td&gt;Reparent selected to active parent&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;`&lt;/td&gt;&lt;td&gt;Kill camera move task&lt;/td&gt;&lt;td&gt;S&lt;/td&gt;&lt;td&gt;Reselect last selected object&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt; &lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;td&gt;V&lt;/td&gt;&lt;td&gt;Toggle widget visibility&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Undo/Redo&lt;/b&gt;&lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;td&gt;Shift + V&lt;/td&gt;&lt;td&gt;Toggle COA marker visibility&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;[&lt;/td&gt;&lt;td&gt;Undo&lt;/td&gt;&lt;td&gt;&lt;&lt;/td&gt;&lt;td&gt;Shrink widget&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;]&lt;/td&gt;&lt;td&gt;Redo&lt;/td&gt;&lt;td&gt;&gt;&lt;/td&gt;&lt;td&gt;Expand widget&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;</text>
    </revision>
  </page>
  <page>
    <title>Environment Mapping with Cube Maps</title>
    <ns>0</ns>
    <id>1231</id>
      <sha1>r0mp2ilx4xzh4xjl0affxrybhlrj266</sha1>
    <revision>
      <id>7641</id>
      <timestamp>2012-03-08T18:07:28Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="2702">Although there are other applications for cube maps, one very common
use of cube maps is as an &lt;b&gt;environment map&lt;/b&gt;, similar to
[[Simple Environment Mapping|sphere mapping]].  In fact, it works very
much the same as sphere mapping.

Just as with a sphere map, you can have Panda3D generate a cube map
for you:

&lt;code python&gt;
scene = loader.loadModel('bvw-f2004--streetscene/street-scene.egg')
scene.reparentTo(render)
scene.setZ(-2)
base.saveCubeMap('streetscene_cube_#.jpg', size = 256)
&lt;/code&gt;

[[Sample Cube Map|Click here]] to see the six images generated by the above sample code.

With the cube map saved out as above, you could apply it as an
environment map to the teapot like this:

&lt;code python&gt;
tex = loader.loadCubeMap('streetscene_cube_#.jpg')
teapot.setTexGen(TextureStage.getDefault(), TexGenAttrib.MEyeCubeMap)
teapot.setTexture(tex)
&lt;/code&gt;

And the result looks very similar to the sphere map:

[[Image:Cubemap teapot.jpg|The cube map on a teapot.]]

In fact, it looks so similar that one might wonder why we bothered.
So far, a cube map looks pretty similar to a sphere map, except that
it consumes six times the texture memory.  Hardly impressive.

But as we mentioned [[Simple Environment Mapping|earlier]], there are
two problems with sphere maps that cube maps can solve.  One of these
problems is that the point-of-view is permanently baked into the
sphere map.  Cube maps don't necessarily have the same problem.  In
fact, we can solve it with one simple variation:

&lt;code python&gt;
tex = loader.loadCubeMap('streetscene_cube_#.jpg')
teapot.setTexGen(TextureStage.getDefault(), TexGenAttrib.MWorldCubeMap)
teapot.setTexture(tex)
&lt;/code&gt;

By changing &lt;code&gt;MEyeCubeMap&lt;/code&gt; to &lt;code&gt;MWorldCubeMap&lt;/code&gt;, we
have indicated that we would like this cube map to vary its
point-of-view as the camera moves.  Now the reflected environment will
vary according to the direction we are looking at it, so that it shows what is behind the camera at runtime, instead of always showing
the area behind the camera when the cube map was generated, as a
sphere map must do.  In order for this to work properly, you should
ensure that your camera is unrotated (that is, &lt;code&gt;setHpr(0, 0,
0)&lt;/code&gt;) when you generate the cube map initially.

Even with MWorldCubeMap, though, the image is still generated ahead of time, so the reflection doesn't &lt;i&gt;actually&lt;/i&gt; show what is behind the camera at runtime.  It just uses the current camera direction to figure out what part of the reflection image to show.

However, you can make a cube map that truly does reflect dynamic objects in the scene, by rendering a [[Dynamic Cube Maps|dynamic cube map]].  This will be discussed in the next section.</text>
    </revision>
  </page>
  <page>
    <title>Evade</title>
    <ns>0</ns>
    <id>2585</id>
      <sha1>qplx827n0b2raamx1tinwiorznduc08</sha1>
    <revision>
      <id>7698</id>
      <timestamp>2012-03-09T10:23:40Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>Panda's &quot;direct&quot; package has nothing to do with &quot;DirectX&quot;</comment>
      <text xml:space="preserve" bytes="4392">&lt;b&gt;'Evade'&lt;/b&gt; is an AI behavior where an AICharacter will move in the opposite direction to a target NodePath or position.

{{#ev:youtube|JchuRRHqPUQ}}

In PandAI, &lt;b&gt;'Evade'&lt;/b&gt; is defined as :

&lt;code python&gt;
aiBehaviors.evade(NodePath target, double panic_distance, double relax_distance, float priority)
&lt;/code&gt;

where :

&lt;b&gt;Panic Distance&lt;/b&gt; is the radius of detection.

&lt;b&gt;Relax Distance&lt;/b&gt; is the distance from the panic distance radius after which the object should stop evading once evade has been initiated.

&lt;b&gt;priority&lt;/b&gt; is by default set to 1.0 and is used when using two or more steering behaviors on an AICharacter.

-----

The velocity at which the AICharacter evades is determined when you first create your AICharacter object using the AICharacter constructor.

* Note: 'Evade' recalculates the direction every frame and so is less efficient than Flee for a static object.

-----

The full working code in Panda3D :

&lt;code python&gt;
import direct.directbase.DirectStart
from panda3d.core import *
from direct.showbase.DirectObject import DirectObject
from direct.task import Task
from direct.actor.Actor import Actor
#for Pandai
from panda3d.ai import *
#for Onscreen GUI
from direct.gui.OnscreenText import OnscreenText

# Globals
speed = 0.75

# Function to put instructions on the screen.
font = loader.loadFont(&quot;cmss12&quot;)
def addInstructions(pos, msg):
    return OnscreenText(text=msg, style=1, fg=(1,1,1,1), font = font,
                        pos=(-1.3, pos), align=TextNode.ALeft, scale = .05)

class World(DirectObject):

    def __init__(self):
        base.disableMouse()
        base.cam.setPosHpr(0,0,55,0,-90,0)
        
        self.loadModels()
        self.setAI()
        self.setMovement()

    def loadModels(self):
        # Seeker
        ralphStartPos = Vec3(-10, 0, 0)
        self.evader = Actor(&quot;models/ralph&quot;,
                                 {&quot;run&quot;:&quot;models/ralph-run&quot;})
        self.evader.reparentTo(render)
        self.evader.setScale(0.5)
        self.evader.setPos(ralphStartPos)
        # Target
        self.target = loader.loadModel(&quot;models/arrow&quot;)
        self.target.setColor(1,0,0)
        self.target.setPos(5,0,0)
        self.target.setScale(1)
        self.target.reparentTo(render)
      
    def setAI(self):
        #Creating AI World
        self.AIworld = AIWorld(render)
 
        self.AIchar = AICharacter(&quot;evader&quot;,self.evader, 100, 0.05, 5)
        self.AIworld.addAiChar(self.AIchar)
        self.AIbehaviors = self.AIchar.getAiBehaviors()
        
        self.AIbehaviors.evade(self.target, 5, 5)
        self.evader.loop(&quot;run&quot;)

        #AI World update        
        taskMgr.add(self.AIUpdate,&quot;AIUpdate&quot;)
        
    #to update the AIWorld    
    def AIUpdate(self,task):
        self.AIworld.update()            
        return Task.cont

    #All the movement functions for the Target
    def setMovement(self):
        self.keyMap = {&quot;left&quot;:0, &quot;right&quot;:0, &quot;up&quot;:0, &quot;down&quot;:0}
        self.accept(&quot;arrow_left&quot;, self.setKey, [&quot;left&quot;,1])
        self.accept(&quot;arrow_right&quot;, self.setKey, [&quot;right&quot;,1])
        self.accept(&quot;arrow_up&quot;, self.setKey, [&quot;up&quot;,1])
        self.accept(&quot;arrow_down&quot;, self.setKey, [&quot;down&quot;,1])
        self.accept(&quot;arrow_left-up&quot;, self.setKey, [&quot;left&quot;,0])
        self.accept(&quot;arrow_right-up&quot;, self.setKey, [&quot;right&quot;,0])
        self.accept(&quot;arrow_up-up&quot;, self.setKey, [&quot;up&quot;,0])
        self.accept(&quot;arrow_down-up&quot;, self.setKey, [&quot;down&quot;,0])
        #movement task
        taskMgr.add(self.Mover,&quot;Mover&quot;)
        
        addInstructions(0.9, &quot;Use the Arrow keys to move the Red Target&quot;)

    def setKey(self, key, value):
        self.keyMap[key] = value
            
    def Mover(self,task):
        startPos = self.target.getPos()
        if (self.keyMap[&quot;left&quot;]!=0):
                self.target.setPos(startPos + Point3(-speed,0,0))
        if (self.keyMap[&quot;right&quot;]!=0):
                self.target.setPos(startPos + Point3(speed,0,0))
        if (self.keyMap[&quot;up&quot;]!=0):
                self.target.setPos(startPos + Point3(0,speed,0))
        if (self.keyMap[&quot;down&quot;]!=0):
                self.target.setPos(startPos + Point3(0,-speed,0))
                        
        return Task.cont
 
w = World()
run()


&lt;/code&gt;

&lt;b&gt;To get the full working demo, please visit :&lt;/b&gt;

https://sites.google.com/site/etcpandai/documentation/steering-behaviors/evade/PandAIEvadeExample.zip?attredirects=0&amp;d=1</text>
    </revision>
  </page>
  <page>
    <title>Event Example</title>
    <ns>0</ns>
    <id>975</id>
      <sha1>r79mqtzr65b1w4jsvnm38b3sy8d9vak</sha1>
    <revision>
      <id>7677</id>
      <timestamp>2012-03-08T20:19:04Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>new import system</comment>
      <text xml:space="preserve" bytes="3821">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

[python]
&lt;p&gt;Here is a short example of using the Collision Handler Events:&lt;/p&gt;
&lt;code python&gt;
from direct.showbase.ShowBase import ShowBase
from direct.showbase.DirectObject import DirectObject
from direct.interval.IntervalGlobal import Sequence, Func, Wait
from panda3d.core import CollisionTraverser, CollisionHandlerEvent
from panda3d.core import CollisionNode, CollisionSphere
from panda3d.core import VBase4


class World(DirectObject):

    def __init__( self ):
        # Initialize the traverser.
        base.cTrav = CollisionTraverser()

        # Initialize the handler.
        self.collHandEvent = CollisionHandlerEvent()
        self.collHandEvent.addInPattern('into-%in')
        self.collHandEvent.addOutPattern('outof-%in')

        # Make a variable to store the unique collision string count.
        self.collCount = 0

        # Load a model. Reparent it to the camera so we can move it.
        s = loader.loadModel('smiley')	
        s.reparentTo(camera)
        s.setPos(0, 25, 0)

        # Setup a collision solid for this model.
        sColl = self.initCollisionSphere(s, True)

        # Add this object to the traverser.
        base.cTrav.addCollider(sColl[0], self.collHandEvent)

        # Accept the events sent by the collisions.
        self.accept('into-' + sColl[1], self.collide3)
        self.accept('outof-' + sColl[1], self.collide4)
        print(sColl[1])

        # Load another model.
        t = loader.loadModel('smiley')
        t.reparentTo(render)
        t.setPos(5, 25, 0)

        # Setup a collision solid for this model.
        tColl = self.initCollisionSphere(t, True)

        # Add this object to the traverser.
        base.cTrav.addCollider(tColl[0], self.collHandEvent)

        # Accept the events sent by the collisions.
        self.accept('into-' + tColl[1], self.collide)
        self.accept('outof-' + tColl[1], self.collide2)
        print(tColl[1])

        print(&quot;WERT&quot;)

    def collide(self, collEntry):
        print(&quot;WERT: object has collided into another object&quot;)
        Sequence(Func(collEntry.getFromNodePath().getParent().setColor,
                      VBase4(1, 0, 0, 1)),
                 Wait(0.2),
                 Func(collEntry.getFromNodePath().getParent().setColor,
                      VBase4(0, 1, 0, 1)),
                 Wait(0.2),
                 Func(collEntry.getFromNodePath().getParent().setColor,
                      VBase4(1, 1, 1, 1))).start()
			

    def collide2(self, collEntry):
        print(&quot;WERT.: object is no longer colliding with another object&quot;)
	
    def collide3(self, collEntry):
        print(&quot;WERT2: object has collided into another object&quot;)

    def collide4(self, collEntry):
        print(&quot;WERT2: object is no longer colliding with another object&quot;)

    def initCollisionSphere(self, obj, show=False):
        # Get the size of the object for the collision sphere.
        bounds = obj.getChild(0).getBounds()
        center = bounds.getCenter()
        radius = bounds.getRadius() * 1.1

        # Create a collision sphere and name it something understandable.
        collSphereStr = 'CollisionHull' + str(self.collCount) + &quot;_&quot; + obj.getName()
        self.collCount += 1
        cNode = CollisionNode(collSphereStr)
        cNode.addSolid(CollisionSphere(center, radius))

        cNodepath = obj.attachNewNode(cNode)
        if show:
            cNodepath.show()

        # Return a tuple with the collision node and its corrsponding string so
        # that the bitmask can be set.
        return (cNodepath, collSphereStr)

ShowBase()
# Run the world. Move around with the mouse to create collisions.
w = World()
run()
&lt;/code&gt;
[/python]

[cxx]
&lt;h2&gt;Incomplete Section&lt;/h2&gt;

&lt;p&gt;Note: this section is incomplete. It will be updated soon.&lt;/p&gt;
[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Event Handlers</title>
    <ns>0</ns>
    <id>1019</id>
      <sha1>hrj5737goxyhffpzg9iex2330zwmg9i</sha1>
    <revision>
      <id>7650</id>
      <timestamp>2012-03-08T18:34:04Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>new import system</comment>
      <text xml:space="preserve" bytes="5209">Events occur either when the user does something (such as clicking a [[Mouse Support|mouse]] or pressing a [[Keyboard Support|key]]) or when sent by the script using &lt;code&gt;messenger.send()&lt;/code&gt;.  When an event occurs, Panda's &quot;messenger&quot; will check to see if you have written an &quot;event handler&quot; routine.  If so, your event handler will be called.  The messenger system is object-oriented, to create an event handler, you have to first create a class that inherits from DirectObject.  Your event handler will be a method of your class.

&lt;h2&gt;Defining a class that can Handle Events&lt;/h2&gt;

The first step is to import class DirectObject:

&lt;code python&gt;
from direct.showbase import DirectObject
&lt;/code&gt;

With DirectObject loaded, it is possible to create a subclass of DirectObject. This allows the class to inherit the messaging API and thus listen for events.

&lt;code python&gt;
class myClassName(DirectObject.DirectObject):
&lt;/code&gt;

The sample below creates a class that can listen for events. The &quot;accept&quot; function notifies panda that the printHello method is an event handler for the mouse1 event.  The &quot;accept&quot; function and the various event names will be explained in detail later.

&lt;code python&gt;
class Hello(DirectObject.DirectObject):
  def __init__(self):
    self.accept('mouse1',self.printHello)
  def printHello(self):
    print 'Hello!'
h = Hello()
&lt;/code&gt;

&lt;h2&gt;Event Handling Functions&lt;/h2&gt;

Events first go to a mechanism built into panda called the &quot;Messenger.&quot; The messenger may accept or ignore events that it receives. If it accepts an event, then an event handler will be called. If ignored, then no handler will be called. 

An object may accept an event an infinite number of times or accept it only once. If checking for an accept within the object listening to it, it should be prefixed with self. If the accept command occurs outside the class, then the variable the class is associated with should be used.

&lt;code python&gt;
myDirectObject.accept('Event Name',myDirectObjectMethod)
myDirectObject.acceptOnce('Event Name',myDirectObjectMethod)
&lt;/code&gt;

Specific events may be ignored, so that no message is sent. Also, all events coming from an object may be ignored.

&lt;code python&gt;
myDirectObject.ignore('Event Name')
myDirectObject.ignoreAll()
&lt;/code&gt;

Finally, there are some useful utility functions for debugging. The messenger typically does not print out when every event occurs. Toggling verbose mode will make the messenger print every event it receives. Toggling it again will revert it to the default. A number of methods exist for checking to see what object is checking for what event, but the print method will show who is accepting each event. Also, if accepts keep changing to the point where it is too confusing, the clear method will start the messenger over with a clear dictionary.

&lt;code python&gt;
messenger.toggleVerbose()
print messenger
messenger.clear()
&lt;/code&gt;

&lt;h2&gt;Sending Custom Events&lt;/h2&gt;
Custom events can be sent by the script using the code

&lt;code python&gt;
messenger.send('Event Name')
&lt;/code&gt;

A list of parameters can optionally be sent to the event handler. Parameters defined in &lt;code&gt;accept()&lt;/code&gt; are passed first, and then the parameters defined in &lt;code&gt;send()&lt;/code&gt;.
for example this would print out &quot;eggs sausage foo bar&quot;:

&lt;code python&gt;
class Test(DirectObject):
    def __init__(self):
        self.accept('spam',self.OnSpam,['eggs','sausage'])
    def OnSpam(self,a,b,c,d):
        print a,b,c,d
Test()
messenger.send('spam',['foo','bar'])
run()
&lt;/code&gt;

&lt;h2&gt;A Note on Object Management&lt;/h2&gt;

When a DirectObject accepts an event, the messenger retains a reference to that DirectObject. To ensure that objects that are no longer needed are properly disposed of, they must ignore any messages they are accepting.

For example, the following code may not do what you expect:

&lt;code python&gt;
import direct.directbase.DirectStart
from direct.showbase import DirectObject
from panda3d.core import *

class Test(DirectObject.DirectObject):
    def __init__(self):
        self.accept(&quot;FireZeMissiles&quot;,self._fireMissiles)

    def _fireMissiles(self):
        print &quot;Missiles fired! Oh noes!&quot;


foo=Test() # create our test object

del foo    # get rid of our test object

messenger.send(&quot;FireZeMissiles&quot;) # oops! Why did those missiles fire?
run()
&lt;/code&gt; 

Try the example above, and you'll find that the missiles fire even though the object that would handle the event had been deleted.

One solution (patterned after other parts of the Panda3d architecture) is to define a &quot;destroy&quot; method for any custom classes you create, which calls &quot;ignoreAll&quot; to unregister from the event-handler system.

&lt;code python&gt;
import direct.directbase.DirectStart
from direct.showbase import DirectObject
from panda3d.core import *

class Test(DirectObject.DirectObject):
    def __init__(self):
        self.accept(&quot;FireZeMissiles&quot;,self._fireMissiles)

    def _fireMissiles(self):
        print &quot;Missiles fired! Oh noes!&quot;
    
    # function to get rid of me
    def destroy(self):
        self.ignoreAll() 


foo=Test() # create our test object

foo.destroy()    # get rid of our test object
del foo

messenger.send(&quot;FireZeMissiles&quot;) # No missiles fire
run()
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>Event Handling</title>
    <ns>0</ns>
    <id>1262</id>
    <redirect title="Tasks and Event Handling" />
      <sha1>6j52anpwty8qj2yz2y1f0z2pvg4n9o3</sha1>
    <revision>
      <id>2543</id>
      <timestamp>2005-11-01T18:58:09Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <comment>Event Handling moved to Tasks and Event Handling</comment>
      <text xml:space="preserve" bytes="39">#REDIRECT [[Tasks and Event Handling]]
</text>
    </revision>
  </page>
  <page>
    <title>Event Handling and Messenger Utilities</title>
    <ns>0</ns>
    <id>976</id>
      <sha1>ip2jz4ise20wq4k0mtbvuh67rx7fu8j</sha1>
    <revision>
      <id>6334</id>
      <timestamp>2009-11-13T19:28:21Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>Remove incorrect information, also, python tags</comment>
      <text xml:space="preserve" bytes="2056">The messenger may accept or ignore events that it receives. If it accepts an event, then a message will be passed to the messenger. If ignored, then no message will be sent. Key and mouse depressions and releases are events that may be sent. Typically, depressions are labeled as whatever key or button was hit. Releases are labeled as the key or button plus “-up.” So when checking to see if the escape key is hit, an object would listen for “escape.” If checking to see if it was released, then the object listens to “escape-up.” Not all events have to be key and mouse hits. One may create their own event and send it to the messenger.

An object may accept an event an infinite number of times or accept it only once. If checking for an accept within the object listening to it, it should be prefixed with self. If the accept command occurs outside the class, then the variable the class is associated with should be used.

&lt;code python&gt;
myDirectObject.accept('Event Name', myDirectObjectMethod)
myDirectObject.acceptOnce('Event Name', myDirectObjectMethod)
&lt;/code&gt;

It is also possible to send an event to the messenger without any sort of outside input.

&lt;code python&gt;
messenger.send('Event Name')
&lt;/code&gt;

Specific events may be ignored, so that no message is sent. Also, all events coming from an object may be ignored.

&lt;code python&gt;
myDirectObject.ignore('Event Name')
myDirectObject.ignoreAll()
&lt;/code&gt;

Finally, there are some useful utility functions for debugging. The messenger typically does not print out when every event occurs. Toggling verbose mode will make the messenger print every event it receives. Toggling it again will revert it to the default. A number of methods exist for checking to see what object is checking for what event, but the print method will show who is accepting each event. Also, if accepts keep changing to the point where it is too confusing, the clear method will start the messenger over with a clear dictionary.

&lt;code python&gt;
messenger.toggleVerbose()
print messenger
messenger.clear()
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>Example</title>
    <ns>0</ns>
    <id>978</id>
      <sha1>4sdnb8bs34pmebotz9r795bfdwcs2gk</sha1>
    <revision>
      <id>7740</id>
      <timestamp>2012-03-10T07:15:30Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="2003">Here is an example of lighting.  There are an ambient light and two directional lights lighting the scene, and a green ambient light that only affects one of the pandas.

&lt;code python&gt;
import direct.directbase.DirectStart
from panda3d.core import *

# Put two pandas in the scene, panda x and panda y.
x= loader.loadModel(&quot;panda&quot;)
x.reparentTo(render)
x.setPos(10,0,-6)

y= loader.loadModel(&quot;panda&quot;)
y.reparentTo(render)
y.setPos(-10,0,-6)

# Position the camera to view the two pandas.
base.trackball.node().setPos(0, 60, 0)

# Now create some lights to apply to everything in the scene.

# Create Ambient Light
ambientLight = AmbientLight( 'ambientLight' )
ambientLight.setColor( Vec4( 0.1, 0.1, 0.1, 1 ) )
ambientLightNP = render.attachNewNode( ambientLight.upcastToPandaNode() )
render.setLight(ambientLightNP)

# Directional light 01
directionalLight = DirectionalLight( &quot;directionalLight&quot; )
directionalLight.setColor( Vec4( 0.8, 0.2, 0.2, 1 ) )
directionalLightNP = render.attachNewNode( directionalLight.upcastToPandaNode() )
# This light is facing backwards, towards the camera.
directionalLightNP.setHpr(180, -20, 0)
render.setLight(directionalLightNP)

# Directional light 02
directionalLight = DirectionalLight( &quot;directionalLight&quot; )
directionalLight.setColor( Vec4( 0.2, 0.2, 0.8, 1 ) )
directionalLightNP = render.attachNewNode( directionalLight.upcastToPandaNode() )
# This light is facing forwards, away from the camera.
directionalLightNP.setHpr(0, -20, 0)
render.setLight(directionalLightNP)

# Now attach a green light only to object x.
ambient = AmbientLight('ambient')
ambient.setColor(Vec4(.5,1,.5,1))
ambientNP = x.attachNewNode(ambient.upcastToPandaNode())

# If we did not call setLightOff() first, the green light would add to
# the total set of lights on this object.  Since we do call
# setLightOff(), we are turning off all the other lights on this
# object first, and then turning on only the green light.
x.setLightOff()
x.setLight(ambientNP)

#run the example
run()
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>Example for Clicking on 3D Objects</title>
    <ns>0</ns>
    <id>1138</id>
      <sha1>tt954z2jftppytukj010p64v9q4f07u</sha1>
    <revision>
      <id>5204</id>
      <timestamp>2008-03-15T05:34:14Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="17">obsolete section.</text>
    </revision>
  </page>
  <page>
    <title>Examples Contributed by Community</title>
    <ns>0</ns>
    <id>1707</id>
      <sha1>ahds5h2b3ktw7toxq36nn0i6umzlix0</sha1>
    <revision>
      <id>3140</id>
      <timestamp>2006-01-04T11:51:12Z</timestamp>
      <contributor>
        <username>IPKnightly</username>
        <id>32</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="371">Here are some Panda3D examples contributed by the community.

In future we will have a way to host them on Panda3D.org.

IPKnightly:&lt;br&gt;
&lt;ul&gt; 
     &lt;li&gt;http://www.americanhammer.com/097G3/boxfall.zip
     &lt;li&gt;http://www.americanhammer.com/097G3/room.zip
     &lt;li&gt;http://www.americanhammer.com/097G3/musicBox.zip
     &lt;li&gt;http://www.americanhammer.com/097G3/ping.zip
&lt;/ul&gt;</text>
    </revision>
  </page>
  <page>
    <title>Examples Contributed by the Community</title>
    <ns>0</ns>
    <id>2060</id>
    <redirect title="User Contributed Tutorials and Examples" />
      <sha1>gaj5iwgv8wdthm2n3f6mbcy6xqhre2v</sha1>
    <revision>
      <id>4086</id>
      <timestamp>2007-02-15T16:09:38Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>[[Examples Contributed by the Community]] moved to [[User Contributed Tutorials and Examples]]</comment>
      <text xml:space="preserve" bytes="53">#REDIRECT [[User Contributed Tutorials and Examples]]</text>
    </revision>
  </page>
  <page>
    <title>FAQ</title>
    <ns>0</ns>
    <id>1257</id>
      <sha1>ehyny4rrqpuaqtvh5nr43wvr4clo3w3</sha1>
    <revision>
      <id>7745</id>
      <timestamp>2012-03-31T11:37:41Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>typo</comment>
      <text xml:space="preserve" bytes="12305">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

__TOC__
----
&lt;br /&gt;
----
== What are the .pz files I am seeing the samples? ==
----
Those are files that are zipped with pzip. Along with punzip, these command-line tools handle compression of files in a format that Panda3D can read; pzip for compressing and punzip for decompressing.
Usage:
    &lt;code bash&gt;pzip file [file2 file3 ...]
pzip -o dest_file file&lt;/code&gt;
Usage:
    &lt;code bash&gt;punzip file.pz [file2.pz file3.pz ...]
punzip -o dest_file file.pz&lt;/code&gt;
----
== What are the .pyc files that are created after I run the Python interpreter? ==
----
.pyc files are compiled versions of Python sources. Similarly, .pyo files are both compiled and &quot;optimized&quot;.
As an important speed-up of the start-up time for short programs that use a lot of standard modules, if a file called &quot;spam.pyc&quot; exists in the directory where &quot;spam.py&quot; is found, this is assumed to contain an already-``byte-compiled'' version of the module spam. The modification time of the version of &quot;spam.py&quot; used to create &quot;spam.pyc&quot; is recorded in &quot;spam.pyc&quot;, and the file is ignored if these don't match.
http://www.python.org/doc/1.5.1p1/tut/node43.html

Optimized bytecode (.pyo) is not generated by default, but you may tell the interpreter to generate them instead of the regular .pyc. When '-O' is added to the command, all assert statements are removed before compiling. When '-OO' is added instead of '-O', all __doc__ strings are removed as well before compiling. Note that these optimizations currently do not significantly improve performance. The following illustrates how to do this (replace python with ppython on Windows):
    &lt;code bash&gt;python -O file.py
python -OO file.py&lt;/code&gt;

Note: if you wish to run the Python interpreter without generating compiled bytecode files at all, then add '-B' to the command. The following illustrates how to do this (replace python with ppython on Windows):
    &lt;code bash&gt;python -B file.py&lt;/code&gt;
----
== Why are my animations/intervals sometimes skipped when I run something heavy on the CPU before playing them? ==
----
If you'll run this example code you might not see the position interval.
&lt;code python&gt;
from panda3d.core import *
import direct.directbase.DirectStart
from direct.interval.IntervalGlobal import *

env = loader.loadModel('environment')
env.reparentTo(render)
env.setZ(-4)

def func():
   # something heavy on the CPU
   for i in range(9999999):
      pass
   # run the interval after
   posival.start()

posival = LerpPosInterval(base.cam, 0.4, (0,base.cam.getY()-12,0), base.cam.getPos())

func()

run()
&lt;/code&gt;
But you will see the interval being played if you comment out the for-loop. What is going on? It looks like Panda3d had skipped the interval, even though it was after the loop, as if Panda3d had &quot;lost focus&quot; when running the loop and even after it had finished it needed some time to start running normally again.

The problem is that everything that happens within one frame is deemed to happen at the same time. This is the &quot;frame time&quot; of the clock object--it is the time as of the start of the frame, and everything you do within that frame is deemed to have happened at the &quot;frame time&quot;.

This is usually a good thing, because it makes the simulation internally consistent. Frames are atomic. If you start five animations in a row with five different calls to actor.start(), you want them all to have &quot;started&quot; at the exact same time, not within a few milliseconds of each other. If you start an interval, you also want it to have started at the same time as every other atomic operation in that frame.

The problem is when you have a single really long frame. In this case, anything you do at the end of this long frame is considered to have actually happened at the beginning of the frame, and when the next frame rolls around (after some considerable time has elapsed from the previous frame), Panda has to skip over all of the intervening time to catch up, and you miss seeing some part or all of your interval or animation.

There are several easy solutions. One is to munge the clock while you're computing your slow frame so that it doesn't actually allow time to advance during this period, by putting this line after your loop, etc.
&lt;code python&gt;globalClock.setFrameTime(globalClock.getRealTime())&lt;/code&gt; 
This simply resets the &quot;frame time&quot; to whatever the current real time is towards the end of your long frame. This will break the atomic-frame rule for (only) that one frame, but in this case that's what you want to happen.

Another approach, that doesn't involve explicitly munging the clock, would be simply to wait to start the interval until the next frame, for instance with a doMethodLater().
&lt;code python&gt;taskMgr.doMethodLater(0, lambda task, posival = posival: posival.start(), 'startInterval') &lt;/code&gt;
----
== I have a bunch of Maya Animations of one model in different mb files. I used maya2egg to port them into panda, but only one of the animations work. ==
----
The key is to use the -cn &lt;character's name&gt; flag in maya2egg for every file. This ensures that the files work together.
Let's say you are making an animated dog.
You have the following animations:
    dog-walk.mb
    dog-sit.mb
    dog-run.mb

To convert these into panda, you would call
    &lt;code bash&gt;maya2egg6 dog-walk.mb -a model -cn dog -o dog-model.egg&lt;/code&gt;

Note, we can grab the model from any of the animations, as long as they are all using the exact same rig:
    &lt;code bash&gt;maya2egg6 dog-walk.mb -a chan -cn dog -o dog-walk.egg
maya2egg6 dog-sit.mb -a chan -cn dog -o dog-sit.egg
maya2egg6 dog-run.mb -a chan -cn dog -o dog-run.egg&lt;/code&gt;
----
== I'm using the &lt;code&gt;lookAt()&lt;/code&gt; method on a NodePath to point it at another object. It works fine until I point upwards, and then it starts to spin my object around randomly ==
----
&lt;code&gt;lookAt()&lt;/code&gt; works as long as you aren't telling it to look in the direction of its up vector.
The up vector can be specified as the second argument of &lt;code&gt;lookAt()&lt;/code&gt;.
    &lt;code python&gt;lookAt(object,Vec3(0,0,1))&lt;/code&gt;
----
== I'm building a 3D game, and I have a huge world. When my world starts up, the program hangs for a few seconds the first time I look around. Is there any way to avoid this? ==
----
It can take a while to prepare objects to be rendered.

Ideally, you don't want this to happen the first time you see an object. You can offload the wait time to the beginning by calling:
    &lt;code python&gt;# self.myWorld is a NodePath that contains a ton of objects
self.myWorld.prepareScene(base.win.getGsg())&lt;/code&gt;

This will walk through the scene graph, starting at &lt;code&gt;self.myWorld&lt;/code&gt;, and prepare each object for rendering.
----
== Is there a way to hide the mouse pointer so that it doesn't show up on my screen? ==
----
You can change to properties of the Panda3D window so that it doesn't show the cursor.
    &lt;code python&gt;props = WindowProperties()
props.setCursorHidden(True)
base.win.requestProperties(props)&lt;/code&gt;
----
== If a model has an animation, then is that animation necessarily represented by an additional .egg file? ==
----
No. A .egg file can either be just geometry, just an animation or a combination of the two.
It's often easiest, however, to create a separate egg for every animation and an egg that contains just the model/skeleton information.
----
== I have a model with an animation. When I try to play the animation I get a KeyError. Why? ==
The exact error is this:
    &lt;code bash&gt;KeyError: lodRoot
display: Closing wglGraphicsWindow&lt;/code&gt;
----
This often happens when you are trying to load animations onto a model that wasn't exported to have animations.
There are two pieces to objects that have animations; their geometry and their skeleton. The geometry is what you see when you load a model, the skeleton is what controls the geometry in an animation. If only the geometry was used to make the egg file, you will have problems when you try to play animations. Look at the manual for more details about exporting models as eggs.
----
== I called &lt;code&gt;setTexture('tex.png')&lt;/code&gt; and it didn't change or send an error. Why? ==
----
To override an existing texture, you need to specify a priority.
The &lt;code&gt;setTexture()&lt;/code&gt; call includes an optional priority parameter, and if the priority is less than 1 the texture will not change.
    &lt;code python&gt;setTexture('tex.png', 1)&lt;/code&gt;
----
== Why do I get sometimes get an AssertionError when instantiating Sequence? ==
Specifically, I get the following error:

    &lt;code bash&gt;assert(self.validateComponents(self.ivals))
AssertionError&lt;/code&gt;

It happens at this line of code:

    &lt;code python&gt;move = Sequence(obj.setX(5))&lt;/code&gt;
----
Sequences and Parallels are a way to combine intervals. You can't put anything inside them that isn't an interval.
The following would have the same effect and work:
    &lt;code python&gt;move = Sequence(Func(obj.setX, 5))&lt;/code&gt;

This will start the execution of the function, but not wait for it to finish.
----
== Does Panda3D use degrees or radians? ==
----
Degrees, but see also the &lt;code&gt;deg2Rad()&lt;/code&gt; and &lt;code&gt;rad2Deg()&lt;/code&gt; functions.
But note that functions like &lt;code&gt;math.sin()&lt;/code&gt;, &lt;code&gt;math.cos()&lt;/code&gt;, &lt;code&gt;math.tan()&lt;/code&gt; are calculated in radians. Don't forget to convert the values!
----
== Why do all my flat objects look weird when lit? ==
----
Flats don't often have a lot of vertices.
Lighting is only calculated at the vertices, and then linearly interpolated between the vertices.  If your vertices are very far apart, lighting can look very strange--for instance, a point light in the center of a large polygon might not show up at all. (The light is far from all four vertices, even though it's very near the polygon's center.)

One solution is to create a model with a lot of polygons to pick up the lighting. It also helps to make a flat surface slightly curved to improve its appearance.

Another approach might be to create an ambient light that only affects this object. See the manual for more detail about attaching lights to objects in your scene.
----
== To smooth my animations, I used the &quot;interpolate-frames 1&quot; option, but it doesn't work somehow. Why? ==
----
Interpolate-frames flag gets set in the PartBundle at the time it is first created, and then baked into the model cache.
Thenceforth, later changes to the interpolate-frames variable mean nothing. If you changed interpolate-frames flag, you will also need to empty your modelcache folder.

Actually, it is not recommended to use interpolate-frames; it is a global setting. It's better to achieve the same effect via &lt;code&gt;actor.setBlend(frameBlend=True)&lt;/code&gt;, which is a per-actor setting (and doesn't get baked into the model cache).
----
== I'm trying to redirect the output of some commands like &lt;code&gt;myNode.ls()&lt;/code&gt; to a file, but the usual method &lt;code&gt;python &gt;&gt; file, myNode.ls()&lt;/code&gt; doesn't work. What's the alternative?  ==
----
There are several alternative approaches.
One approach using StringStream is this:
    &lt;code python&gt;strm = StringStream()
render.ls(strm)
open('out.txt', 'w').write(strm.getData())&lt;/code&gt;

The following is another approach using StringStream:
    &lt;code python&gt;strm = StringStream()
cvMgr.write(strm)
open('out.txt', 'w').write(strm.getData())&lt;/code&gt;

If you don't want to use a StringStream you can do this:
    &lt;code python&gt;strm = MultiplexStream()
strm.addFile(Filename('out.txt'))
render.ls(strm)&lt;/code&gt;

There is also a way to specify the output file in the config file.
    &lt;code prc&gt;notify-output out.txt&lt;/code&gt;
----
== How do I create a node from a string containing a .egg source? ==
----
Use the EggData class.
    &lt;code python&gt;egg = EggData()
egg.read(StringStream(eggText))
model = NodePath(loadEggData(egg))&lt;/code&gt;
----
== How can I know which letter is below the pointer when I click on a TextNode? ==
----
Use the TextAssembler class.
    &lt;code python&gt;tn = TextNode('tn')
tn.setText('abcdef\nghi')
ta = TextAssembler(tn)
ta.setWtext(tn.getWtext())
for ri in range(ta.getNumRows()):
    for ci in range(ta.getNumCols(ri)):
        print(&quot;ri = %s, ci = %s, char = %s, pos = %s, %s&quot; %
              (ri, ci, chr(ta.getCharacter(ri, ci)),
                           ta.getXpos(ri, ci),
                           ta.getYpos(ri, ci)))&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>FSM Introduction</title>
    <ns>0</ns>
    <id>1713</id>
      <sha1>nqw6413cxpbldv8idydzz5de6v1ltl3</sha1>
    <revision>
      <id>6781</id>
      <timestamp>2010-04-05T21:08:46Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>Slight clean-up; added code tags and language segregation.</comment>
      <text xml:space="preserve" bytes="5458">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

[python]
&lt;p&gt;In Panda3D, FSM's are frequently used in game code to automatically
handle the cleanup logic in game state changes.  For instance, suppose
you are writing a game in which the avatar spends most of his time
walking around, but should go into swim mode when he enters the water.
While he is walking around, you want certain animations and sound
effects to be playing, and certain game features to be active; but
while he is swimming, there should be a different set of animations,
sound effects, and game features (this is just an example, of course):&lt;/p&gt;

&lt;center&gt;&lt;table style=&quot;border-collapse: separate; border-spacing: 20pt 0pt&quot;&gt;
&lt;tr&gt;&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding: 5pt&quot;&gt;
&lt;b&gt;Walk state&lt;/b&gt;
&lt;ul&gt;
&lt;li&gt;Should be playing &quot;walk&quot; animation
&lt;li&gt;Should hear footsteps sound effect
&lt;li&gt;Collision detection with doors should be active
&lt;/ul&gt;&lt;/td&gt;

&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding: 5pt&quot;&gt;
&lt;b&gt;Swim state&lt;/b&gt;
&lt;ul&gt;
&lt;li&gt;Should be playing &quot;swim&quot; animation
&lt;li&gt;Should hear underwater sound effect
&lt;li&gt;Should have fog on camera
&lt;li&gt;Should have an air timer running
&lt;/ul&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;

&lt;p&gt;So, when your avatar switches from walking to swimming, you would
need to stop the footsteps sound effect, disable the door collisions,
start playing the &quot;swim&quot; animation, start the underwater sound effect,
enable the fog on the camera, and start the air timer.&lt;/p&gt;

&lt;p&gt;You could do all this by hand, of course.  But using an FSM can
make it easier.  In this simple model, you could define an FSM with
two states, &quot;Walk&quot; and &quot;Swim&quot;.  This might be represented graphically
like this:&lt;/p&gt;

&lt;center&gt;&lt;table style=&quot;border-collapse: separate; border-spacing: 1pt 0pt&quot;&gt;
&lt;tr&gt;&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding: 5pt&quot;&gt;
Walk
&lt;/td&gt;
&lt;td&gt;&lt;big&gt;&amp;larr;&amp;rarr;&lt;/big&gt;&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding: 5pt&quot;&gt;
Swim
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;

&lt;p&gt;To implement this as a Panda3D FSM, you would declare an new class
that inherits from FSM, and within this class you would define four
methods: &lt;code&gt;enterWalk()&lt;/code&gt;, &lt;code&gt;exitWalk()&lt;/code&gt;, &lt;code&gt;enterSwim()&lt;/code&gt;, and &lt;code&gt;exitSwim()&lt;/code&gt;.  This might look something like this:&lt;/p&gt;

&lt;code python&gt;
from direct.fsm.FSM import FSM

class AvatarFSM(FSM):
    def __init__(self):#optional because FSM already defines __init__
        #if you do write your own, you *must* call the base __init__ :
        FSM.__init__(self, 'AvatarFSM')
        ##do your init code here

    def enterWalk(self):
        avatar.loop('walk')
        footstepsSound.play()
        enableDoorCollisions()
        
    def exitWalk(self):
        avatar.stop()
        footstepsSound.stop()
        disableDoorCollisions()

    def enterSwim(self):
        avatar.loop('swim')
        underwaterSound.play()
        render.setFog(underwaterFog)
        startAirTimer()
        
    def exitSwim(self):
        avatar.stop()
        underwaterSound.stop()
        render.clearFog()
        stopAirTimer()

myfsm = AvatarFSM()
&lt;/code&gt;

&lt;p&gt;Keep in mind this is just an imaginary example, but it should give you an idea of what an FSM class looks like.&lt;/p&gt;

&lt;p&gt;Note that each enter method activates everything that is important for
its particular state, and--this is the important part--the
corresponding exit method turns off or undoes &lt;em&gt;everything&lt;/em&gt; that
was turned on by the enter method.  This means that whenever the FSM
leaves a particular state, you can be confident that it will
completely disable anything it started when it entered that state.&lt;/p&gt;

&lt;p&gt;Now to switch from Walk state to Swim state, you would just need to
request a transition, like this:&lt;/p&gt;

&lt;code python&gt;
myfsm.request('Swim')
&lt;/code&gt;

&lt;p&gt;This FSM is a very simple example.  Soon you will find the need for
more than two states.  For instance, you might want to play a
transition animation while the avatar is moving from Walk state to
Swim state and back again, and these can be encoded as separate
states.  There might be a &quot;drowning&quot; animation if the avatar stays too
long underwater, which again might be another state.  Graphically,
this now looks like this:&lt;/p&gt;

&lt;center&gt;&lt;table style=&quot;border-collapse: separate; border-spacing: 1pt 0pt&quot;&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;big&gt;&amp;#8599;&lt;/big&gt;&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding: 5pt&quot;&gt;
Walk2Swim
&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;big&gt;&amp;#8600;&lt;/big&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding: 5pt&quot;&gt;
Walk
&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding: 5pt&quot;&gt;
Swim
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;big&gt;&amp;rarr;&lt;/big&gt;&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding: 5pt&quot;&gt;
Drowning
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;big&gt;&amp;#8598;&lt;/big&gt;&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding: 5pt&quot;&gt;
Swim2Walk
&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;big&gt;&amp;#8601;&lt;/big&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;

&lt;p&gt;In a real-world example, you might easily find you have a need for
dozens of states.  This is when using the FSM class to manage all of
these transitions for you can really make things a lot simpler; if you
had to keep all of that cleanup code in your head, it can very quickly
get out of hand.&lt;/p&gt;
[/python]
[cxx]
&lt;p&gt;This section does not apply to C++ users.&lt;/p&gt;
[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>FSM with input</title>
    <ns>0</ns>
    <id>1715</id>
      <sha1>1qagcqt093oaggqz6r38crrml3bkzt1</sha1>
    <revision>
      <id>6783</id>
      <timestamp>2010-04-05T21:18:49Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>Slight clean-up; added code tags and language segregation.</comment>
      <text xml:space="preserve" bytes="6324">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

[python]
&lt;p&gt;Another common use for FSM's is to provide an abstraction for AI
state.  For this purpose, you would like to supply an &quot;input&quot; string
to the FSM and let the FSM decide which state it should transition
to rather than explicitly specifying the target state name.&lt;/p&gt;

&lt;p&gt;Consider the following FSM state diagram:&lt;/p&gt;

&lt;center&gt;&lt;table style=&quot;border-collapse: separate; border-spacing: 1pt 0pt; text-align: center&quot;&gt;
&lt;tr&gt;
&lt;td&gt;&lt;big&gt;&amp;#8631;&lt;/big&gt; straight&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;big&gt;&amp;#8630;&lt;/big&gt; straight&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding: 5pt&quot;&gt;
North&lt;/td&gt;
&lt;td&gt;&lt;big&gt;&amp;larr;&lt;/big&gt; left&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding: 5pt&quot;&gt;
East&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;big&gt;&amp;darr;&lt;/big&gt; left&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;big&gt;&amp;uarr;&lt;/big&gt; left&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding: 5pt&quot;&gt;
West&lt;/td&gt;
&lt;td&gt;&lt;big&gt;&amp;rarr;&lt;/big&gt; left&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding: 5pt&quot;&gt;
South&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;big&gt;&amp;#8634;&lt;/big&gt; straight&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;big&gt;&amp;#8635;&lt;/big&gt; straight&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;

&lt;p&gt;Here the text next to an arrow represents the &quot;input&quot; string given
to the FSM, and the direction of the arrow represents the state
transition that should be made for that particular input string, from
the indicated starting state.&lt;/p&gt;

&lt;p&gt;In this example, we have encoded a simple FSM that determines which
compass direction a character will be facing after either turning left
or continuing straight.  The input will be either &quot;left&quot; or
&quot;straight&quot;, and the result is a transition to a new state that
represents the new compass direction, based on the previous compass
direction.  If we request &quot;left&quot; from state North, the FSM transitions
to state West.  On the other hand, if we request &quot;left&quot; from state
South, the FSM transitions to state East.  If we request &quot;straight&quot;
from any state, the FSM should remain in its current state.&lt;/p&gt;

&lt;p&gt;To implement this in Panda3D, we define a number of &lt;b&gt;filter
functions&lt;/b&gt;, one for each state.  The purpose of this function is to
decide what state to transition to next, if any, on receipt of a
particular input.&lt;/p&gt;

&lt;p&gt;A filter function is created by defining a python method named
&lt;code&gt;filterStateName()&lt;/code&gt;, where StateName is the name of the FSM
state to which this filter function applies.  The filterStateName
method receives two parameters, a string and a tuple of arguments (the
arguments contain the optional additional arguments that might have
been passed to the &lt;code&gt;fsm.request()&lt;/code&gt; call; it's usually an
empty tuple).  The filter function should return the name of the state
to transition to.  If the transition should be disallowed, the filter
function can either return None to quietly ignore it, or it can raise
an exception.  For example:&lt;/p&gt;

&lt;code python&gt;
class CompassDir(FSM):

    def filterNorth(self, request, args):
        if request == 'straight':
            return 'North'
        elif request == 'left':
            return 'West'
        else:
            return None

    def filterWest(self, request, args):
        if request == 'straight':
            return 'West'
        elif request == 'left':
            return 'South'
        else:
            return None

    def filterSouth(self, request, args):
        if request == 'straight':
            return 'South'
        elif request == 'left':
            return 'East'
        else:
            return None

    def filterEast(self, request, args):
        if request == 'straight':
            return 'East'
        elif request == 'left':
            return 'North'
        else:
            return None
&lt;/code&gt;

&lt;p&gt;Note that input strings, by convention, should begin with a
lowercase letter, as opposed to state names, which should begin with
an uppercase letter.  This allows you to make the distinction between
requesting a state directly, and feeding a particular input string to
an FSM.  To feed input to this FSM, you would use the &lt;code&gt;request()&lt;/code&gt; call,
just as before:&lt;/p&gt;

&lt;code python&gt;
myfsm.request('left') # or myfsm.request_left()
myfsm.request('left')
myfsm.request('straight') # or myfsm.request_straight()
myfsm.request('left')
&lt;/code&gt;

&lt;p&gt;If the FSM had been in state North originally, after the above
sequence of operations it would now be in state East.&lt;/p&gt;

== The defaultFilter method ==

&lt;p&gt;Although defining a series of individual filter methods gives you
the most flexibility, for many FSM's you may not need this much
explicit control.  For these cases, you can simply define a
defaultFilter method that does everything you need.  If a particular
&lt;code&gt;filterStateName()&lt;/code&gt; method does not exist, then the FSM
will call the method named &lt;code&gt;defaultFilter()&lt;/code&gt; instead; you
can put any logic here that handles the general case.&lt;/p&gt;

&lt;p&gt;For instance, we could have defined the above FSM using just the
defaultFilter method, and a lookup table:&lt;/p&gt;

&lt;code python&gt;
class CompassDir(FSM):
    nextState = {
        ('North', 'straight') : 'North',
        ('North', 'left') : 'West',
        ('West', 'straight') : 'West',
        ('West', 'left') : 'South',
        ('South', 'straight') : 'South',
        ('South', 'left') : 'East',
        ('East', 'straight') : 'East',
        ('East', 'left') : 'North',
        }

    def defaultFilter(self, request, args):
        key = (self.state, request)
        return self.nextState.get(key)
&lt;/code&gt;

&lt;p&gt;The base FSM class defines a &lt;code&gt;defaultFilter()&lt;/code&gt; method
that implements the default FSM transition rules (that is, allow all
direct-to-state (uppercase) transition requests unless
&lt;code&gt;self.defaultTransitions&lt;/code&gt; is defined; in either case, quietly ignore
input (lowercase) requests).&lt;/p&gt;

&lt;p&gt;In practice, you can mix-and-match the use of the defaultFilter
method and your own custom methods.  The defaultFilter method will be
called only if a particular state's custom filter method does not
exist.  If a particular state's filterStateName method &lt;em&gt;is&lt;/em&gt;
defined, that method will be called upon a new request; it can do any
custom logic you require (and it can call up to the defaultFilter
method if you like).&lt;/p&gt;
[/python]
[cxx]
&lt;p&gt;This section does not apply to C++ users.&lt;/p&gt;
[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Fetching the textures from a Window</title>
    <ns>0</ns>
    <id>1267</id>
      <sha1>5xhbhavakui45ylanhpxc4vfslxojop</sha1>
    <revision>
      <id>2546</id>
      <timestamp>2005-11-01T23:35:53Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="20">Section coming soon.</text>
    </revision>
  </page>
  <page>
    <title>File Reading</title>
    <ns>0</ns>
    <id>2260</id>
      <sha1>4nvetxxoudz7r6zwarvc06v0ycbrjjx</sha1>
    <revision>
      <id>7468</id>
      <timestamp>2011-12-24T12:27:51Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>typo</comment>
      <text xml:space="preserve" bytes="1596">General file reading in Panda is handled by the Virtual File System.

Although it presents the files and directories that it provides access to as a single, unbroken file system, it can in fact include files from multiple sources (such as [[Multifiles]]) in the hierarchy, regardless of the underlying structure.

This has the advantage of allowing one to access files and directories without worrying overmuch about where they actually reside, and even access Multifile archives as a directory hierarchy.

NB: While present in C++, on the Python side Panda does not offer file &lt;em&gt;writing&lt;/em&gt; functionality, with the exception of writing to certain specialized file types.  For general file writing, however, Python itself offers file-handling functionality, including potentially-useful features such as reading to the end of the line in a single call.

[python]&lt;h2&gt;Thread-safe file I/O&lt;/h2&gt;
In versions 1.6.0 and above, Panda3D offers a [[thread]]-safe replacement for the Python file module. You can find it in direct.stdpy.file. The interface is exactly the same as Python's, so it's safe to put this import above all the files where you want to use the &quot;file&quot; or &quot;open&quot; functions:
&lt;code python&gt;from direct.stdpy.file import *&lt;/code&gt;
This module reimplements Python's file I/O mechanisms using Panda constructs.  This enables Python to interface more easily with Panda's virtual file system, and it also better-supports Panda's SIMPLE_THREADS model, by avoiding blocking all threads while waiting for I/O to complete.
[/python]
&lt;h2&gt;Incomplete Section&lt;/h2&gt;

Note: This section is incomplete.</text>
    </revision>
  </page>
  <page>
    <title>Filename</title>
    <ns>0</ns>
    <id>2253</id>
    <redirect title="Panda Filename Syntax" />
      <sha1>g8kiorrbycziu3sz7t9wprjz2vfpmcu</sha1>
    <revision>
      <id>5358</id>
      <timestamp>2008-04-28T17:38:55Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[Panda Filename Syntax]]</comment>
      <text xml:space="preserve" bytes="35">#REDIRECT [[Panda Filename Syntax]]</text>
    </revision>
  </page>
  <page>
    <title>Finite State Machines</title>
    <ns>0</ns>
    <id>979</id>
      <sha1>ka27i84jfym695iczaf0oafxkkn4bp1</sha1>
    <revision>
      <id>6785</id>
      <timestamp>2010-04-05T21:21:53Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>Slight clean-up; added language segregation.</comment>
      <text xml:space="preserve" bytes="1094">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

[python]
&lt;p&gt;A &quot;Finite State Machine&quot; is a concept from computer science.  Strictly speaking, it means any system that involves a finite number of different states, and a mechanism to transition from one state to another.&lt;/p&gt;

&lt;p&gt;In Panda3D, a Finite State Machine, or FSM, is implemented as a Python class.  To define a new FSM, you should define a Python class that inherits from the FSM class.  You define the available states by writing appropriate method names within the class, which define the actions the FSM takes when it enters or leaves certain states.  Then you can request your FSM to transition from state to state as you need it to.&lt;/p&gt;

&lt;p&gt;You may come across some early Panda3D code that creates an instance of the ClassicFSM class.  ClassicFSM is an earlier implementation of the FSM class, and is now considered deprecated.  It is no longer documented here.  We recommend that new code use the FSM class instead, which is documented on the following pages.&lt;/p&gt;
[/python]
[cxx]
&lt;p&gt;This section does not apply to C++ users.&lt;/p&gt;
[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Flee</title>
    <ns>0</ns>
    <id>2583</id>
      <sha1>np1vd11g41d1ejreucrx8s8v7ww28wo</sha1>
    <revision>
      <id>7738</id>
      <timestamp>2012-03-10T07:14:44Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="2742">'Flee' is an AI behavior where an AICharacter will move in the opposite direction to a target NodePath or position.

{{#ev:youtube|sXzzuK2Vnnk}}

In PandAI, &lt;b&gt;'Flee'&lt;/b&gt; is defined as :
&lt;code python&gt;
aiBehaviors.flee(NodePath target, double panic_distance, double relax_distance, float priority)
aiBehaviors.flee(Vec3 position, double panic_distance, double relax_distance, float priority)
&lt;/code&gt;
where :

&lt;b&gt;Panic Distance&lt;/b&gt; is the radius of detection.

&lt;b&gt;Relax Distance&lt;/b&gt; is the distance from the panic distance radius after which the object should stop fleeing once flee has been initiated.

&lt;b&gt;priority&lt;/b&gt; is by default set to 1.0 and is used when using two or more steering behaviors on an AICharacter.

-----

The velocity at which the AICharacter flees is determined when you first create your AICharacter object using the AICharacter constructor.

* Note: 'Flee' takes in a target or a position to be fled away from; this position should be static. (For moving objects use Evade).

-----

A fully working flee demo :

&lt;code python&gt;
import direct.directbase.DirectStart
from panda3d.core import *
from direct.showbase.DirectObject import DirectObject
from direct.task import Task
from direct.actor.Actor import Actor
#for Pandai
from panda3d.ai import *

class World(DirectObject):

    def __init__(self):
        base.disableMouse()
        base.cam.setPosHpr(0,0,55,0,-90,0)
        
        self.loadModels()
        self.setAI()
       
    def loadModels(self):
		# Seeker
        ralphStartPos = Vec3(2, 0, 0)
        self.fleer = Actor(&quot;models/ralph&quot;,
                                 {&quot;run&quot;:&quot;models/ralph-run&quot;})
        self.fleer.reparentTo(render)
        self.fleer.setScale(0.5)
        self.fleer.setPos(ralphStartPos)
        # Target
        self.target = loader.loadModel(&quot;models/arrow&quot;)
        self.target.setColor(1,0,0)
        self.target.setPos(5,0,0)
        self.target.setScale(1)
        self.target.reparentTo(render)
      
    def setAI(self):
        #Creating AI World
        self.AIworld = AIWorld(render)
 
        self.AIchar = AICharacter(&quot;fleer&quot;,self.fleer, 100, 0.05, 5)
        self.AIworld.addAiChar(self.AIchar)
        self.AIbehaviors = self.AIchar.getAiBehaviors()
        
        self.AIbehaviors.flee(self.target, 5, 5)
        self.fleer.loop(&quot;run&quot;)
		
        #AI World update        
        taskMgr.add(self.AIUpdate,&quot;AIUpdate&quot;)
        
    #to update the AIWorld    
    def AIUpdate(self,task):
        self.AIworld.update()            
        return Task.cont
 
w = World()
run()

&lt;/code&gt;

-----

To get a working demo of this example, please visit :

https://sites.google.com/site/etcpandai/documentation/steering-behaviors/flee/PandAIFleeExample.zip?attredirects=0&amp;d=1</text>
    </revision>
  </page>
  <page>
    <title>Flock</title>
    <ns>0</ns>
    <id>2587</id>
      <sha1>ie5i913ctfurd7f00dhcs1lwxva3ksp</sha1>
    <revision>
      <id>7704</id>
      <timestamp>2012-03-09T10:29:35Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>new import system</comment>
      <text xml:space="preserve" bytes="6951">&lt;b&gt;What is flocking?&lt;/b&gt;

&lt;b&gt;Flocking&lt;/b&gt; is an emergent behavior and is the resultant of the following forces:

&lt;b&gt;cohesion&lt;/b&gt; -- finds average position of neighbors and tries to move to that position
&lt;b&gt;separation&lt;/b&gt; -- object keeps a certain distance between itself and its neighbor
&lt;b&gt;alignment&lt;/b&gt; -- finds average direction in which all neighbors are moving and tries to move in that direction

Each NPC has a &lt;b&gt;&quot;visibility cone&quot;&lt;/b&gt; and this is used to compute it's neighbors. The neighbors contribute towards the forces mentioned above.

&lt;b&gt;Tuners:&lt;/b&gt;

1. The angle and length of each NPC's &quot;visibility cone&quot;.
2. Weight of cohesion, separation, and alignment (how much each sub-behavior of flock affects the overall flocking behavior).

&lt;b&gt;Note:&lt;/b&gt; Flocking behavior is NOT a standalone behavior. It needs to be combined with other steering behaviors such as seek, pursue, flee, evade etc. to function.


{{#ev:youtube|dkfnlqH06IY}}


-----

Using PandAI's flocking system:

&lt;code python&gt;
// To create the flock
flockObject = Flock(unsigned int flock_id, double vcone_angle, double vcone_radius, unsigned int cohesion_wt, unsigned int separation_wt, unsigned int alignment_wt)
&lt;/code&gt;

&lt;b&gt;&quot;flock_id&quot;&lt;/b&gt; is a value identifying the flock.

&lt;b&gt;&quot;vcone_angle&quot;&lt;/b&gt; is the visibility angle of the character (represented by a cone around it)

&lt;b&gt;&quot;vcone_radius&quot;&lt;/b&gt; is the length of the visibility cone.

&lt;b&gt;&quot;cohesion_wt&quot;, &quot;separation_wt&quot; and &quot;alignment_wt&quot;&lt;/b&gt; is the amount of separation force that contributes to the overall flocking behavior.


-----


&lt;b&gt;Some standard values to start you off with:&lt;/b&gt;

Type	 	 	vcone_angle	 	 	vcone_radius	 	 	separation_wt	 	 	cohesion_wt	 	 	alignment_wt

Normal Pack	 	 	 270	 	 	10	 	 	2	 	 	4	 	 	1

Loose Pack	 	 	180	 	 	10	 	 	2	 	 	4	 	 	5

Tight Pack	 	 	45	 	 	5	 	 	2	 	 	4	 	 	5


You could try experimenting with your own values to customize your flock.


-----


To add your AI Character to the above created flock
&lt;code python&gt;
flockObject.addAiChar(aiChar)     // aiChar is an AICharacter object. 
&lt;/code&gt;


After all the AI Characters are added to the flock, add the flock to the world.
&lt;code python&gt;
aiWorld.addFlock(flockObject)    // aiWorld is an AIWorld object.
&lt;/code&gt;


Specify the flock behavior priority. As mentioned earlier, flock behavior works with other steering behaviors.
&lt;code python&gt;
aiBehaviors.flock(float priority)       // aiBehaviors is an AIBehaviors object.
&lt;code&gt;

&lt;b&gt;Other useful flock functions:&lt;/b&gt;
&lt;code python&gt;
aiWorld.flockOff(unsigned int flock_id);            // Turns the flock behavior off.

aiWorld.flockOn(unsigned int flock_id);           // Turns the flock behavior on.

aiWorld.removeFlock(unsigned int flock_id);    // Removes the flock behavior. Note: This does NOT remove the AI characters of the flock.

aiWorld.getFlock(unsigned int flock_id);          // Returns a handle to the flock object.

&lt;/code&gt;


-----


&lt;b&gt;The full working code in Panda3D :&lt;/b&gt;

&lt;code python&gt;
import direct.directbase.DirectStart
from panda3d.core import *
from direct.showbase.DirectObject import DirectObject
from direct.task import Task
from direct.actor.Actor import Actor
#for Pandai
from panda3d.ai import *
#for Onscreen GUI
from direct.gui.OnscreenText import OnscreenText

# Globals
speed = 0.75

# Function to put instructions on the screen.
font = loader.loadFont(&quot;cmss12&quot;)
def addInstructions(pos, msg):
    return OnscreenText(text=msg, style=1, fg=(1,1,1,1), font = font,
                        pos=(-1.3, pos), align=TextNode.ALeft, scale = .05)

class World(DirectObject):

    def __init__(self):
        base.disableMouse()
        base.cam.setPosHpr(0,0,85,0,-90,0)
        
        self.loadModels()
        self.setAI()
        self.setMovement()

    def loadModels(self):
        # Seeker
        self.flockers = []
        for i in range(10):
            ralphStartPos = Vec3(-10+i, 0, 0)
            self.flockers.append(Actor(&quot;models/ralph&quot;,
                                     {&quot;run&quot;:&quot;models/ralph-run&quot;}))
            self.flockers[i].reparentTo(render)
            self.flockers[i].setScale(0.5)
            self.flockers[i].setPos(ralphStartPos)
            self.flockers[i].loop(&quot;run&quot;)
            
        # Target
        self.target = loader.loadModel(&quot;models/arrow&quot;)
        self.target.setColor(1,0,0)
        self.target.setPos(0,20,0)
        self.target.setScale(1)
        self.target.reparentTo(render)            
      
    def setAI(self):
        #Creating AI World
        self.AIworld = AIWorld(render)
  
        #Flock functions
        self.MyFlock = Flock(1, 270, 10, 2, 4, 0.2)
        self.AIworld.addFlock(self.MyFlock)
        self.AIworld.flockOn(1);
  
        self.AIchar = []
        self.AIbehaviors = []
        for i in range(10):
            self.AIchar.append(AICharacter(&quot;flockers&quot;+str(i),self.flockers[i], 100, 0.05, 5))
            self.AIworld.addAiChar(self.AIchar[i])
            self.AIbehaviors.append(self.AIchar[i].getAiBehaviors())
            self.MyFlock.addAiChar(self.AIchar[i])
            self.AIbehaviors[i].flock(0.5)             
            self.AIbehaviors[i].pursue(self.target, 0.5)

        #AI World update        
        taskMgr.add(self.AIUpdate,&quot;AIUpdate&quot;)
        
    #to update the AIWorld    
    def AIUpdate(self,task):
        self.AIworld.update()            
        return Task.cont
    
#All the movement functions for the Target
    def setMovement(self):
        self.keyMap = {&quot;left&quot;:0, &quot;right&quot;:0, &quot;up&quot;:0, &quot;down&quot;:0}
        self.accept(&quot;arrow_left&quot;, self.setKey, [&quot;left&quot;,1])
        self.accept(&quot;arrow_right&quot;, self.setKey, [&quot;right&quot;,1])
        self.accept(&quot;arrow_up&quot;, self.setKey, [&quot;up&quot;,1])
        self.accept(&quot;arrow_down&quot;, self.setKey, [&quot;down&quot;,1])
        self.accept(&quot;arrow_left-up&quot;, self.setKey, [&quot;left&quot;,0])
        self.accept(&quot;arrow_right-up&quot;, self.setKey, [&quot;right&quot;,0])
        self.accept(&quot;arrow_up-up&quot;, self.setKey, [&quot;up&quot;,0])
        self.accept(&quot;arrow_down-up&quot;, self.setKey, [&quot;down&quot;,0])
        #movement task
        taskMgr.add(self.Mover,&quot;Mover&quot;)
        
        addInstructions(0.9, &quot;Use the Arrow keys to move the Red Target&quot;)

    def setKey(self, key, value):
        self.keyMap[key] = value
            
    def Mover(self,task):
        startPos = self.target.getPos()
        if (self.keyMap[&quot;left&quot;]!=0):
                self.target.setPos(startPos + Point3(-speed,0,0))
        if (self.keyMap[&quot;right&quot;]!=0):
                self.target.setPos(startPos + Point3(speed,0,0))
        if (self.keyMap[&quot;up&quot;]!=0):
                self.target.setPos(startPos + Point3(0,speed,0))
        if (self.keyMap[&quot;down&quot;]!=0):
                self.target.setPos(startPos + Point3(0,-speed,0))
                        
        return Task.cont    
 
w = World()
run()
&lt;/code&gt;

&lt;b&gt;To get the full working demo, please visit : &lt;/b&gt;

https://sites.google.com/site/etcpandai/documentation/steering-behaviors/flock/PandAIFlockExample.zip?attredirects=0&amp;d=1</text>
    </revision>
  </page>
  <page>
    <title>Fog</title>
    <ns>0</ns>
    <id>981</id>
      <sha1>qc75lgtihb7bnl7j8b4uitjphg6zf3c</sha1>
    <revision>
      <id>7359</id>
      <timestamp>2011-10-08T13:42:34Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>mention exp2 fog at least once.</comment>
      <text xml:space="preserve" bytes="7851">==Basic Fog==

To turn on fog, create an object of class &lt;code&gt;Fog&lt;/code&gt;, and then apply it using the &lt;code&gt;[func]setFog[/func]&lt;/code&gt; operator:

&lt;code python&gt;
myFog = Fog(&quot;Fog Name&quot;)
myFog.setColor(R,G,B)
myFog.setExpDensity(Float 0 to 1)
render.setFog(myFog)
&lt;/code&gt;

However, there is more here than meets the eye.  We have created a &lt;i&gt;fog node&lt;/i&gt;, which goes into the scene graph.  Therefore, the fog has a position,
a place where the fog is (conceptually) thickest.  

If the fog object is not parented into the scene graph (in the example above, for instance), then the fog's position is ignored, and the fog is
camera-relative.  Likewise, if the fog is exponential, the fog's position
is ignored, and the fog is camera-relative.

The &lt;code&gt;[func]setFog[/func]&lt;/code&gt; directive creates a fog attribute object.  Like any [[Render Attributes|Render Attribute]], the fog attribute affects the node that it is attached to, and any nodes below it in the scene graph.  So you can easily cause only a subset of the objects (or just a single model) to be affected by the fog, by calling &lt;code&gt;[func]setFog[/func]&lt;/code&gt; on the root of the subgraph you want to be affected.  To remove the fog attribute later, use the &lt;code&gt;clearFog&lt;/code&gt; directive:

&lt;code python&gt;
render.clearFog()
&lt;/code&gt;

While you have fog in effect, it is often desirable to set the background color to match the fog:

&lt;code python&gt;
base.setBackgroundColor( myFogColor )
&lt;/code&gt;

==Fog Modes==
There are three fog modes in Panda: &lt;code&gt;Fog.MExponential&lt;/code&gt;, &lt;code&gt;Fog.MExponentialSquared&lt;/code&gt; and &lt;code&gt;Fog.MLinear&lt;/code&gt;. You can switch the mode of a &lt;code&gt;Fog&lt;/code&gt; object using &lt;code&gt;fog.getMode()&lt;/code&gt; and &lt;code&gt;fog.setMode(Fog.Mode)&lt;/code&gt;. This explicit mode switching isn't normally necessary, as &lt;code&gt;Fog&lt;/code&gt; methods implicitly switch the mode for you.

A &lt;code&gt;Fog&lt;/code&gt; object in Panda3D is a &lt;em&gt;node&lt;/em&gt; that can be parented into the scene graph with a position, colour and orientation like any other node (importantly, &lt;code&gt;Fog&lt;/code&gt; is a subclass of &lt;code&gt;PandaNode&lt;/code&gt;, not of &lt;code&gt;NodePath&lt;/code&gt;) &lt;em&gt;(do &lt;code&gt;Fog&lt;/code&gt; nodes have a scale?)&lt;/em&gt;.

The position of a &lt;code&gt;Fog&lt;/code&gt; node in the scene graph &lt;em&gt;does not determine which objects the fog affects&lt;/em&gt;, it determines the origin and direction of the fog &lt;em&gt;when it is in linear mode&lt;/em&gt;. When a fog node is in exponential mode its position and orientation in the scene graph are irrelevant. Either way, a &lt;code&gt;Fog&lt;/code&gt; node must be activated by calling &lt;code&gt;nodePath.setFog(fogNode)&lt;/code&gt; on some &lt;code&gt;NodePath&lt;/code&gt; in the scene graph. Which &lt;code&gt;NodePath&lt;/code&gt; you call the &lt;code&gt;[func]setFog[/func]&lt;/code&gt; method on determines which parts of the scene will be fogged: that &lt;code&gt;NodePath&lt;/code&gt; and all its children.

===Linear Fog===

This is the default mode. In this mode the &lt;i&gt;position&lt;/i&gt; and &lt;i&gt;orientation&lt;/i&gt; of a &lt;code&gt;Fog&lt;/code&gt; node are important. A linear-mode &lt;code&gt;Fog&lt;/code&gt; node must first be parented into the scene graph, then activated by calling &lt;code&gt;[func]setFog[/func](fogNode)&lt;/code&gt; on some &lt;code&gt;NodePath&lt;/code&gt; in the scene graph.

Setup a linear fog node at the origin:
&lt;code python&gt;
colour = (0.5,0.8,0.8)
linfog = Fog(&quot;A linear-mode Fog node&quot;)
linfog.setColor(*colour)
linfog.setLinearRange(0,320)
linfog.setLinearFallback(45,160,320)
render.attachNewNode(linfog)
render.setFog(linfog)
&lt;/code&gt;

In linear mode, the &lt;em&gt;onset&lt;/em&gt; and &lt;em&gt;opaque&lt;/em&gt; distances of the fog are defined as offsets &lt;em&gt;along the local forward (+Y) axis&lt;/em&gt; of the fog node. The onset distance is the distance from the fog node at which the fog will begin to have effect, and the opaque distance is the distance from the fog node at which the fog will be completely opaque. From reading the API page for the &lt;code&gt;Fog&lt;/code&gt; class, it sounds as if beyond this opaque point there is no fog (rather than continuing opaque fog up to the location of the fog node as you might expect): &quot;the fog will be rendered as if it extended along the vector from the onset point to the opaque point.&quot;

These settings can be modified using the methods &lt;code&gt;[func]getLinearOnsetPoint[/func]()&lt;/code&gt;, &lt;code&gt;[func]getLinearOpaquePoint[/func]()&lt;/code&gt;, &lt;code&gt;[func]setLinearOnsetPoint[/func](float x,y,z)&lt;/code&gt;, &lt;code&gt;[func]setLinearOpaquePoint[/func](Point3D pos)&lt;/code&gt; and &lt;code&gt;[func]setLinearRange[/func](float onset, float opaque)&lt;/code&gt; of &lt;code&gt;Fog&lt;/code&gt;.

There is a hardware issue with rendering fog which means that linear fog can breakdown and vanish depending on the angle from which it is viewed:

&lt;blockquote&gt;
&quot;the underlying fog effect supported by hardware is generally only one-dimensional, and must be rendered based on linear distance from the camera plane. Thus, this in-the-world effect is most effective when the fog vector from onset point to opaque point is most nearly parallel to the camera&amp;#8217;s eye vector. As the angle between the fog vector and the eye vector increases, the accuracy of the effect diminishes, up to a complete breakdown of the effect at a 90 degree angle.&quot;
&lt;/blockquote&gt;

The &lt;code&gt;Fog&lt;/code&gt; method &lt;code&gt;[func]setLinearFallback[/func](float angle, float onset, float opaque)&lt;/code&gt; defines how the fog should be rendered when the fog effect is diminished in this way. &lt;code&gt;angle&lt;/code&gt; is the minimum viewing angle (angle between the camera direction and fog direction) at which the fallback effect will be employed. &lt;code&gt;onset&lt;/code&gt; and &lt;code&gt;opaque&lt;/code&gt; specify &lt;em&gt;camera-relative&lt;/em&gt; onset and opaque distances that will be fallen back on, overriding the &lt;code&gt;Fog&lt;/code&gt; node&amp;#8217;s own onset and opaque distances.

The &lt;code&gt;[func]setLinearFallback[/func](float angle, float onset, float opaque)&lt;/code&gt; workaround will only look good in certain situations, for example when the fog is deep inside a dark cave. So in general, exponential mode fog is more useful than the default linear mode fog.

===Exponential Fog===

In exponential fog mode the position and orientation of your fog node in the scene graph and the onset and opaque points are ignored (in fact you don&amp;#8217;t even have to put your fog node in the scene graph). Instead, fog is rendered camera relative according to a density factor: the fog begins at the camera and continues to infinity, with an exponentially increasing density determined by the density factor. The fog moves with the camera as the camera&amp;#8217;s position and orientation changes:

&lt;blockquote&gt;
&quot;the onset point and opaque point are not used, and the fog effect is based on the value specified to &lt;code&gt;set_exp_density()&lt;/code&gt;, and it doesn&amp;#8217;t matter to which node the fog object is parented, or if it is parented anywhere at all.&quot;
&lt;/blockquote&gt;

The &lt;code&gt;fog[-&gt;][func]setExpDensity[/func](float)&lt;/code&gt; method determines the density value used for exponential fog calculations.

You activate an exponential fog effect by calling the &lt;code&gt;[func]setFog[/func](Fog)&lt;/code&gt; method of &lt;code&gt;NodePath&lt;/code&gt;, for example: &lt;code&gt;render.[func]setFog[/func](myFog)&lt;/code&gt;:

Setup some scene-wide exponential fog:

&lt;code python&gt;
colour = (0.5,0.8,0.8)
expfog = Fog(&quot;Scene-wide exponential Fog object&quot;)
expfog.setColor(*colour)
expfog.setExpDensity(0.005)
render.setFog(expfog)
base.setBackgroundColor(*colour)
&lt;/code&gt;

The last line in the sample above doesn't actually affect the fog,
however, it generally looks better if the scene background color
matches the color of the fog.

Since &lt;code&gt;[func]setFog[/func]&lt;/code&gt; is called on &lt;code&gt;render&lt;/code&gt; it effects
the entire scene. &lt;code&gt;[func]setFog[/func]&lt;/code&gt; can just as easily be called on
some other &lt;code&gt;NodePath&lt;/code&gt; and will effect only that
&lt;code&gt;NodePath&lt;/code&gt; and its children.

The expontential fog effect can be turned off again using &lt;code&gt;clearFog&lt;/code&gt;:

&lt;code python&gt;
render.clearFog()
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>Fog and Lighting</title>
    <ns>0</ns>
    <id>980</id>
      <sha1>rxb9dvzz124ug6zmyva4io7xjjx5i0n</sha1>
    <revision>
      <id>2265</id>
      <timestamp>2005-04-16T21:30:07Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="384">&lt;p&gt;Fog and lighting are two techniques to add dimension to a virtual space. Panda3D contains a variety of lights that work by vertex lighting. Vertex lighting shades an entire polygon, so the more polygons the world uses, the better the lighting becomes. In areas where lighting is critical, it is best to tessellate the area as much as can be done without killing the frame rate.&lt;/p&gt;</text>
    </revision>
  </page>
  <page>
    <title>Frequently Asked Questions</title>
    <ns>0</ns>
    <id>982</id>
    <redirect title="FAQ" />
      <sha1>1chp1kpwmmzd1pt3pqxuc4un6hc56dq</sha1>
    <revision>
      <id>4144</id>
      <timestamp>2007-02-22T07:49:00Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>Redirected to FAQ</comment>
      <text xml:space="preserve" bytes="17">#REDIRECT [[FAQ]]</text>
    </revision>
  </page>
  <page>
    <title>Function Intervals</title>
    <ns>0</ns>
    <id>983</id>
      <sha1>ooczh6r1qaxkfxey764l1ycn1j4vqnc</sha1>
    <revision>
      <id>6538</id>
      <timestamp>2010-01-14T19:33:41Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <minor/>
      <comment>Minor word change for class constructor; 'argument' -&gt; 'parameter'.</comment>
      <text xml:space="preserve" bytes="1078">[python]
Function intervals are different from function lerp intervals. While the function lerp interval passes data to a function over a period of time, a function interval will simply execute a function when called. As such, a function interval’s use really appears when combined with sequences and parallels. The function interval’s format is simple.

&lt;code python&gt;
intervalName = Func(myFunction)
&lt;/code&gt;

You pass the function without parentheses (i.e. you pass &lt;code&gt;Func&lt;/code&gt; - a function pointer) as the parameter. If &lt;code&gt;myFunction&lt;/code&gt; takes arguments, then pass them as parameters to &lt;code&gt;Func&lt;/code&gt; as follows:

&lt;code python&gt;
def myFunction(arg1, arg2):
   # Do something.

intervalName = Func(myFunction, arg1, arg2)
&lt;/code&gt;

Functions cannot be called on their own in sequences and parallels, so it is necessary to wrap them in an interval in order to call them. Since function intervals have no duration, they complete the moment they are called.
[/python]
[cxx]
As FunctionInterval is implemented in Python, this section does not apply to C++.
[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Garbage Collection</title>
    <ns>0</ns>
    <id>2658</id>
      <sha1>p79c8nycdbrr0wj2bhod0z9jlxw86t9</sha1>
    <revision>
      <id>7371</id>
      <timestamp>2011-11-13T15:37:02Z</timestamp>
      <contributor>
        <username>PiratePanda</username>
        <id>522</id>
      </contributor>
      <text xml:space="preserve" bytes="165">This section of the manual discusses how to properly ensure that items created during run time are properly removed from the computer's memory when no longer needed.</text>
    </revision>
  </page>
  <page>
    <title>General Preparation</title>
    <ns>0</ns>
    <id>932</id>
      <sha1>1ua78mco6vo0z2ijlnapp52cy1o2h3g</sha1>
    <revision>
      <id>60537</id>
      <timestamp>2015-07-23T12:14:46Z</timestamp>
      <contributor>
        <username>Sal</username>
        <id>22868</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="4941">You can use multiple programming languages with Panda3D. The most commonly used language is Python, followed by C++. Some manual pages offer both C++ and Python information - use the toggle button at the top of the manual page to toggle between C++ information and Python information.

[python]For example, if you want this page to contain information about learning C++ instead of learning Python, just hit the &quot;C++&quot; link at the top of this page.[/python]
[cxx]For example, if you want this page to contain information about learning Python instead of learning C++, just hit the &quot;Python&quot; link at the top of this page.[/cxx]

[python]
==Learning Python==

Since Panda3D is a library, and not a point-n-click game maker, it is needed to learn Python or C++ before you will be able to use it. Since this engine's main goal is to support Python, it would be a good idea to familiarize yourself with Python before continuing.

Python is an interpreted, interactive,
object-oriented language comparable to Java or Perl. It is available
on several platforms, including UNIX, Windows, OS/2, and Mac. Python
also has a large number of modules outside of the standard Python
installation, and additional modules can be created in C or
C++. Because it is late-binding and requires minimal memory
management, it is an ideal language for rapid prototyping.

&lt;b&gt;The Copy of Python that comes with Panda&lt;/b&gt;

It is not necessary to install Python, because the windows installer for Panda3D includes a copy.  This is a completely normal copy of Python, identical to what you would have if you installed Python using the standard Python installer.  Panda's built-in copy of Python is automatically added to the PATH environment variable.  This enables you to type &quot;python&quot; at the command prompt, and it will run the Python that comes with Panda.

&lt;b&gt;What if I already have a copy of Python?&lt;/b&gt;

If you already have a copy of Python, and you wish to use that instead of the one provided with panda, it is easy to do so.  Simply create a &quot;panda.pth&quot; file inside your copy of Python, containing the path of the panda directory and the bin directory within it on separate lines (for example C:\Program Files\Panda3D-1.2.3 and C:\Program Files\Panda3D-1.2.3\bin).  This will enable your copy of Python to find the panda libraries.

For this to work, the version of Python that you use must match the version of Python included with panda.  The panda libraries are compiled for that particular version, and will not work with any other.

Of course, if you do use your own copy of Python, you may wish to delete panda's copy of Python, or at least, remove it from the PATH environment variable.  Otherwise, you will have two copies of Python, which can lead to confusion.

&lt;b&gt;Python Programming Resources&lt;/b&gt;

There are a lot of other resources available for programming in Python.
Here is a list of some of the best:

Links from the official Python website:
&lt;ul&gt;
        &lt;li&gt;[http://www.python.org Official Website - http://www.python.org]&lt;/li&gt;
        &lt;li&gt;[http://docs.python.org/ Current Python Documentation ]&lt;/li&gt;
        &lt;li&gt;[http://www.python.org/doc Python Documentation]&lt;/li&gt;
&lt;/ul&gt;

Here are some other good links for learning Python:

&lt;ul&gt;
        &lt;li&gt;[http://www.swaroopch.com/notes/python/ Byte of Python]&lt;/li&gt;
        &lt;li&gt;[http://www.diveintopython.net Dive Into Python]&lt;/li&gt;
        &lt;li&gt;[http://wiki.python.org/moin/BeginnersGuide Beginner's Guide from Python's wiki]&lt;/li&gt;
        &lt;li&gt;[http://www.effbot.org/zone/librarybook-index.htm The Standard Python Library]&lt;/li&gt;
        &lt;li&gt;[http://www.voidspace.org.uk/python/articles/OOP.shtml Introduction to OOP with Python]&lt;/li&gt;
&lt;/ul&gt;[/python]

[cxx]
==Learning C++==

It is possible to write Panda3D programs using C++.  However, since most of the documentation uses Python, it may be better to learn Panda3D using Python first, and then switch to C++ later.  If you do switch, the function calls are very similar.

C++ is an object-oriented high-level multi-purpose language. It is actually a copy of the C programming language, but object-oriented, with more functions.
Here are a few links to C++ tutorials that might be useful for you:
*[http://www.cplusplus.com/doc/tutorial/ http://www.cplusplus.com/doc/tutorial/]
*[http://www.learncpp.com/ www.learncpp.com]

The binaries of the last Windows release are built with Microsoft Visual C++ 2008 Service Pack 1. If you want to use the provided binaries you must use that version of Visual Studio.

If you wish to use another version you will have to build Panda from source. Note that if you do that you will need all the dependencies (such us libjpeg, libpng, etc) built by the same compiler than you are using. You can do this yourself or look around for 3rd party binaries.

On UNIX-like operating systems you can use the GNU G++ compiler.

For information about compiling your C++ program, see [[How to build a CXX Panda3D game|this page]].[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Generalized Image Filters</title>
    <ns>0</ns>
    <id>2185</id>
      <sha1>pmeku7ljeiaviifxqqxwd72tjyb6g1f</sha1>
    <revision>
      <id>7560</id>
      <timestamp>2012-01-10T07:42:56Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="6225">[cxx]&lt;b&gt;Note:&lt;/b&gt; Sorry, but the CommonFilters and FilterManager classes are implemented in Python and will not be of much use to C++ users.

[/cxx]&lt;h2&gt;The Filter Manager&lt;/h2&gt;

Class FilterManager is designed to make it easier to apply filters to your
scene.  Of course, the easiest way to apply filters to your scene is to use
class [[Common Image Filters|CommonFilters]].  But if that utility does not
contain the filters you need, then the FilterManager is your next best
choice.  The main function of the FilterManager is to help you set up the offscreen buffers, the quads, and the textures.

Import the class like this:

&lt;code python&gt;
from direct.filter.FilterManager import FilterManager
&lt;/code&gt;


&lt;h2&gt;The Simplest Filter&lt;/h2&gt;

The simplest possible code that uses the FilterManager looks like this:

&lt;code python&gt;
manager = FilterManager(base.win, base.cam)
tex = Texture()
quad = manager.renderSceneInto(colortex=tex)
quad.setShader(Shader.load(&quot;myfilter.sha&quot;))
quad.setShaderInput(&quot;tex&quot;, tex)
&lt;/code&gt;

The first line creates an object of class FilterManager.  We have told
it that we want to apply filtering to the contents of the main window.
We have also told it that we want to filter the stuff that's being
rendered by the main camera, and not, for instance, the 2D camera.

The second line creates a texture - this is the texture that we're going
to render the scene into.

The third line does most of the work.  This removes the scene from the window, 
and instead, directs the rendering of the scene into 'tex'.  
It puts a quad into the window in place of the scene.  The quad is
returned.

Finally, we apply a shader to the quad, and pass the scene texture
to the shader.  Presumably, the shader is rendering the scene
onto the quad, which covers the window.  Presto, filtered scene.

There's one tricky aspect of all this.  Usually, the window is usually not a
power of two.  The texture will end up being bigger than the window: for
instance, if the window is 800x600, then the texture will be 1024x1024.
The scene will be rendered into the lower-left 800x600 pixels of the
texture.  The shader needs to compensate for this.  If you forget this,
you will see an empty band above and to the right of the texture.

Here is a basic shader code example, it applies a simple black and white effect :

&lt;code cg&gt;
//Cg

void vshader(
    float4 vtx_position : POSITION,
    float2 vtx_texcoord0 : TEXCOORD0,
    out float4 l_position : POSITION,
    out float2 l_texcoord0 : TEXCOORD0,
    uniform float4 texpad_tex,
    uniform float4x4 mat_modelproj)
{
    l_position=mul(mat_modelproj, vtx_position);
    l_texcoord0 = vtx_position.xz * texpad_tex.xy + texpad_tex.xy;
}

void fshader(float2 l_texcoord0 : TEXCOORD0,
             out float4 o_color : COLOR,
             uniform sampler2D k_tex : TEXUNIT0)
{
    float4 c = tex2D(k_tex, l_texcoord0);

    // To have a useless filter that outputs the original view
    // without changing anything, just use :
    //o_color  = c;
    
    // basic black and white effet
    float moyenne = (c.x + c.y + c.z)/3;
    o_color = float4(moyenne, moyenne, moyenne, 1);
}
&lt;/code&gt;



&lt;h2&gt;Extracting More Information from the Scene&lt;/h2&gt;

In addition to fetching the color buffer of the scene, you can also fetch
the depth buffer:

&lt;code python&gt;
manager = FilterManager(base.win, base.cam)
tex = Texture()
dtex = Texture()
quad = manager.renderSceneInto(colortex=tex, depthtex=dtex)
&lt;/code&gt;

The depth buffer is particularly useful for filters like depth-of-field.  You can pass the depth-texture to the shader too.

Sometimes, scene rendering may generate not just a color buffer and a depth
buffer, but also an auxiliary buffer.  If so, you can fetch that too:

&lt;code python&gt;
manager = FilterManager(base.win, base.cam)
tex = Texture()
atex = Texture()
quad = manager.renderSceneInto(colortex=tex, auxtex=atex)
&lt;/code&gt;

Doing this would really only make sense if you've asked the renderer
to put something of interest into the auxiliary buffer.  To do this,
see AuxBitplaneAttrib.


&lt;h2&gt;Using Intermediate Stages&lt;/h2&gt;

The setup shown above works for any filter that can be computed in one stage.
However, for certain filters, you want to perform intermediate computations
before putting the output into the window.

The method &lt;code&gt;renderQuadInto&lt;/code&gt; creates a quad, and then causes that
quad to be rendered into a texture.  This is the classic intermediate
processing step for image postprocessing.  Using &lt;code&gt;renderQuadInto&lt;/code&gt;,
we can create a simple two-stage filter:

&lt;code python&gt;
manager = FilterManager(base.win, base.cam)
tex1 = Texture()
tex2 = Texture()
finalquad = manager.renderSceneInto(colortex=tex1)
interquad = manager.renderQuadInto(colortex=tex2)
interquad.setShader(Shader.load(&quot;stage1.sha&quot;))
interquad.setShaderInput(&quot;tex1&quot;, tex1)
finalquad.setShader(Shader.load(&quot;stage2.sha&quot;))
finalquad.setShaderInput(&quot;tex2&quot;, tex2)
&lt;/code&gt;

So tex1 will contain the raw, unfitered scene.  Tex2 will contain a scene
that has been filtered through stage1.sha.  The window will contain a
scene that has been filtered through both stage1.sha and stage2.sha.

The function 'renderQuadInto' accepts the keywords 'colortex', 'auxtex0', and 'auxtex1'.  It does not accept 'depthtex,' since no depth buffer is used
when rendering a quad.

&lt;h2&gt;Resolution Management&lt;/h2&gt;

Unless you specify otherwise, all textures will be the same resolution
as the window.  The FilterManager will preserve this condition - it will
automatically resize the offscreen textures if the window gets resized.

The intermediate stages created by &lt;code&gt;renderQuadInto&lt;/code&gt; can be
the same size as the window, but they can also be larger or smaller by
a constant factor.  The function takes the following keyword arguments:

* mul - The 'mul' option multiplies the size by an integer constant.

* div - The 'div' option divides the size by an integer constant.

* align - Relevant only when using the 'div' option - the window size is aligned to a specified alignment before dividing.  This is useful to minimize resampling artifacts.

&lt;h2&gt;Cleaning Up&lt;/h2&gt;

This function will cause the FilterManager to put everything back the way
it started:

&lt;code python&gt;
manager.cleanup()
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>Generating Heightfield Terrain</title>
    <ns>0</ns>
    <id>2227</id>
    <redirect title="The Heightfield Tesselator" />
      <sha1>37es23yugcdre7rwy4owbxoqgqadleg</sha1>
    <revision>
      <id>5240</id>
      <timestamp>2008-03-15T11:00:57Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>[[Generating Heightfield Terrain]] moved to [[The Heightfield Tesselator]]: To avoid confusion with geoMipTerrain(PGMM).</comment>
      <text xml:space="preserve" bytes="40">#REDIRECT [[The Heightfield Tesselator]]</text>
    </revision>
  </page>
  <page>
    <title>GeoMipTerrain</title>
    <ns>0</ns>
    <id>2232</id>
    <redirect title="Geometrical MipMapping" />
      <sha1>jbxp11lcpy3gqjk2wpbxbm1mk9jtyus</sha1>
    <revision>
      <id>5245</id>
      <timestamp>2008-03-15T11:16:48Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[Geometrical MipMapping]]</comment>
      <text xml:space="preserve" bytes="36">#REDIRECT [[Geometrical MipMapping]]</text>
    </revision>
  </page>
  <page>
    <title>Geom</title>
    <ns>0</ns>
    <id>1093</id>
      <sha1>ggu1qfxh1ctip9h0kjge9ttex22xxb1</sha1>
    <revision>
      <id>3410</id>
      <timestamp>2006-05-11T14:27:45Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="1964">The &lt;b&gt;Geom&lt;/b&gt; object collects together a [[GeomVertexData]] and one or more
[[GeomPrimitive]] objects, to make a single renderable piece of geometry.
In fact, an individual Geom is the smallest piece into which Panda
will subdivide the scene for rendering; in any given frame, either an
entire Geom is rendered, or none of it is.

Fundamentally, a Geom is very simple; it contains a pointer to a
single GeomVertexData, and a list of one or more GeomPrimitives, of
various types, as needed.  All the associated GeomPrimitives index
into the same GeomVertexData.

&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding: 5pt&quot;&gt;
Geom

&lt;table&gt;
&lt;tr&gt;&lt;td style=&quot;border: 1px solid black; background: #9197d8; padding: 5pt&quot;&gt;
GeomVertexData
&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&lt;table&gt;
&lt;tr&gt;&lt;td style=&quot;border: 1px solid black; background: #acb1ed; padding: 5pt&quot;&gt;
GeomTriangles
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style=&quot;border: 1px solid black; background: #acb1ed; padding: 5pt&quot;&gt;
GeomTriangles
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style=&quot;border: 1px solid black; background: #acb1ed; padding: 5pt&quot;&gt;
GeomTristrips
&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;

The GeomVertexData pointer may be unique to each Geom, or one
GeomVertexData may be shared among many different Geoms (each of which
might use a different subset of its vertices).  Also, although the
GeomPrimitive objects are usually unique to each Geom, they may
also be shared between different Geoms.

Although a Geom can have any number of GeomPrimitives associated with
it, all of the GeomPrimitives must be of the same fundamental
primitive type: triangles, lines, or points.  A particular Geom might
have GeomTriangles, GeomTristrips, and GeomTrifans; or it might have
GeomLines and GeomLinestrips; or it might have GeomPoints.  But no one
Geom can have primitives from two different fundamental types.  You
can call &lt;b&gt;geom.getPrimitiveType()&lt;/b&gt; to determine the fundamental
primitive type stored within a particular Geom.</text>
    </revision>
  </page>
  <page>
    <title>GeomNode</title>
    <ns>0</ns>
    <id>1767</id>
      <sha1>lzxyeiaqmphnw3mhtvp7p5e7gybfh9r</sha1>
    <revision>
      <id>3392</id>
      <timestamp>2006-05-11T13:31:19Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="2233">Finally, &lt;b&gt;GeomNode&lt;/b&gt; is the glue that connects [[Geom|Geoms]] into the scene
graph.  A GeomNode contains a list of one or more Geoms.

&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding: 5pt&quot;&gt;
GeomNode

&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;table style=&quot;border: 1px solid black; background: #acb1ed; padding: 5pt&quot;&gt;
&lt;tr&gt;&lt;td style=&quot;border: 1px solid black; background: #9197d8; padding: 5pt&quot;&gt;
Geom 
&lt;/td&gt;&lt;td style=&quot;border: 1px solid black; background: #9197d8; padding: 5pt&quot;&gt;
RenderState 
&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;&lt;table style=&quot;border: 1px solid black; background: #acb1ed; padding: 5pt&quot;&gt;
&lt;tr&gt;&lt;td style=&quot;border: 1px solid black; background: #9197d8; padding: 5pt&quot;&gt;
Geom 
&lt;/td&gt;&lt;td style=&quot;border: 1px solid black; background: #9197d8; padding: 5pt&quot;&gt;
RenderState 
&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;&lt;table style=&quot;border: 1px solid black; background: #acb1ed; padding: 5pt&quot;&gt;
&lt;tr&gt;&lt;td style=&quot;border: 1px solid black; background: #9197d8; padding: 5pt&quot;&gt;
Geom 
&lt;/td&gt;&lt;td style=&quot;border: 1px solid black; background: #9197d8; padding: 5pt&quot;&gt;
RenderState 
&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;

The GeomNode class inherits from [[The Scene Graph|PandaNode]], so a GeomNode can be
attached directly to the scene graph like any other node; and like any
node, it inherits a transform and a render state from its parents in
the scene graph.  This transform and state is then applied to each of
the node's Geoms.

Furthermore, the GeomNode stores an additional render state definition
for each Geom.  This allows each Geom within a given GeomNode to have
its own unique state; for instance, each Geom may have a different
texture applied.

When a model is loaded from an egg file, normally all the state
definitions required to render the geometry will be stored on these
per-Geom state definitions, rather than at the GeomNode level.  These
per-Geom states will override any state that is inherited from the
scene graph, unless that scene graph state has a priority higher than
the default priority of zero.  (This is why it is necessary to specify
a second parameter of 1 to the nodePath.setTexture() call, if you want
to replace a texture that was applied to a model in the egg file.)</text>
    </revision>
  </page>
  <page>
    <title>GeomPrimitive</title>
    <ns>0</ns>
    <id>1766</id>
      <sha1>br2nzcbf7zn4qrznriz0hhx33u1g6hd</sha1>
    <revision>
      <id>7437</id>
      <timestamp>2011-12-09T07:03:34Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>typo</comment>
      <text xml:space="preserve" bytes="9985">In order to use the vertices in a [[GeomVertexData]] to render anything,
Panda needs to have a &lt;b&gt;GeomPrimitive&lt;/b&gt; of some kind, which indexes into
the vertex table and tells Panda how to tie together the vertices to
make lines, triangles, or individual points.

There are several different kinds of GeomPrimitive objects, one for
each different kind of primitive.  Each GeomPrimitive object actually
stores several different individual primitives, each of which is
represented simply as a list of vertex numbers, indexing into the
vertices stored in the associated GeomVertexData.  For some
GeomPrimitive types, like GeomTriangles, all the primitives must have
a fixed number of vertex numbers (3, in the case of GeomTriangles);
for others, like GeomTristrips, each primitive can have a different
number of vertex numbers.

For instance, a GeomTriangles object containing three triangles, and a
GeomTristrips containing two triangle strips, might look like this:

&lt;center&gt;&lt;table style=&quot;border-collapse: collapse&quot;&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: center; padding-left: 5pt; padding-right: 5pt&quot;&gt;GeomTriangles&lt;/td&gt;
&lt;td style=&quot;padding-right: 64pt&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center; padding-left: 5pt; padding-right: 5pt&quot;&gt;GeomTristrips&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; text-align: center&quot;&gt;0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; text-align: center&quot;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; text-align: center&quot;&gt;1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; text-align: center&quot;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; text-align: center&quot;&gt;2&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; text-align: center&quot;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; text-align: center&quot;&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; text-align: center&quot;&gt;2&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; text-align: center&quot;&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; text-align: center&quot;&gt;1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; text-align: center&quot;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; text-align: center&quot;&gt;3&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; text-align: center&quot;&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; text-align: center&quot;&gt;0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; text-align: center&quot;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; text-align: center&quot;&gt;5&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; text-align: center&quot;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; text-align: center&quot;&gt;6&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; text-align: center&quot;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;

Note that the GeomPrimitive objects don't themselves contain any
vertex data; they only contain a list of vertex index numbers, which
is used to look up the actual vertex data in a GeomVertexData object,
stored elsewhere.

&lt;h3&gt;GeomTriangles&lt;/h3&gt;

This is the most common kind of GeomPrimitive.  This kind of primitive
stores any number of connected or unconnected triangles.  Each
triangle must have exactly three vertices, of course.  In each
triangle, the vertices should be listed in counterclockwise order, as
seen from the front of the triangle.

[[Image:GeomTriangles.png]]

&lt;h3&gt;GeomTristrips&lt;/h3&gt;

This kind of primitive stores lists of connected triangles, in a
specific arrangement called a triangle strip.  You can store any
number of individual triangle strips in a single GeomTristrips object,
and each triangle strip can have an arbitrary number of vertices (at
least three).

The first three vertices of a triangle strip define one triangle, with
the vertices listed in counterclockwise order.  Thereafter, each
additional vertex defines an additional triangle, based on the new
vertex and the preceding two vertices.  The vertices go back and
forth, defining triangles in a zigzag fashion.

[[Image:GeomTristrips.png]]

Note that the second triangle in a triangle strip is defined in
clockwise order, the third triangle is in counterclockwise order, the
fourth triangle is in clockwise order again, and so on.

On certain hardware, particularly older SGI hardware and some console games, using triangle strips is an important
optimization to reduce the number of vertices that are sent to the
graphics pipe, since most triangles (except for the first one) can be
defined with only a single vertex, rather than three vertices for each
triangle.

Modern PC graphics cards prefer to receive a group of triangle strips connected together into one very long triangle strip, by the introduction of repeated vertices and degenerate triangles.  Panda will do this automatically, but in order for this to work you should ensure that every triangle strip has an even number of vertices in it.

Furthermore, since modern PC graphics cards incorporate a short
vertex cache, they can generally render individual,
indexed triangles as fast as triangle strips; so triangle
strips are less important on PC hardware than they have been in the past.  Unless you have a good reason to use a GeomTristrips, it may be easier just to use GeomTriangles.

When loading a model from an egg file, Panda will assemble the polygons into triangle strips if it can do so without making other compromises; otherwise, it will leave the polygons as individual triangles.

&lt;h3&gt;GeomTrifans&lt;/h3&gt;

This is similar to a GeomTristrips, in that the primitive can contain
any number of triangle fans, each of which has an arbitrary number of
vertices.  Within each triangle fan, the first three vertices (in
counterclockwise order) define a triangle, and each additional vertex
defines a new triangle.  However, instead of using the preceding two
vertices to define each new triangle, a triangle fan uses the
previous vertex and the &lt;em&gt;first&lt;/em&gt; vertex, which means that all of the
resulting triangles fan out from a single point, like this:

[[Image:GeomTrifans.png]]

Like the triangle strip, a triangle fan can be an important
optimization on certain hardware.  However, its use can actually incur
a performance &lt;em&gt;penalty&lt;/em&gt; on modern PC hardware, because it is impossible to send more than one triangle fan in one batch, so you
probably shouldn't use triangle fans on a PC.  Use GeomTriangles or GeomTristrips instead.

&lt;h3&gt;GeomLines&lt;/h3&gt;

This kind of GeomPrimitive stores any number of connected or
unconnected line segments.  It is similar to a GeomTriangles, but it
draws lines instead of triangles.  Each line has exactly two vertices.

[[Image:GeomLines.png]]

By default, line segments are one pixel wide, no matter how far away
they are from the camera.  You can use
&lt;b&gt;nodePath.setRenderModeThickness()&lt;/b&gt; to change this; if you specify a
thickness greater than 1, this will make the lines render as thick
lines, the specified number of pixels wide.  However, the lines will
always be the same width in pixels, regardless of how far away from
the camera they are.

Thick lines are not supported by the DirectX
renderer; in DirectX, the thickness parameter is ignored.

&lt;h3&gt;GeomLinestrips&lt;/h3&gt;

This is the analogue of a GeomTristrips object: the GeomLinestrips
object can store any number of line strips, each of which can have any
number of vertices, at least two.  Within a particular line strip, the
first two vertices define a line segment; and thereafter, each new
vertex defines an additional line segment, connected end-to-end with
the previous line segment.  This primitive type can be used to draw a
curve approximation with many bends fairly easily.

[[Image:GeomLinestrips.png]]

&lt;h3&gt;GeomPoints&lt;/h3&gt;

This is the simplest kind of GeomPrimitive; it stores a number of
individual points.  Each point has exactly one vertex.

[[Image:GeomPoints.png]]

By default, each point is rendered as one pixel.  You can use
&lt;b&gt;nodePath.setRenderModeThickness()&lt;/b&gt; to change this; if you specify a
thickness greater than 1, this will make the points render as squares
(which always face the camera), where the vertex coordinate is the
center point of the square, and the square has the specified number of
pixels along each side.  Each point will always be the same width in
pixels, no matter how far it is from the camera.  Unlike line
segments, thick points &lt;em&gt;are&lt;/em&gt; supported by DirectX.

[[Image:GeomPointsThick.png]]

In addition to ordinary thick points, which are always the same size no matter how far they are from the camera, you can also use &lt;b&gt;nodePath.setRenderModePerspective()&lt;/b&gt; to
enable a mode in which the points scale according to their distance
from the camera.  This makes the points appear more like real objects
in the 3-D scene, and is particularly useful for rendering sprite
polygons, for instance for particle effects.  In fact, Panda's
[[Particle Renderers|SpriteParticleRenderer]] takes advantage of this render mode.  (This
perspective mode works only for points; it does not affect line
segments.)

Even though the sprite polygons are rendered as squares, remember they
are really defined with one vertex, and each vertex can only supply
one UV coordinate.  This means each sprite normally has only one UV
coordinate pair across the whole polygon.  If you want to apply a
texture to the face of each sprite, use [[Automatic Texture Coordinates|nodePath.setTexGen()]] with the
mode &lt;b&gt;TexGenAttrib.MPointSprite&lt;/b&gt;; this will generate texture coordinates
on each polygon in the range (0, 0) to (1, 1).  You can then transform
the texture coordinates, if you wish, using one of the methods like
nodePath.setTexOffset(), setTexScale(), etc.</text>
    </revision>
  </page>
  <page>
    <title>GeomVertexData</title>
    <ns>0</ns>
    <id>1094</id>
      <sha1>j5nau7u1j5d5tmvysrxr8j5gwerou01</sha1>
    <revision>
      <id>3423</id>
      <timestamp>2006-05-11T17:39:07Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="7123">The fundamental object used to store vertex information in Panda is the
&lt;b&gt;GeomVertexData&lt;/b&gt;.  This stores a list of vertices, organized
conceptually as a table, where each row of the table represents a
different vertex, and the columns of the table represent the different
kinds of per-vertex data that may be associated with each vertex.  For
instance, the following table defines four vertices, each with its own
vertex position, normal vector, color, and texture coordinate
pair:

&lt;center&gt;&lt;table style=&quot;border-collapse: collapse&quot;&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;vertex&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;normal&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;color&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;texcoord&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td style=&quot;padding-right: 5pt&quot;&gt;0&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(1, 0, 0)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0, 1)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0, 1, 1)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(1, 0)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td style=&quot;padding-right: 5pt&quot;&gt;1&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(1, 1, 0)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0, 1)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0, 1, 1)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(1, 1)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td style=&quot;padding-right: 5pt&quot;&gt;2&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 1, 0)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0, 1)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0, 1, 1)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 1)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td style=&quot;padding-right: 5pt&quot;&gt;3&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0, 0)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0, 1)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0, 1, 1)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0)&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;

Vertices are always numbered beginning at 0, and continue to the
number of rows in the table (minus 1).

Not all GeomVertexData objects will use these same four columns; some
will have fewer columns, and some will have more.  In fact, all
columns, except for &quot;vertex&quot;, which stores the vertex position, are
optional.

The order of the columns is not meaningful, but the column names are.
There are certain column names that are reserved for Panda, and
instruct Panda what the meaning of each column is.  For instance, the
vertex position column is always named &quot;vertex&quot;, and the lighting
normal column, if it is present, must be named &quot;normal&quot;.  See
[[GeomVertexFormat]] for the complete list of reserved column names.

You can define your own custom columns.  If there are any columns that
have a name that Panda does not recognize, Panda will not do anything
special with the column, but it can still send it to the graphics
card.  Of course, it is then up to you to write a [[Shader Basics|vertex shader]] that
understands what to do with the data in the column.

It is possible to break up a GeomVertexData into more than one array.
A &lt;b&gt;GeomVertexArray&lt;/b&gt; is table of vertex data that is stored in one
contiguous block of memory.  Typically, each GeomVertexData consists
of just one array; but it is also possible to distribute the data so
that some columns are stored in one array, while other columns are
stored in another array:

&lt;center&gt;&lt;table style=&quot;border-collapse: collapse&quot;&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;vertex&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;texcoord&lt;/td&gt;
&lt;td style=&quot;padding-right: 16pt&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;normal&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;color&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td style=&quot;padding-right: 5pt&quot;&gt;0&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(1, 0, 0)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(1, 0)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0, 1)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0, 1, 1)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td style=&quot;padding-right: 5pt&quot;&gt;1&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(1, 1, 0)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(1, 1)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0, 1)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0, 1, 1)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td style=&quot;padding-right: 5pt&quot;&gt;2&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 1, 0)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 1)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0, 1)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0, 1, 1)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td style=&quot;padding-right: 5pt&quot;&gt;3&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0, 0)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0)&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0, 1)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding-left: 5pt; padding-right: 5pt&quot;&gt;(0, 0, 1, 1)&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;

You might want to do this, for instance, if you have certain columns
of data that are always the same between different blocks of vertices;
you can put those columns in a separate array, and then use the same
array within multiple different GeomVertexData objects.  There is no
limit to the number of different arrays you can have within one
GeomVertexData; you can make each column a separate array if you like.
(There may be performance implications to consider.  Some graphics
drivers may work better with one block of contiguous data--one
array--while others may prefer many different arrays.  This
performance difference is likely to be small, however.)</text>
    </revision>
  </page>
  <page>
    <title>GeomVertexFormat</title>
    <ns>0</ns>
    <id>1765</id>
      <sha1>9go29xdl5ylrw3wsetqzeuu3964qx3z</sha1>
    <revision>
      <id>60514</id>
      <timestamp>2015-06-14T21:23:53Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>Add C_normal</comment>
      <text xml:space="preserve" bytes="14474">The &lt;b&gt;GeomVertexFormat&lt;/b&gt; object describes how the columns of a
GeomVertexData are ordered and named, and exactly what kind of numeric
data is stored in each column.  Every GeomVertexData has an associated
GeomVertexFormat, which describes how the data in that object is
stored.

Just as a GeomVertexData object is really a list of one or more
GeomVertexArrayData objects, a GeomVertexFormat object is a list of
one or more &lt;b&gt;GeomVertexArrayFormat&lt;/b&gt; objects, each of which
defines the structure of the corresponding array.  There will be one
GeomVertexArrayFormat object for each array in the format.  Each
GeomVertexArrayFormat, in turn, consists of a list of
&lt;b&gt;GeomVertexColumn&lt;/b&gt; objects, one for each column in the array.
For instance, the format for a GeomVertexData with six columns,
distributed over three different arrays, might look like this:

&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding: 5pt&quot;&gt;
GeomVertexFormat

&lt;table&gt;
&lt;tr&gt;&lt;td style=&quot;border: 1px solid black; background: #acb1ed; padding: 5pt&quot;&gt;
GeomVertexArrayFormat
&lt;table&gt;
&lt;tr&gt;&lt;td style=&quot;border: 1px solid black; background: #9197d8; padding: 5pt&quot;&gt;
GeomVertexColumn 
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style=&quot;border: 1px solid black; background: #9197d8; padding: 5pt&quot;&gt;
GeomVertexColumn 
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style=&quot;border: 1px solid black; background: #9197d8; padding: 5pt&quot;&gt;
GeomVertexColumn 
&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;
&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&lt;table&gt;
&lt;tr&gt;&lt;td style=&quot;border: 1px solid black; background: #acb1ed; padding: 5pt&quot;&gt;
GeomVertexArrayFormat
&lt;table&gt;
&lt;tr&gt;&lt;td style=&quot;border: 1px solid black; background: #9197d8; padding: 5pt&quot;&gt;
GeomVertexColumn 
&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;
&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&lt;table&gt;
&lt;tr&gt;&lt;td style=&quot;border: 1px solid black; background: #acb1ed; padding: 5pt&quot;&gt;
GeomVertexArrayFormat
&lt;table&gt;
&lt;tr&gt;&lt;td style=&quot;border: 1px solid black; background: #9197d8; padding: 5pt&quot;&gt;
GeomVertexColumn 
&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style=&quot;border: 1px solid black; background: #9197d8; padding: 5pt&quot;&gt;
GeomVertexColumn 
&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;
&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;

Each GeomVertexColumn has a number of properties:

&lt;center&gt;&lt;table style=&quot;border-collapse: collapse&quot;&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; style=&quot;border-top: 1px solid black; padding: 5pt&quot;&gt;&lt;b&gt;getNumComponents()&lt;/b&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; padding: 5pt&quot;&gt;
This defines the number of numeric components of the data in the
column.  For instance, the vertex position, which is typically an (X,
Y, Z) triple, has three components: X, Y, and Z.  A texture coordinate
usually has two components (U, V), but sometimes has three components
(U, V, W).
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; style=&quot;border-top: 1px solid black; padding: 5pt&quot;&gt;&lt;b&gt;getNumericType()&lt;/b&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; padding: 5pt&quot;&gt;
This defines the kind of numeric data that is stored in each
component.  It must be one of the following symbols:

&lt;table&gt;
&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;b&gt;Geom.NT_float32&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;
Each component is a 32-bit floating-point number.  This is by far the
most common type.
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;b&gt;Geom.NT_uint8&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;
Each component is a single 8-bit integer, in the range 0 - 255.
OpenGL encodes an RGBA color value as a four-component array of 8-bit
integers of this type, in R, G, B, A order.
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;b&gt;Geom.NT_uint16&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;
Each component is a single 16-bit integer, in the range 0 - 65535.
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;b&gt;Geom.NT_uint32&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;
Each component is a single 32-bit integer, in the range 0 -
4294967295.
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;b&gt;Geom.NT_packed_dcba&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;
Each component is a 32-bit word, with four 8-bit integer index values packed into
it in little-endian order (D, C, B, A), DirectX-style.  This is
usually used with a 1-component column (since each component already
has four values).  DirectX uses this format to store up to four
indexes into a transform table for encoding vertex animation.  (The
GeomVertexReader and GeomVertexWriter classes will automatically
reorder the A, B, C, D parameters you supply into DirectX's D, C, B, A
order.)
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;b&gt;Geom.NT_packed_dabc&lt;/b&gt;&lt;/td&gt; 
&lt;td&gt;
Each component
is a 32-bit word, with four 8-bit integer index values packed into it in ARGB
order (D, A, B, C).  As above, this is normally used with a
1-component column.  DirectX uses this format to represent an RGBA
color value.  (The GeomVertexReader and GeomVertexWriter classes will
automatically reorder the R, G, B, A parameters you supply into
DirectX's A, R, G, B order.)  
This should only be used with a C_color contents value.
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;b&gt;Geom.NT_packed_ufloat&lt;/b&gt;&lt;/td&gt; 
&lt;td&gt;
Each component is a 32-bit word, containing two packed unsigned 11-bit floats and one 10-bit float.  Only supported in newer OpenGL versions from Panda3D 1.10 onward.  Can only encode values between 0.0 and 64512.0.
&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt; 
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot; style=&quot;border-top: 1px solid black; padding: 5pt&quot;&gt;&lt;b&gt;getContents()&lt;/b&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; padding: 5pt&quot;&gt;

This defines, in a general way, the semantic meaning of the data in
the column.  It is used by Panda to decide how the data should be
modified when a transform matrix or texture matrix is applied; it also
controls the default value for the column data, as well as the way
data is stored and fetched from the column.

The contents specification must be one of the following symbols:

&lt;table&gt;
&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;b&gt;Geom.C_point&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;

The data represents a point in object coordinates, either in 3-D space
(if it is a 3-component value) or in 4-D homogenous space (if it is a
4-component value).  When a transform matrix is applied to the vertex
data, the data in this column is transformed as a point.  If a
4-component value is stored into a 3-component column, the fourth
component is understood to be a homogenous coordinate, and it
implicitly scales the first three.  Similarly, if a 4-component value
is read from a 3-component column, the fourth value is implicitly 1.0.

&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;b&gt;Geom.C_clip_point&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;
The data represents a point already transformed into clip coordinates;
that is, these points have already been transformed for rendering
directly.  Panda will not transform the vertices again during
rendering.  Points in clip coordinates should be in 4-D homogeneous
space, and thus usually have four components.
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;b&gt;Geom.C_normal&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;
The data represents a 3-D normal vector, perpendicular to the surface.
This is different from C_vector in that it preserves this orthogonality
when non-uniform scales are applied.  It also makes sure that a unit
length vector stays normalized when a scale is applied.
New in 1.9.1; C_vector is used in earlier releases.
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;b&gt;Geom.C_vector&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;
The data represents a generic 3-D vector, such as a tangent, or
binormal, in object coordinates.  When a transform matrix is applied
to the vertex data, the data in this column is transformed as a vector
(that is, ignoring the matrix's translation component).
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;b&gt;Geom.C_texcoord&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;
The data represents a texture coordinate, either 2-D or 3-D.
When a texture matrix (not a transform matrix) is applied to the
vertex data, it transforms the data in this column, as a point.
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;b&gt;Geom.C_color&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;
The data represents an RGBA color value.  If a floating-point value is
used to read or write into an integer color component, it is
automatically scaled from 0.0 .. 1.0 into the full integer range.
Also, the default value of a color column is (1, 1, 1, 1), as opposed
to any other column type, whose default value is 0.
Must have 3 or 4 components.
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;b&gt;Geom.C_index&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;
The data represents an integer index into some table.
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;b&gt;Geom.C_morph_delta&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;
The data represents an offset value that will be applied to some other
column during animation.
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;b&gt;Geom.C_other&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;
The data has some other, custom meaning; do not attempt to transform
it.
&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td valign=&quot;top&quot; style=&quot;border-top: 1px solid black; padding: 5pt&quot;&gt;&lt;b&gt;getName()&lt;/b&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; padding: 5pt&quot;&gt;
The column name is the most important single piece of information to
Panda.  The column name tells Panda the specific meaning of the data
in the column.  The name is also a unique handle to the column; within
a given GeomVertexFormat, there may not be two different columns with
the same name.

There are a number of column names that have special meaning to Panda:

&lt;table&gt;
&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;b&gt;vertex&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;
The position in space of each vertex, usually given as an (x, y, z)
triple in 3-D coordinates.  This is the only mandatory column for
rendering geometry; all other columns are optional.  The vertex is
usually Geom.NTFloat32, Geom.CPoint, 3 components.

&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;b&gt;normal&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;
The surface normal at each vertex.  This is used to compute the
visible effects of lighting; it is not related to the collision
system, which has its own mechanism for determining the surface
normal.  You should have a normal column if you intend to enable
lighting; if this column is not present, the object may look strange
in the presence of lighting.  The normal should always be
Geom.NTFloat32, Geom.CVertex, 3 components.

&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;b&gt;texcoord&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;
The U, V texture coordinate pair at each vertex, for the default
coordinate set.  This column is necessary in order to apply a texture
to the geometry (unless you use a TexGenAttrib).  It is usually a 2-D
coordinate pair, but sometimes, when you are using 3-d textures or
cube maps, you will need a 3-D U, V, W coordinate triple.  The
texcoord should be Geom.NTFloat32, Geom.CTexcoord, 2 or 3 components.

&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;b&gt;texcoord.&lt;i&gt;foo&lt;/i&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;
This is the U, V texture coordinate pair for the texture coordinate
set with the name &lt;i&gt;&quot;foo&quot;&lt;/i&gt; (where &lt;i&gt;foo&lt;/i&gt; is any arbitrary
name).  It is only necessary if you need to have multiple different
texture coordinate sets on a piece of geometry, in order to apply
multitexturing.  As with texcoord, above, it may be a 2-d or a 3-d
value.

&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;b&gt;tangent&lt;br&gt;binormal&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;
These two columns work together, along with the normal column, to
implement normal maps (bump maps).  They define the normal map space
at each vertex.  Like a normal, these should be Geom.NTFloat32,
Geom.CVertex, 3 components.

&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;b&gt;tangent.&lt;i&gt;foo&lt;/i&gt;&lt;br&gt;binormal.&lt;i&gt;foo&lt;/i&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;
These column names define a tangent and binormal for the texture
coordinate set with the name &lt;i&gt;&quot;foo&quot;&lt;/i&gt;.

&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;b&gt;color&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;
This defines an RGBA color value.  If this column is not present, the
default vertex color is white (unless it is overridden with a
nodePath.setColor() call).  Internally, OpenGL expects the color
format to be Geom.NTUint8 (or Geom.NTFloat32), Geom.CColor, 4
components, while DirectX expects the color to be Geom.NTPackedDabc,
Geom.CColor, 1 component.  In fact, you may use either format
regardless of your current rendering backend, and Panda will
automatically convert the column as necessary.

&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;b&gt;rotate&lt;br&gt;size&lt;br&gt;aspect_ratio&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;
These three columns are used when rendering sprites (that is,
GeomPoints with nodePath.setRenderModeThickness() in effect).  If
present, they control the rotation counterclockwise in degrees, the
per-vertex thickness, and the aspect ratio of the square,
respectively.  Each of these should be Geom.NTFloat32, Geom.COther, 1
component.

&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;
&lt;td colspan=&quot;2&quot; style=&quot;padding-top: 10pt; padding-bottom: 5pt&quot;&gt;
The remaining column names have meaning only to define vertex
animation, for instance to implement Actors.  Although these column
names are documented below, vertex animation is an advanced feature
of the Panda vertex representation; we recommend you let Panda take
care of setting up the vertex animation tables, rather than attempting
to create them yourself.
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;b&gt;transform_blend&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;
This is used to control vertex assignment to one or more animated
transform spaces.  The value in this column is an integer index into
the TransformBlendTable that is associated with the GeomVertexData;
each entry in the TransformBlendTable defines a different weighted
combination of transform spaces, so by indexing into this table, you
can associate each vertex with a different weighted combination of
transform spaces.

&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;b&gt;transform_weight&lt;br&gt;transform_index&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;
These two columns work together, in a manner similar to
transform_blend, but they index into the TransformTable associated
with the GeomVertexData, instead of the TransformBlendTable.  This is
particularly suited for sending vertices to OpenGL or DirectX to do
the animation, rather than performing the animation on the CPU.

&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;b&gt;&lt;i&gt;column&lt;/i&gt;.morph.&lt;i&gt;slider&lt;/i&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;
Columns with names of this form define a floating-point morph offset
that should be scaled by the value of the morph slider named
&lt;i&gt;&quot;slider&quot;&lt;/i&gt;, and then added to the column named &lt;i&gt;&quot;column&quot;&lt;/i&gt;
(where &lt;i&gt;slider&lt;/i&gt; and &lt;i&gt;column&lt;/i&gt; are arbitrary names).  This is
used during vertex animation on the CPU.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;/table&gt;

A column may have any name (though each name must be unique within a given GeomVertexFormat).  If there are additional columns with
names other than those in the above table, Panda will not do anything
special with the columns, but it will send the vertex data to any
vertex shader that requests that data by name, using the vtx_&lt;i&gt;columnname&lt;/i&gt; parameter name.  See [[List of Possible Shader Inputs]].

There are also additional properties associated with each
GeomVertexColumn that determine its exact offset and byte-alignment
within each row of the array, but normally you do not need to worry
about these, unless you are designing a GeomVertexFormat that matches
some already-existing block of data.  See the auto-generated API
specification for more details.</text>
    </revision>
  </page>
  <page>
    <title>GeomVertexWriter</title>
    <ns>0</ns>
    <id>1095</id>
      <sha1>648kvs0mz5qcljhstgb9qpgcpwmra8e</sha1>
    <revision>
      <id>2376</id>
      <timestamp>2005-05-03T08:07:08Z</timestamp>
      <contributor>
        <username>Hughperkins</username>
        <id>10</id>
      </contributor>
      <comment>First created</comment>
      <text xml:space="preserve" bytes="2087">== Summary ==

A GeomVertexWriter is used to write to a [[GeomVertexData]] object, which contains data on the actual position of vertices used within a [[Geom]].

== GeomVertexWriter ==

There are two lines of GeomVertexWriter: with or without a qp prefix.  The qp prefixed versions are the current versions, and will be described here.

The qpGeomVertexWriter class provides a high-level interface for quickly writing a sequence of numeric values from a vertex table. 

This object can be used both to replace existing vertices in the table, or to extend the table with new vertices.  The set_data*() family of methods can only be used to replace existing data; it is an error to allow these to run past the end of the data.  The add_data*() family of methods, on the other hand, can be used to replace existing data or add new data; if you call set_row() into the middle of existing data the add_data*() methods will behave like the corresponding set_data*(), but if they run past the end of existing data they will quietly add new vertices.

Like GeomVertexReader, the writer is particularly optimized for writing a single column of data values for a series of vertices, without changing columns between each number.  Although you can also use one GeomVertexWriter to write across the columns if it is convenient, by calling set_column() repeatedly at each vertex, it is faster to write down the columns, and to use a different GeomVertexWriter for each column.

Note that, like a GeomVertexReader, a GeomVertexWriter does not keep a reference count to the actual vertex data buffer.  This means that it is important not to keep a GeomVertexWriter object around over a long period of time in which the data buffer is likely to be deallocated; it is intended for making a quick pass over the data in one session.

It also means that you should create any GeomVertexWriters *before* creating GeomVertexReaders on the same data, since the writer itself might cause the vertex buffer to be deallocated.  Better yet, use a GeomVertexRewriter if you are going to create both of them anyway.</text>
    </revision>
  </page>
  <page>
    <title>Geometrical MipMapping</title>
    <ns>0</ns>
    <id>2231</id>
      <sha1>99b18mpa46bee9e8i9yny0uhnwvra5u</sha1>
    <revision>
      <id>7584</id>
      <timestamp>2012-02-12T21:21:54Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>fix typo</comment>
      <text xml:space="preserve" bytes="8592">The GeoMipTerrain generates terrain geometry from a heightfield image, but it does more than any bruteforce terrain generator: the GeoMipTerrain divides the terrain into multiple chunks, where each of them can have a different level of detail.
The advantage of this approach is that, when the focal point (the place where the terrain has the highest quality, probably the camera) moves, not the entire terrain has to be regenerated to match the correct detail level, like the [[HeightfieldTesselator]], but only the chunks that have a different LOD can be regenerated. Also, it improves culling and collision detection.

&lt;h3&gt;Basic Usage&lt;/h3&gt;
Using the GeoMipTerrain is quite easy, it does not require to write much complicated calculations:

[python]&lt;code python&gt;
terrain = GeoMipTerrain(&quot;mySimpleTerrain&quot;)
terrain.setHeightfield(&quot;yourHeightField.png&quot;)
#terrain.setBruteforce(True)
terrain.getRoot().reparentTo(render)
terrain.generate()
&lt;/code&gt;[/python]

[cxx]&lt;code cxx&gt;
GeoMipTerrain *terrain;
terrain =  new GeoMipTerrain(&quot;mySimpleTerrain&quot;);
terrain-&gt;set_heightfield(Filename(&quot;maps/yourHeightField.png&quot;));
terrain-&gt;set_bruteforce(true);
terrain-&gt;get_root().reparent_to(window-&gt;get_render()); 
terrain-&gt;generate();
&lt;/code&gt;[/cxx]

First, the code creates a GeoMipTerrain instance. The 
&lt;code&gt;[func]setHeightfield[/func]()&lt;/code&gt;call loads in a heightfield image.
Preferably this is a size of a power of two plus one (like 129, 257, 513, 1025, etc.), but if it is not, the GeoMipTerrain will automatically scale it up to the nearest correct size (which is quite slow). 
&lt;code&gt;[func]setHeightfield[/func]()&lt;/code&gt; can take a [[PNMImage]],[[Texture]] or [[Filename]] instance.


The &lt;code&gt;[func]setBruteforce[/func](True)&lt;/code&gt; call sets the terrain to bruteforce rendering -- this means that the terrain is created at the highest quality (the lowest detail level), and LOD is not applied. In the next section we will explain how to set a LOD level and a Focal Point.
The &lt;code&gt;[func]getRoot[/func]()&lt;/code&gt; call returns the NodePath of the terrain. It is then reparented to &lt;code&gt;render&lt;/code&gt; to be a part of the scene graph. You can apply [[Common State Changes]] to this NodePath.
Finally, the &lt;code&gt;[func]generate[/func]()&lt;/code&gt; call generates the terrain geometry. Note that if the terrain is still quite flat, you will have to scale the terrain NodePath in the Z direction, because by default, the Z positions are between 0 and 1. To fix this, scale the terrain up in the Z direction (before generating it, otherwise it might require you to regenerate it):
[python]&lt;code python&gt;terrain.getRoot().setSz(100)&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;terrain-&gt;get_root().set_sz(100);&lt;/code&gt;[/cxx]

&lt;h3&gt;Dynamic Terrains&lt;/h3&gt;
This code shows a dynamically updated terrain with LOD:
[python]
&lt;code python&gt;
# Set up the GeoMipTerrain
terrain = GeoMipTerrain(&quot;myDynamicTerrain&quot;)
terrain.setHeightfield(&quot;yourHeightField.png&quot;)

# Set terrain properties
terrain.setBlockSize(32)
terrain.setNear(40)
terrain.setFar(100)
terrain.setFocalPoint(base.camera)

# Store the root NodePath for convenience
root = terrain.getRoot()
root.reparentTo(render)
root.setSz(100)

# Generate it.
terrain.generate()
# Add a task to keep updating the terrain
def updateTask(task):
  terrain.update()
  return task.cont
taskMgr.add(updateTask, &quot;update&quot;)
&lt;/code&gt;
[/python]

[cxx]
&lt;code cxx&gt;
// Set up the GeoMipTerrain
GeoMipTerrain *terrain;
terrain =  new GeoMipTerrain(&quot;myDynamicTerrain&quot;);
terrain-&gt;set_heightfield(Filename(&quot;maps/yourHeightField.png&quot;));

// Set terrain properties
terrain-&gt;set_block_size(32);
terrain-&gt;set_near(40);
terrain-&gt;set_far(100);
terrain-&gt;set_focal_point(camera);

// Store the root NodePath for convenience
NodePath root = terrain-&gt;get_root();
root.reparent_to(window-&gt;get_render()); 
root.set_sz(100);

// Generate it.
terrain-&gt;generate();

// Add a task to keep updating the terrain
taskMgr-&gt;add(new GenericAsyncTask(&quot;Updates terrain&quot;, &amp;UpdateTerrain, (void*) NULL));

// And the task, outside main:
AsyncTask::DoneStatus UpdateTerrain(GenericAsyncTask* task, void* data) 
{
 terrain-&gt;update();
 return AsyncTask::DS_cont;
}
&lt;/code&gt;
[/cxx]

This code shows a dynamically updated terrain, which is updated every frame with the camera as focal point.
You see that a few functions are called: The blocksize is set to 32. This means that GeoMipTerrain has to divide the terrain in chunks of 32x32 quads. Then, the near and far distances are set. The Near distance is the distance from the focal point to where the terrain starts to decrease in quality. The far clip is the distance where the terrain is lowest quality.
Also, the focal point is set to the Camera's NodePath; you can specify any NodePath you want, but also a Point2 or Point3. If you specify the latter, please note that only the X and Y positions are used to calculate the distance; the Z position is disregarded.
Note that you need to experiment with those values to get a good quality terrain while still maintaining a good performance.

Next, for convenience, the terrain root is stored in a separate variable, which is scaled and placed in the scene graph. The terrain is then initially generated, and a task is created which calls &lt;code&gt;[func]terrain.update[/func]()&lt;/code&gt; every frame. This function calculates the new LOD levels based on the movement of the focal point and updates the chunks which have got a new LOD level.

&lt;h3&gt;Advanced Control&lt;/h3&gt;
The GeoMipTerrain provides some advanced features over the terrain:

&lt;b&gt;Minimum Level&lt;/b&gt;&lt;br&gt;
You can specify a minimum LOD level to GeoMipTerrain. You can do this if you find the terrain a bit too high quality near the focal point, and this could waste your performance. If you set a minimum LOD level, you can prevent this and force the chunks to have a minimum level of detail:
[python]&lt;code python&gt;terrain.setMinLevel(2)&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;terrain-&gt;set_min_level(2);&lt;/code&gt;[/cxx]
If you make the value higher, it will decrease the quality level near the focal point.

&lt;b&gt;Automatic Flattening&lt;/b&gt;&lt;br&gt;
Since flattening the terrain root might interfere with the updating system, GeoMipTerrain provides an auto-flattening function, which can be really useful if you have [http://panda3d.org/wiki/index.php/Performance_Issue:_Too_Many_Meshes too many meshes] in your scene. This function calls one of NodePath's flattening functions every time the terrain is regenerated, and each time before the chunks are modified the terrain is restored from a backup node:
[python]&lt;code python&gt;terrain.setAutoFlatten(GeoMipTerrain.AFMStrong)&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;terrain-&gt;set_auto_flatten(GeoMipTerrain::AFMStrong);&lt;/code&gt;[/cxx]
There are multiple options: AFMStrong for &lt;code&gt;[func]flattenStrong[/func]()&lt;/code&gt;, AFMMedium for &lt;code&gt;[func]flattenMedium[/func]()&lt;/code&gt;, AFMLight for &lt;code&gt;[func]flattenLight[/func]()&lt;/code&gt;, and AFMOff for no flattening at all. After setting the AutoFlattenMode, GeoMipTerrain will automatically take care of it at the next &lt;code&gt;[func]update[/func]()&lt;/code&gt; call.

&lt;h3&gt;Notes&lt;/h3&gt;
* For a full function overview, see the [python][http://www.panda3d.org/reference/python/classpanda3d_1_1core_1_1GeoMipTerrain.php API page][/python][cxx][http://www.panda3d.org/reference/cxx/class_geo_mip_terrain.php API page][/cxx].
* The near and far settings are only available in Panda3D versions 1.6.0 and higher. For older versions, use &lt;code&gt;[func]setFactor[/func]()&lt;/code&gt;. This function is still available for backward compatibility.
* The GeoMipTerrain generates texture coordinates between 0 and 1, making the texture stretched over the entire terrain. If you are using a shader, please do &lt;b&gt;not&lt;/b&gt; directly base the coordinates on the &lt;code&gt;vtx_position&lt;/code&gt;, because since the terrain can have multiple chunks the vertex position is relative to the chunk. Instead, base your shader calculations on the &lt;code&gt;vtx_texcoord0&lt;/code&gt; generated by the GeoMipTerrain.
* The GeoMipTerrain class implements part of the GeoMipMapping algorithm, described in [http://www.flipcode.com/archives/article_geomipmaps.pdf this paper] by Willem H. de Boer.
* In Panda3D versions 1.5.1 and 1.5.2 there is a bug in the bruteforce generator, which might cause your application to crash. It has been fixed in 1.5.3, please upgrade your Panda3D version if you are experiencing this crash.
* PGMM / GeoMipTerrain is a community-contributed algorithm that is included in Panda3D from version 1.5.1. If you are using an older version of Panda3D, you can download a limited version at [http://panda3d.org/phpbb2/viewtopic.php?t=3028 the original forum topic].</text>
    </revision>
  </page>
  <page>
    <title>Getting Started</title>
    <ns>0</ns>
    <id>2580</id>
      <sha1>lujee2kx87d42zwdcfaf0za8ve4obvw</sha1>
    <revision>
      <id>7695</id>
      <timestamp>2012-03-09T10:19:06Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="4397">&lt;b&gt;The basics :&lt;/b&gt;

&lt;b&gt;Theory :&lt;/b&gt;

The PandAI  library has been built upon the design pattern of composition.

There exists a main AIWorld Class which governs all updates of any AICharacters added to it. Each AICharacter has its own AIBehavior object which keeps track of all position and rotation updates based on the type of AI which is acting on that character.

So in short :  AIWorld -&gt; AICharacter -&gt; AIBehavior

Each AIBehavior object has the functionality to implement all the steering behaviors and pathfinding behaviors. So once you get a reference to this object from the AICharacter, it should give you the ability to call the respective functions.

&lt;b&gt;Implementation :&lt;/b&gt;

Following are the steps to get the basics of PandAI working. Don't worry if you can't understand some of them. 

&lt;b&gt;Step 1 :&lt;/b&gt;

To use our AI library into your game you need to import PandAI into your game code via :  
&lt;code python&gt;
from panda3d.ai import *
&lt;/code&gt;

&lt;b&gt;Step 2 :&lt;/b&gt;

Create an object of the AIWorld class which defines your AI in your game world. 

&lt;b&gt;Step 3 :&lt;/b&gt;   

Setup a task which runs continuously which keeps calling the 'Update()' function for your previously created AIWorld object 

&lt;b&gt;Step 4 :&lt;/b&gt;   

To test this out let us also implement a simple call to the 'seek' behavior function in PandAI. To do this we need two objects: A seeker and a target. For this example, we will use Ralph (seeker) and an arrow model (target).

&lt;b&gt;Step 5 :&lt;/b&gt;   

Create an &lt;b&gt;'AICharacter'&lt;/b&gt; object and attach it to your AIWorld class (previously created). The AICharacter constructor looks for a NodePath, this can be a Model or an Actor or even an Empty NodePath.

&lt;b&gt;Step 6 :&lt;/b&gt;

Get a reference to the AIBehaviors object of your previously created AICharacter class via the &lt;b&gt;'getAiBehaviors'&lt;/b&gt; function().

&lt;b&gt;Step 7 :&lt;/b&gt;

Call the &lt;b&gt;seek&lt;/b&gt; function on your AIBehaviors reference (previously created). The seek function takes a NodePath or a Vector3 position to seek to.

&lt;b&gt;Step 8 :&lt;/b&gt;

Start your AIWorld update task which you created earlier.

&lt;b&gt;Step 9 :&lt;/b&gt;

Watch how your awesome seek function works !

&lt;b&gt;The actual code :&lt;/b&gt;

&lt;code python&gt;
import direct.directbase.DirectStart
from panda3d.core import *
from direct.showbase.DirectObject import DirectObject
from direct.task import Task
from direct.actor.Actor import Actor
#for Pandai
from panda3d.ai import *

class World(DirectObject):

    def __init__(self):
        base.disableMouse()
        base.cam.setPosHpr(0,0,55,0,-90,0)
        
        self.loadModels()
        self.setAI()
       
    def loadModels(self):
        # Seeker
        ralphStartPos = Vec3(-10, 0, 0)
        self.seeker = Actor(&quot;models/ralph&quot;,
                                 {&quot;run&quot;:&quot;models/ralph-run&quot;})
        self.seeker.reparentTo(render)
        self.seeker.setScale(0.5)
        self.seeker.setPos(ralphStartPos)
        # Target
        self.target = loader.loadModel(&quot;models/arrow&quot;)
        self.target.setColor(1,0,0)
        self.target.setPos(5,0,0)
        self.target.setScale(1)
        self.target.reparentTo(render)
      
    def setAI(self):
        #Creating AI World
        self.AIworld = AIWorld(render)
 
        self.AIchar = AICharacter(&quot;seeker&quot;,self.seeker, 100, 0.05, 5)
        self.AIworld.addAiChar(self.AIchar)
        self.AIbehaviors = self.AIchar.getAiBehaviors()
        
        self.AIbehaviors.seek(self.target)
        self.seeker.loop(&quot;run&quot;)

        #AI World update        
        taskMgr.add(self.AIUpdate,&quot;AIUpdate&quot;)
        
    #to update the AIWorld    
    def AIUpdate(self,task):
        self.AIworld.update()            
        return Task.cont
 
w = World()
run()
&lt;/code&gt;

* &lt;b&gt;Note :&lt;/b&gt;  It doesn't matter where your seek is first called (ie. before the AIWorld update or after) it should still work as soon as the Update starts processing.

* &lt;b&gt;Note :&lt;/b&gt;  This above example is only for seek but if you go to each of the pages, a separate example is provided showing you each AI individually.


-----
&lt;b&gt; If you want to get a working demo of this tutorial, please visit :

https://sites.google.com/site/etcpandai/documentation/getting-started/PandAIBasicTutorial.zip?attredirects=0&amp;d=1
&lt;/b&gt;
-----


&lt;b&gt;Next Steps :&lt;/b&gt;

Now that you have a basic working program of PandAI, you should proceed to the Steering Behaviors page and gain more knowledge of the system from there.</text>
    </revision>
  </page>
  <page>
    <title>Getting Started on OSX</title>
    <ns>0</ns>
    <id>2311</id>
      <sha1>lqcl9bur6a1svb2igh8dwqn1ob3dz4z</sha1>
    <revision>
      <id>7400</id>
      <timestamp>2011-12-03T16:41:04Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>typo</comment>
      <text xml:space="preserve" bytes="3634">Congratulations! You've installed Panda3D on your machine. Now, what next?

First of all, you should [[General Preparation|prepare]] by learning Python. You can also use C++ with Panda3D, but since most of its users use Python, and it is a very easy language to master, Python is the most recommended choice.

Then, you can dive into the [[Main Page|Manual]] and try the Hello World samples. The manual is a great resource for learning Panda3D and getting in-depth information about various subjects. However, for more concrete examples, you can dive into the [[Sample Programs]], which ship with the Panda3D build.


&lt;h1&gt;Running the Sample Programs&lt;/h1&gt;
Panda3D comes with a handful of Sample Programs, which are stored in /Developer/Examples/Panda3D (for Panda3D 1.6.x, they are stored in /Applications/Panda3D/1.6.0/samples). After opening a terminal window navigate to the directory of the sample program you want to see.

Then, you can run the program by using the 'ppython' command: (For Panda3D 1.6.x, use '/usr/bin/python' rather than 'ppython')
&lt;pre class=&quot;codeblock&quot;&gt;ppython Tut-Asteroids.py&lt;/pre&gt;


&lt;h1&gt;Troubleshooting Common Issues&lt;/h1&gt;
&lt;b&gt;What to do if you see the Error Message:&lt;/b&gt;
&lt;i&gt;&lt;br&gt;dyld: Library not loaded: @executable_path/../Library/Frameworks/Cg.framework/Cg
&lt;br&gt;Referenced from: /Applications/Panda3D/1.6.0/lib/libpanda.dylib
&lt;br&gt;Reason: image not found
&lt;br&gt;Trace/BPT trap&lt;/i&gt;

This means you need to download and install the [http://developer.nvidia.com/object/cg_toolkit.html#downloads NVIDIA Cg Toolkit] before you will be able to use Panda3D.

&lt;b&gt;What to do if you see the Error Message:&lt;/b&gt;
&lt;i&gt;&lt;br&gt;Fatal Python error: Interpreter not initialized (version mismatch?)
&lt;br&gt;Abort trap&lt;/i&gt;

You are running a version of Python that is not compatible with the version Panda3D has been compiled with. However, OSX always ships with a system version of Python that should be compatible. The fact that it doesn't work simply indicating that the wrong copy of python is ran.

You need to make sure you are running Apple's version of Python. Fortunately, Panda3D ships with a file called 'ppython' that is a mere symlink to /usr/bin/python, where Apple's copy of Python resides. So, instead of 'python', you should call 'ppython'.

&lt;b&gt;What to do if you see the Error Message:&lt;/b&gt;
&lt;i&gt;&lt;br&gt;Warning: DirectNotify: category 'Interval' already exists&lt;/i&gt;

This error is of no consequence.  Ignore it.

&lt;b&gt;What to do if you see the Error Message:&lt;/b&gt;
&lt;i&gt;
&lt;br&gt;display(error): The application requested hardware acceleration, but your OpenGL
&lt;br&gt;display(error): driver, GDI Generic, only supports software rendering.
&lt;br&gt;display(error): You need to install a hardware-accelerated OpenGL driver, or,
&lt;br&gt;display(error): if you actually *want* to use a software renderer, then
&lt;br&gt;display(error): alter the hardware/software configuration in your Config.prc file.
&lt;br&gt;display(error): Window wouldn't open; abandoning window.
&lt;/i&gt;

This error is fairly self-explanatory: it means your video drivers are inadequate. Obtain updated drivers by running Software Update or, if you have installed a 3rd party video card, installing new drivers from the video card vendor.

Alternatively, you can use Panda3D in software rendering mode, You will not be able to use fancy shaders and it will be much slower than in hardware mode. However, if you still want to use it, you need to edit your Config.prc file (which can be found in the &quot;etc&quot; dir of your Panda3D installation) and find this line:
&lt;pre class=&quot;codeblock&quot;&gt;load-display pandagl&lt;/pre&gt;
Replace that line with this instead:
&lt;pre class=&quot;codeblock&quot;&gt;load-display tinydisplay&lt;/pre&gt;</text>
    </revision>
  </page>
  <page>
    <title>Getting Started with your Code Editor</title>
    <ns>0</ns>
    <id>2389</id>
    <redirect title="Getting Started with your Development Environment" />
      <sha1>6knzlwzvakn20dcans7drehrmd207x6</sha1>
    <revision>
      <id>6190</id>
      <timestamp>2009-09-29T10:41:41Z</timestamp>
      <contributor>
        <username>Gogg</username>
        <id>389</id>
      </contributor>
      <comment>[[Getting Started with your Code Editor]] moved to [[Getting Started with your Development Environment]]</comment>
      <text xml:space="preserve" bytes="63">#REDIRECT [[Getting Started with your Development Environment]]</text>
    </revision>
  </page>
  <page>
    <title>Getting Started with your Development Environment</title>
    <ns>0</ns>
    <id>1744</id>
      <sha1>af92xtj85eszgc1i3jmssnx3i9td3qv</sha1>
    <revision>
      <id>7856</id>
      <timestamp>2012-12-13T08:21:48Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>fix geany link, add ST2</comment>
      <text xml:space="preserve" bytes="6452">[cxx]
&lt;h2&gt;Setting up your IDE&lt;/h2&gt;

This section explains how to set up your environment in order to build a Panda3D game written in C++.

On Windows, compiling using g++ will not work. It is however possible to compile your Panda3D project using the MSVC (Microsoft Visual Studio 2008 C++) compiler.  The following page describes how to do that:
* [[How_to_build_a_CXX_Panda3D_game_using_Microsoft_Visual_Studio_2008|Windows MSVC version]]

On Linux and Mac OS X you can compile using the g++ compiler. The following pages describes how to do that:
* [[How to build a CXX Panda3D game on Linux|Linux version]]
* [[How to compile a CXX Panda3D program on Mac OS X|Mac OS X version]]

[/cxx]

[python]&lt;h2&gt;Creating a Program: General Outline&lt;/h2&gt;

Panda3D is a library of subroutines; not an application. This means that
unlike all the other programs on your computer, you won’t find any program
icons or shortcuts to start it.  Instead, you must use a
programmer's editor to create your program.  The basic steps are:

* Create an empty directory for your program.
* Obtain a programmer's editor.
* Start the programmer's editor.
* Type in a program into the editor.
* Save the program in your program's directory.
* Start a command prompt.
* Change directory to your program's directory.
* Run the program using 'python.exe'

These steps will be explained in more detail below.  The detailed descriptions are for windows users and cover only the PyPE editor.  Linux users, you're on your own.

Possible programmer's editors are:

Windows:
* [http://pype.sf.net/ PyPE]
* [http://www.pspad.com/ PSPad]
* [http://www.geany.org/ Geany]
* [http://www.crimsoneditor.com/ Crimson Editor]
* [http://notepad-plus.sf.net/ Notepad++]
* [http://pythonide.blogspot.com/ Stani's Python Editor]
* [http://www.eclipse.org Eclipse] in combination with [http://pydev.sourceforge.net/ PyDev]
* [http://www.sublimetext.com/ Sublime Text]

Linux:
* [http://www.geany.org/ Geany]
* [http://pythonide.blogspot.com/ Stani's Python Editor]
* [http://www.eclipse.org Eclipse] in combination with [http://pydev.sourceforge.net/ PyDev]
* [http://www.die-offenbachs.de/eric/index.html Eric Python IDE]
* [http://kate-editor.org/ Kate] (KDE only)
* [http://scribes.sourceforge.net/ Scribes] or [http://www.gnome.org/projects/gedit/ gedit] in combination with [http://ipython.scipy.org/moin/ IPython]
* [http://www.sublimetext.com/ Sublime Text]

The next part of this page will only explain usage with PyPE.

&lt;h2&gt;Creating a Directory for your Program&lt;/h2&gt;

So, you now need to create a place where you can save all your scripts. Panda3D  can run a script from anywhere on your computer, but it looks for models and other assets in the folder that it is run from. If those assets aren’t present, then you’ll get an error message when you try to run it. So, I believe that the easiest thing for the beginner to do, is to make a new folder in the main Panda3D directory itself (which already contains all the models and other assets that you’ll need).

To do this, click your computers ‘Start’ button, then ‘My Computer’. 

[[Image:pic018kw.jpg]]

Then double-click ‘Local Disk (C)’ (if the contents of this drive are hidden, just click ‘Show the contents of this folder’). Now find the Panda3D folder and double-click on it to open it.

On the top menu bar click ‘File &gt; New &gt; Folder’. This will create a new folder in the Panda3D directory, backspace out the name and type a new name for it (I called mine mystuff).

&lt;h2&gt;Obtaining a Programmer's Editor&lt;/h2&gt;

One of python’s strong points, is that you don’t need a compiler to write your scripts, however, you do need a good editor.  Do not try to use Windows Notepad or Wordpad: they are not designed for this.  Instead, you will need a programmer's editor. A well-known python editor is PyPE (which is completely free and makes writing python scripts a whole lot easier). You can download it from this location:

http://sourceforge.net/projects/pype/

If you're using Windows, download the PyPE-2.8-win-ansi.zip (as of writing this was the latest version). You don't need to install this program, you just download and unzip it somewhere, then open the unzipped folder and double-click on the PyPE icon to run it (or right-click on the icon and send it to the desktop as a shortcut, then simply run it by double-clicking the icon on your desktop).

[[Image:pic036qj.jpg]]

&lt;h2&gt;Typing your Program into the Editor&lt;/h2&gt;

Open PyPE, then click ‘File &gt; New’ on the top menu bar to open a new work environment.  Now type the following code (or just copy and paste it):

&lt;code python&gt;
import direct.directbase.DirectStart
run()
&lt;/code&gt;

Notice that PyPE automatically highlights certain words and numbers the lines for you. This is a very nice feature which makes finding errors much easier. 

[[Image:pic048lg.jpg]]

You’ve just written your first Panda3D script. It’s not much, but those few lines of code tell Panda3D to start. But before you can run this script, you must save it. So click ‘File &gt; Save As’ on the top menu bar and a new window should open.

[[Image:pic053gq.jpg]]

At the top of this new window there is a ‘Save in:’ text box, which is pointing to ‘PyPE-2.8-win-ansi’, you DON’T want to save your script there, so click the little down arrow beside the text box, then scroll down the list and click ‘Local Disk (C)’, then double-click on the Panda3D folder to open it.  Find the ‘mystuff’ folder that we created earlier and double-click on it to open it. 

[[Image:pic069he.jpg]]

Next, type a name for your script in the ‘File name:’ text box. I called mine myscript.py (make sure you put .py on the end of the name). Then click the ‘Save’ button. 

[[Image:pic073oi.jpg]]

You can now close PyPE.



&lt;h2&gt;Using NetBeans IDE&lt;/h2&gt;
Download NetBeans IDE and install it.
Start NetBeans.
Select 'Tools'-&gt;'Python platforms'.
Under Platforms (at the left of the screen) select 'New'
A new browser window pops up, asking for an executable.
Browse to your panda folder, for example C:\Panda3D-1.6.2\python
and select python.exe

Now you have created a new platform you can use.

Now, create a new empty Python project.
Then, under Projects, right click your project and select 'Properties'
Under 'Categories', select Python.
At the right, 'Python platform'-&gt; select your new platform.

Now you should be ready to compile your panda examples.



[/python]</text>
    </revision>
  </page>
  <page>
    <title>Graphics Buffers and Windows</title>
    <ns>0</ns>
    <id>1150</id>
      <sha1>2trjpzw40cgij4xkp50mz8b10phftr1</sha1>
    <revision>
      <id>7727</id>
      <timestamp>2012-03-10T07:02:27Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="4852">We'll now describe in detail what functions are specific to buffers and windows in Panda.

&lt;h2&gt;GraphicsBuffer and ParasiteBuffer&lt;/h2&gt;

Use these if you want to do off-screen rendering. You must pass &lt;code&gt;True&lt;/code&gt; when you [[The Graphics Engine|create]] it if you want to get a texture from it. Otherwise, there is no difference in functionality than a [[The GraphicsOutput class|GraphicsOutput]].

The only difference between a &lt;code&gt;GraphicsBuffer&lt;/code&gt; and a &lt;code&gt;ParasiteBuffer&lt;/code&gt; is that a &lt;code&gt;ParasiteBuffer&lt;/code&gt; does not create it own framebuffer space. To create a &lt;code&gt;ParasiteBuffer&lt;/code&gt; you call &lt;code&gt;makeParasite()&lt;/code&gt; from the graphics engine.
&lt;code python&gt;
makeParasite(host, name,sort, xSize, ySize)
&lt;/code&gt;

The arguments &lt;code&gt;name&lt;/code&gt;, &lt;code&gt;sort&lt;/code&gt;, &lt;code&gt;xSize&lt;/code&gt;, and &lt;code&gt;ySize&lt;/code&gt; mean the same things they mean for [[The Graphics Engine|makeWindow and makeBuffer]]. The new argument &lt;code&gt;host&lt;/code&gt; is the [[The GraphicsOutput class|GraphicsOutput object]] whose space in memory it will use. Any rendering done to the parasite is done to the same space in memory as its host. The function [[The GraphicsOutput class|makeTextureBuffer]] sometimes returns a &lt;code&gt;ParasiteBuffer&lt;/code&gt; for space saving reasons. It is also useful for APIs that don't support offscreen rendering.

&lt;code&gt;ParasiteBuffer&lt;/code&gt; objects are automatically setup for calls to &lt;code&gt;getTexture()&lt;/code&gt; since their contents get cleared when &lt;code&gt;host&lt;/code&gt; draws itself.

&lt;h2&gt;GraphicsWindows&lt;/h2&gt;
Unlike &lt;code&gt;GraphicsBuffer&lt;/code&gt; objects &lt;code&gt;GraphicsWindow&lt;/code&gt; objects have a lot more functionality than &lt;code&gt;GraphicsOutput&lt;/code&gt; objects.

The most basic of these functions is &lt;code&gt;hasKeyboard()&lt;/code&gt; and &lt;code&gt;hasPointer()&lt;/code&gt; which returns whether or not this window has the focus of keyboard and pointer respectively. Any calls to keyboard or pointer functions when you do not have control of them generates an error. 

You can get the number of input devices for this window by using &lt;code&gt;getNumInputDevices()&lt;/code&gt;. In the absence of a joystick, etc. there is usually only one input device, the 'keyboard/mouse' device. If the API you are using supports it, you can move a mouse to a certain place in the window by using &lt;code&gt;movePointer(device, x,y)&lt;/code&gt; where &lt;code&gt;device&lt;/code&gt; is the name of the device that holds the mouse (most probabaly 'keyboard/mouse') and &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; represent the [[Scene Graph Manipulations|screen position]] where you want to move the pointer. It returns &lt;code&gt;True&lt;/code&gt; if it was succesful, and &lt;code&gt;False&lt;/code&gt; otherwise.

You can also ask a window if it &lt;code&gt;isFullscreen()&lt;/code&gt; and if it &lt;code&gt; isClosed()&lt;/code&gt;. It is important to note that a window is not automatically opened after a call to [[The Graphics Engine|makeWindow]] and is not automatically closed after a call to [[The Graphics Engine|closeWindow]].

In order to get the full set of properties for a given window you use the function &lt;code&gt;getProperties()&lt;/code&gt;. This returns a &lt;code&gt;WindowProperties&lt;/code&gt; object that holds all the information for the given screen. See the API documentation for the full functionality of the &lt;code&gt;WindowProperties&lt;/code&gt; class. 

If you want to change these properties, use &lt;code&gt;getRequestedProperties()&lt;/code&gt; and apply the proper &lt;code&gt;WindowProperties&lt;/code&gt; functions. 

To run panda3d in full screen, rather than a window, do the following:
&lt;code python&gt;
wp = WindowProperties() 
wp.setFullscreen(True) 
base.win.requestProperties(wp)
&lt;/code&gt;

Alternatively, you can modify the fullscreen configuration variable before importing &lt;code&gt;direct.directbase.DirectStart&lt;/code&gt;:
&lt;code python&gt;
from panda3d.core import loadPrcFileData
loadPrcFileData(&quot;&quot;, &quot;&quot;&quot;fullscreen 1
win-size 1024 768&quot;&quot;&quot;)

from direct.showbase.DirectObject import DirectObject   # for event handling 
import direct.directbase.DirectStart 
import sys 

class World(DirectObject): 
   def __init__(self): 
      self.accept(&quot;escape&quot;,sys.exit) 

w= World() 
run()
&lt;/code&gt;


If a requested change is not possible or invalid, you can call &lt;code&gt;getRejectedProperties()&lt;/code&gt;. It returns a &lt;code&gt;WindowProperties&lt;/code&gt; object that holds all of the properties that could not be changed.

Windows can also send [[Event Handling|Events]] when the user changes a property of the window. You can get the name of this event by calling &lt;code&gt;getWindowEvent()&lt;/code&gt;. Initially, all windows send the same event when changed. If you want to setup events for a certain window, use &lt;code&gt;setWindowEvent(name)&lt;/code&gt; where &lt;code&gt;name&lt;/code&gt; is the name of the event you want sent when this window gets changed externally.

For more advanced functionality see [http://www.panda3d.org/apiref.php?page=GraphicsWindow &lt;code&gt;GraphicsWindow&lt;/code&gt; in the API documentation.]</text>
    </revision>
  </page>
  <page>
    <title>Graphics Card Performance</title>
    <ns>0</ns>
    <id>2208</id>
    <redirect title="Basic Performance Diagnostics" />
      <sha1>t8zmp6kf5pv2fossurljt79fxkr5mi9</sha1>
    <revision>
      <id>4861</id>
      <timestamp>2008-03-13T01:27:13Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <comment>[[Graphics Card Performance]] moved to [[Basic Performance Diagnostics]]: I'm writing an entire section of the manual on Graphics Card Performance.  This is going to be just a small piece of it.</comment>
      <text xml:space="preserve" bytes="43">#REDIRECT [[Basic Performance Diagnostics]]</text>
    </revision>
  </page>
  <page>
    <title>HTTPS (Apache) certificates</title>
    <ns>0</ns>
    <id>2401</id>
      <sha1>314bst6bxjj1zbgoju5e7coqrc5pn8y</sha1>
    <revision>
      <id>6242</id>
      <timestamp>2009-10-17T15:36:30Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="1517">If you already have an SSL-protected website with its own https
address, then you can use that website's certificate to sign your p3d
files.  When the user is shown your certificate, he/she will be told
something like &quot;This application has been signed by
myhost.mydomain.net,&quot; where myhost.mydomain.net is your website's
hostname.  If the user knows your web page, then this will reassure
the user that it is safe to allow your p3d app to run.

This kind of certificate may be most appropriate for a corporate or
commercial p3d file; the user may closely identify the company's web
address with the company itself.

Panda3D requires your certificate to be formatted in PEM form, which
is the same format used by Apache.  If you are using Apache to host
your website, then you can use the public key and private key
certificate files directly from your system install directory.  (There
may also be a third file, that lists the certificate's authentication
chain.  If so, all three files are needed to sign your p3d file.)  If
you are using IIS or some other software to host your website, then
you may need to convert your certificate to PEM form first; you can
use the openssl command to do this.  Search the internet for the exact
command sequence.

You can obtain an HTTPS certificate from numerous sources; they range
in price considerably, and many are quite inexpensive.  Several companies offer a completely cost-free
HTTPS certificate, but these usually come with a very short expiration
date (90 days or so).</text>
    </revision>
  </page>
  <page>
    <title>Hardware support</title>
    <ns>0</ns>
    <id>984</id>
      <sha1>81qnkoqp771zpave2x8jwqd5xb5iaz8</sha1>
    <revision>
      <id>7585</id>
      <timestamp>2012-02-18T09:26:54Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>typo</comment>
      <text xml:space="preserve" bytes="184">&lt;p&gt;Here is some advice on interacting with hardware using Panda3D's build in keyboard and mouse support, as well as some suggestions for getting joystick information into Panda3D. &lt;/p&gt;</text>
    </revision>
  </page>
  <page>
    <title>HeightfieldTesselator</title>
    <ns>0</ns>
    <id>2230</id>
    <redirect title="The Heightfield Tesselator" />
      <sha1>37es23yugcdre7rwy4owbxoqgqadleg</sha1>
    <revision>
      <id>5243</id>
      <timestamp>2008-03-15T11:14:31Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[The Heightfield Tesselator]]</comment>
      <text xml:space="preserve" bytes="40">#REDIRECT [[The Heightfield Tesselator]]</text>
    </revision>
  </page>
  <page>
    <title>Hosting packages</title>
    <ns>0</ns>
    <id>2413</id>
      <sha1>1kagqrom4gjur4glypcweziuw4hrizo</sha1>
    <revision>
      <id>6273</id>
      <timestamp>2009-10-21T00:01:29Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="1206">After you build one or more packages, you have to make them available for download.  This means you must copy the entire contents of the output directory (the directory named with -i on the ppackage command line) to a web server where it will be visible for download under a particular URL.

The root URL that contains the output directory, including the contents.xml file therein, is called the &quot;host URL&quot;.  This is the URL that you must use when referencing your package in your p3d file(s).

When the Panda3D plugin system downloads a package, it first downloads the contents.xml file at the root of the host URL, and it uses this file to determine which packages are defined at this host and whether any packages need to be redownloaded.  So it is important to copy the entire contents of the output directory, and not to change any parts of it other than with the ppackage tool.

Although not strictly necessary, it is helpful to tell the package, at the time you build it, what its final host URL will be.  You can do this by calling packager.setHost() at the top of the pdef file (before the first class definition), like this:

&lt;code python&gt;
packager.setHost('http://myhost.com/myrootdir/')
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>How Panda3D Stores Vertices and Geometry</title>
    <ns>0</ns>
    <id>1776</id>
      <sha1>hlgbc8mmc1v795ttqidiiwz7qdqckyq</sha1>
    <revision>
      <id>6720</id>
      <timestamp>2010-03-09T10:39:02Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>Added &lt;p&gt; tags; suppressed sreenshots.</comment>
      <text xml:space="preserve" bytes="378">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

&lt;p&gt;This section describes the structure and interconnections of Panda3D's internal vertex and geometry data objects, in general terms.&lt;/p&gt;

&lt;p&gt;You should read through this section carefully, so that you have a good understanding of Panda3D's data structures, before attempting to read the section about generating procedural data.&lt;/p&gt;</text>
    </revision>
  </page>
  <page>
    <title>How to Control Render Order</title>
    <ns>0</ns>
    <id>1790</id>
      <sha1>m7nsw39psbz366z4kfrz7uqb6zyw5gx</sha1>
    <revision>
      <id>7671</id>
      <timestamp>2012-03-08T20:05:40Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tag</comment>
      <text xml:space="preserve" bytes="5926">&lt;b&gt;How to Control Render Order&lt;/b&gt;

In most simple scenes, you can naively attach geometry to the scene
graph and let Panda decide the order in which objects should be
rendered.  Generally, it will do a good enough job, but there are
occasions in which it is necessary to step in and take control of the
process.

To do this well, you need to understand the implications of render
order.  In a typical OpenGL- or DirectX-style Z-buffered system, the
order in which primitives are sent to the graphics hardware is
theoretically unimportant, but in practice there are many important
reasons for rendering one object before another.

Firstly, state sorting is one important optimization.  This means
choosing to render things that have similar state (texture, color,
etc.) all at the same time, to minimize the number of times the
graphics hardware has to be told to change state in a particular
frame.  This sort of optimization is particularly important for very
high-end graphics hardware, which achieves its advertised theoretical
polygon throughput only in the absence of any state changes; for many
such advanced cards, each state change request will completely flush
the register cache and force a restart of the pipeline.

Secondly, some hardware has a different optimization requirement, and
may benefit from drawing nearer things before farther things, so that
the Z-buffer algorithm can effectively short-circuit some of the
advanced shading features in the graphics card for pixels that would
be obscured anyway.  This sort of hardware will draw things fastest
when the scene is sorted in order from the nearest object to the
farthest object, or &quot;front-to-back&quot; ordering.

Finally, regardless of the rendering optimizations described above, a
particular sorting order is required to render transparency properly
(in the absence of the specialized transparency support that only a
few graphics cards provide).  Transparent and semitransparent objects
are normally rendered by blending their semitransparent parts with
what has already been drawn to the framebuffer, which means that it is
important that everything that will appear behind a semitransparent
object must have already been drawn before the semitransparent parts
of the occluding object is drawn.  This implies that all
semitransparent objects must be drawn in order from farthest away to
nearest, or in &quot;back-to-front&quot; ordering, and furthermore that the
opaque objects should all be drawn before any of the semitransparent
objects.

Panda achieves these sometimes conflicting sorting requirements
through the use of bins.

&lt;B&gt;Cull Bins&lt;/B&gt;

The CullBinManager is a global object that maintains a list of all of
the cull bins in the world, and their properties.  Initially, there
are five default bins, and they will be rendered in the following
order:

    Bin Name        Sort  Type
    --------------  ----  ----------------
    &quot;background&quot;     10   BT_fixed
    &quot;opaque&quot;         20   BT_state_sorted
    &quot;transparent&quot;    30   BT_back_to_front
    &quot;fixed&quot;          40   BT_fixed
    &quot;unsorted&quot;       50   BT_unsorted

When Panda traverses the scene graph each frame for rendering, it
assigns each Geom it encounters into one of the bins defined in the
CullBinManager.  (The above lists only the default bins.  Additional
bins may be created as needed, using either the
CullBinManager::add_bin() method, or the Config.prc &quot;cull-bin&quot;
variable.)

You may assign a node or nodes to an explicit bin using the
NodePath::set_bin() interface.  set_bin() requires two parameters, the
bin name and an integer sort parameter; the sort parameter is only
meaningful if the bin type is BT_fixed (more on this below), but it
must always be specified regardless.

If a node is not explicitly assigned to a particular bin, then Panda
will assign it into either the &quot;opaque&quot; or the &quot;transparent&quot; bin,
according to whether it has transparency enabled or not.  (Note that
the reverse is not true: explicitly assigning an object into the
&quot;transparent&quot; bin does not automatically enable transparency for the
object.)

When the entire scene has been traversed and all objects have been
assigned to bins, then the bins are rendered in order according to
their sort parameter.  Within each bin, the contents are sorted
according to the bin type.

If you want simple geometry that's in back of something to render in front
of something that it logically shouldn't, add the following code to the model that you want in front:

&lt;code python&gt;
model.setBin(&quot;fixed&quot;, 40)
model.setDepthTest(False)
model.setDepthWrite(False)
&lt;/code&gt;

The above code will only work for simple models. If your model self occludes (parts of the model covers other parts of the model), the code will not work as expected. An alternative method is to use a [[Display_Regions|display region]] with &lt;code&gt;displayRegion.clearDepthActive(True)&lt;/code&gt;.

The following bin types may be specified:

  BT_fixed

    Render all of the objects in the bin in a fixed order specified by
    the user.  This is according to the second parameter of the
    NodePath::set_bin() method; objects with a lower value are drawn
    first.

  BT_state_sorted

    Collects together objects that share similar state and renders
    them together, in an attempt to minimize state transitions in the
    scene.

  BT_back_to_front

    Sorts each Geom according to the center of its bounding volume, in
    linear distance from the camera plane, so that farther objects are
    drawn first.  That is, in Panda's default right-handed Z-up
    coordinate system, objects with large positive Y are drawn before
    objects with smaller positive Y.

  BT_front_to_back

    The reverse of back_to_front, this sorts so that nearer objects
    are drawn first.

  BT_unsorted

    Objects are drawn in the order in which they appear in the scene
    graph, in a depth-first traversal from top to bottom and then from
    left to right.</text>
    </revision>
  </page>
  <page>
    <title>How to build a CXX Panda3D game</title>
    <ns>0</ns>
    <id>2085</id>
    <redirect title="How to compile a CXX Panda3D program" />
      <sha1>1ppzf70uytxyj6qqxhqq3jb5m2mqpyp</sha1>
    <revision>
      <id>4217</id>
      <timestamp>2007-03-10T14:04:28Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>[[How to build a CXX Panda3D game]] moved to [[How to compile a CXX Panda3D program]]</comment>
      <text xml:space="preserve" bytes="50">#REDIRECT [[How to compile a CXX Panda3D program]]</text>
    </revision>
  </page>
  <page>
    <title>How to build a CXX Panda3D game on Linux</title>
    <ns>0</ns>
    <id>2086</id>
    <redirect title="How to compile a CXX Panda3D program on Linux" />
      <sha1>7omd9b8wf9echi1hp8o5gpn5pmp8fbl</sha1>
    <revision>
      <id>4219</id>
      <timestamp>2007-03-10T14:05:18Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>[[How to build a CXX Panda3D game on Linux]] moved to [[How to compile a CXX Panda3D program on Linux]]</comment>
      <text xml:space="preserve" bytes="59">#REDIRECT [[How to compile a CXX Panda3D program on Linux]]</text>
    </revision>
  </page>
  <page>
    <title>How to build a CXX Panda3D game on Windows</title>
    <ns>0</ns>
    <id>2087</id>
    <redirect title="How to compile a CXX Panda3D program on Windows" />
      <sha1>917n57agn2ogb6nodx367chjzfesiyi</sha1>
    <revision>
      <id>4221</id>
      <timestamp>2007-03-10T14:06:05Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>[[How to build a CXX Panda3D game on Windows]] moved to [[How to compile a CXX Panda3D program on Windows]]</comment>
      <text xml:space="preserve" bytes="61">#REDIRECT [[How to compile a CXX Panda3D program on Windows]]</text>
    </revision>
  </page>
  <page>
    <title>How to build a CXX Panda3D game under Linux</title>
    <ns>0</ns>
    <id>2075</id>
    <redirect title="How to build a CXX Panda3D game on Linux" />
      <sha1>ovtft5k5ywkmsa1uumka8a0tsmma69o</sha1>
    <revision>
      <id>4174</id>
      <timestamp>2007-03-10T08:18:44Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>[[How to build a CXX Panda3D game under Linux]] moved to [[How to build a CXX Panda3D game on Linux]]: same problem. it's not under, it's on.</comment>
      <text xml:space="preserve" bytes="54">#REDIRECT [[How to build a CXX Panda3D game on Linux]]</text>
    </revision>
  </page>
  <page>
    <title>How to build a CXX Panda3D game under Windows</title>
    <ns>0</ns>
    <id>2074</id>
    <redirect title="How to build a CXX Panda3D game on Windows" />
      <sha1>b1q84hvvy7gyobuxgsgfn7iw42seth8</sha1>
    <revision>
      <id>4172</id>
      <timestamp>2007-03-10T08:18:05Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>[[How to build a CXX Panda3D game under Windows]] moved to [[How to build a CXX Panda3D game on Windows]]: it's not under, it's on. sry.</comment>
      <text xml:space="preserve" bytes="56">#REDIRECT [[How to build a CXX Panda3D game on Windows]]</text>
    </revision>
  </page>
  <page>
    <title>How to build a CXX Panda3D game using Microsoft Visual Studio 2008</title>
    <ns>0</ns>
    <id>2379</id>
      <sha1>ots0vs9y2bi7d426ssarr5f65wpvsu0</sha1>
    <revision>
      <id>58200</id>
      <timestamp>2014-03-20T21:57:35Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>add note about msvc 2010</comment>
      <text xml:space="preserve" bytes="5168">[python]This page is related to C++ usage of Panda3D and not to Python usage. If you are a Python user, please skip this page. For C++ users, please toggle to the C++ version of this page.[/python]
[cxx]
Note: For Panda3D versions from 1.7.2 up to 1.8.1, the pre-built DLL's provided for download from this site are compiled with Microsoft Visual Studio 2008, which is not compatible with other versions of Microsoft Visual Studio.  Therefore, you &lt;em&gt;must&lt;/em&gt; also use Visual Studio 2008 to compile your own application; you cannot use another version.

Note: As of the latest development version of Panda3D (1.9), we have switched to MSVC 2010.  Please see this thread for links to the thirdparty packages:
https://www.panda3d.org/forums/viewtopic.php?f=9&amp;t=16346

It is possible to compile Panda using 2012, but in order to do this you must download Panda from source and build all of Panda yourself, rather than using the pre-built DLL's available here.  You may also need to recompile some of the thirdparty DLL's, though there are conflicting reports on this.  Many people find it easier just to use the supported version.

&lt;h2&gt;Steps to compile C++ in Visual Studio 2008&lt;/h2&gt;

Open Visual Studio 2008 and start a new project.

&lt;h3&gt;Step one: Set project mode (very important!)&lt;/h3&gt;
&lt;em&gt;You must set your new project to &quot;Release&quot; mode.&lt;/em&gt;  This is absolutely necessary, because the version of Panda that's provided for download on this website is also built in &quot;Release&quot; mode, and in MSVS, you can't mix-and-match Release and Debug projects, especially if both of them are C++.

If you attempt to build your code in &quot;Debug&quot; mode, everything may appear to build correctly, but when you attempt to run the program, it will crash in mysterious ways.

(In the future, we may provide an optional &quot;Debug&quot; build for download from this site.  In this case, you must be careful to choose &quot;Release&quot; for your project when you are linking against the &quot;Release&quot; Panda build, and &quot;Debug&quot; for your project when you are linking against the &quot;Debug&quot; Panda build.)

&lt;strong&gt;Also very important:&lt;/strong&gt; you must remove the NDEBUG macro definition from your project file.  MSVS automatically defines this when you set the project to Release mode, but it isn't appropriate to set this unless you really are making the final build of your project before releasing it to users.  Also, in Panda version 1.6.x, &lt;em&gt;leaving this defined will cause mysterious crashes&lt;/em&gt; when you run your program.  (This will not be true of Panda version 1.7.x or later, but it is still a good idea to remove it.)

&lt;h3&gt;Step two: Add directories&lt;/h3&gt;

You need to add directories corresponding to your installed Panda3D version.  If you installed to C:\Panda3D-1.6.2, for example, then you would add the following directories by using the &lt;code&gt; Tools -&gt; Options... &lt;/code&gt; pull-down menu and then selecting &lt;code&gt; Projects and Solutions &lt;/code&gt; and in that selecting &lt;code&gt; VC++ Directories &lt;/code&gt; and continuing on to enter the following:

&lt;code cxx&gt;
	Executable Files 
        C:\Panda3D-1.7.0\bin
&lt;/code&gt;
&lt;code cxx&gt;
	Include Files  
        C:\Panda3D-1.7.0\python\include
        C:\Panda3D-1.7.0\include 
&lt;/code&gt;
&lt;code cxx&gt;
	Library Files 
        C:\Panda3D-1.7.0\python\libs
        C:\Panda3D-1.7.0\lib 
&lt;/code&gt;

&lt;b&gt;Note about VS2010:&lt;/b&gt; From Visual Studio 2010 onwards, Microsoft has removed global path settings, so you have to set these paths on a per project basis. In this case, in order to set the Executable path you should add it to the environment. You can do that on the Debugging section of your project properties. Set &quot;merge environment&quot; to yes and set environment to &quot;PATH=C:\Panda3D-1.7.0\bin&quot;. Adding include and library paths is straightforward. Even if you don't use VS2010, it's not a bad idea to enter the settings this way since it's cleaner. The correct way of reusing settings across projects is through the use of [http://msdn.microsoft.com/en-us/library/a4xbdz1e(VS.80).aspx Property Sheets] (External link to MSDN).  But also see the note about VS2010 above: if you are using 2010, you must build all of Panda from source; you cannot use the prebuilt DLL's provided for download.

&lt;b&gt;Note about dependencies:&lt;/b&gt; Depending on what Panda features you use in C++ you may need to specify some extra paths, for example:

&lt;pre&gt;
C:\Panda3D-1.7.0\thirdparty\win-libs-vc9\openssl\include
C:\Panda3D-1.7.0\thirdparty\win-libs-vc9\ode\include
C:\Panda3D-1.7.0\thirdparty\win-libs-vc9\freetype\include
&lt;/pre&gt;

You can get a package containing the &lt;i&gt;thirdparty&lt;/i&gt; folder separately from the Panda3D website. The same goes for library paths.

&lt;h3&gt;Step three: Add libraries&lt;/h3&gt;
                 
After adding all these directories, right click on project and select properties. In the menu that comes up select the &lt;code&gt; Linker &lt;/code&gt; and then the &lt;code&gt; Input &lt;/code&gt; tab. In the Additional Dependencies row add the following libraries:
&lt;code cxx&gt;
libp3framework.lib
libpanda.lib
libpandafx.lib
libpandaexpress.lib
libp3dtool.lib
libp3dtoolconfig.lib
libp3pystub.lib
libp3direct.lib
&lt;/code&gt;

You may also need to add more libraries depending on the features you use.
[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>How to compile a CXX Panda3D program</title>
    <ns>0</ns>
    <id>2076</id>
      <sha1>lqxtvdifzucz5v2u8nz4h0rwvz739tq</sha1>
    <revision>
      <id>6047</id>
      <timestamp>2009-07-29T17:54:13Z</timestamp>
      <contributor>
        <username>MikeC</username>
        <id>281</id>
      </contributor>
      <text xml:space="preserve" bytes="991">[python]This page is related to C++ usage of Panda3D and not to Python usage. If you are a Python user, please skip this page. For C++ users, please toggle to the C++ version of this page.[/python]
[cxx]This short guide explains how to compile and run a Panda3D game written in C++.
If you use Python for your Panda3D programs, you can skip this section.


On UNIX, it is a very good possibility that you can compile using the g++ compiler. The following page describes how to do that:
* [[How to build a CXX Panda3D game on Linux|Linux version]]

On Windows, compiling using g++ will not work. It is however possible to compile your Panda3D project using the MSVC (Microsoft Visual Studio 2008 C++) compiler.  The following page describes how to do that:
* [[How_to_build_a_CXX_Panda3D_game_using_Microsoft_Visual_Studio_2008|MSVC version]]

Some have also managed to build Panda3D under OSX. This is the related forum thread:
* [[http://www.panda3d.org/phpbb2/viewtopic.php?t=1193]]
[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>How to compile a CXX Panda3D program on Linux</title>
    <ns>0</ns>
    <id>2072</id>
      <sha1>abdqwxb3z27d3b4jh3os9s1jnwvvg2m</sha1>
    <revision>
      <id>7382</id>
      <timestamp>2011-11-24T20:52:11Z</timestamp>
      <contributor>
        <username>Ambyra</username>
        <id>535</id>
      </contributor>
      <text xml:space="preserve" bytes="2114">[python]This page is related to C++ usage of Panda3D and not to Python usage. If you are a Python user, please skip this page. For C++ users, please toggle to the C++ version of this page.[/python]
[cxx]
This short guide explains how to build a Panda3D game written in C++ game under Linux.

First of all, download the following files:
# [http://www.python.org/ Python], the development package
# The GNU G++ compiler. On most Linux versions, this is already pre-installed.

Now, first of all, we need to create a .o file from our cxx file. We need to link to the Panda3D include files and to the Python include files. Please change the paths in these commands to the appropiate locations.

&lt;pre class=&quot;codeblock&quot;&gt;
g++ -c filename.cxx -o filename.o -fPIC -O2 -I{pythoninclude} -I{panda3dinclude}
&lt;/pre&gt;

To generate an executable, you can use the following command:

&lt;pre class=&quot;codeblock&quot;&gt;
g++ filename.o -o filename -fPIC -L{panda3dlibs} -lp3framework -lpanda
     -lpandafx -lpandaexpress -lp3dtoolconfig -lp3dtool -lp3pystub -lp3direct
&lt;/pre&gt;

&lt;b&gt;Note:&lt;/b&gt; In this two commands, you need to change a few paths:
* {pythoninclude}: The path to your Python include folder. For version 2.4, this is /usr/include/python2.4 by default.
* {panda3dinclude}: Change this to the path to your Panda3D include directory. This would probably look like /usr/include/panda3d/.
* {panda3dlibs}: Change this to the path to your Panda3D libraries. Usually this is just /usr/lib/panda3d or sometimes /usr/lib.


Here is an equivalent SConstruct file, organized for clarity:

&lt;pre class=&quot;codeblock&quot;&gt;
pyInc= '/usr/include/python2.4'
pandaInc= '/usr/include/panda3d'
pandaLib= '/usr/lib/panda3d'

Program('filename.cpp',
	CCFLAGS=['-fPIC', '-O2'],
	CPPPATH=[pyInc, pandaInc],
	LIBPATH=pandaLib,
	LIBS=[	'libp3framework',
		'libpanda',
		'libpandafx',
		'libpandaexpress',
		'libp3dtoolconfig',
		'libp3dtool',
		'libp3pystub',
		'libp3direct'])
&lt;/pre&gt;

To run your newly created executable, type:
&lt;pre class=&quot;codeblock&quot;&gt;
./filename
&lt;/pre&gt;

If it runs, congratulations! You have successfully compiled your own Panda3D program!
[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>How to compile a CXX Panda3D program on Mac OS X</title>
    <ns>0</ns>
    <id>2381</id>
      <sha1>j0yqz9p6gxx8iviil49tt29w0zo0nmc</sha1>
    <revision>
      <id>7045</id>
      <timestamp>2011-01-18T22:58:59Z</timestamp>
      <contributor>
        <username>Treeform</username>
        <id>163</id>
      </contributor>
      <comment>Updated mac steps</comment>
      <text xml:space="preserve" bytes="3050">[python]This page is related to C++ usage of Panda3D and not to Python usage. If you are a Python user, please skip this page. For C++ users, please toggle to the C++ version of this page.[/python]

[cxx]This short guide explains how to build a Panda3D game written in C++ game under Mac OS. 

Mac OS comes with python installed, however because of production cycles your version may be a bit outdated, if you want to download the latest python version, you can go to the [http://www.python.org/download/ Python] website. Just make sure that the Panda3D version is compatible with it.

In order to compile you need also to have the &lt;b&gt;GNU G++ compiler&lt;/b&gt;.  Unlike in Linux, the G++ compiler is not pre-installed in Mac OS X, you will need to install &lt;b&gt;Xcode development tools&lt;/b&gt;, the installer comes in the Mac OS installer CDs or DVDs, however for newer versions, you can download it from its [http://developer.apple.com/ website]. You will need to register for an account.

Having these two components, we can proceed to compile: 

First we must create &lt;b&gt;.o&lt;/b&gt; file from our cxx file. We need to link to the Panda3D include files and to the Python include files.  Note: only 386 arch is supported for panda 1.7.0 so we need to include the -arch i386 flag.

&lt;code bash&gt;g++ -c filename.cxx -o filename.o -fPIC -O2 -arch i386 -I{pythoninclude} -I{panda3dinclude} &lt;/code&gt;

Please change the paths in these commands to the appropiate locations. A list of locations is at the end of the page.

Secondly, we need to generate an executable, you can use the following command: 

&lt;code bash&gt;g++ filename.o -o filename -fPIC -arch i386 -L{panda3dlibs} -lp3framework -lpanda      -lpandafx -lpandaexpress -lp3dtoolconfig -lp3dtool -lp3pystub -lp3direct &lt;/code&gt;

As mentioned above, we need to change the paths accordingly, the paths for Mac OS are listed below:

•	{pythoninclude}: The path to your Python include folder. For version 2.5, this is &lt;b&gt;/usr/include/python2.5 &lt;/b&gt;by default. 

•	{panda3dinclude}: Change this to the path to your Panda3D include directory. This would probably look like &lt;b&gt;/Developer/Panda3D/include/ &lt;/b&gt;in the case of 1.7.0. (for 1.6.2 use /Applications/Panda3D/1.6.2/include/)

•	{panda3dlibs}: Change this to the path to your Panda3D libraries. This is &lt;b&gt;/Developer/Panda3D/lib  &lt;/b&gt;in the case of 1.7.0. (for 1.6.2 use /Applications/Panda3D/1.6.2/lib/)

And lastly to run the created executable, type:
 
&lt;code bash&gt;./filename&lt;/code&gt;


• If you get warnings like &quot;missing required architecture x86_64 in file&quot; or &quot;Undefined symbols: 
&quot;_main&quot;, referenced from:&quot; you need to the -arch i368 flag.

• If you get errors like &quot;Undefined symbols: &quot;TypedObject::_type_handle&quot;, referenced from: &quot; you are not including some panda3d libraries needed or missing the-arch i386 flag.

• If you get an error running your executable like  &quot;dyld: Library not loaded: @executable_path/../Library/Frameworks/Cg.framework/Cg&quot; means you need to install Cg library from http://developer.nvidia.com/object/cg_download.html

[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>How to compile a CXX Panda3D program on Windows</title>
    <ns>0</ns>
    <id>2073</id>
      <sha1>3673mlg9apjg9123mh82v1o0aaoeisp</sha1>
    <revision>
      <id>4256</id>
      <timestamp>2007-03-26T16:34:16Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>deprecated this page</comment>
      <text xml:space="preserve" bytes="1573">&lt;b&gt;DEPRECATED:&lt;/b&gt; This guide does not work, so it has to be removed from the manual. Panda3D does &lt;b&gt;not&lt;/b&gt; compile under g++ on windows.

This short guide explains how to build a Panda3D game written in C++ game under Windows. If you use Python for programming, you can skip this page.
For the Linux version of this guide, click [[How to build a CXX Panda3D game on Linux|here]].

First of all, download the following files:
# [http://www.python.org Python]
# The thirdparty package, downloadable from the Downloads section
# The GNU G++ compiler. A recommended compiler is [http://prdownloads.sf.net/mingw/MinGW-3.1.0-1.exe?download MinGW].

Now, first of all, we need to create a .o file from our cxx file. We need to link to the NSPR include files, to the Panda3D include files and to the Python include files. Please change the paths in these commands to the appropiate locations.
&lt;table class=&quot;code&quot;&gt;&lt;tr&gt;&lt;td&gt;
g++ -c filename.cxx -o filename.o -fPIC -O2 -I&quot;c:\path\to\python.h\&quot; -I&quot;c:\Panda3D-1.3.2\thirdparty\linux-libs-a\nspr\include\&quot; -I&quot;C:\Panda3D-1.3.2\include\&quot;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
Now, we need to make a .exe file out of this. To do that, use this command:
&lt;table class=&quot;code&quot;&gt;&lt;tr&gt;&lt;td&gt;
g++ filename.o -o filename.exe -fPIC -L&quot;C:\Panda3D-1.3.2\lib\&quot; -lp3framework -lpanda -lpandafx -lpandaexpress -lp3dtoolconfig -lp3dtool -lp3pystub -L&quot;C:\Panda3D-1.3.2\thirdparty\linux-libs-a\nspr\lib&quot; -lpandanspr4
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

To run your newly created executable, type:
&lt;table class=&quot;code&quot;&gt;&lt;tr&gt;&lt;td&gt;
filename.exe
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

And behold, your C++ Panda3D file!</text>
    </revision>
  </page>
  <page>
    <title>How to compile a CXX Panda3D program using Microsoft Visual Studio</title>
    <ns>0</ns>
    <id>2092</id>
    <redirect title="Using Microsoft Visual Studio" />
      <sha1>qfh22qtlfpmllf3x9ml7v4ze6i51f5l</sha1>
    <revision>
      <id>4258</id>
      <timestamp>2007-03-26T16:49:18Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>redirected</comment>
      <text xml:space="preserve" bytes="43">#REDIRECT [[Using Microsoft Visual Studio]]</text>
    </revision>
  </page>
  <page>
    <title>How to use a Python Editor</title>
    <ns>0</ns>
    <id>2388</id>
    <redirect title="Getting Started with your Code Editor" />
      <sha1>7w0zhq63z07o56b0fp2pq7lqc1051a6</sha1>
    <revision>
      <id>6186</id>
      <timestamp>2009-09-29T10:29:49Z</timestamp>
      <contributor>
        <username>Gogg</username>
        <id>389</id>
      </contributor>
      <comment>[[How to use a Python Editor]] moved to [[Getting Started with your Code Editor]]: name change so that it's language agnostic</comment>
      <text xml:space="preserve" bytes="51">#REDIRECT [[Getting Started with your Code Editor]]</text>
    </revision>
  </page>
  <page>
    <title>Installing Panda</title>
    <ns>0</ns>
    <id>2152</id>
    <redirect title="Installing Panda in Windows" />
      <sha1>1z0epxg5iem7u3oegy4dfibhfdbz4jt</sha1>
    <revision>
      <id>4544</id>
      <timestamp>2007-09-09T19:21:05Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <comment>[[Installing Panda]] moved to [[Installing Panda in Windows]]</comment>
      <text xml:space="preserve" bytes="41">#REDIRECT [[Installing Panda in Windows]]</text>
    </revision>
  </page>
  <page>
    <title>Installing Panda3D in Linux</title>
    <ns>0</ns>
    <id>2153</id>
      <sha1>8m4pavbiv76m4m2q4qjcqbxdu12sxvu</sha1>
    <revision>
      <id>60534</id>
      <timestamp>2015-07-23T12:00:33Z</timestamp>
      <contributor>
        <username>Sal</username>
        <id>22868</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="4505">&lt;h2&gt;The Installation Process - Linux&lt;/h2&gt;

The easiest way to install panda is to use the
RPM or DEB packages.  This is only possible if your version of Linux
is one of the provided versions of Linux.  If not, you will need to
[[Building_Panda3D_from_Source|compile from source]].  If there is an installer available, download
and install the RPM or DEB appropriate to your version of Linux. 

After installing Panda, you should run the sample programs to verify that the installation is good. To do so, you need to change directory to the Panda samples directory, select a sample program, change directory to that sample, and run the sample using Python:

&lt;pre class=&quot;codeblock&quot;&gt;
$ cd /usr/share/panda3d/samples
$ ls
Asteroids
Ball-in-Maze
Boxing-Robots
Carousel
Cartoon-Shader
Chessboard
Disco-Lights
Fireflies
Fractal-Plants
Glow-Filter
GUI
Infinite-Tunnel
Looking-and-Gripping
Media-Player
Motion-Trails
Music-Box
Normal-Mapping
Particles
Procedural-Cube
Roaming-Ralph
Shadows
Solar-System
Teapot-on-TV
Texture-Swapping
$ cd Boxing-Robots
$ python Tut-Boxing-Robots.py
&lt;/pre&gt;

&lt;b&gt;Using an Unsupported Linux Distribution or an Unsupported Python&lt;/b&gt;

Python packages need to be compiled for a particular variant of Python.  For example, a package that works with Python 2.4 will not work with Python 2.5.  A package that works with 32-bit Python will not work with 64-bit Python.  A package that works with UCS2 Python will not work with UCS4 Python.  And so forth.  In short, a Python package must be carefully aligned, feature-for-feature, with one particular Python interpreter.  That package will not work with any other Python interpreter.

Fortunately for you, our prepackaged copies of Panda3D are already carefully matched.  For example, our Panda3D for Ubuntu is already perfectly matched to the Python interpreter that comes with that version of Ubuntu.  So normally, you don't need to worry about this at all.

If your Linux Distribution is not listed, you will need to build your own copy of Panda3D.  The build process will automatically create a copy of Panda3D which perfectly matches your Linux Distribution's Python interpreter.  This is easy to do, but it does require a time-consuming compile.  On the other hand, trying to use an RPM or a DEB from some other Distribution is very unlikely to work, because of this need for an exact feature-for-feature match  between the Python package (Panda3D) and the Python interpreter.

If you are using a copy of Python other than the one that came with the Linux Distribution, you have a bigger problem.  Panda3D's build-scripts automatically build Panda3D for the system's native Python interpreter, not for some other Python interpreter.  To get Panda3D to build for some other Python interpreter, you will have to edit the build scripts.

&lt;b&gt;What to do if you see the Error Message:&lt;/b&gt;

If you see this error:

&lt;pre class=&quot;codeblock&quot;&gt;
display(error): The application requested hardware acceleration, but your OpenGL
display(error): driver, GDI Generic, only supports software rendering.
display(error): You need to install a hardware-accelerated OpenGL driver, or,
display(error): if you actually *want* to use a software renderer, then
display(error): alter the hardware/software configuration in your Config.prc file.
display(error): Window wouldn't open; abandoning window.
&lt;/pre&gt;

This error is fairly self-explanatory: it means your video drivers are inadequate.  Obtain better drivers.


&lt;b&gt;What to do if you see the Error Message:&lt;/b&gt;
&lt;i&gt;&lt;br&gt;ImportError: No module named direct.directbase.DirectStart&lt;/i&gt;

This error means it couldn't find the Python modules -- please make sure you are running the correct version of Python (probably Python 2.5, that depends on the Panda3D version) and that the panda3d.pth is located inside the Python site-packages directory.

&lt;b&gt;What to do if you see the Error Message:&lt;/b&gt;
&lt;i&gt;&lt;br&gt;Warning: DirectNotify: category 'Interval' already exists&lt;/i&gt;

This error is of no consequence.  Ignore it.


&lt;b&gt;What to do if you see the Error Message:&lt;/b&gt;
&lt;i&gt;&lt;br&gt;ImportError: /usr/lib/panda3d/libpandaexpress.so: undefined symbol: PyUnicodeUCS4_AsWideChar&lt;/i&gt;

This could mean that your version of Python is compiled with the flag &lt;code&gt;Py_UNICODE_SIZE&lt;/code&gt; set to &lt;code&gt;2&lt;/code&gt;. Please find a Python version compiled with Py_UNICODE_SIZE set to 4 (which is usually the default).
See [http://panda3d.org/phpbb2/viewtopic.php?t=3904#20510 this forum topic] for a more detailed explanation about this problem.</text>
    </revision>
  </page>
  <page>
    <title>Installing Panda3D in Windows</title>
    <ns>0</ns>
    <id>930</id>
      <sha1>s76b1k487fp3j6ro56mufz0g4kbjoih</sha1>
    <revision>
      <id>60533</id>
      <timestamp>2015-07-23T11:56:21Z</timestamp>
      <contributor>
        <username>Sal</username>
        <id>22868</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="3313">If you have already installed Panda previously, you
should uninstall it before installing a new version.
Once your machine is clean of all previous versions
of Panda, you should download the windows
installer from the [http://panda3d.org/download.php download] page.
Run the installer, and follow the prompts:

&lt;br&gt;&lt;br&gt;
[[Image:Install-1.jpg]]
&lt;br&gt;&lt;br&gt;

After installing Panda, you should run the sample programs to verify
that the installation is good.  Under Windows, the easiest way to run
a sample program is to find it in the Start Menu:

&lt;br&gt;&lt;br&gt;
[[Image:Install-2.jpg]]
&lt;br&gt;&lt;br&gt;

But you can also run a sample program manually, using a command prompt.

Open a command prompt, then change directory to the location where you
installed Panda.  Then, change to the samples subdirectory.
There, you will find a large number of samples:

&lt;br&gt;&lt;br&gt;
[[Image:Install-3.jpg]]
&lt;br&gt;&lt;br&gt;

Change directory into one of the sample program directories, then use
Python to run the sample program in question:

&lt;br&gt;&lt;br&gt;
[[Image:Install-4.jpg]]
&lt;br&gt;&lt;br&gt;

If the test programs don't run, then usually, you need to update
your video drivers.  If you want to know exactly why a program didn't run,
you may need to run it using the command prompt - this will enable you
to see the error messages.

&lt;b&gt;What to do if you see the Error Message:&lt;/b&gt;
&lt;pre class=&quot;codeblock&quot;&gt;
display(error): The application requested hardware acceleration, but your OpenGL
display(error): driver, GDI Generic, only supports software rendering.
display(error): You need to install a hardware-accelerated OpenGL driver, or,
display(error): if you actually *want* to use a software renderer, then
display(error): alter the hardware/software configuration in your Config.prc file.
display(error): Window wouldn't open; abandoning window.
&lt;/pre&gt;

This error is fairly self-explanatory: it means your video drivers are inadequate.  Obtain better drivers.

&lt;b&gt;What to do if you see the Error Message:&lt;/b&gt;
&lt;i&gt;&lt;br&gt;python is not a recognized internal command&lt;/i&gt;

This error message means that the command prompt was not able to locate
python.  Normally, during the panda installation process,
the PATH environment variable is configured to indicate the location of
python.  However, some PCs have unusual security configurations that
prevent the installer from modifying the PATH.  This can result in the
error message shown above.  

To solve this problem, it may be necessary to modify the PATH manually. Click on the &quot;My Computer&quot; icon on your desktop and select Properties. Choose the tab &quot;Advanced&quot;.  Click the Button &quot;Environment Variables&quot;:

[[Image:Environvariables.png]]

If you have administrator access to the PC, select the PATH line in the list under System Variables, otherwise, select the PATH line in the list of personal environment Variables.

[[Image:Environvariables2.png]]

Now double click the PATH (or Path) line. a small window opens containing a series of directories separated by semicolons.  Add Panda3D's bin and python directories to the end of the PATH.

[[Image:Environvariables3.png]]

It may be necessary to log off and log back in to obtain the updated settings.

&lt;b&gt;What to do if you see the Error Message:&lt;/b&gt;
&lt;i&gt;&lt;br&gt;Warning: DirectNotify: category 'Interval' already exists&lt;/i&gt;

This error is of no consequence.  Ignore it.</text>
    </revision>
  </page>
  <page>
    <title>Installing Panda in Linux</title>
    <ns>0</ns>
    <id>2457</id>
    <redirect title="Installing Panda3D in Linux" />
      <sha1>d8c5yjwlz2xvip1fplaki0uhpwr24di</sha1>
    <revision>
      <id>6606</id>
      <timestamp>2010-02-07T04:38:21Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>[[Installing Panda in Linux]] moved to [[Installing Panda3D in Linux]]: Panda3D is the name of the engine; not Panda.</comment>
      <text xml:space="preserve" bytes="41">#REDIRECT [[Installing Panda3D in Linux]]</text>
    </revision>
  </page>
  <page>
    <title>Installing Panda in Windows</title>
    <ns>0</ns>
    <id>2456</id>
    <redirect title="Installing Panda3D in Windows" />
      <sha1>r1vn3z7lge2w5c4nsv4j16n6rjdxssq</sha1>
    <revision>
      <id>6604</id>
      <timestamp>2010-02-07T04:38:00Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>[[Installing Panda in Windows]] moved to [[Installing Panda3D in Windows]]: Panda3D is the name of the engine; not Panda.</comment>
      <text xml:space="preserve" bytes="43">#REDIRECT [[Installing Panda3D in Windows]]</text>
    </revision>
  </page>
  <page>
    <title>Installing packages</title>
    <ns>0</ns>
    <id>2407</id>
      <sha1>9nu5tozyc0jmuyuusl6n42y8yimbuta</sha1>
    <revision>
      <id>6276</id>
      <timestamp>2009-10-21T21:32:09Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="1513">A package file is a Panda3D multifile.  When a package is installed onto a user's machine, it means the multifile is downloaded and placed in its own subdirectory of the Panda3D installation directory (e.g. ~/Library/Caches/Panda3d, on Mac).  This directory name is then stored in the environment variable PACKAGENAME_ROOT, where PACKAGENAME is the name of the package converted to uppercase, e.g. PANDA3D_ROOT or ODE_ROOT.  (You can query this environment variable name at runtime with ExecutionEnvironment.getEnvironmentVariable('PANDA3D_ROOT').)

The multifile is also automatically &quot;mounted&quot; using Panda's VirtualFileSystem, onto the same directory, so that it is as if all of the contents of the multifile are actually available as individual files within the PACKAGENAME_ROOT directory, even though the individual files may not actually appear on disk at all.  Furthermore, the PACKAGENAME_ROOT directory is added to Python's sys.path, as well as to Panda's model-path, so that any Python modules can be imported, and any model files can be imported, directly from the package.  In addition, any prc files in the PACKAGENAME_ROOT directory will be automatically loaded.

Some file types, such as DLL files, really do need to be extracted to disk to be used, because they are loaded directly by the operating system and not by Panda.  These files are extracted automatically when the package is installed and left within the PACKAGENAME_ROOT directory (or within a subdirectory if the filename so indicates).</text>
    </revision>
  </page>
  <page>
    <title>Instancing</title>
    <ns>0</ns>
    <id>1096</id>
      <sha1>aeiqq9wisexitmelwyiw9zunafcgagm</sha1>
    <revision>
      <id>7413</id>
      <timestamp>2011-12-07T09:18:07Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="7010">In the musical &quot;A Chorus Line,&quot; the most well-known scene is when about 50 identical-looking young women line up left-to-right across the stage, and they all kick-left-kick-right in unison.  To implement this in Panda3D, you might do this:

&lt;code python&gt;
for i in range(50):
  dancer = Actor.Actor(&quot;chorus-line-dancer.egg&quot;, {&quot;kick&quot;:&quot;kick.egg&quot;})
  dancer.loop(&quot;kick&quot;)
  dancer.setPos(i*5,0,0)
  dancer.reparentTo(render)
&lt;/code&gt;

Here is the scene graph that we just created:

&lt;center&gt;[[Image:Instancing1.jpg]]&lt;/center&gt;

This works fine, but it is a little expensive.  Animating a model involves a lot of per-vertex matrix calculations.  In this case, we're animating 50 copies of the exact same model using 50 copies of the exact same animation.  That's a lot of redundant calculation.  It would seem that there &lt;i&gt;must&lt;/i&gt; be some way avoid calculating the exact same values 50 times.  There is: the technique is called &lt;i&gt;instancing&lt;/i&gt;.

The idea is this: instead of creating 50 separate dancers, create only one dancer, so that the engine only has to update her animation once.  Cause the engine to render her 50 times, by inserting her into the scene graph in 50 different places.  Here is how it is done:

&lt;code python&gt;
dancer = Actor.Actor(&quot;chorus-line-dancer.egg&quot;, {&quot;kick&quot;:&quot;kick.egg&quot;})
dancer.loop(&quot;kick&quot;)
dancer.setPos(0,0,0)
for i in range(50):
  placeholder = render.attachNewNode(&quot;Dancer-Placeholder&quot;)
  placeholder.setPos(i*5, 0, 0)
  dancer.instanceTo(placeholder)
&lt;/code&gt;

Here is a diagram of the scene graph we just created:

&lt;center&gt;[[Image:Instancing2.jpg]]&lt;/center&gt;

It's not a tree any more, it is a directed acyclic graph.  But the renderer still traverses the graph using a recursive tree-traversal algorithm.  As a result, it ends up traversing the dancer node 50 times.  Here is a diagram of the depth-first traversal that the renderer takes through the graph.  Note that this is &lt;i&gt;not&lt;/i&gt; a diagram of the scene graph - it's a diagram of the renderer's &lt;i&gt;path&lt;/i&gt; through the scene graph:

&lt;center&gt;[[Image:Instancing3.jpg]]&lt;/center&gt;

In other words, the renderer visits the dancer actor 50 times.  It doesn't even notice that it's visiting the same actor 50 times, rather than visiting 50 different actors.  It's all the same to the renderer.

There are 50 placeholder nodes, lined up across the stage.  These are called &lt;i&gt;dummy nodes&lt;/i&gt;.  They don't contain any polygons, they're little tiny objects used mainly for organization.  In this case, I'm using each placeholder as a platform on which a dancer can stand.

The position of the dancer is (0,0,0).  But that's relative to the position of the parent.  When the renderer is traversing placeholder 1's subtree, the dancer's position is treated as relative to placeholder 1.  When the renderer is traversing placeholder 2's subtree, the dancer's position is treated as relative to placeholder 2.  So although the position of the dancer is fixed at (0,0,0), it appears in multiple locations in the scene (on top of each placeholder).

In this way, it is possible to render a model multiple times without storing and animating it multiple times.

&lt;h2&gt;Advanced Instancing&lt;/h2&gt;

Now, let's go a step further:

&lt;code python&gt;
dancer = Actor.Actor(&quot;chorus-line-dancer.egg&quot;, {&quot;kick&quot;:&quot;kick.egg&quot;})
dancer.loop(&quot;kick&quot;)
dancer.setPos(0,0,0)
chorusline = NodePath('chorusline')
for i in range(50):
  placeholder = chorusline.attachNewNode(&quot;Dancer-Placeholder&quot;)
  placeholder.setPos(i*5,0,0)
  dancer.instanceTo(placeholder)
&lt;/code&gt;

This is the exact same code as before, except that instead of putting the 50 placeholders beneath &lt;code&gt;render&lt;/code&gt;, I put them beneath a dummy node called &lt;code&gt;chorusline&lt;/code&gt;.  So my line of dancers is not part of the scene graph yet.  Now, I can do this:

&lt;code python&gt;
for i in range(3):
  placeholder = render.attachNewNode(&quot;Line-Placeholder&quot;)
  placeholder.setPos(0,i*10,0)
  chorusline.instanceTo(placeholder)
&lt;/code&gt;

Here is the scene graph I just created:

&lt;center&gt;[[Image:Instancing4.jpg]]&lt;/center&gt;

But when the renderer traverses it using a recursive tree-traversal algorithm, it will see 3 major subtrees (rooted at a line-placeholder), and each subtree will contain 50 placeholders and 50 dancers, for a grand total of 150 apparent dancers.

&lt;h2&gt;Instancing: an Important Caveat&lt;/h2&gt;

Instancing saves panda quite a bit of CPU time when animating the model.  But that doesn't change the fact that the renderer still needs to render the model 150 times.  If the dancer is a 1000 polygon model, that's still 150,000 polygons.

Note that each instance has its own bounding box, each is occlusion-culled and frustum-culled separately.

&lt;h2&gt;The NodePath: a Pointer to a Node plus a Unique Instance ID&lt;/h2&gt;

If I had a pointer to the chorus-line dancer model, and I tried to ask the question &quot;where is the dancer,&quot; there would be no well-defined answer.  The dancer is not in one place, she is in 150 places.  Because of this, the data type &lt;i&gt;pointer to node&lt;/i&gt; does not have a method that retrieves the net transform.

This is very inconvenient.  Being able to ask &quot;where is this object located&quot; is fundamental.  There are other incredibly useful queries that you cannot perform because of instancing.  For example, you cannot fetch the parent of a node.  You cannot determine its global color, or any other global attribute.  All of these queries are ill-defined, because a single node can have many positions, many colors, many parents.  Yet these queries are essential.  It was therefore necessary for the panda3d designers to come up with some way to perform these queries, even though a node can be in multiple locations at the same time.

The solution is based on the following observation: if I had a pointer to the chorus line-dancer model, and I &lt;i&gt;also&lt;/i&gt; had a unique identifier that distinguishes one of the 150 instances from all the others, then I could meaningfully ask for the net transform of that particular instance of the node.

Earlier, it was noted that a NodePath contains a pointer to a node, plus some administrative information.  The purpose of that administrative information is to uniquely identify one of the instances.  There is no method &lt;code&gt;PandaNode[::][func]getNetTransform[/func]&lt;/code&gt;, but there &lt;i&gt;is&lt;/i&gt; a method &lt;code&gt;NodePath[::][func]getNetTransform[/func]&lt;/code&gt;.  Now you know why.

To understand how NodePath got its name, think about what is necessary to uniquely identify an instance.  Each of the 150 dancers in the graph above corresponds to a single path through the scene graph.  For every possible path from root to dancer, there exists one dancer-instance in the scene.  In other words, to uniquely identify an instance, you need a &lt;i&gt;list of nodes&lt;/i&gt; that starts at the leaf and goes up to the root.

The administrative information in a NodePath is a list of nodes.  You can fetch any node in the list, using the &lt;code&gt;NodePath[::]node(i)&lt;/code&gt; method. The first one, &lt;code&gt;node(0)&lt;/code&gt;, is the node to which the NodePath points.</text>
    </revision>
  </page>
  <page>
    <title>Interrogate</title>
    <ns>0</ns>
    <id>2237</id>
      <sha1>qzavsji972d1y1fo5uz6van1l2nlcwy</sha1>
    <revision>
      <id>60267</id>
      <timestamp>2014-07-29T14:18:55Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>fix video link</comment>
      <text xml:space="preserve" bytes="6084">&lt;h2&gt;Interrogate&lt;/h2&gt;
Interrogate is a program to parse a body of C++ code and build up a table
of classes, methods, functions, and symbols found, for the purposes of
calling into the codebase via a non-C++ scripting language like Python (Scheme and Smalltalk were also tried at some point) The design of interrogate is such that it should be able to produce wrappers for any other language without too much trouble. You'll have to be responsible for writing and maintaining the interface layer to produce the wrappers, though. 

In addition to identifying all the classes and their relationships,
interrogate will generate a wrapper function for each callable function.
The wrapper functions will be callable directly from the scripting language,
with no understanding of C++ necessary; these wrapper functions will in turn
call the actual C++ functions or methods.

Most exportable features of C++ are supported, including templates, default
parameters, and function overloading.

&lt;h2&gt;How to use it&lt;/h2&gt;
There are a few steps involved in generating python wrappers using interrogate.
Steps for Interrogate:
* In this example it is assumed you have a header file called test.h and a source file called test.cxx.
* Run Interrogate on your .h file which will generate a test_igate.cxx and a test.in file, for example:
&lt;pre class=&quot;codeblock&quot;&gt;interrogate -oc test_igate.cxx -od test.in -python-native test.h&lt;/pre&gt;
* Most likely, you want to specify more flags to the interrogate command, like -string, -fnames, -refcount, or -assert. Consult the interrogate help file for more information about that (run interrogate with -h option)
* Now, you will need to call interrogate_module and generate an interrogate_module.cxx file based on your two files from the previous step:
&lt;pre class=&quot;codeblock&quot;&gt;interrogate_module -oc test_module.cxx -python-native test.in&lt;/pre&gt;
* Note that you can also run interrogate with the -do-module option which will automatically make sure interrogate_module gets called too.
* Now you can compile all your source files, and, the test_module.cxx and test_igate.cxx files.
* When you want to link your C++ files together to form a library, also include the _igate and _module object files. This will make sure it will include the python wrappers.
* You can now put it on your python path (or make sure it's in the same directory) and import it directly by the name of your library.
&lt;code python&gt;from libtest import TestClass&lt;/code&gt;
* Note: In python versions 2.5 and higher, you can not directly load .dll files on windows this way. You will either need to rename your dll into a pyd extension (which will load without problems, hopefully) or you need to preload your library using the imp module.

&lt;h2&gt;Calling Interrogate&lt;/h2&gt;
This section will explain how to call interrogate and will briefly address the most important options. For the full documentation, however, refer to the interrogate help file (accessible by calling interrogate with the -h option).

When calling interrogate, you will need to include the -oc and -od options, which specify where the generated code and function tables, respectively, will be written.

The -module and -library options are used to specify the name of your module and library. These options are mainly code-organizational. You can omit both options.

With -D you can ignore or make interrogate interpret symbols differently. For example, if your code uses a non-standard C macro like __inline, you would need to call interrogate with -D__inline. Or, if you would like certain defines to be defined differently, you can use -Ddefvar=value.

Furthermore, there are a few special flags that you most likely want to include. There is the -string option, which treats the C++ char* and STL strings as special cases, and maps them to the scripting language's string equivalent, instead of a wrapper to basic_string&lt;char&gt;. The option -refcount makes the wrappers compatible with Panda3D's smart reference counting system, if your library depends on Panda3D you will want to include it too. The -assert option is just used for Python wrappers and specifies that when the C++ code throws an assert, this will be translated to an AssertionError exception in python.

&lt;h3&gt;Wrapper functions&lt;/h3&gt;
There are three/four options that specify how to generate the wrapper functions:
* The -c option will generate function wrappers using the C calling convention. Any scripting language that can call a C function should be able to make advantage of the interrogate database.
* The -python option will generate function wrappers using the Python calling convention. In this case, the shared library will directly be loadable as python module (after interrogate_module is called), although C++ objects and methods will be converted into an object handle and a list of independent Python functions.
* The -python-native option generates true python objects for C++ objects, and translates all C++ methods to true Python methods. This is the option you will most likely want to use.
* There is also the -python-obj option, but I think it does the same as -python-native.

You can also specify a combination of any of those. If all are omitted, the default is -c.

Here's a small example:
&lt;pre class=&quot;codeblock&quot;&gt;interrogate -D__inline -DCPPPARSER -D__cplusplus -S/usr/include/panda3d/parser-inc -S/usr/include/ -I/usr/include/panda3d/
-oc myModule_igate.cxx -od myModule.in -fnames -string -refcount -assert -python-native
-module libMyModule -library libMyModule myModule.h

interrogate_module -oc myModule_module.cxx -module libMyModule
-library libMyModule -python-native myModule.in&lt;/pre&gt;

&lt;h2&gt;More Information&lt;/h2&gt;
* You can run the interrogate commands with the -h option to get a more detailed explanation of the options available.
* There is a sample C++ extension in the skel/ directory in the Panda3D source to use as reference and sandbox.
* David Rose, from Walt Disney VR Studio, has held a lecture about interrogate. You can watch a video recording of it [https://www.youtube.com/watch?v=rh8X5pImzrI here]. (Recorded June 4, 2008)</text>
    </revision>
  </page>
  <page>
    <title>Interrogate Module</title>
    <ns>0</ns>
    <id>2240</id>
    <redirect title="Interrogate" />
      <sha1>i07xa5uf1ulwei89nks84h681eloouu</sha1>
    <revision>
      <id>5303</id>
      <timestamp>2008-03-17T17:02:46Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[Interrogate]]</comment>
      <text xml:space="preserve" bytes="25">#REDIRECT [[Interrogate]]</text>
    </revision>
  </page>
  <page>
    <title>Interrogate module</title>
    <ns>0</ns>
    <id>2241</id>
    <redirect title="Interrogate" />
      <sha1>i07xa5uf1ulwei89nks84h681eloouu</sha1>
    <revision>
      <id>5304</id>
      <timestamp>2008-03-17T17:03:01Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[Interrogate]]</comment>
      <text xml:space="preserve" bytes="25">#REDIRECT [[Interrogate]]</text>
    </revision>
  </page>
  <page>
    <title>Intervals</title>
    <ns>0</ns>
    <id>985</id>
      <sha1>tii4q6ietta6tzw733n1wv0exn63god</sha1>
    <revision>
      <id>7649</id>
      <timestamp>2012-03-08T18:30:30Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="3867">Panda3D's Interval system is a sophisticated mechanism for playback of scripted actions.  With the use of Intervals, you can build up a complex interplay of animations, sound effects, or any other actions, and play the script on demand.

The core of system is the &lt;code&gt;Interval&lt;/code&gt; class.  There are several different kinds of Intervals, which will be discussed in detail in the following pages, but all of them have in common the following property: each Interval represents an action (or a series of actions) that occur over a specific, finite interval of time (hence the name).

The real power of the Interval system comes from [[Sequences and Parallels]], which are a special kind of Interval that can contain nested Intervals of any kind (including additional Sequences and/or Parallels).  By using these grouping Intervals, you can easily assemble complex scripts from the basic atoms.

&lt;h2&gt;Using Intervals&lt;/h2&gt;

In any Panda3D module that uses Intervals, you should first import the interval module:

&lt;code python&gt;
from direct.interval.IntervalGlobal import *
&lt;/code&gt;

There are a handful of methods that all Intervals have in common.

To start an Interval playing, use one of the following:

&lt;code python&gt;
interval.start()
interval.start(startT, endT, playRate)
interval.loop()
interval.loop(startT, endT, playRate)
&lt;/code&gt;

The three parameters are optional.  The startTime and endTime parameters define the subset of the interval to play; these should be given as times in seconds, measured from the start of the interval.  The playRate, if specified, allows you play the interval slower or faster than real time; the default is 1.0, to play at real time.

Normally, an Interval will play to the end and stop by itself, but you
can stop a playing Interval prematurely:

&lt;code python&gt;
interval.finish()
&lt;/code&gt;

This will stop the interval and move its state to its final state, as if it had played to the end.  This is a very important point, and it allows you to define critical cleanup actions within the interval itself, which are guaranteed to have been performed by the time the interval is finished.

You can also temporarily pause and resume an interval:

&lt;code python&gt;
interval.pause()
interval.resume()
&lt;/code&gt;

If you pause an interval and never resume or finish it, the remaining
actions in the interval will not be performed.

And you can jump around in time within an interval:

&lt;code python&gt;
interval.setT(time)
&lt;/code&gt;

This causes the interval to move to the given time, in seconds since the beginning of the interval.  The interval will perform all of the actions between its current time and the new time; there is no way to skip in time without performing the intervening actions.

It is legal to set the time to an earlier time; the interval will do its best to reset its state to the previous state.  In some cases this may not be possible (particularly if a [[Function Intervals|Function Interval]] is involved).

&lt;code python&gt;
interval.setPlayRate(playRate)
&lt;/code&gt;

With this you can change the play rate of the interval when it is already running.

Finally, there are a handful of handy query methods:

&lt;code python&gt;
interval.getDuration()
&lt;/code&gt;

Returns the length of the interval in seconds.

&lt;code python&gt;
interval.getT()
&lt;/code&gt;

Returns the current elapsed time within the interval, since the beginning of the interval.

&lt;code python&gt;
interval.isPlaying()
&lt;/code&gt;

Returns true if the interval is currently playing, or false if it was not started, has already finished, or has been explicitly paused or finished.

&lt;code python&gt;
interval.isStopped()
&lt;/code&gt;

Returns true if the interval has not been started, has already played to its completion, or has been explicitly stopped via finish().  This is not quite the same this as &lt;code&gt;(not interval.isPlaying())&lt;/code&gt;, since it does not return true for a paused interval.</text>
    </revision>
  </page>
  <page>
    <title>Introducing Graphics Classes</title>
    <ns>0</ns>
    <id>2275</id>
      <sha1>as4gkbqifsrwyj2qbiy2t8fewq7fj53</sha1>
    <revision>
      <id>5599</id>
      <timestamp>2008-11-10T21:23:27Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <minor/>
      <comment>minor word changes</comment>
      <text xml:space="preserve" bytes="5150">==GraphicsEngine==

The &lt;b&gt;GraphicsEngine&lt;/b&gt; is where it all begins.  There is only one, global, GraphicsEngine in an application, and its job is to keep all of the pointers to your open windows and buffers, and also to manage the task of doing the rendering, for all of the open windows and buffers.  Panda normally creates a GraphicsEngine for you at startup, which is available as &lt;code&gt;base.graphicsEngine&lt;/code&gt;.  There is usually no reason to create a second GraphicsEngine.

==GraphicsPipe==

Each application will also need at least one &lt;b&gt;GraphicsPipe&lt;/b&gt;.  The GraphicsPipe encapsulates the particular API used to do rendering.  For instance, there is one GraphicsPipe class for OpenGL rendering, and a different GraphicsPipe for DirectX.  Although it is possible to create a GraphicsPipe of a specific type directly, normally Panda will create a default GraphicsPipe for you at startup, which is available in &lt;code&gt;base.pipe&lt;/code&gt;.

The GraphicsPipe object isn't often used directly, except to create the individual GraphicsWindow and GraphicsBuffer objects.

==GraphicsWindow and GraphicsBuffer==

The &lt;b&gt;GraphicsWindow&lt;/b&gt; class is the class that represents a single onscreen window for rendering.  Panda normally opens a default window for you at startup, which is available in &lt;code&gt;base.win&lt;/code&gt;.  You can create as many additional windows as you like.  (Note, however, that some graphics drivers incur a performance penalty when multiple windows are open simultaneously.)

Similarly, &lt;b&gt;GraphicsBuffer&lt;/b&gt; is the class that represents a hidden, offscreen buffer for rendering special offscreen effects, such as render-to-texture.  It is common for an application to have many offscreen buffers open at once.

Both classes inherit from the base class &lt;b&gt;GraphicsOutput&lt;/b&gt;, which contains all of the code common to rendering to a window or offscreen buffer.

==GraphicsStateGuardian==

The &lt;b&gt;GraphicsStateGuardian&lt;/b&gt;, or &lt;b&gt;GSG&lt;/b&gt; for short, represents the actual graphics context.  This class manages the actual nuts-and-bolts of drawing to a window; it manages the loading of textures and vertex buffers into graphics memory, and has the functions for actually drawing triangles to the screen.  (During the process of rendering the frame, the &quot;graphics state&quot; changes several times; the GSG gets its name from the fact that most of its time is spent managing this graphics state.)

You would normally never call any methods on the GSG directly; Panda handles all of this for you, via the GraphicsEngine.  This is important, because in some modes, the GSG may operate almost entirely in a separate thread from all of your application code, and it is important not to interrupt that thread while it might be in the middle of drawing.

Each GraphicsOutput object keeps a pointer to the GSG that will be used to render that window or buffer.  It is possible for each GraphicsOutput to have its own GSG, or it is possible to share the same GSG between multiple different GraphicsOutputs.  Normally, it is preferable to share GSG's, because this tends to be more efficient for managing graphics resources.

Consider the following diagram to illustrate the relationship between these classes.  This shows a typical application with one window and two offscreen buffers:

&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding: 5pt&quot;&gt;
GraphicsEngine

&lt;table style=&quot;border-collapse: separate; border-spacing: 1pt 0pt&quot;&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #acb1ed; padding: 5pt&quot;&gt;
GraphicsPipe&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;

&lt;/tr&gt;&lt;tr&gt;

&lt;td style=&quot;text-align: right&quot;&gt;&lt;big&gt;&amp;#8601;&lt;/big&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;big&gt;&amp;darr;&lt;/big&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: left&quot;&gt;&lt;big&gt;&amp;#8600;&lt;/big&gt;&lt;/td&gt;

&lt;/tr&gt;&lt;tr&gt;

&lt;td style=&quot;border: 1px solid black; background: #acb1ed; padding: 5pt; text-align: center&quot;&gt;
GraphicsOutput&lt;br&gt;(window)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #acb1ed; padding: 5pt; text-align: center&quot;&gt;
GraphicsOutput&lt;br&gt;(buffer)&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #acb1ed; padding: 5pt; text-align: center&quot;&gt;
GraphicsOutput&lt;br&gt;(buffer)&lt;/td&gt;

&lt;/tr&gt;&lt;tr&gt;

&lt;td style=&quot;text-align: center&quot;&gt;&lt;big&gt;&amp;#9482;&lt;/big&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;big&gt;&amp;#9482;&lt;/big&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;big&gt;&amp;#9482;&lt;/big&gt;&lt;/td&gt;

&lt;/tr&gt;&lt;tr&gt;

&lt;td style=&quot;border: 1px solid black; background: #acb1ed; padding: 5pt; text-align: center&quot;&gt;
GSG&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #acb1ed; padding: 5pt; text-align: center&quot;&gt;
GSG&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #acb1ed; padding: 5pt; text-align: center&quot;&gt;
GSG&lt;/td&gt;

&lt;/tr&gt;
&lt;/table&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;

The GraphicsPipe was used to create each of the three GraphicsOutputs, of which one is a GraphicsWindow, and the remaining two are GraphicsBuffers.  Each GraphicsOutput has a pointer to the GSG that will be used for rendering.  Finally, the GraphicsEngine is responsible for managing all of these objects.

In the above illustration, each window and buffer has its own GSG, which is legal, although it's usually better to share the same GSG across all open windows and buffers.</text>
    </revision>
  </page>
  <page>
    <title>Introduction to Panda</title>
    <ns>0</ns>
    <id>2455</id>
    <redirect title="Introduction to Panda3D" />
      <sha1>jq3fxtzhj7jun1v92z1u2nnoiz3ids2</sha1>
    <revision>
      <id>6602</id>
      <timestamp>2010-02-07T04:37:26Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>[[Introduction to Panda]] moved to [[Introduction to Panda3D]]: Panda3D is the name of the engine; not Panda.</comment>
      <text xml:space="preserve" bytes="37">#REDIRECT [[Introduction to Panda3D]]</text>
    </revision>
  </page>
  <page>
    <title>Introduction to Panda3D</title>
    <ns>0</ns>
    <id>929</id>
      <sha1>6jchegudyr0fxxx9720cbzhkpskald0</sha1>
    <revision>
      <id>60540</id>
      <timestamp>2015-08-04T12:34:20Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>Fixing grammar and spelling errors; rewording some sentences</comment>
      <text xml:space="preserve" bytes="5950">&lt;h2&gt;Panda3D Basics&lt;/h2&gt;

Panda3D is a &lt;i&gt;3D engine&lt;/i&gt;: a library of subroutines for 3D rendering and game development. The library is C++ with a set of Python bindings. Game development with Panda3D usually consists of writing a Python or C++ program that controls the Panda3D library.

Panda3D was created for commercial game development and is still used for developing commercial games. Because of this, the engine needs
to emphasize four areas: &lt;i&gt;power&lt;/i&gt;, &lt;i&gt;speed&lt;/i&gt;, &lt;i&gt;completeness&lt;/i&gt;,
and &lt;i&gt;error tolerance&lt;/i&gt;.  Everyone knows what power and speed
are. But completeness and error tolerance deserve some extra commentary.

Completeness means that Panda3D contains many unexciting but essential
tools: scene graph browsing, performance monitoring, animation optimizers,
and so forth.

Error tolerance is about the fact that all game developers create bugs.
When you do, you want your engine to give you a clear error message
and help you find the mistake. Too many engines will just crash if
you pass the wrong value to a function. Panda3D almost never crashes,
and much code is dedicated to the problem of tracking and isolating
errors.

Finally, to come back to power and speed: to gauge Panda3D's
capabilities you can take a look at the [[Sample Programs in the Distribution|Sample Programs]]. These are
short programs that demonstrate a sampling of Panda3D's capabilities.
The screenshots have frame-rates in the upper-right corner, taken on
a Radeon X700. Note that some samples are old and use placeholder art and so are not great examples of Panda3D's visual capabilities.

Panda3D was developed by Disney for their massively multiplayer online game, Toontown Online. It was released as free software in 2002. Carnegie Mellon University's Entertainment Technology Center, which currently hosts the website and other Panda3D services, was actively involved in the development of Panda3D into an open source project. It is now developed jointly by Disney and contributors from around the world.

You can read more about [http://panda3d.org/features.php Panda3D's Features].

&lt;h2&gt;Panda3D is not a Beginner's Tool or a Toy&lt;/h2&gt;

To successfully use Panda3D, you must be a skilled programmer. If you do
not know what an &quot;API&quot; is, or if you don't know what a &quot;tree&quot; 
is, you will probably find Panda3D overwhelming.  This is no
point-and-click game-maker: this is a tool for professionals. While it is important to point that out so you have accurate expectations, it's also relevant to be aware that Panda3D is one of the easiest and most powerful engines you will ever use, and we welcome your participation.

If you are just getting started with programming, 
we suggest that your best option is to start with a class on
programming.  Alternately, you could try teaching yourself using a training
tool like [http://alice.org Alice], from CMU.

Panda3D supports the full range of what modern engines
should: it provides convenient support for normal mapping, gloss mapping,
HDR, cartoon shading and inking, bloom, and a number of other things.
It also allows you to write your own shaders.

People sometimes have the mistaken impression that Panda3D is written
in Python, which would make it very slow. But Panda3D is
not written in Python; it's written in C++. Python is just used for
scripting. Developers usually write the performance-intensive bits, if any, 
in C++ or something similar [http://www.panda3d.org/blog/panda3d-and-cython/ Cython].  To see what kind of framerate
a small Panda3D program typically gets, take a look at the screenshots
of the [[Sample Programs in the Distribution|Sample Programs]].
Those were taken using an old Radeon x700.
Of course, only a sample program can run at 400 fps like that, but for a real game, 60 fps is quite attainable.  One caveat, though:
to get that kind of performance, you need to understand 3D cards and
3D performance optimization.  It doesn't happen automatically.  Panda3D
includes profiling tools you need to hit 60 fps.

&lt;h2&gt;Panda3D's Software License&lt;/h2&gt;

Since version 1.5.3, Panda3D has been released under the so-called &quot;Modified BSD license,&quot; which is a free software license with very few restrictions on usage.  In versions 1.5.2 and before, it used a proprietary license which was very similar in intention to the BSD and MIT licenses, though there was some disagreement about the freeness of two of the clauses. The old license can still be accessed [http://panda3d.cvs.sourceforge.net/viewvc/*checkout*/panda3d/doc/doc/LICENSE?revision=1.1 here].

Although the engine itself is completely free, it comes with various third-party libraries that are not free software. Some of them (like FMOD) even restrict you from using them in commercial games unless you have licensed copies. Because of this reason, Panda3D makes it easy to disable or remove these restricted third-party libraries, and most of the time it offers an alternative. For example, it also comes with OpenAL which you can use instead of FMOD.

You can read [http://panda3d.org/license.php Panda3D's License].

&lt;h2&gt;Who is Working on Panda3D&lt;/h2&gt;

There are a number of developers in the commercial and open-source community. Currently, besides the active contributions from the open-source community, the most active member of the development community is Disney.
Disney's primary interest in Panda3D is commercial. Panda3D is being used in the development of a number of Disney games and amusement-park exhibits. To serve Disney's needs, Panda3D must be a fully-featured engine, capable of all the performance and quality one expects in any 'A-grade' commercial title.

The most supported language is Python. Though you can use C++ too, the documentation is mostly aimed at Python use.

&lt;h2&gt;The Introductory Chapter&lt;/h2&gt;

This introductory chapter of the manual is designed to walk you through
some of the basics of using Panda3D. This chapter is structured as a
tutorial, not as a reference work.</text>
    </revision>
  </page>
  <page>
    <title>Introduction to p3d files</title>
    <ns>0</ns>
    <id>2391</id>
      <sha1>k1edcw7yjx9y2213wk09ci80tpefxdh</sha1>
    <revision>
      <id>6230</id>
      <timestamp>2009-10-17T15:15:28Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="1205">The p3d file is the heart of Panda's packaging system.  When you
package your application for distribution, you will pack it into a p3d
file.  This file contains everything you need to run your application:
Python code, models, textures, prc files, even compiled dll's or pyd's
if part of your application is written in C++.

The p3d file is really a Panda multifile object; you can inspect its
contents or add and remove components with the multify command, as
with any multifile.  However, a p3d file is a special kind of
multifile that is specifically intended to contain a Panda
application.  The file extension &quot;.p3d&quot; is used to differentiate it
from a generic multifile (which may contain anything whatsoever).

Although it is possible to build a p3d file up by hand using the
multify command, it's usually easier to use one of the packaging tools
provided, such as packp3d or ppackage, to create a new p3d file from
an application on disk.

The p3d file indicates the particular version of Panda3D that should
be used to run your application. This allows you to write an
application using a particular version of Panda3D, without being
forced to update it when a new version of Panda3D is released.</text>
    </revision>
  </page>
  <page>
    <title>Introductory Tutorials</title>
    <ns>0</ns>
    <id>2057</id>
    <redirect title="Tutorials" />
      <sha1>0gix2xri4j3grz0gx8k3mmlakxagwjj</sha1>
    <revision>
      <id>4070</id>
      <timestamp>2007-02-15T15:53:01Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>[[Introductory Tutorials]] moved to [[Tutorials]]: changed to tutorials</comment>
      <text xml:space="preserve" bytes="23">#REDIRECT [[Tutorials]]</text>
    </revision>
  </page>
  <page>
    <title>Issues with Using Cg as Of Panda 1.0.4</title>
    <ns>0</ns>
    <id>1152</id>
      <sha1>4hngmuo751xkd93y1hynpgrsoegyrwl</sha1>
    <revision>
      <id>4056</id>
      <timestamp>2007-02-15T13:37:29Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>fixed typing error</comment>
      <text xml:space="preserve" bytes="1813">Caution: it is well-known that the panda/Cg interface is flaky.  We plan on spending the fall semester, 2005 making a much better shader interface.

&lt;h2&gt;Bugs Encountered When Using Cg&lt;/h2&gt;

* CgShader.setParam uses overloading to determine what type of parameter you want to set.  But since python doesn't have a &quot;float&quot; data type, it only has &quot;double&quot;, there is no way to pass a &quot;uniform float&quot; parameter.

* Panda does not calculate normals on models unless you [[Lighting|enable lighting]] for them. Therefore, if you want to do anything that needs normals (like lighting) through Cg you must first set up Panda's lights.

* You need at least one model in your scene that is not affected by a CgShaderAttrib. Otherwise the default camera controls will not work. A know fix around the problem is to add a transparent teapot (or any other model you want) to your scene, but &lt;b&gt;not&lt;/b&gt; by parenting it to the Cg affected node.

* There are subtle issues with using textures with Cg. You must still call &lt;code&gt;setTexture()&lt;/code&gt; with the &lt;code&gt;TextureStage&lt;/code&gt; object thats setup for the coordinates you want to use. The order in which you call &lt;code&gt;setTexture()&lt;/code&gt; decides the TEXCOORD number in Cg. If you use the default &lt;code&gt;TextureStage&lt;/code&gt; in &lt;code&gt;setTexture()&lt;/code&gt; you must pass the same texture that you pass into Cg. Otherwise, &lt;code&gt;setTexture()&lt;/code&gt; seems to override the CgShader. See [[Multitexture Introduction]] for more information on using textures.

* The PSIZE semantic is currently not enabled.

* You cannot currently pass a Cg matrix you make yourself. You can pass them in row by row and reconstruct your matrix in the Cg program. Hopefully this will be fixed soon.

* There seems to be issues with passing the correct model matrix to Cg. Hopefully this will be fixed soon.</text>
    </revision>
  </page>
  <page>
    <title>Joystick Support</title>
    <ns>0</ns>
    <id>986</id>
      <sha1>28mc1tcyedjrqftn5e18awok2hgf9yh</sha1>
    <revision>
      <id>59902</id>
      <timestamp>2014-05-11T08:38:05Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <text xml:space="preserve" bytes="1689">Note: I have been told that these instructions are inaccurate.  - Josh

While Panda3D has mouse and keyboard support, it is best to look to the open source community for joystick support.  Pyglet is a Python library with joystick and gamepad support that may be used; the relevant modules can be extracted from the Pyglet source code.  The advantage is that pyglet is pure Python and can be used without pulling in heavy C++ modules such as SDL.

Alternatively, Pygame is an open-source module that contains joystick support that may be easily included into a Panda3D application.  This is not recommended since Pygame is relatively big and pulls in C++ modules such as SDL. Pygame may be found at [http://www.pygame.org http://www.pygame.org].

After downloading pygame, simply import the modules as you would any Panda3D module.

&lt;code python&gt;
import pygame
&lt;/code&gt;

Once pygame is imported, it needs to be initialized. Also, when the program is through with using pygame, it should be exited cleanly.

&lt;code python&gt;
pygame.init()
pygame.quit() 
&lt;/code&gt;

Also, the joystick should be initialized. It too has a quit function.

&lt;code python&gt;
joystick.init()
joystick.quit()
&lt;/code&gt;

From here, it is possible to get the axis information of the joystick as well as the state of the buttons.

&lt;code python&gt;
# Consume PyGame events.
# This seems superfluous, but it is necessary.
# Otherwise get_axis and get_button don't work.
for e in pygame.event.get(): pass

joystick.get_axis(&lt;Axis&gt;)
joystick.get_button(&lt;Button&gt;)
&lt;/code&gt;

These are the primary functions for the joystick, but there are a number of other functions available for joystick support. This can be found at the pygame website.</text>
    </revision>
  </page>
  <page>
    <title>Keyboard Support</title>
    <ns>0</ns>
    <id>987</id>
      <sha1>feb817vz8nuhtjfirgtq199q4rbq7gu</sha1>
    <revision>
      <id>60460</id>
      <timestamp>2015-01-20T06:08:17Z</timestamp>
      <contributor>
        <username>MRamesh</username>
        <id>22861</id>
      </contributor>
      <comment>/* Keyboard events */</comment>
      <text xml:space="preserve" bytes="12039">== Keyboard events ==
Panda3D has keyboard support built-in.  Keyboard presses send [[Event Handling|Events]].  Each keyboard key will send an event when it is first pressed down, when it is released, and one repeatedly while its pressed.

The events can be accepted with the following code:

&lt;syntaxhighlight lang=&quot;python&quot;&gt;
self.accept(&lt;event name&gt;, &lt;function&gt;)
self.accept(&lt;event name&gt;, &lt;function&gt;, &lt;parameters list&gt;)
self.acceptOnce(&lt;event name&gt;, &lt;function&gt;)
self.acceptOnce(&lt;event name&gt;, &lt;function&gt;, &lt;parameters list&gt;)
&lt;/syntaxhighlight&gt;

&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
framework-&gt;define_key(&lt;event name&gt;, &lt;description&gt;, &lt;function&gt;, NULL);
framework-&gt;define_key(&lt;event name&gt;, &lt;description&gt;, &lt;function&gt;, &lt;data&gt;);
&lt;/syntaxhighlight&gt;

&lt;event name&gt; is a string that labels the event.
&lt;function&gt; is a python function to be called when the event is sent.
&lt;parameters list&gt; is a python list of parameters to use to call &lt;function&gt;. 

If you're wondering which events are being fired for certain keyboard activity, it is advised to call &lt;code&gt;base.messenger.toggleVerbose()&lt;/code&gt;.  This will cause Panda3D to print out all the events that are being sent to the command-line prompt.  This way, you can find out which keyboard key corresponds to which event name.

In general, the keyboard event naming follows the following rules:

1. Keys that type a character are named that character. It is always lowercase, even when shift or caps lock is pressed. (Shift and other modifiers are explained below.)

e.g.
&lt;pre class=&quot;codeblock&quot;&gt;
 &quot;a&quot;, &quot;b&quot;, &quot;3&quot;, &quot;[&quot;, etc.
&lt;/pre&gt;
not 
&lt;pre class=&quot;codeblock&quot;&gt;
 &quot;A&quot;, &quot;B&quot;, &quot;#&quot;, &quot;{&quot;
&lt;/pre&gt; 

2. The key down event is named for the key.

3. As of 1.3.0 The keyboard autorepeat is named for the key + &quot;-repeat&quot; e.g.

&lt;pre class=&quot;codeblock&quot;&gt;
 &quot;a-repeat&quot;, &quot;2-repeat&quot;, &quot;[-repeat&quot;
&lt;/pre&gt;

4. The key up event is named for the key + &quot;-up&quot; e.g.

&lt;pre class=&quot;codeblock&quot;&gt;
 &quot;a-up&quot;, &quot;2-up&quot;, &quot;[-up&quot;
&lt;/pre&gt;

5. All key events (including &quot;-up&quot;) have a corresponding time event labeled

&lt;pre class=&quot;codeblock&quot;&gt;  
&quot;time-&quot; + &lt;key name&gt;
&lt;/pre&gt;

Here is an example of time reading in code:

&lt;syntaxhighlight lang=&quot;python&quot;&gt;
class ReadKeys(DirectObject.DirectObject):
  def __init__(self):
      self.accept('time-a-repeat', self.printRepeat)

  def printRepeat(self, when):
      print &quot;repeat a&quot;, when
&lt;/syntaxhighlight&gt;

that send a time argument corresponding to the time that event was fired

6. Keys that don't type a character are labeled as follows:

&lt;pre class=&quot;codeblock&quot;&gt;
&quot;escape&quot;, &quot;f&quot;+&quot;1-12&quot; (e.g. &quot;f1&quot;,&quot;f2&quot;,...&quot;f12&quot;), &quot;print_screen&quot; &quot;scroll_lock&quot;
&quot;backspace&quot;, &quot;insert&quot;, &quot;home&quot;, &quot;page_up&quot;, &quot;num_lock&quot;
&quot;tab&quot;,  &quot;delete&quot;, &quot;end&quot;, &quot;page_down&quot;
&quot;caps_lock&quot;, &quot;enter&quot;, &quot;arrow_left&quot;, &quot;arrow_up&quot;, &quot;arrow_down&quot;, &quot;arrow_right&quot;
&quot;shift&quot;, &quot;lshift&quot;, &quot;rshift&quot;,
&quot;control&quot;, &quot;alt&quot;, &quot;lcontrol&quot;, &quot;lalt&quot;, &quot;space&quot;, &quot;ralt&quot;, &quot;rcontrol&quot;
&lt;/pre&gt;

Note that some key combinations (like &lt;code&gt;print_screen&lt;/code&gt; on Windows) may be intercepted by the operating system and may therefore not be available.  If you want to be able to catch these keys, you need to find some way to prevent the system from intercepting the events. (however, &quot;print_screen-up&quot; is still available in most cases.)

7. Some physical keys are distinguishable from the events that they fire, and some are not. The modifier keys distinguish between left and right, but send a neutral event as well. (e.g. the left shift key sends both &quot;lshift&quot; and &quot;shift&quot; events when pressed) Save for &quot;num_lock&quot;, &quot;*&quot;, and &quot;+&quot; the numpad keys are indistinguishable from the main keyboard counterparts. (e.g. when Num Lock is on the both the numpad and keyboard 1 keys send &quot;1&quot;)

Here are some examples in code:

&lt;syntaxhighlight lang=&quot;python&quot;&gt;
self.accept('k', self.__spam) # calls the function __spam() on the k key event.
self.accept('k-up', self.__spam, [eggs, sausage, bacon,]) # calls __spam(eggs,sausage,bacon)
self.accept('escape', sys.exit) # exit on esc
self.accept('arrow_up', self.spamAndEggs) # call spamAndEggs when up is pressed
self.accept('arrow_up-repeat', self.spamAndEggs) # and at autorepeat if held
self.accept('arrow_up-up', self.spamAndEggs) # calls when the up arrow key is released
&lt;/syntaxhighlight&gt;

&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
framework-&gt;define_key(&quot;k&quot;, &quot;call k&quot; __spam, NULL) # calls the function __spam(const Event* eventPtr, void* dataPtr) on the k key event.
framework-&gt;define_key(&quot;k&quot;, &quot;call k&quot; __spam, &amp;data) # calls the function __spam(const Event* eventPtr, void* dataPtr) on the k key event.
framework-&gt;define_key(&quot;escape&quot;, &quot;sys Exit&quot;, exit(0), NULL) # exit on esc
framework-&gt;define_key(&quot;arrow_up&quot;, &quot;spam and egg&quot;, spamAndEggs, NULL) # call spamAndEggs(const Event* eventPtr, void* dataPtr) when up is pressed
framework-&gt;define_key(&quot;arrow_up-repeat&quot;, &quot;spam and egg&quot;, spamAndEggs, NULL) # and at autorepeat if held
framework-&gt;define_key(&quot;arrow_up-up&quot;, &quot;spam and egg&quot;, spamAndEggs, NULL) # calls when the up arrow key is released
&lt;/syntaxhighlight&gt;

Please, note then when the Panda window is minimized or Panda3D loses focus somehow else, &quot;-up&quot; event is sent for all keys.  Read this forum thread to learn more: https://www.panda3d.org/forums/viewtopic.php?t=4630

== Modifier keys ==

When a key is pressed while a modifier key is pressed, such as shift, control or alt, it is not sent in the usual way.  Instead, the event name is modified by prepending the name of the modifier key to the event name, separated by a dash, in the order &quot;shift&quot;, &quot;control&quot;, &quot;alt&quot;, for example:

&lt;pre class=&quot;codeblock&quot;&gt;  
&quot;shift-a&quot; &quot;shift-control-alt-a&quot; &quot;shift-alt-a&quot;
&lt;/pre&gt;

These compound events don't send a &quot;time-&quot; event. If you need one, use the &quot;time-&quot; event sent by one of the keys in the combination.

The modifier compound events may optionally be turned off, in which case the &quot;a&quot; event and the &quot;shift&quot; event will be sent separately:

[python]&lt;syntaxhighlight lang=&quot;python&quot;&gt;
base.mouseWatcherNode.set_modifier_buttons(ModifierButtons())
base.buttonThrowers[0].node().set_modifier_buttons(ModifierButtons())
&lt;/syntaxhighlight&gt;
[/python][cxx]
&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
PT(MouseWatcher) mouseWatcher;
mouseWatcher = (MouseWatcher*)window-&gt;get_mouse().node();

if (mouseWatcher != NULL) {
  mouseWatcher-&gt;set_modifier_buttons(ModifierButtons());
}

ButtonThrower *bt = DCAST(ButtonThrower, window-&gt;get_mouse().get_child(0).node());
if (bt != NULL) {
  bt-&gt;set_modifier_buttons(ModifierButtons());
}
&lt;/syntaxhighlight&gt;[/cxx]


== Polling interface ==

The above interfaces make use of events to cause a method to be called when the key pressed or released.  However, in some situations, it may be more desirable to instead ask Panda every frame whether or not a certain key is pressed.  In this situation, you can use the polling interface instead, via the &lt;code&gt;is_button_down&lt;/code&gt; method on the MouseWatcher node.  (The name of this class is a bit misleading - it listens for keyboard events as well.)

&lt;syntaxhighlight lang=&quot;python&quot;&gt;
forward_speed = 5.0 # units per second
backward_speed = 2.0
forward_button = KeyboardButton.ascii_key('w')
backward_button = KeyboardButton.ascii_key('s')

def move_task(self, task):
    speed = 0.0

    # Check if the player is holding W or S
    is_down = base.mouseWatcherNode.is_button_down

    if is_down(forward_button):
        speed += forward_speed

    if is_down(backward_button):
        speed -= backward_speed

    # Move the player
    y_delta = speed * globalClock.get_dt()
    self.player.set_y(self.player, y_delta)
&lt;/syntaxhighlight&gt;


== Keystroke events ==

The interfaces described above are useful for listening for predetermined key presses, like navigational keys or hot keys, but not for text input.  Not only are there no events for fancy keys in foreign languages, but a single key press may not necessarily associate with a single letter to be entered in a text field.  This is because some international characters can only be typed using multiple key presses.

Therefore, Panda3D has a concept of a ''keystroke event'', which is used for text input.  Panda3D uses this under the hood for all GUI text entry.  If you are writing your own GUI widgets, it may be desirable for you to catch your own keystroke events.  To do this, it is first necessary to inform Panda3D which event name should be sent when a keystroke occurs, after which you can accept it as you would with any other event:
&lt;syntaxhighlight lang=&quot;python&quot;&gt;
base.buttonThrowers[0].node().setKeystrokeEvent('keystroke')
self.accept('keystroke', self.myFunc)

def myFunc(self, keyname):
    print(keyname)
&lt;/syntaxhighlight&gt;


== Raw keyboard events ==

Normally, when you listen for a keyboard event, the user's configured keyboard layout is taken into account.  This may present problems for key bindings that are determined by ''position'' on the keyboard.  For instance, when using the popular WASD control scheme for navigating the player, someone who's using an AZERTY or dvorak keyboard layout may have to bend their fingers in an unnatural way in order to use this scheme!

In light of this, Panda3D 1.9.0 introduces some features that will help to solve this problem.  The easiest way to fix this problem is to instead refer to the keys by how they would appear on an ANSI US (QWERTY) keyboard layout.  To do this, you can prepend the &lt;code&gt;raw-&lt;/code&gt; prefix to any key event.  This will cause Panda3D to ''ignore'' the user's configured keyboard layout, and instead report the key as if the user had set his keyboard layout to ANSI US.  It does this by interpreting the raw scancode as sent by the hardware, rather than the virtual key as reported by the operating system.  (Note that raw events do not have prefixes for modifier keys.)

This works for simple cases, but it is often necessary to have more specific information about the way the keys are mapped in the user's system.  For example, showing &quot;press W to move forward&quot; may be confusing on someone with an AZERTY layout, in which case it is more appropriate to say &quot;press Z to move forward&quot;.  When the application has a configuration screen for the keyboard control scheme, acquiring more information about the mapping may also be necessary.

This can be done using the &lt;code&gt;get_keyboard_map()&lt;/code&gt; on the GraphicsWindow object, returning a ButtonMap object, which can be used to find out which virtual key event will be fired for a certain raw keyboard button:
&lt;syntaxhighlight lang=&quot;python&quot;&gt;
# Get the current keyboard layout.
# This may be a somewhat expensive operation, so don't call
# it all the time, instead storing the result when possible.
map = base.win.get_keyboard_map()

# Use this to print all key mappings
print(map)

# Find out which virtual key is associated with the ANSI US &quot;w&quot;
w_button = map.get_mapped_button(&quot;w&quot;)

# Get a textual representation for the button
w_label = map.get_mapped_button_label(&quot;w&quot;)
if w_label:
    # There is none, use the event name instead.
    w_label = str(w_button)
w_label = w_label.capitalize()

# Use this label to tell the player which button to press.
self.tutorial_text = &quot;Press %s to move forward.&quot; % (w_label)

# Poll to check if the button is pressed...
if base.mouseWatcherNode.is_button_down(w_button):
    print(&quot;%s is currently pressed&quot; % (w_label))

# ...or register event handlers
self.accept(&quot;%s&quot; % (w_button), self.start_moving_forward)
self.accept(&quot;%s-up&quot; % (w_button), self.stop_moving_forward)
&lt;/syntaxhighlight&gt;

The above code example also illustrates the use of the &lt;code&gt;get_mapped_button_label&lt;/code&gt; function to get a textual representation for the button, if the operating system provides it.  This is most useful for keys like &quot;shift&quot; or &quot;enter&quot;, which may be called differently on different keyboards or in different languages.  However, this is both system-dependent and locale-dependent.  You should not rely on it being present, and if it is, you should not rely on consistent formatting or capitalization.

Of course, it is always advisable to still add in a configuration screen so that users can customize key bindings in case they find a particular control scheme difficult to use.</text>
    </revision>
  </page>
  <page>
    <title>Known Shader Bugs and Limitations</title>
    <ns>0</ns>
    <id>1721</id>
      <sha1>tb7nmmm6mt9bni16kk7fetzmn0nc5mj</sha1>
    <revision>
      <id>57098</id>
      <timestamp>2014-02-13T12:46:51Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>Cg on AMD sucks whale penis.  Just use GLSL, guys.</comment>
      <text xml:space="preserve" bytes="3496">&lt;b&gt;Known Bugs in the Shader Subsystem&lt;/b&gt;

Here is a list of known bugs, with workarounds:

&lt;b&gt;Problem: Register Allocation.&lt;/b&gt;

&lt;i&gt;Problem:&lt;/i&gt; nVidia's Cg compiler tries to assign registers to parameters.  Under a variety of circumstances, the Cg compiler will assign the same register to two parameters, or to a parameter and to a constant in the program.

&lt;i&gt;Workaround:&lt;/i&gt; We have found that if you manually allocate registers by supplying a semantic string for each parameter, this problem is bypassed.

&lt;b&gt;Problem: Bad Target Languages.&lt;/b&gt;

&lt;i&gt;Problem:&lt;/i&gt; nVidia's Cg compiler will choose one of several different &quot;target&quot; languages to translate the Cg program into.  When the Cg compiler tries to translate the program into the VP40/FP40 language, it often produces incorrect output.

&lt;i&gt;Workaround:&lt;/i&gt; We have discovered that translation into ARBvp1/ARBvp1 seems to work reliably.  Since that language is supported on essentially every video card, it is usually safe to translate into that language.  We have provided a config-variable that you can use to suppress bleeding edge stuff:

&lt;pre class=&quot;codeblock&quot;&gt;
basic-shaders-only #t
&lt;/pre&gt;
This variable is disabled by default, though on most non-NVIDIA cards, the ARBvp1/ARBfp1 profiles are still used by default in light of the problem above.

At some point, when functionality that is currently flaky becomes reliable,
we may expand the definition of what constitutes 'basic' shaders.

&lt;b&gt;Problem: Invalid output when using ATI/AMD cards.&lt;/b&gt;

&lt;i&gt;Problem:&lt;/i&gt; This is a specific case of the problem above.  The Cg Toolkit only supports two sets of profiles on most non-nVidia cards; the basic ARB profiles, and the GLSL profiles.  The ARB profiles are limited in functionality, which prompts people to use the GLSL profiles.  However, these often produce incorrect results (read: are completely broken) on ATI/AMD cards.

&lt;i&gt;Workaround:&lt;/i&gt; Enable &quot;basic-shaders-only #t&quot; as described above.  For advanced shader effects, write your shaders in GLSL instead of Cg if you intend to support non-nVidia cards.

&lt;b&gt;Problem: Cg program too complex for driver.&lt;/b&gt;

&lt;i&gt;Problem:&lt;/i&gt; Panda will translate the shader into the ARBvp1/ARBvp1 profile by default, for the reason stated above. If instructions are used that are not supported by these profiles, this error will occur.

&lt;i&gt;Workaround:&lt;/i&gt; The recommended approach is to first try and find out which instructions are causing it to fail to compile under the ARB profiles.  The most common problem is when a loop is used with a variable length, which cannot be unrolled by the compiler:
&lt;pre class=&quot;codeblock&quot;&gt;
for (i = 0; i &lt; k_iterations.x; ++i)
&lt;/pre&gt;
Instead, you should use a constant that is known at compile-time:
&lt;pre class=&quot;codeblock&quot;&gt;
#define ITERATIONS 10
for (i = 0; i &lt; ITERATIONS; ++i)
&lt;/pre&gt;

&lt;i&gt;Workaround:&lt;/i&gt; You need to disable the basic-shaders-only flag to allow Panda to translate the shaders into profiles that do support the used instructions:
&lt;pre class=&quot;codeblock&quot;&gt;
basic-shaders-only #f
&lt;/pre&gt;
Note that by doing so you might run into the problem above, and it is not recommended to do so unless you really need it.

&lt;b&gt;Problem: Untested/Unfinished DirectX Support.&lt;/b&gt;

&lt;i&gt;Problem:&lt;/i&gt; Shader development is currently being done in OpenGL.  The DirectX support typically lags behind, and is often less fully-tested.

&lt;i&gt;Workaround:&lt;/i&gt; The default setting for Panda is to use OpenGL, not DirectX.  For now, when using shaders, do not change this setting.</text>
    </revision>
  </page>
  <page>
    <title>Known bugs with Using Cg as Of Panda 1.0.4</title>
    <ns>0</ns>
    <id>1154</id>
    <redirect title="Issues with Using Cg as Of Panda 1.0.4" />
      <sha1>d3dhazqgrsy3tjpfds7smxd8oln87hu</sha1>
    <revision>
      <id>2435</id>
      <timestamp>2005-06-23T14:41:17Z</timestamp>
      <contributor>
        <username>Kmensah</username>
        <id>13</id>
      </contributor>
      <comment>Known bugs with Using Cg as Of Panda 1.0.4 moved to Issues with Using Cg as Of Panda 1.0.4</comment>
      <text xml:space="preserve" bytes="53">#REDIRECT [[Issues with Using Cg as Of Panda 1.0.4]]
</text>
    </revision>
  </page>
  <page>
    <title>Learning Python</title>
    <ns>0</ns>
    <id>933</id>
      <sha1>phoiac9h4m842xq45sp7s6u21eteeq1</sha1>
    <revision>
      <id>2214</id>
      <timestamp>2005-04-16T22:08:50Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="0" />
    </revision>
  </page>
  <page>
    <title>Lenses and Field of View</title>
    <ns>0</ns>
    <id>988</id>
      <sha1>e777a958nftz6uczzzade79bctebtzt</sha1>
    <revision>
      <id>4324</id>
      <timestamp>2007-05-26T15:40:49Z</timestamp>
      <contributor>
        <username>ThomasEgi</username>
        <id>111</id>
      </contributor>
      <comment>-removed spamlinks</comment>
      <text xml:space="preserve" bytes="9760">Every Camera has a Lens object that defines the properties of its view.  For simple applications, you do not need to think about the lens; you will probably be happy with the default lens properties.  However, you will occasionally want to adjust some properties of the lens, such as its field of view, and there are several interfaces to do this, depending on how you want to think about the lens.

When you start Panda3D, a default camera and lens are created for you automatically.  The default camera object is stored in &lt;code&gt;base.cam&lt;/code&gt; (although by convention, if you want to move the default camera you should manipulate &lt;code&gt;base.camera&lt;/code&gt; instead), and the default lens is &lt;code&gt;base.camLens&lt;/code&gt;.

This default lens will almost always be a perspective lens--that is, an instance of the class &lt;code&gt;PerspectiveLens&lt;/code&gt;--unless you have done something to change it to another kind of lens.  A perspective lens is by far the most common kind of lens used, and it behaves the same way the physical lens in a camera works, or for that matter the same way the lenses in our eyes work:

[[Image:Lens tutorial perspective.jpg|Lens tutorial, perspective view]]

The illustration above shows a camera with an ordinary perspective lens observing a model in the world.  The camera can only see the part of the world that falls within the black lines; this area is called the lens &lt;b&gt;frustum&lt;/b&gt;.

In the picture, you can also see the image that the lens is capturing (and that image is shown upside-down, just as it would be in a real, physical camera).  This image is just for the purposes of illustration; it isn't really part of a Panda3D camera.  It is included to help show the relationship between a Panda3D lens and a real, physical lens.

There are several different properties that can be set on a PerspectiveLens.  Not all of them are independent; setting some properties will change the values of other properties.  Here is an illustration:

[[Image:Lens tutorial top.jpg|Lens tutorial, top view]]

A. This point is the &lt;b&gt;nodal point&lt;/b&gt; or eyepoint of the lens.  It is also (usually) the origin, that is, the (0, 0, 0) point of the camera that holds the lens.  Normally (in a default Z-up coordinate system), the lens will be looking down the +Y axis, so in the above illustration the +Y axis extends to the right from point A.  The plane containing the nodal point, perpendicular the viewing direction (that is, the plane corresponding to the vertical line through point A), is called the &lt;b&gt;camera plane&lt;/b&gt;.

Although it is possible to change the nodal point or view direction of a lens to some point other than (0, 0, 0) or some direction other than down the +Y axis, it is usually simplest and best just to move the entire camera using the basic NodePath operations like setPos() and setHpr().

B. This angle is the &lt;b&gt;field of view&lt;/b&gt;, or fov, of the lens.  You can easily change this by setting a new value in degrees with &lt;code&gt;lens.setFov(angle)&lt;/code&gt;.  Making the field of view smaller will bring things in closer, like a telephoto lens; it will also diminish the visible effects of perspective.  Making the field of view larger will open up the view to more objects, like a wide-angle lens; it will also increase the visible distortion of perspective.  The field of view must be greater than 0 degrees and less than 180, but values greater than 90 will seem extremely distorted.  (In the real world, perspective lenses rarely go wider than 80 degrees, and that's pretty wide.)  The default field of view is 40 degrees, which is usually a pretty comfortable viewing angle.

There is actually a separate horizontal field of view and vertical field of view, both of which may be independently controlled with the two-parameter form of setFov: &lt;code&gt;lens.setFov(horizontalAngle, verticalAngle)&lt;/code&gt;.  Using the two-parameter form will change the &lt;b&gt;aspect ratio&lt;/b&gt; of the lens (see below).  Normally, you would set the field of view using only the one-parameter form, which sets the horizontal field of view directly, and automatically recomputes the vertical field of view to preserve the same aspect ratio.

C. This distance is called the &lt;b&gt;near distance&lt;/b&gt; or &lt;b&gt;near plane&lt;/b&gt; of the lens.  Objects that are closer than this to the camera plane will not be rendered.  You may set the near distance as small as you like, but it must be greater than 0; and the smaller you set it, the greater the likelihood that you will observe an artifact called &lt;b&gt;Z-fighting&lt;/b&gt;, a shimmering of objects that are off in the distance.  The default near distance is 1.0, which for many scenes is a reasonable compromise.  Of course, the most appropriate value for your scene depends on the nature of the scene (as well as the measurement units in which your scene is modeled).

You may change the near distance at any time with the call &lt;code&gt;lens.setNear(distance)&lt;/code&gt;.

D. This is the &lt;b&gt;far distance&lt;/b&gt; or &lt;b&gt;far plane&lt;/b&gt; of the lens.  Similar to the near distance, objects that are farther than this from the camera plane will not be rendered.  You may set this as large as you like, but like the near distance, setting it too large may result in Z-fighting.  (However, the near distance value has a much greater impact on Z-fighting than the far distance value, because of the nature of the math involved.)  The default far distance is 1000.0, which is appropriate for small scenes; you may need to set it larger if you have a large scene.

You may change the far distance with the call &lt;code&gt;lens.setFar(distance)&lt;/code&gt;.  Since the near distance and far distance are often changed at the same time, there is a convenience function to set then both: &lt;code&gt;lens.setNearFar(nearDistance, farDistance)&lt;/code&gt;.

E. This size is the &lt;b&gt;film size&lt;/b&gt; of the lens.  This is only an abstract concept in Panda3D; it is designed to simulate the actual film size of a physical lens.  In a real, physical camera, the lens casts light onto a piece of film behind the lens, and the size of the film impacts the effective field of view of the lens via a mathematical formula that every photographer knows (and which I won't repeat here).  In Panda3D, you will probably ignore the film size, unless you are a photographer, or you want to set up a virtual lens that exactly matches the properties of some real, physical lens.

You can specify the film size with &lt;code&gt;lens.setFilmSize(width)&lt;/code&gt; or &lt;code&gt;lens.setFilmSize(width, height)&lt;/code&gt;.  Like field of view, the film size has two components, a horizontal film size and a vertical film size.  Also like field of view, if you specify both components at once it will change the &lt;b&gt;aspect ratio&lt;/b&gt; of the lens, but if you set only the width, Panda will automatically compute the height to keep the aspect ratio the same.

Setting the film size defines the units to be used for some of the other advanced lens properties, such as the &lt;b&gt;focal length&lt;/b&gt; (below) and the &lt;b&gt;lens offset&lt;/b&gt;.  For instance, a 35mm camera exposes a rectangle on the film about 24mm x 36mm, so if you wanted to simulate a 35mm camera, you would use &lt;code&gt;lens.setFilmSize(24, 36)&lt;/code&gt;.  This establishes that your film units are in millimeters, so you could then specify a lens with a focal length of 50mm using &lt;code&gt;lens.setFocalLength(50)&lt;/code&gt;.  (Setting both the film size and the focal length like this would automatically calculate the field of view; see below.)

F. This distance is the &lt;b&gt;focal length&lt;/b&gt; of the lens.  Like film size, this is only an abstract concept in Panda3D, but it is a very important concept in a real, physical camera.  Technically, it is the distance between a lens's nodal point or camera plane and its focal plane or film plane, and it affects the field of view of the lens.  In real photography, lenses are typically described by their focal length, rather than by their field of view.  You can set the focal length via &lt;code&gt;lens.setFocalLength(distance)&lt;/code&gt;.

G (not pictured). The final important property of a lens is its &lt;b&gt;aspect ratio&lt;/b&gt;.  This is the ratio of the width to the height of the image produced by the lens.  It is almost, but not quite, the same as the ratio of the horizontal field of view to the vertical field of view.  (It is not quite this, because a perspective lens is not linear in proportion to the angle.)  Normally, you will want the aspect ratio of the lens to match the aspect ratio of your window; if it is something different, the image may seem stretched or squashed.

You can set the aspect ratio explicitly via &lt;code&gt;lens.setAspectRatio(ratio)&lt;/code&gt;.  For instance, if you open a window that is 800 pixels wide and 300 pixels tall, you might want to call &lt;code&gt;lens.setAspectRatio(800.0 / 300.0)&lt;/code&gt;.

&lt;h2&gt;Interplay of lens properties&lt;/h2&gt;

Note that, as mentioned above, several of these properties are interrelated.  In particular, the field of view, focal length, and film size are closely tied together.  Setting any two of these three properties will implicitly define the third one.

Panda will let you set all three of these properties as often as you like, but only the last two properties you set will be important.  That is, if you set field of view and film size, Panda will calculate the focal length.  If you set film size and focal length, Panda will calculate the field of view.  If you set focal length and field of view, Panda will calculate the film size.

Also, the aspect ratio can be set either implicitly, by using the two-parameter &lt;code&gt;setFov()&lt;/code&gt; or &lt;code&gt;setFilmSize()&lt;/code&gt; methods, or explicitly, by directly specifying it with &lt;code&gt;setAspectRatio()&lt;/code&gt;.  If you set the aspect ratio explicitly, Panda will recompute your vertical field of view and vertical film size to match.</text>
    </revision>
  </page>
  <page>
    <title>Lenses and the Field of View</title>
    <ns>0</ns>
    <id>2318</id>
    <redirect title="Lenses and Field of View" />
      <sha1>tu4rwyaw1vv77afs68cn5zgbyz28hb3</sha1>
    <revision>
      <id>5728</id>
      <timestamp>2009-03-26T18:49:53Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[Lenses and Field of View]]</comment>
      <text xml:space="preserve" bytes="38">#REDIRECT [[Lenses and Field of View]]</text>
    </revision>
  </page>
  <page>
    <title>Lerp Intervals</title>
    <ns>0</ns>
    <id>989</id>
      <sha1>gqmkbk3w4hlzzdcxyj9vmiwym91ktf0</sha1>
    <revision>
      <id>7992</id>
      <timestamp>2013-05-14T15:55:34Z</timestamp>
      <contributor>
        <username>Croxis</username>
        <id>430</id>
      </contributor>
      <text xml:space="preserve" bytes="9050">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;
[python]
&lt;p&gt;The &lt;code&gt;LerpInterval&lt;/code&gt; is the main workhorse of the Interval system. The word &quot;lerp&quot; is short for &quot;linearly interpolate&quot; and means to smoothly adjust properties, such as position, from one value to another over a period of time. You can use &lt;code&gt;LerpIntervals&lt;/code&gt; to move and rotate objects around in your world.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;LerpInterval&lt;/code&gt; is also the most complex of all of the intervals, since there are many different parameters that you might want to specify to control the lerp.&lt;/p&gt;

&lt;h2&gt;An overview of the NodePath-based LerpIntervals&lt;/h2&gt;

&lt;p&gt;Most &lt;code&gt;LerpIntervals&lt;/code&gt; adjust the various transform properties of a &lt;code&gt;NodePath&lt;/code&gt;, such as &lt;code&gt;pos&lt;/code&gt;, &lt;code&gt;hpr&lt;/code&gt;, and &lt;code&gt;scale&lt;/code&gt;, and they all have a similar form. Consider the &lt;code&gt;LerpPosInterval&lt;/code&gt;, which will smoothly move a model from one point in space to another:&lt;/p&gt;

&lt;code python&gt;
from direct.interval.LerpInterval import LerpPosInterval
i = LerpPosInterval(nodePath,
                    duration,
                    pos,
                    startPos=None,
                    other=None,
                    blendType='noBlend',
                    bakeInStart=1,
                    fluid=0,
                    name=None)
&lt;/code&gt;

&lt;p&gt;The only required parameters are the model whose position is being changed, the length of time to apply the move, and the model's new position. The remaining parameters are all optional and are often omitted.&lt;/p&gt;

&lt;p&gt;Here is a breakdown of what each parameter means:&lt;/p&gt;

&lt;table&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;&lt;p&gt;&lt;code&gt;nodePath&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;The model whose position is being changed.&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;&lt;p&gt;&lt;code&gt;duration&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;The duration of the lerp in seconds.&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;&lt;p&gt;&lt;code&gt;pos&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;The model's target position (the new position it will move to).  Usually this is a &lt;code&gt;Point3(x, y, z)&lt;/code&gt;, but as a special advanced feature, it might be a Python function that, when called, returns a &lt;code&gt;Point3&lt;/code&gt;. If it is a function, then it will be called at the time the lerp actually begins to play.&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;&lt;p&gt;&lt;code&gt;startPos&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;The starting position of the model at the beginning of the lerp. If this is omitted, the model will start from its current position. As with &lt;code&gt;pos&lt;/code&gt;, above, this might be a Python function, which will be called at the time the lerp actually begins.&lt;/p&gt;

&lt;p&gt;Note that if you intend to move an object from its current position, it is better to omit this parameter altogether rather than try to specify it explicitly with something like &lt;code&gt;startPos=object.getPos()&lt;/code&gt; since the latter will be evaluated at the time the interval is created; not when it is played. This is especially true if you plan to embed a series of consecutive &lt;code&gt;LerpIntervals&lt;/code&gt; within a [[Sequences and Parallels|Sequence]].&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;&lt;p&gt;&lt;code&gt;other&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;Normally this is set to None to indicate a normal lerp. If a &lt;code&gt;NodePath&lt;/code&gt; is passed in, however, it indicates that this is a relative lerp, and the &lt;code&gt;pos&lt;/code&gt; and &lt;code&gt;startPos&lt;/code&gt; will be computed as a relative transform from that &lt;code&gt;NodePath&lt;/code&gt;. The relative transform is recomputed each frame, so if the other &lt;code&gt;NodePath&lt;/code&gt; is animating during the lerp, the animation will be reflected here. For this reason, you should not attempt to lerp a model relative to itself.&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;&lt;p&gt;&lt;code&gt;blendType&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;This specifies how smoothly the lerp starts and stops. It may be any of the following values:&lt;/p&gt;&lt;/td&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;&lt;/td&gt;
&lt;td&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;&lt;p&gt;&lt;code&gt;'easeIn'&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;The lerp begins slowly, ramps up to full speed, and stops abruptly.&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;&lt;p&gt;&lt;code&gt;'easeOut'&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;The lerp begins at full speed, and then slows to a gentle stop at the end.&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;&lt;p&gt;&lt;code&gt;'easeInOut'&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;The lerp begins slowly, ramps up to full speed, and then slows to a gentle stop.&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;&lt;p&gt;&lt;code&gt;'noBlend'&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;The lerp begins and ends abruptly.&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;&lt;p&gt;&lt;code&gt;bakeInStart&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;

&lt;td&gt;&lt;p&gt;This is an advanced feature. Normally this is 1, which means the original starting position of the model is determined when the interval starts to play and saved for the duration of the interval. You almost always want to keep it that way. If you pass this as 0, however, the starting position is cleverly re-inferred at each frame, based on the model's current position and the elapsed time in the lerp; this allows your application to move the model even while it is being lerped, and the lerp will adapt. This has nothing to do with controlling when the &lt;code&gt;startPos&lt;/code&gt; parameter is evaluated.&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;&lt;p&gt;&lt;code&gt;fluid&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;If this is 1, then the lerp uses &lt;code&gt;[func]setFluidPos[/func]()&lt;/code&gt; rather than &lt;code&gt;[func]setPos[/func]()&lt;/code&gt; to animate the model. See [[Rapidly-Moving Objects]]. This is meaningful only when the collision system is currently active on the model. Since usually there is no reason to have the collision system active while a model is under direct application control, this parameter is rarely used.&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;&lt;p&gt;&lt;code&gt;name&lt;/code&gt;&lt;/p&gt;&lt;/td&gt;

&lt;td&gt;&lt;p&gt;This specifies the name of the lerp, and may be useful for debugging. Also, by convention, there may only be one lerp with a given name playing at any given time, so if you put a name here, any other interval with the same name will automatically stop when this one is started. The default is to assign a unique name for each interval.&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;h2&gt;The rest of the NodePath-based LerpIntervals&lt;/h2&gt;

&lt;p&gt;Many &lt;code&gt;NodePath&lt;/code&gt; properties other than position may be controlled via a lerp. Here is the list of the various &lt;code&gt;LerpIntervals&lt;/code&gt; that control &lt;code&gt;NodePath&lt;/code&gt; properties:&lt;/p&gt;

&lt;code python&gt;
LerpPosInterval(nodePath, duration, pos, startPos)
LerpHprInterval(nodePath, duration, hpr, startHpr)
LerpQuatInterval(nodePath, duration, quat, startHpr, startQuat)
LerpScaleInterval(nodePath, duration, scale, startScale)
LerpShearInterval(nodePath, duration, shear, startShear)
LerpColorInterval(nodePath, duration, color, startColor)
LerpColorScaleInterval(nodePath, duration, colorScale, startColorScale)
&lt;/code&gt;

&lt;p&gt;Each of the above has a similar set of parameters as those of &lt;code&gt;LerpPosInterval&lt;/code&gt;. They also have a similar shortcut (e.g. &lt;code&gt;model.hprInterval()&lt;/code&gt;, etc.)&lt;/p&gt;

&lt;p&gt;Finally, there is a handful of combination &lt;code&gt;LerpIntervals&lt;/code&gt; that perform multiple lerps at the same time. (You can also achieve the same effect by combining several &lt;code&gt;LerpIntervals&lt;/code&gt; within a [[Sequences and Parallels|Parallel]], but these combination intervals are often simpler to use, and they execute just a bit faster.)&lt;/p&gt;

&lt;code python&gt;
LerpPosHprInterval(nodePath, duration, pos, hpr, startPos, startHpr)
LerpPosQuatInterval(nodePath, duration, pos, quat, startPos, startQuat)
LerpHprScaleInterval(nodePath, duration, hpr, scale, startHpr, startScale)
LerpQuatScaleInterval(nodePath, duration, quat, scale, startQuat, startScale)
LerpPosHprScaleInterval(nodePath, duration, pos, hpr, scale, startPos, startHpr, startScale)
LerpPosQuatScaleInterval(nodePath, duration, pos, quat, scale, startPos, startQuat, startScale)
LerpPosHprScaleShearInterval(nodePath, duration, pos, hpr, scale, shear, startPos, startHpr, startScale, startShear)
LerpPosQuatScaleShearInterval(nodePath, duration, pos, quat, scale, shear, startPos, startQuat, startScale, startShear)
&lt;/code&gt;

&lt;h2&gt;Other types of LerpInterval&lt;/h2&gt;

&lt;p&gt;Beyond animating NodePaths, you can create a &lt;code&gt;LerpInterval&lt;/code&gt; that blends any parameter of any object over time. This can be done with a &lt;code&gt;LerpFunctionInterval&lt;/code&gt;:&lt;/p&gt;

&lt;code python&gt;
def myFunction(t):
  # Do something based on t.

i = LerpFunc(myFunction,
             fromData=0,
             toData=1,
             duration=0.0,
             blendType='noBlend',
             extraArgs=[],
             name=None)
&lt;/code&gt;

&lt;p&gt;This advanced interval has many things in common with all of the above &lt;code&gt;LerpIntervals&lt;/code&gt;, but instead of directly animating a value, it instead calls the function you specify, passing a single floating-point parameter, &lt;code&gt;t&lt;/code&gt;, that ranges from &lt;code&gt;fromData&lt;/code&gt; to &lt;code&gt;toData&lt;/code&gt; over the duration of the interval.&lt;/p&gt;

&lt;p&gt;It is then up to your function to set whatever property of whatever object you like according to the current value of &lt;code&gt;t&lt;/code&gt;.&lt;/p&gt;
[/python]
[cxx]
&lt;h2&gt;Incomplete Section&lt;/h2&gt;

&lt;p&gt;Note: this section is incomplete. It will be updated soon.&lt;/p&gt;
[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Level of Detail</title>
    <ns>0</ns>
    <id>2627</id>
      <sha1>a2c8iac3sdgjszc3xv15mmkyebm3rrg</sha1>
    <revision>
      <id>7417</id>
      <timestamp>2011-12-07T09:28:39Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>&quot;disappear&quot;</comment>
      <text xml:space="preserve" bytes="1662">Using multiple levels of detail for a part of your scene can help improve performance. For example you could use LOD to simplify an Actor that is far away, saving on costly vertex skinning operations. Another use would be to combine several small objects into a simplified single object, or to apply a cheaper shader. LOD can also be used to hide objects when they are far away.

[cxx]
Include file:
&lt;code cxx&gt;#include &quot;lodNode.h&quot;&lt;/code&gt;[/cxx]

To create an LODNode and NodePath:
[python]
&lt;code python&gt;lod = LODNode('my LOD node')
lod_np = NodePath(lod)
lod_np.reparentTo(render)&lt;/code&gt;[/python]
[cxx]
&lt;code cxx&gt;PT(LODNode) lod = new LODNode(&quot;my LOD node&quot;);
NodePath lod_np (lod);
lod_np.reparent_to(render);&lt;/code&gt;[/cxx]

To add a level of detail to the LODNode:
[python]
&lt;code python&gt;lod.addSwitch(50.0, 0.0)
my_model.reparentTo(lod_np)&lt;/code&gt;[/python]
[cxx]
&lt;code cxx&gt;lod-&gt;add_switch(50.0, 0.0);
my_model.reparent_to(lod_np);&lt;/code&gt;[/cxx]
my_model can be any NodePath you like.

Note that the first argument is the &quot;far&quot; distance after which this LOD will disappear, and the second argument is the &quot;near&quot; distance at which it will appear.

Continue this pattern to add as many levels of detail as you like. For your lowest level of LOD the far distance will be where the model will disappear. If you would prefer it to stay visible even when very far away then use a sufficiently large number for the far distance.

Note that the order in which the switches are added must be the same as the order in which the LODs are reparented to the LODNode's NodePath. This is important to remember if you are not reparenting the LOD immediately after adding the switch.</text>
    </revision>
  </page>
  <page>
    <title>License Info</title>
    <ns>0</ns>
    <id>2323</id>
      <sha1>hhgf2n0r8qn40udn2cfs6jsurql9wy8</sha1>
    <revision>
      <id>7845</id>
      <timestamp>2012-10-06T19:55:57Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>add freetype info</comment>
      <text xml:space="preserve" bytes="4863">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

&lt;p&gt;While Panda3D itself uses the Modified BSD license, it brings together many third-party libraries released under different licenses. This page provides information on the different libraries and their licenses.&lt;/p&gt;


==Disclaimer==
&lt;p&gt;Panda3D takes no responsibility for any act committed using the information presented here. For legal advice, it is recommended to consult a lawyer.&lt;/p&gt;


==Library Index==
&lt;p&gt;
{| class=&quot;wikitable sortable&quot; border=&quot;1&quot; cellpadding=&quot;5&quot; cellspacing=&quot;0&quot;
!width=&quot;20%&quot;|Library
!width=&quot;30%&quot;|License
!width=&quot;50%&quot;|Notes
|-
| [http://www.panda3d.org Panda3D]
| [http://www.panda3d.org/license.php BSD license]
|
|-
| [http://www.python.org Python]
| [http://www.python.org/download/releases/2.6.2/license PSF license]
|
|-
| [http://www.zlib.net ZLib]
| [http://www.zlib.net/zlib_license.html zlib license]
| 
|-
| [http://www.libpng.org libpng]
| [http://www.libpng.org/pub/png/src/libpng-LICENSE.txt libpng license]
| 
|-
| [http://www.ijg.org libjpeg]
| libjpeg license
|
|-
| [http://www.remotesensing.org/libtiff libtiff]
| [http://www.epsiia.com/licenses/libtiff.html libtiff license]
| 
|-
| [http://code.google.com/p/libsquish squish]
| MIT license
| 
|-
| [http://www.openssl.org OpenSSL]
| [http://www.openssl.org/source/license.html OpenSSL license]
| Must include this acknowledgement with distribution:
&lt;center&gt;&lt;code text&gt;This product includes software written by Tim Hudson (tjh@cryptsoft.com)&lt;/code&gt;&lt;/center&gt;&lt;br /&gt;&lt;br /&gt;
[http://rechten.uvt.nl/koops/cryptolaw Some governments] place restrictions on cryptography.
|-
| [http://www.feelingsoftware.com/en_US/3D-collada-tools/collada-tools/collada-premium/fcollada.html FCollada]
| MIT license
|
|-
| [http://www.cs.unc.edu/Research/vrpn VRPN]
| [http://www.cs.unc.edu/Research/vrpn/obtaining_vrpn.html Public domain]
|
|-
| [http://opencv.willowgarage.com/wiki OpenCV]
| BSD license
| 
|-
| [http://freetype.sourceforge.net FreeType]
| [http://freetype.sourceforge.net/FTL.TXT FreeType License] or [http://freetype.sourceforge.net/GPL.TXT GPL]
| To distribute under a proprietary license, FreeType License must be chosen instead of GPLv2.  Use of FreeType must be acknowledged in product documentation.
|-
| [http://netpbm.sourceforge.net Netpbm]
| Artistic License or MIT license or GPL
|
|-
| [http://www.ffmpeg.org FFmpeg]
| [http://www.ffmpeg.org/legal.html LGPL]
| Must link dynamically. 
|-
| [http://www.ode.org/ode.html Open Dynamics Engine (ODE)]
| [http://www.ode.org/ode-license.html LGPL or Modified BSD License]
|
|-
| [http://bulletphysics.org Bullet Physics]
| [http://www.zlib.net/zlib_license.html zlib license]
|
|-
| [http://librocket.com/ libRocket]
| [http://librocket.com/wiki/license MIT License]
|
|-
| [http://www.hitl.washington.edu/artoolkit ARToolKit]
| [http://www.hitl.washington.edu/artoolkit/license.html GPL or Proprietary]
|  To distribute under a proprietary license, GPL must not be used, and ARToolKit proprietary license must be purchased.
|-
| [http://www.fftw.org FFTW]
| [http://www.fftw.org/fftw3_doc/License-and-Copyright.html GPL or Proprietary]
| To distribute under a proprietary license, GPL must not be used, and FFTW proprietary license must be purchased.
|-
| [http://msdn.microsoft.com/en-us/library/d06h2x6e%28VS.80%29.aspx MFC]
| Proprietary
| Windows libraries.
|-
| [http://msdn.microsoft.com/en-us/directx/default.aspx DirectX]
| Proprietary
| Windows libraries.
|-
| [http://developer.nvidia.com/object/cg_toolkit.html Nvidia Cg Toolkit]
| [http://developer.download.nvidia.com/cg/Cg_2.2/license.pdf Proprietary]
| Required to use the Panda3D Shader Generator, which utilizes Nvidia Cg.
|-
| [http://www.fmod.org FMOD]
| [http://www.fmod.org/index.php/sales Proprietary]
| Non-commercial distribution costs nothing.
Commercial distribution costs between US$100 and US$6000 depending on FMOD licensing option.
|}
&lt;/p&gt;


==Patent Restriction Issues==
===MP3===
&lt;p&gt;MPEG-1 Audio Layer 3 (MP3), while commonly used, is recommended against. The format has patent and licensing issues in many countries. Unlicensed use of MP3 runs the risk of infringing in these countries. [http://mp3licensing.com/royalty/software.html Licensing] the use of MP3 costs at minimum royalties of US$15000 per calendar year.&lt;/p&gt;

===MPEG===
&lt;p&gt;Other MPEG related formats are restricted by [http://www.mpegla.com/main/default.aspx patents] as well. Finding the prices of licenses for these formats is not even as easy as it is with MP3. More info [http://bemasc.net/wordpress/2010/02/02/no-you-cant-do-that-with-h264/ here].&lt;/p&gt;

===Recommended Alternatives===
&lt;p&gt;Free alternatives exist and are highly encouraged. These formats include [http://www.vorbis.com Ogg Vorbis] (lossy) and [http://flac.sourceforge.net Ogg FLAC] (lossless) for audio, and [http://www.theora.org Ogg Theora] for video.&lt;/p&gt;</text>
    </revision>
  </page>
  <page>
    <title>Light Ramps</title>
    <ns>0</ns>
    <id>2218</id>
      <sha1>5z63bqt5ew8omqo8pgb8n6w7h89039w</sha1>
    <revision>
      <id>7630</id>
      <timestamp>2012-03-08T17:46:28Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="3241">==Light Ramps==

In standard OpenGL and DirectX lighting, the following calculations are performed:

* the lighting value is calculated
* it is clamped to the range 0-1
* it is combined with the textures
* it is clamped to the range 0-1 again
* it is written to the frame buffer

This process contains two clamps.  The LightRampAttrib is a means to specify that you wish to replace these two clamping operators with something a little smarter.  This is particularly relevant for two major graphics algorithms: HDR tone mapping, and cartoon shading.

It must be emphasized that light ramps have no effect unless per-pixel
lighting is enabled via [[The Shader Generator|the shader generator]].

==HDR Tone Mapping==

In HDR tone mapping, the first clamp is removed entirely, and the second one is
replaced with the tone mapping operator.  The tone mapping operator maps brightness values in the range 0-infinity to new brightness values in the range 0-1, however, it does so without clamping.  To turn on HDR tone mapping, use one of the following:

&lt;code python&gt;
np.setAttrib(LightRampAttrib.makeHdr0())
np.setAttrib(LightRampAttrib.makeHdr1())
np.setAttrib(LightRampAttrib.makeHdr2())
&lt;/code&gt;

The HDR2 tone mapping operator is a familiar operator that is used in many systems.  It has the downside that it tends to reduce contrast a lot:

* FINAL_RGB = (RGB) / (RGB + 1)

The HDR1 tone mapping operator is similar, but it allocates more of the contrast range to brightnesses in the range 0-1, and less to brightnesses in the range 1-infinity.  This yields a higher-contrast scene, but with more washout:

* FINAL_RGB = (RGB^2 + RGB) / (RGB^2 + RGB + 1)

The HDR0 tone mapping operator allocates even more of the available contrast range to brightnesses in the range 0-1.  This is even more contrasty, but with even more washout:

* FINAL_RGB = (RGB^3 + RGB^2 + RGB) / (RGB^3 + RGB^2 + RGB + 1)

==Cartoon Shading (Quantized Lighting)==

In cartoon shading, the first clamp is removed entirely, and the second one is replaced with a quantization function.  This replaces a continuous gradient of brightness values with a discrete set of light levels.  This quantization function only applies to directional lights, not ambient ones.  

To enable quantized lighting, use one of these:

&lt;code python&gt;
np.setAttrib(LightRampAttrib.makeSingleThreshold(t0, l0))
np.setAttrib(LightRampAttrib.makeDoubleThreshold(t0, l0, t1, l1))
&lt;/code&gt;

In a single-threshold system, the brightness of the diffuse lighting contribution is compared to the threshold &lt;code&gt;t0&lt;/code&gt;.  If the threshold is not met, the diffuse light contribution is eliminated.  If it is met, the pixel's brightness is normalized to the specified level &lt;code&gt;l0&lt;/code&gt;.  

In a double-threshold system, the brightness of the diffuse lighting contribution is compared to the thresholds &lt;code&gt;t0&lt;/code&gt; and &lt;code&gt;t1&lt;/code&gt;.  If neither is attained, the diffuse light contribution is eliminated.  If it is met, the pixel's brightness is normalized to either &lt;code&gt;l0&lt;/code&gt; or &lt;code&gt;l1&lt;/code&gt;, depending on which threshold was passed.

==Future Light Ramps==

We are interested in knowing if there are any other light ramps you would like to see.  If so, please notify us on the forums.</text>
    </revision>
  </page>
  <page>
    <title>Lighting</title>
    <ns>0</ns>
    <id>990</id>
      <sha1>k6binlvauvwmyes0rp6pcys9jdq6gh4</sha1>
    <revision>
      <id>7766</id>
      <timestamp>2012-05-30T04:44:50Z</timestamp>
      <contributor>
        <username>Eadthem</username>
        <id>561</id>
      </contributor>
      <comment>added a c++ block</comment>
      <text xml:space="preserve" bytes="12131">==Lighting Basics==

In the real world, if you put a light in a room, objects in that room are 
illuminated.  For example, if you put a table lamp in your living room, that
lamp automatically illuminates your sofa and your chair.  In a 3D engine like Panda3D, lights don't illuminate things automatically.  Instead, you must tell the chair and the sofa to ''be illuminated'' by the lamp.  

So to reiterate, lighting a scene in Panda3D consists of two steps:
&lt;br&gt;1. Creating lights, and positioning them within the scene.
&lt;br&gt;2. Telling the other objects to ''be illuminated'' by the lights.

Panda3D defines four different kinds of light objects: point,
directional, ambient, and spotlight.  Each of these is a node that
should be attached somewhere within the scene graph. Like anything you put into the scene, lights have a position and orientation, which is determined by the basic scene graph operations like &lt;code&gt;setPos()&lt;/code&gt;, &lt;code&gt;setHpr()&lt;/code&gt;, etc.  The &lt;code&gt;lookAt()&lt;/code&gt; method is particularly useful for pointing spotlights and directional lights at a particular object.[cxx]

Note that you will need to include the following headers according to the type of lights you are gonna use:

&lt;code cxx&gt;
#include &quot;ambientLight.h&quot;
#include &quot;directionalLight.h&quot;
#include &quot;pointLight.h&quot;
#include &quot;spotlight.h&quot;
&lt;/code&gt;

[/cxx] The following code inserts a directional light into the scene:

[python]&lt;code python&gt;
dlight = DirectionalLight('my dlight')
dlnp = render.attachNewNode(dlight)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
PT(DirectionalLight) d_light;
d_light = new DirectionalLight(&quot;my d_light&quot;);
NodePath dlnp = window-&gt;get_render().attach_new_node(d_light);
&lt;/code&gt;[/cxx]

Note that, unlike a real, physical light bulb, the light objects are not themselves directly visible.  Although you can't see a Panda light itself, you ''can'' see the effect it has on the geometry around it.  If you want to make a light visible, one simple trick is to load a simple model (like a sphere) and parent it directly to the light itself.

Creating the light and putting it in the scene graph doesn't, by itself, have any visible effect.  Your next step is to tell some object to be illuminated
by the light.  To do this, use the &lt;code&gt;nodePath.setLight()&lt;/code&gt; method, which turns on the light for the indicated NodePath and everything below it in the scene graph.

In the simplest case, you want all of your lights to illuminate everything they can, so you turn them on at render, the top of the scene graph:

[python]&lt;code python&gt;
render.setLight(plnp)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
window-&gt;get_render().set_light(pnlp);
&lt;/code&gt;[/cxx]

You can remove the light setting from render:

[python]&lt;code python&gt;
render.clearLight(plnp)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
window-&gt;get_render().clear_light(pnlp);
&lt;/code&gt;[/cxx]

You could also apply the &lt;code&gt;setLight()&lt;/code&gt; call to a sub-node in the scene graph, so that a given light only affects a particular object or group of objects:

[python]&lt;code python&gt;
sofa.setLight(plnp)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
sofa.set_light(plnp)
&lt;/code&gt;[/cxx]


Note that there are two (or more) different NodePaths involved here: the NodePath of the light itself, which defines the position and/or orientation of the light, and the NodePath(s) on which you call &lt;code&gt;setLight()&lt;/code&gt;, which determines what subset of the scene graph the light illuminates.  There's no requirement for these two NodePaths to be related in any way.

==Lots of Lights: Performance Implications==

Each light slows down rendering a little.  Using a half-dozen lights to illuminate an object is no problem at all.  However, if you were to use a hundred lights to illuminate an object, that object would render slowly.

Because of this, when you create a big virtual world, you need to pick and choose which lights affect which objects.  For example, if you had a dungeon
containing a hundred torches, it would not be practical to tell every object
to be illuminated by every torch.  Instead, for each object in the dungeon,
you would want to search for the three or four nearest torches, and tell
the object to be illuminated only by those three or four torches.

When per-pixel lighting is enabled, lights are considerably more costly.

==Colored Lights==

All lights have a color, which is specified by &lt;code&gt;light.setColor(VBase4(r, g, b, a))&lt;/code&gt;.  The default color is full white: &lt;code&gt;setColor(VBase4(1, 1, 1, 1))&lt;/code&gt;.  The alpha component is largely irrelevant.

&lt;b&gt;Note:&lt;/b&gt; The R, G, B values can be larger than 1, if you want brighter lights!  However, you can't use lighting to make a model brighter than its texture color.

==Point Lights==

Point lights are the easiest kind of light to understand: a point
light simulates a light originating from a single point in space and
shining in all directions, like a very tiny light bulb.  A point
light's position is important, but its orientation doesn't matter.

[python]&lt;code python&gt;
plight = PointLight('plight')
plight.setColor(VBase4(0.2, 0.2, 0.2, 1))
plnp = render.attachNewNode(plight)
plnp.setPos(10, 20, 0)
render.setLight(plnp)
&lt;/code&gt;[/python]
[cxx]
&lt;code cxx&gt;
PointerTo&lt;PointLight&gt; plightSun = new PointLight(&quot;sun&quot;);
plightSun-&gt;set_color(LVecBase4f(.7,.7,.7,1));
NodePath plightSun_p = render.attach_new_node(plightSun);
plightSun_p.set_pos(500,500,500);
render.set_light(plightSun_p);
&lt;/code&gt;
[/cxx]

==Attenuation==
You can set the attenuation coefficients, which causes the light to drop off gradually with distance. There are three attenuation coefficients: A, B, C.  
&lt;code python&gt;
plight.setAttenuation(Point3(A, B, C))
&lt;/code&gt;
Setting coefficients A and B to 0 and C between 0 and 1 works well.
&lt;code python&gt;
plight.setAttenuation(Point3(0, 0, 0.5))
&lt;/code&gt;

==Directional Lights==

A directional light is an infinite wave of light, always in the same
direction, like sunlight.  A directional light's position doesn't
matter, but its orientation is important.  The default directional
light is shining down the forward (+Y) axis; you can use
&lt;code&gt;nodePath.setHpr()&lt;/code&gt; or &lt;code&gt;nodePath.lookAt()&lt;/code&gt; to
rotate it to face in a different direction.

[python]&lt;code python&gt;
dlight = DirectionalLight('dlight')
dlight.setColor(VBase4(0.8, 0.8, 0.5, 1))
dlnp = render.attachNewNode(dlight)
dlnp.setHpr(0, -60, 0)
render.setLight(dlnp)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
PT(DirectionalLight) d_light;
d_light = new DirectionalLight('my d_light');
d_light-&gt;set_color(LVecBase4f(0.8, 0.8, 0.5, 1));
NodePath dlnp = window-&gt;get_render().attach_new_node(d_light);
dlnp.set_hpr(-30, -60, 0);
window-&gt;get_render().set_light(dlnp);
&lt;/code&gt;[/cxx]

==Ambient Lights==

An ambient light is used to fill in the shadows on the dark side of an
object, so it doesn't look completely black.  The light from an
ambient light is uniformly distributed everywhere in the world, so the
ambient light's position and orientation are irrelevant.

Usually you don't want to create an ambient light without also
creating one of the other kinds of lights, since an object illuminated
solely by ambient light will be completely flat shaded and you won't
be able to see any of its details.  Typically, ambient lights are
given a fairly dark gray color, so they don't overpower the other
lights in the scene.

&lt;code python&gt;
alight = AmbientLight('alight')
alight.setColor(VBase4(0.2, 0.2, 0.2, 1))
alnp = render.attachNewNode(alight)
render.setLight(alnp)
&lt;/code&gt;

==Spotlights==

Spotlights represent the most sophisticated kind of light.  A spotlight has
both a point and a direction, and a field-of-view.  In fact, a
spotlight contains a lens, just like a camera does; the lens should be
a PerspectiveLens and is used to define the area of effect of the
light (the light illuminates everything within the field of view of the lens).

Note that the English word &quot;spotlight&quot; is one word, as opposed to the
other kinds of lights, which are two words.  Thus, the class name is
correctly spelled &quot;Spotlight&quot;, not &quot;SpotLight&quot;.

&lt;code python&gt;
slight = Spotlight('slight')
slight.setColor(VBase4(1, 1, 1, 1))
lens = PerspectiveLens()
slight.setLens(lens)
slnp = render.attachNewNode(slight)
slnp.setPos(10, 20, 0)
slnp.lookAt(myObject)
render.setLight(slnp)
&lt;/code&gt;

==Putting it all Together==

Here is an example of lighting.  There are an ambient light and two directional lights lighting the scene, and a green ambient light that only affects one of the pandas.

&lt;code python&gt;
import direct.directbase.DirectStart
from panda3d.core import *

# Put two pandas in the scene, panda x and panda y.
x = loader.loadModel('panda')
x.reparentTo(render)
x.setPos(10,0,-6)

y = loader.loadModel('panda')
y.reparentTo(render)
y.setPos(-10,0,-6)

# Position the camera to view the two pandas.
base.trackball.node().setPos(0, 60, 0)

# Now create some lights to apply to everything in the scene.

# Create Ambient Light
ambientLight = AmbientLight('ambientLight')
ambientLight.setColor(Vec4(0.1, 0.1, 0.1, 1))
ambientLightNP = render.attachNewNode(ambientLight)
render.setLight(ambientLightNP)

# Directional light 01
directionalLight = DirectionalLight('directionalLight')
directionalLight.setColor(Vec4(0.8, 0.2, 0.2, 1))
directionalLightNP = render.attachNewNode(directionalLight)
# This light is facing backwards, towards the camera.
directionalLightNP.setHpr(180, -20, 0)
render.setLight(directionalLightNP)

# Directional light 02
directionalLight = DirectionalLight('directionalLight')
directionalLight.setColor(Vec4(0.2, 0.2, 0.8, 1))
directionalLightNP = render.attachNewNode(directionalLight)
# This light is facing forwards, away from the camera.
directionalLightNP.setHpr(0, -20, 0)
render.setLight(directionalLightNP)

# Now attach a green light only to object x.
ambient = AmbientLight('ambient')
ambient.setColor(Vec4(0.5, 1, 0.5, 1))
ambientNP = x.attachNewNode(ambient)

# If we did not call setLightOff() first, the green light would add to
# the total set of lights on this object. Since we do call
# setLightOff(), we are turning off all the other lights on this
# object first, and then turning on only the green light.
x.setLightOff()
x.setLight(ambientNP)

#run the example
run()
&lt;/code&gt;


== Shadow Mapping ==

As for version 1.7.0, Panda3D offers fully automatic shadow mapping support for spotlights and directional lights. You can enable shadows by calling &lt;code&gt;[func]setShadowCaster[/func]()&lt;/code&gt;. The nodes that receive shadows will need to have [[the Shader Generator]] enabled, otherwise no shadows will appear.

[python]&lt;code python&gt;
# Use a 512x512 resolution shadow map
light.setShadowCaster(True, 512, 512)
# Enable the shader generator for the receiving nodes
render.setShaderAuto()
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
// Use a 512x512 resolution shadow map
light-&gt;set_shadow_caster(true, 512, 512);
// Enable the shader generator for the receiving nodes
window-&gt;get_render().set_shader_auto();
&lt;/code&gt;[/cxx]

Note that, even though in general shadowing is easy to set-up, you will want to tweak the light's lens settings to get the best depth buffer precision. Use the &lt;code&gt;[func]setNearFar[/func]()&lt;/code&gt; method on the Lens to get a perfect fit of what is being rendered. Also, for directional lights, you will need to call &lt;code&gt;[func]setFilmSize[/func]()&lt;/code&gt; on the Lens and position the light properly so that the light camera will get an optimal view of the scene.

Also note that every Light is in fact also a Camera, so you can easily exclude objects from being shadowed (e.g. for performance reasons) by use of camera masks.

If you have very thin objects, you may run into self-shadowing issues if the backside of the object casts shadows on its frontside. You can easily fix this by applying a depth offset to the object in question. A depth offset of 1 means to use an offset as small as possible, but big enough to make a difference. This should generally be enough. You can call &lt;code&gt;[func]setDepthOffset[/func]()&lt;/code&gt; on the NodePath or use the &lt;code&gt;depth-offset&lt;/code&gt; scalar in the .egg file.

[python]&lt;code python&gt;
leaves.setDepthOffset(1)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
leaves.set_depth_offset(1);
&lt;/code&gt;[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Lights</title>
    <ns>0</ns>
    <id>950</id>
    <redirect title="Lighting" />
      <sha1>nv3b3witez17dvurxj8rz07z7fcpu8y</sha1>
    <revision>
      <id>4099</id>
      <timestamp>2007-02-15T17:50:48Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>double one. redirected to Lighting</comment>
      <text xml:space="preserve" bytes="22">#REDIRECT [[Lighting]]</text>
    </revision>
  </page>
  <page>
    <title>List of All Attributes</title>
    <ns>0</ns>
    <id>2214</id>
      <sha1>5sevmd4x6pa3si3b04k6sn43t9zxagw</sha1>
    <revision>
      <id>5094</id>
      <timestamp>2008-03-15T01:03:52Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="3662">==List of All Attributes==

The following is a concise list of all the RenderAttribs supported by Panda3D. Additional documentation can be found by clicking on the name of the RenderAttrib.

*&lt;b&gt;[[Alpha Testing|AlphaTestAttrib]]&lt;/b&gt;: Hides part of the model, based on the texture's alpha channel.

*&lt;b&gt;[[Antialiasing|AntialiasAttrib]]&lt;/b&gt;: Controls full-screen antialiasing and polygon-edge antialiasing.

*&lt;b&gt;[[#Undocumented|AudioVolumeAttrib]]&lt;/b&gt;: Applies a scale to audio volume for positional sounds.

*&lt;b&gt;[[Auxiliary Bitplane Control|AuxBitplaneAttrib]]&lt;/b&gt;: Causes shader generator to produce extra data.

*&lt;b&gt;[[Clip Planes|ClipPlaneAttrib]]&lt;/b&gt;: Slices off a piece of the model, using a clipping plane.

*&lt;b&gt;[[Tinting and Recoloring|ColorAttrib]]&lt;/b&gt;: Tints the model.  Only works if the model is not illuminated.

*&lt;b&gt;[[Transparency and Blending|ColorBlendAttrib]]&lt;/b&gt;: This specifies how colors are blended into the frame buffer, for special effects.

*&lt;b&gt;[[Tinting and Recoloring|ColorScaleAttrib]]&lt;/b&gt;: Modulates vertex colors with a flat color.

*&lt;b&gt;[[Color Write Masks|ColorWriteAttrib]]&lt;/b&gt;: Causes the model to not affect the R, G, B, or A channel of the framebuffer.

*&lt;b&gt;[[#Undocumented|CullBinAttrib]]&lt;/b&gt;: Controls the order in which Panda renders geometry.

*&lt;b&gt;[[Backface Culling and Frontface Culling|CullFaceAttrib]]&lt;/b&gt;: Causes backfaces or frontfaces of the model to be visible.

*&lt;b&gt;[[#Undocumented|DepthOffsetAttrib]]&lt;/b&gt;: Causes the Z-buffer to treat the object as if it were closer or farther.

*&lt;b&gt;[[Depth Test and Depth Write|DepthTestAttrib]]&lt;/b&gt;: Alters the way the Z-buffer affects the model.

*&lt;b&gt;[[Depth Test and Depth Write|DepthWriteAttrib]]&lt;/b&gt;: Controls whether or not the model affects the Z-buffer.

*&lt;b&gt;[[#Undocumented|DrawMaskAttrib]]&lt;/b&gt;: Controls which cameras can see which objects.

*&lt;b&gt;[[Fog|FogAttrib]]&lt;/b&gt;: Causes the model to be obscured by fog if it is far from the camera.

*&lt;b&gt;[[Lighting|LightAttrib]]&lt;/b&gt;: Causes the model to be illuminated by certain lights.

*&lt;b&gt;[[Light Ramps|LightRampAttrib]]&lt;/b&gt;: Enables HDR tone mapping or cartoon shading.

*&lt;b&gt;[[Materials|MaterialAttrib]]&lt;/b&gt;: Changes the way the model reflects light.

*&lt;b&gt;[[#Undocumented|RenderModeAttrib]]&lt;/b&gt;: Used to enable wireframe rendering.

*&lt;b&gt;[[#Undocumented|RescaleNormalAttrib]]&lt;/b&gt;: Can disable the automatic correction of non-unit normals.

*&lt;b&gt;[[#Undocumented|ShadeModelAttrib]]&lt;/b&gt;: Can cause the model to appear faceted instead of smooth.

*&lt;b&gt;[[Pixel and Vertex Shaders|ShaderAttrib]]&lt;/b&gt;: Gives almost unlimited control, but difficult to use.

*&lt;b&gt;[[Stencil Test/Write Attribute|StencilAttrib]]&lt;/b&gt;: Causes the model to affect the stencil buffer, or be affected by the stencil buffer.

*&lt;b&gt;[[Automatic Texture Coordinates|TexGenAttrib]]&lt;/b&gt;: Causes the system to synthesize texture coordinates for the model.

*&lt;b&gt;[[Texture Transforms|TexMatrixAttrib]]&lt;/b&gt;: Alters the existing texture coordinates.

*&lt;b&gt;[[Texturing|TextureAttrib]]&lt;/b&gt;: Applies a texture map to the model.

*&lt;b&gt;[[Transparency and Blending|TransparencyAttrib]]&lt;/b&gt;: Causes the model to be partially transparent.


==Undocumented==

Unfortunately, the Panda3D manual is still a work in progress: there are many aspects of it that are not fully documented yet.  These attributes are not yet documented:

AudioVolumeAttrib, CullBinAttrib, DepthOffsetAttrib, DrawMaskAttrib, RenderModeAttrib, RescaleNormalAttrib, ShadeModelAttrib

However, although the manual does not document these classes,
the [http://panda3d.org/apiref.php?page=classes Reference] documentation does. 

&lt;h2&gt;Incomplete Section&lt;/h2&gt;

Note: this section is incomplete.  It will be updated soon.</text>
    </revision>
  </page>
  <page>
    <title>List of All Config Variables</title>
    <ns>0</ns>
    <id>2101</id>
      <sha1>2ls2gc693rdhd84kj897gicbxz7zlbv</sha1>
    <revision>
      <id>60529</id>
      <timestamp>2015-07-21T15:48:40Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <text xml:space="preserve" bytes="99219">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

The following is an incomplete list of config variables as of Jun, 2009.  It was generated using this code:

[python]&lt;code python&gt;
ConfigVariableManager.getGlobalPtr().listVariables()
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
ConfigVariableManager::get_global_ptr()-&gt;list_variables();
&lt;/code&gt;[/cxx]

Bear in mind that this list includes configuration parameters that control functionality that isn't fully implemented yet.  Ie, not all of these config variables are as useful as they sound.

You can use this command yourself in case this list gets out of date.

List of Panda3D variables:

{| class=&quot;wikitable sortable&quot; border=&quot;1&quot; cellpadding=&quot;5&quot; cellspacing=&quot;0&quot;
! Variable
! Value Type
! class=&quot;unsortable&quot; | Default
! class=&quot;unsortable&quot; | Description
|-
| accept-clock-skew
| bool
| 0
| This controls the default value of SmoothMover::get_accept_clock_skew().
|-
| adaptive-lru-max-updates-per-frame
| int
| 40
| The number of pages the AdaptiveLru class will update per frame.  Do not set this too high or it will degrade performance.
|-
| adaptive-lru-weight
| double
| 0.2
| Specifies the weight factor used to compute the AdaptiveLru's exponential moving average.
|-
| allow-collider-multiple
| bool
| 0
| Set this true to enable the use of a DoubleBitMask or QuadBitMask to manage many colliders added to a single traverser in one pass.  If this is false, a one-word BitMask is always used instead, which is faster per pass, but may require more passes.
|-
| allow-flatten-color
| bool
| 0
| allows color to always be flattened to vertices
|-
| allow-incomplete-render
| bool
| 1
| When this is true, the frame may be rendered even if some of the geometry in the scene has been paged out, or if the textures are unavailable.  The nonresident geometry and textures will be rendered as soon as they can be read from disk, which may be several frames in the future.  When this is false, geometry is always paged in immediately when needed, holding up the frame render if necessary.
|-
| allow-live-flatten
| bool
| 1
| Set this true to allow the use of flatten_strong() or any variant on a node that is attached to a live scene graph node, or false to disallow this.  Flattening a live scene graph node can cause problems when threading is enabled.  This variable only has an effect when Panda is not compiled for a release build.
|-
| allow-nonpipeline-threads
| bool
| 0
| This variable should only be set true for debugging or development purposes.  When true, the threading-model variable may specify a threaded pipeline mode, even if pipelining is not compiled in.  This will certainly result in erroneous behavior, and quite likely will cause a crash.  Do not set this unless you know what you are doing.
|-
| allow-portal-cull
| bool
| 0
| Set this true to enable portal clipping.  This will enable the renderer to cull more objects that are clipped if not in the current list of portals.  This is still somewhat experimental.
|-
| allow-unrelated-wrt
| bool
| 1
| Set this true to allow unrelated NodePaths (that is, nodes which have no common ancestor) to be adjusted relative to each other.  If true, these will be treated as if they had a common node above their top nodes.
|-
| alpha-bits
| int
| 0  (from /etc/Config.prc)
| The minimum number of alpha buffer bits requested.
|-
| alpha-scale-via-texture
| bool
| 1
| When this is true, Panda will try to implement ColorScaleAttribs that affect alpha by creating an additional Texture layer over the geometry with a uniform alpha scale applied everywhere, if there is at least one available Texture slot available on the multitexture pipeline.  Set this false to avoid this trickery, so that texturing is only enabled when the application specifically enables it.  See also color-scale-via-lighting.
|-
| anim-blend-type
| enum
| normalized_linear
| The default blend type to use for blending animations between frames, or between multiple animations.  See interpolate-frames, and also PartBundle::set_anim_blend_flag() and PartBundle::set_frame_blend_flag().
|-
| aspect-ratio
| double
| 0
| -
|-
| assert-abort
| bool
| 0
| Set this true to trigger a core dump and/or stack trace when the first assertion fails
|-
| async-bind-priority
| int
| 100
| This specifies the priority assign to an asynchronous bind task when it is requested via PartBundle::load_bind_anim().  This controls the relative order in which asynchronous loads happen (in particular, relative to asynchronous texture or model loads).  A higher number here makes the animations load sooner.
|-
| async-load-delay
| double
| 0
| If this is nonzero, it represents an artificial delay, in seconds, that is imposed on every asynchronous load attempt (within the thread).  Its purpose is to help debug errors that may occur when an asynchronous load is delayed.  The delay is per-model, and all aync loads will be queued up behind the delay--it is as if the time it takes to read a file is increased by this amount per read.
|-
| asynchronous-clients
| bool
| 1
| -
|-
| audio-active
| bool
| 1
| -
|-
| audio-buffering-seconds
| double
| 3
| Controls the amount of audio buffering when streaming audio. If you are playing a streaming sound, and any single frame takes longer than this, the audio will stutter.  Caution: buffering streaming audio takes a lot of memory.  For example, 5 seconds of stereo audio at 44,100 samples/sec takes one megabyte.  The 3-second default is intentionally high, favoring correctness over efficiency, but for a commercial application you may wish to lower this.
|-
| audio-cache-limit
| int
| 15
| The number of sounds in the cache.
|-
| audio-distance-factor
| double
| 1
| -
|-
| audio-dls-file
| filename
| -
| Specifies a DLS file that defines an instrument set to load for MIDI file playback.  If this is not specified, the sound interface will try to use the system default DLS file, if one is available; the likely success of this depends on the operating system.
|-
| audio-doppler-factor
| double
| 1
| -
|-
| audio-drop-off-factor
| double
| 1
| -
|-
| audio-library-name
| string
| p3openal_audio  (from /etc/Config.prc); fmodex_audio hardcoded
| -
|-
| audio-min-hw-channels
| int
| 15
| Guarantee this many channels on the local sound card, or just play EVERYTHING in software.
|-
| audio-music-active
| bool
| 1
| DConfig
|-
| audio-output-bits
| int
| 16
| -
|-
| audio-output-channels
| int
| 2
| -
|-
| audio-output-rate
| int
| 22050
| -
|-
| audio-play-midi
| bool
| 1
| -
|-
| audio-play-mp3
| bool
| 1
| -
|-
| audio-play-wave
| bool
| 1
| -
|-
| audio-preload-threshold
| int
| 1000000
| If the decompressed size of a sound file exceeds this amount, then Panda3D will not attempt to store that sound file in RAM. Instead, it will stream the sound file from disk.  It is not practical to stream multiple sound-files from disk at the same time - the hard drive seek time makes it stutter.
|-
| audio-sfx-active
| bool
| 1
| DConfig
|-
| audio-software-midi
| bool
| 1
| -
|-
| audio-volume
| double
| 1
| -
|-
| auto-break-cycles
| bool
| 1
| Set this true to automatically detect and break reference-count cycles in the TransformState and RenderState caches.  When this is false, you must explicitly call TransformState.clear_cache() from time to time to prevent gradual memory bloat.
|-
| auto-flip
| bool
| 0
| This indicates the initial setting of the auto-flip flag.  Set it true to cause render_frame() to flip all the windows before it returns (in single-threaded mode only), or false to wait until an explicit call to flip_frame() or the next render_frame().  Setting it true gets more immediate response time, while setting it false can get a better frame rate as more is achieved in parallel with the graphics card.
|-
| auto-single-cpu-affinity
| bool
| 0
| DConfig
|-
| aux-display
| list
| -
| Names each of the graphics display libraries that are available on a particular platform.  This variable may be repeated several times.  These libraries will be tried one at a time if the library specified by load_display cannot be loaded.
|-
| average-frame-rate-interval
| double
| 1
| See ClockObject::set_average_frame_rate_interval().
|-
| back-buffers
| int
| 1
| The default number of back buffers requested.
|-
| background-color
| double
| 0.41 0.41 0.41
| Specifies the rgb(a) value of the default background color for a new window or offscreen buffer.
|-
| bam-endian
| enum
| littleendian
| The default endianness to use for writing major numeric data tables to bam files.  This does not affect all numbers written to bam files, only those for which the individual object was designed to support this flag.  The default is &quot;native&quot;; you may set it to &quot;littleendian&quot; or &quot;bigendian&quot; to target a particular platform.
|-
| bam-texture-mode
| enum
| relative
| Set this to specify how textures should be written into Bam files.See the panda source or documentation for available options.
|-
| basic-shaders-only
| bool
| #t  (from /etc/Config.prc); 0 hardcoded
| Set this to true if you aren't interested in shader model three and beyond.  Setting this flag will cause panda to disable bleeding-edge shader functionality which tends to be unreliable or broken.  At some point, when functionality that is currently flaky becomes reliable, we may expand the definition of what constitutes 'basic' shaders.
|-
| bmp-bpp
| int
| 0
| This controls how many bits per pixel are written out for BMP files.  If this is zero, the default, the number of bits per pixel is based on the image.
|-
| bounds-type
| enum
| sphere
| Specify the type of bounding volume that is created automatically by Panda to enclose geometry.  Use 'sphere' or 'box', or use 'best' to let Panda decide which is most appropriate.
|-
| cache-report
| bool
| 0
| -
|-
| cache-report-interval
| double
| 5
| -
|-
| check-debug-notify-protect
| bool
| 0
| Set true to issue a warning message if a debug or spam notify output is not protected within an if statement.
|-
| client-cpu-affinity
| int
| -1
| DConfig
|-
| client-cpu-affinity-mask
| int
| -1
| DConfig
|-
| client-sleep
| double
| 0
| DConfig
|-
| clip-plane-cull
| bool
| 1
| This is normally true; set it false to disable culling of objects that are completely behind one or more clip planes (primarily useful for debugging).
|-
| clock-degrade-factor
| double
| 1
| In degrade clock mode, returns the ratio by which the performance is degraded.  A value of 2.0 causes the clock to be slowed down by a factor of two (reducing performance to 1/2 what would be otherwise).  See ClockObject::set_degrade_factor().
|-
| clock-frame-rate
| double
| 1
| In non-real-time clock mode, sets the number of frames per second that we should appear to be running.  In forced mode or limited mode, sets our target frame rate.  In normal mode, this has no effect.  See ClockObject::set_frame_rate().
|-
| clock-mode
| enum
| normal
| Specifies the mode of the global clock.  The default mode, normal, is a real-time clock; other modes allow non-real-time special effects like simulated reduced frame rate.  See ClockObject::set_mode().
|-
| cluster-mode
| string
| -
| DConfig
|-
| cluster-sync
| bool
| 0
| DConfig
|-
| collect-tcp
| bool
| 0
| Set this true to enable accumulation of several small consecutive TCP datagrams into one large datagram before sending it, to reduce overhead from the TCP/IP protocol.  See Connection::set_collect_tcp() or SocketStream::set_collect_tcp().
|-
| collect-tcp-interval
| double
| 0.2
| -
|-
| collision-parabola-bounds-sample
| int
| 10
| This is the number of points along a CollisionParabola to sample in order to determine an accurate bounding box.
|-
| collision-parabola-bounds-threshold
| double
| 10
| This is the threshold size for a CollisionParabola to make a bounding box (BoundingHexahedron).  If the parabola is smaller than this, it will make a BoundingSphere instead, which is much easier to make and will be good enough for small parabolas.
|-
| color-bits
| int
| 1  (from /etc/Config.prc); 0 hardcoded
| The minimum number of color buffer bits requested.
|-
| color-scale-via-lighting
| bool
| 1
| When this is true, Panda will try to implement ColorAttribs and ColorScaleAttribs using the lighting interface, by creating a default material and/or an ambient light if necessary, even if lighting is ostensibly disabled.  This avoids the need to munge the vertex data to change each vertex's color.  Set this false to avoid this trickery, so that lighting is only enabled when the application specifically enables it.  See also alpha-scale-via-texture.
|-
| compose-componentwise
| bool
| 1
| Set this true to perform componentwise compose and invert operations when possible.  If this is false, the compositions are always computed by matrix.
|-
| compress-chan-quality
| int
| 95
| The quality level is an integer number that generally ranges between 0 and 100, where smaller numbers indicate greater compression at the cost of quality, and larger numbers indicate higher quality but less compression.  Generally, 95 is the highest useful value; values between 95 and 100 produce substantially larger, but not substantially better, output files.  This is akin to the JPEG compression level.
|-
| compress-channels
| bool
| 0
| Set this true to enable lossy compression of animation channels when writing to the bam file.  This serves to reduce the size of the bam file only; it does not reduce the memory footprint of the channels when the bam file is loaded.
|-
| compressed-textures
| bool
| 0
| Set this to true to compress textures as they are loaded into texture memory, if the driver supports this.  Specifically, this changes the meaning of set_compression(Texture::CM_default) to Texture::CM_on.
|-
| connect-triangle-strips
| bool
| 1
| Set this true to send a batch of triangle strips to the graphics card as one long triangle strip, connected by degenerate triangles, or false to send them as separate triangle strips with no degenerate triangles.  On PC hardware, using one long triangle strip may help performance by reducing the number of separate graphics calls that have to be made.
|-
| coordinate-system
| string
| zup-right
| The default coordinate system to use throughout Panda for rendering, user input, and matrix operations, unless specified otherwise.
|-
| copy-texture-inverted
| bool
| 0
| Set this true to indicate that the GSG in use will invert textures when it performs a framebuffer-to-texture copy operation, or false to indicate that it does the right thing.  If this is not set, the default behavior is determined by the GSG's internal logic.
|-
| cull-bin
| list
| gui-popup 60 unsorted  (from /etc/Confauto.prc)
| Creates a new cull bin by name, with the specified properties.  This is a string in three tokens, separated by whitespace: 'bin_name sort type'.
|-
| cursor-filename
| filename
| -
| -
|-
| cursor-hidden
| bool
| 0
| -
|-
| dc-multiple-inheritance
| bool
| 1
| Set this true to support multiple inheritance in the dc file.  If this is false, the old way, multiple inheritance is not supported, but field numbers will be numbered sequentially, which may be required to support old code that assumed this.
|-
| dc-sort-inheritance-by-file
| bool
| 1
| This is a temporary hack.  This should be true if you are using version 1.42 of the otp_server.exe binary, which sorted inherited fields based on the order of the classes within the DC file, rather than based on the order in which the references are made within the class.
|-
| dc-virtual-inheritance
| bool
| 1
| Set this true to support proper virtual inheritance in the dc file, so that diamond-of-death type constructs can be used.  This also enables shadowing (overloading) of inherited method names from a base class.
|-
| debug-portal-cull
| bool
| 0
| Set this true to enable debug visualization during portal clipping. (You first need to enable portal culling, using the allow-portal-cull variable.)
|-
| decompressor-step-time
| double
| 0.1
| Specifies the maximum amount of time that should be consumed by a single call to Decompressor::run().
|-
| default-converge
| double
| 25
| The default convergence distance for stereo cameras.
|-
| default-directnotify-level
| string
| warning  (from /etc/Config.prc); info hardcoded
| DConfig
|-
| default-far
| double
| 100000
| The default far clipping distance for all cameras.
|-
| default-fov
| double
| 30
| The default field of view in degrees for all cameras.  This is defined as a min_fov; that is, it is the field-of-view for the smallest of the X and Y sizes of the window, which is usually the vertical field of view (windows are usually wider than they are tall).  For a 4x3 window, 30 degrees vertical is roughly 40 degrees horizontal.
|-
| default-iod
| double
| 0.2
| The default interocular distance for stereo cameras.
|-
| default-keystone
| double
| 0
| The default keystone correction, as an x y pair, for all cameras.
|-
| default-lod-type
| enum
| pop
| Set this to either 'pop' or 'fade' to determine the type of LODNode that is created by LODNode::make_default_lod().
|-
| default-model-extension
| string
| .egg  (from /etc/Confauto.prc)
| This specifies the filename extension (with leading dot) that should be assumed if an attempt is made to load a filename that has no extension.  This is primarily designed to support legacy code that used the now-deprecated implicit-extension feature of Panda's loader; new code should probably give the correct name for each model file they intend to load.
|-
| default-near
| double
| 1
| The default near clipping distance for all cameras.
|-
| default-stereo-camera
| bool
| 1
| When this is true, the default DisplayRegion created for a window or buffer with the stereo property will be a StereoDisplayRegion, which activates the stereo properties of the camera lens, and enables stereo.  Set this false to require StereoDisplayRegions to be created explicitly.
|-
| default_max_angular_dt
| double
| 0.0333333
| -
|-
| default_max_linear_dt
| double
| 0.0333333
| -
|-
| default_noise_force_seed
| int
| 665
| -
|-
| default_terminal_velocity
| double
| 400
| -
|-
| depth-bits
| int
| 1  (from /etc/Config.prc); 0 hardcoded
| The minimum number of depth buffer bits requested.
|-
| depth-offset-decals
| bool
| 0
| Set this true to allow decals to be implemented via the advanced depth offset feature, if supported, instead of via the traditional (and slower) two-pass approach.  This is false by default because it appears that many graphics drivers have issues with their depth offset implementation.
|-
| detect-graph-cycles
| bool
| 1
| Set this true to attempt to detect cycles in the scene graph (e.g. a node which is its own parent) as soon as they are made.  This has no effect in NDEBUG mode.
|-
| direct-gui-edit
| bool
| 0
| DConfig
|-
| direct-wtext
| bool
| 1
| -
|-
| disable-sticky-keys
| bool
| 0
| DConfig
|-
| display
| string
| -
| Specify the X display string for the default display.  If this is not specified, $DISPLAY is used.
|-
| display-list-animation
| bool
| 0
| Set this true to allow the use of OpenGL display lists for rendering animated geometry (when the geometry is animated by the hardware).  This is not on by default because there appear to be some driver issues with this on my FireGL T2, but it should be perfectly doable in principle, and might get you a small performance boost.
|-
| display-lists
| bool
| 0
| Set this true to allow the use of OpenGL display lists for rendering static geometry.  On some systems, this can result in a performance improvement over vertex buffers alone; on other systems (particularly low-end systems) it makes little to no difference.  On some systems, using display lists can actually reduce performance.  This has no effect on DirectX rendering or on dynamic geometry (e.g. soft-skinned animation).
|-
| downloader-byte-rate
| int
| 3600
| We'd like this to be about 1 second worth of download assuming a 28.8Kb connection (28.8Kb / 8 = 3600 bytes per second).
|-
| downloader-disk-write-frequency
| int
| 4
| How often we write to disk is determined by this ratio which is relative to the downloader-byte-rate (e.g. if disk-write-ratio is 4, we will write every 4 seconds if the frequency is 0.2)
|-
| downloader-frequency
| double
| 0.2
| Frequency of download chunk requests in seconds (or fractions of) (Estimated 200 msec round-trip to server).
|-
| downloader-timeout
| int
| 15
| -
|-
| downloader-timeout-retries
| int
| 5
| -
|-
| drive-forward-speed
| double
| 20
| -
|-
| drive-horizontal-center
| double
| 0
| -
|-
| drive-horizontal-dead-zone
| double
| 0.1
| -
|-
| drive-horizontal-ramp-down-time
| double
| 0
| -
|-
| drive-horizontal-ramp-up-time
| double
| 0
| -
|-
| drive-reverse-speed
| double
| 10
| -
|-
| drive-rotate-speed
| double
| 80
| -
|-
| drive-vertical-center
| double
| 0
| -
|-
| drive-vertical-dead-zone
| double
| 0.1
| -
|-
| drive-vertical-ramp-down-time
| double
| 0
| -
|-
| drive-vertical-ramp-up-time
| double
| 0
| -
|-
| driver-compress-textures
| bool
| 0
| Set this true to ask the graphics driver to compress textures, rather than compressing them in-memory first.  Depending on your graphics driver, you may or may not get better performance or results by setting this true.  Setting it true may also allow you to take advantage of some exotic compression algorithm other than DXT1/3/5 that your graphics driver supports, but which is unknown to Panda.  If the libsquish library is not compiled into Panda, textures cannot be compressed in-memory, and will always be handed to the graphics driver, regardless of this setting.
|-
| driver-generate-mipmaps
| bool
| 0
| Set this true to use the hardware to generate mipmaps automatically in all cases, if supported.  Set it false to generate mipmaps in software when possible.  This is false by default because some drivers (Intel) seem to do a poor job of generating mipmaps when needed; also, generating mipmaps in software may allow smoother texture loads.
|-
| dump-generated-shaders
| bool
| 0
| Set this true to cause all generated shaders to be written to disk.  This is useful for debugging broken shader generators.
|-
| early-random-seed
| bool
| 0
| Configure this true to compute the SSL random seed early on in the application (specifically, when the libpandaexpress library is loaded), or false to defer this until it is actually needed (which will be the first time you open an https connection or otherwise use encryption services).  You can also call HTTPClient::initialize_ssl() to do this when you are ready.  The issue is that on Windows, OpenSSL will attempt to randomize its seed by crawling through the entire heap of allocated memory, which can be extremely large in a Panda application, especially if you have already opened a window and started rendering; and so this can take as much as 30 seconds or more.  For this reason it is best to initialize the random seed at startup, when the application is still very small.
|-
| egg-accept-errors
| bool
| 1
| When this is true, certain kinds of recoverable errors (not syntax errors) in an egg file will be allowed and ignored when an egg file is loaded.  When it is false, only perfectly pristine egg files may be loaded.
|-
| egg-alpha-mode
| enum
| blend
| Specifies the alpha mode to apply when the alpha specification &quot;on&quot; appears in the egg file (or when a primitive is implicitly transparent, because of a &lt;RGBA&gt; that involves a non-unity alpha, or because of a four-channel texture.
|-
| egg-combine-geoms
| bool
| 0
| Set this true to combine sibling GeomNodes into a single GeomNode, when possible.  This usually shouldn't be necessary, since the egg loader does a pretty good job of combining these by itself.
|-
| egg-consider-fans
| bool
| 0
| Set this true to enable the egg mesher to consider making triangle fans out of triangles that are connected at a common vertex.  This may help if your scene involves lots of such connected triangles, but it can also make the overall stripping less effective (by interfering with triangle strips).
|-
| egg-coordinate-system
| enum
| default
| -
|-
| egg-coplanar-threshold
| double
| 0.01
| The numerical threshold below which polygons are considered to be coplanar.  Determined empirically.
|-
| egg-emulate-bface
| bool
| 0
| When this is true, the bface flag applied to a polygon will cause two different polygons to be created, back-to-back.  When it is false, a single polygon will be created with the two_sided flag set on it.
|-
| egg-flat-shading
| bool
| 0
| Set this true to allow the egg loader to create geometry with the ShadeModelAttrib::M_flat attribute set.  It will do this only for geometry that has per-polygon normals and/or colors.  This allows the egg loader to avoid duplicating vertices when they are shared between connected polygons with different normals or colors, but it prevents the flat-shaded geometry from being combined with any adjacent smooth-shaded geometry (for instance, as the result of a flatten_strong operation).  It is false by default, since flat-shaded geometry is rare; but you may wish to set it true if your scene largely or entirely consists of flat-shaded polygons.
|-
| egg-flatten
| bool
| 1
| This is normally true to flatten out useless nodes after loading an egg file.  Set it false if you want to see the complete and true hierarchy as the egg loader created it (although the extra nodes may have a small impact on render performance).
|-
| egg-flatten-radius
| double
| 0
| This specifies the minimum cull radius in the egg file.  Nodes whose bounding volume is smaller than this radius will be flattened tighter than nodes larger than this radius, to reduce the node count even further.  The idea is that small objects will not need to have their individual components culled separately, but large environments should.  This allows the user to specify what should be considered &quot;small&quot;.  Set it to 0.0 to disable this feature.
|-
| egg-ignore-decals
| bool
| 0
| -
|-
| egg-ignore-filters
| bool
| 0
| -
|-
| egg-ignore-mipmaps
| bool
| 0
| -
|-
| egg-load-classic-nurbs-curves
| bool
| 0
| When this is true (and the above is also true), a &lt;NurbsCurve&gt; entry appearing in an egg file will load a ClassicNurbsCurve object instead of the default, a NurbsCurve object.  This only makes a difference when the NURBS++ library is available, in which case the default, NurbsCurve, is actually a NurbsPPCurve object.
|-
| egg-load-old-curves
| bool
| 1
| When this is true, a &lt;NurbsCurve&gt; entry appearing in an egg file will load as a NurbsCurve or ClassicNurbsCurve object (see below). When this is false, it will load a RopeNode instead, which uses the new NurbsCurveEvaluator interface.
|-
| egg-max-indices
| int
| 65535
| Specifies the maximum number of vertex indices that will be added to any one GeomPrimitive by the egg loader.
|-
| egg-max-tfan-angle
| double
| 40
| The maximum average angle per triangle to allow in a triangle fan.  If triangles are larger than this--that is, more loosely packed--then we figure a triangle strip is likely to do a more effective job than a triangle fan, and the fan maker leaves it alone.
|-
| egg-max-vertices
| int
| 65534
| Specifies the maximum number of vertices that will be added to any one GeomVertexData by the egg loader.
|-
| egg-mesh
| bool
| 1
| Set this true to convert triangles and higher-order polygons into triangle strips and triangle fans when an egg file is loaded or converted to bam.  Set this false just to triangulate everything into independent triangles.
|-
| egg-min-tfan-tris
| int
| 4
| The minimum number of triangles that must be involved in order to generate a triangle fan.  Fewer than this is just interrupting a triangle strip.
|-
| egg-normal-scale
| double
| 1
| -
|-
| egg-preload-simple-textures
| bool
| 1
| This specifies whether the egg loader will generate simple texture images for each texture loaded.  This supercedes the preload-simple-textures global default, for egg files.  In fact, the egg loader will generate simple texture images if either this or preload-simple-textures is true.
|-
| egg-retesselate-coplanar
| bool
| 0
| If this is true, the egg loader may reverse the tesselation direction of a single pair of planar triangles that share the same properties, if that will help get a better triangle strip.  In some rare cases, doing so can distort the UV's on a face; turning this off should eliminate that artifact (at the cost of less-effective triangle stripping).
|-
| egg-rigid-geometry
| bool
| 0
| Set this true to create rigid pieces of an animated character as separate static nodes, or false to leave these in with the parent node as vertex-animated geometry.  Setting this true means less geometry has to be vertex-animated, but there will tend to be more separate pieces.
|-
| egg-show-normals
| bool
| 0
| -
|-
| egg-show-qsheets
| bool
| 0
| Set this true to color each quadsheet a random color, so you can visually observe the quadsheet algorithm.
|-
| egg-show-quads
| bool
| 0
| Set this true to color each detected quad a random color, so you can visually observe the algorithm that unifies pairs of triangles into quads (prior to generating triangle strips).
|-
| egg-show-tstrips
| bool
| 0
| Set this true to color each triangle strip a random color, with the leading triangle a little bit darker, so you can visually observe the quality of the triangle stripping algorithm.
|-
| egg-subdivide-polys
| bool
| 1
| This is obsolete.  In the old Geom implementation, it used to be true to force higher-order polygons that were not otherwise meshed to be subdivided into triangles.  In the new Geom implementation, this happens anyway.
|-
| egg-support-old-anims
| bool
| 1
| Set this true to support loading of old character animation files, which had the convention that the order &quot;phr&quot; implied a reversed roll.
|-
| egg-suppress-hidden
| bool
| 0
| When this is true, objects flagged as &quot;hidden&quot; with the visibility scalar are not created at all.  When false, these objects are created, but initially stashed.
|-
| egg-unify
| bool
| 1
| When this is true, then in addition to flattening the scene graph nodes, the egg loader will also combine as many Geoms as possible within a given node into a single Geom.  This has theoretical performance benefits, especially on higher-end graphics cards, but it also slightly slows down egg loading.
|-
| egg-unroll-fans
| bool
| 1
| Set this true to allow the egg loader to convert weak triangle fans--triangles that share the same vertex but aren't connected enough to justify making a triangle fan primitive from them--into a series of zig-zag triangles that can make a triangle strip that might connect better with its neighbors.
|-
| empty-node-path
| enum
| transition
| This is a temporary transition variable to control the behavior of a NodePath when it is used as a boolean false.  Set this to 'deprecated' to preserve the original behavior: every NodePath evaluates true, even an empty NodePath.  Set it to 'future' to support the new behavior: non-empty NodePaths evaluate true, and empty NodePaths evaluate false.  Set it to 'transition' to raise an exception if an empty NodePath is used as a boolean.
|-
| enforce-attrib-lock
| bool
| 1
| When a MaterialAttrib, TextureAttrib, or LightAttrib is constructed, the corresponding Material, Texture, or Light is 'attrib locked.'  The attrib lock prevents qualitative changes to the object.  This makes it possible to hardwire information about material, light, and texture properties into generated shaders.  This config variable can disable the attrib lock.  Disabling the lock will break the shader generator, but doing so may be necessary for backward compatibility with old code.
|-
| even-animation
| bool
| 0
| When this is true, characters' vertices will be recomputed every frame, whether they need it or not.  This will tend to balance out the frame rate so that it is more uniformly slow.  The default is to compute vertices only when they need to be computed, which can lead to an uneven frame rate.
|-
| exclude-texture-scale
| list
| -
| This is a list of glob patterns for texture filenames (excluding the directory part of the filename, but including the extension); for instance, 'digits_*.png'.  Any texture filenames that match one of these patterns will not be affected by max-texture-dimension or texture-scale.
|-
| expected-ssl-server
| list
| -
| -
|-
| extended-exceptions
| bool
| 0
| DConfig
|-
| extractor-step-time
| double
| 0.1
| Specifies the maximum amount of time that should be consumed by a single call to Extractor::step().
|-
| fake-texture-image
| filename
| -
| Set this to enable a speedy-load mode in which you don't care what the world looks like, you just want it to load in minimal time.  This causes all texture loads via the TexturePool to use the same texture file, which will presumably only be loaded once.
|-
| fake-view-frustum-cull
| bool
| 0
| Set this true to cause culling to be performed by rendering the object in red wireframe, rather than actually culling it.  This helps make culling errors obvious.
|-
| fft-error-threshold
| double
| 0.2
| -
|-
| fft-exponent
| double
| 4
| -
|-
| fft-factor
| double
| 0.1
| -
|-
| fft-offset
| double
| 0.001
| -
|-
| flatten-collision-nodes
| bool
| 0
| Set this true to allow NodePath::flatten_medium() and flatten_strong() to combine multiple CollisionNodes into a single CollisionNode--but only if they share the same name and collide masks.  When false, CollisionNodes are never combined.  This is false by default, since collision tests rely heavily on bounding volume tests to be efficient, and combining CollisionNodes is likely to merge bounding volumes inappropriately.
|-
| flatten-geoms
| bool
| 1
| When this is true (the default), NodePath::flatten_strong() and flatten_medium() will attempt to combine multiple Geoms into as few Geoms as possible, by combing GeomVertexDatas and then unifying.  Setting this false disables this behavior, so that NodePath flatten operations will only reduce nodes.  This affects only the NodePath interfaces; you may still make the lower-level SceneGraphReducer calls directly.
|-
| fluid-cap-amount
| int
| 100
| ensures that fluid pos doesn't check beyond X feet
|-
| fmod-number-of-sound-channels
| int
| 128
| Guarantee this many channels you will have with FMOD.  AKA the max number of sounds you can play at one time.
|-
| fmod-use-surround-sound
| bool
| 0
| Determines if an FMOD Flavor of PANDA use 5.1 Surround Sound or Not.
|-
| force-parasite-buffer
| bool
| 0
| Set this true to make GraphicsOutput::make_texture_buffer() really strongly prefer ParasiteBuffers over conventional offscreen buffers.  With this set, it will create a ParasiteBuffer every time an offscreen buffer is requested, even if this means reducing the buffer size to fit within the window.  The only exceptions are for buffers that, by their nature, really cannot use ParasiteBuffers (like depth textures).  You might set this true if you don't trust your graphics driver's support for offscreen buffers.
|-
| frame-rate-meter-layer-sort
| int
| 1000
| -
|-
| frame-rate-meter-scale
| double
| 0.05
| -
|-
| frame-rate-meter-side-margins
| double
| 0.5
| -
|-
| frame-rate-meter-text-pattern
| string
| %0.1f fps
| -
|-
| frame-rate-meter-update-interval
| double
| 1.5
| -
|-
| framebuffer-alpha
| bool
| 1
| True if FM_alpha should be added to the default framebuffer properties, which requests an alpha channel if possible.
|-
| framebuffer-depth
| bool
| 1
| True if FM_depth should be added to the default framebuffer properties, which requests a depth buffer.
|-
| framebuffer-hardware
| bool
| #t  (from /etc/Config.prc); 1 hardcoded
| True if FM_hardware should be added to the default framebuffer properties, which requests a hardware-accelerated display.
|-
| framebuffer-mode
| string
| -
| No longer has any effect. Do not use.
|-
| framebuffer-multisample
| bool
| 0
| True if FM_multisample should be added to the default framebuffer properties, which requests a multisample-capable display, if possible.  This can be used to implement full-screen antialiasing.
|-
| framebuffer-software
| bool
| #f  (from /etc/Config.prc); 0 hardcoded
| True if FM_software should be added to the default framebuffer properties, which requests a software-only display.
|-
| framebuffer-stencil
| bool
| 0
| True if FM_stencil should be added to the default framebuffer properties, which requests an stencil buffer if possible.
|-
| framebuffer-stereo
| bool
| 0
| True if FM_stereo should be added to the default framebuffer properties, which requests a stereo-capable display, if supported by the graphics driver.
|-
| fullscreen
| bool
| #f  (from /etc/Config.prc); 0 hardcoded 
| -
|-
| game-server-timeout-ms
| int
| 20000
| This represents the amount of time to block waiting for the TCP connection to the game server.  It is only used when the connection method is NSPR.
|-
| geom-cache-min-frames
| int
| 1
| Specifies the minimum number of frames any one particular object will remain in the geom cache, even if geom-cache-size is exceeded.
|-
| geom-cache-size
| int
| 5000
| Specifies the maximum number of entries in the cache for storing pre-processed data for rendering vertices.  This limit is flexible, and may be temporarily exceeded if many different Geoms are pre-processed during the space of a single frame.
|-
| gl-cheap-textures
| bool
| 0
| Configure this true to GLP(Hint) the textures into the cheapest possible mode.
|-
| gl-color-mask
| bool
| 1
| Configure this false if your GL's implementation of glColorMask() is broken (some are).  This will force the use of a (presumably) more expensive blending operation instead.
|-
| gl-compile-and-execute
| bool
| 0
| Configure this true if you know your GL's implementation of glNewList(n, GL_COMPILE_AND_EXECUTE) works.  It is false by default, since it is known to cause a crash with Intel 855GM driver 4.14.10.3889 at least.  Turning this on *may* reduce the chug you get for preparing display lists for the first time, by allowing the display list to be rendered at the same time it is being compiled.
|-
| gl-debug-buffers
| bool
| 0
| Set this true, in addition to enabling debug notify for glgsg, to enable debug messages about the creation and destruction of OpenGL vertex buffers.
|-
| gl-finish
| bool
| 0
| Set this true to force a call to glFinish() after every major graphics operation.  This is likely to slow down rendering performance substantially, but it will make PStats graphs more accurately reflect where the graphics bottlenecks are.  This variable is enabled only if PStats is compiled in.
|-
| gl-force-depth-stencil
| bool
| 0
| Temporary hack variable 7x00 vs 8x00 nVidia bug.  See glGraphicsStateGuardian_src.cxx.
|-
| gl-force-mipmaps
| bool
| 0
| Configure this true to enable full trilinear mipmapping on every texture, whether it asks for it or not.
|-
| gl-force-no-error
| bool
| 0
| Avoid reporting OpenGL errors, for a small performance benefit.
|-
| gl-force-no-flush
| bool
| 0
| Avoid calling glFlush(), for a potential performance benefit.  This may be a little dangerous.
|-
| gl-ignore-clamp
| bool
| 0
| Configure this true to disable texture clamp mode (all textures repeat, a little cheaper for software renderers).
|-
| gl-ignore-filters
| bool
| 0
| Configure this true to disable any texture filters at all (forcing point sampling).
|-
| gl-ignore-mipmaps
| bool
| 0
| Configure this true to disable mipmapping only.
|-
| gl-interleaved-arrays
| bool
| 0
| Set this true to convert OpenGL geometry such that the primary data columns vertex, normal, color, and texcoord are interleaved into one array when possible, or false to render geometry as it appears in the GeomVertexData.  See also gl-parallel-arrays.
|-
| gl-matrix-palette
| bool
| 0
| Temporary hack variable protecting untested code.  See glGraphicsStateGuardian_src.cxx.
|-
| gl-max-errors
| int
| 20
| This is the limit on the number of OpenGL errors Panda will detect and report before it shuts down rendering.  Set it to -1 for no limit.
|-
| gl-min-buffer-usage-hint
| enum
| stream
| This specifies the first usage hint value that will be loaded as a vertex buffer, instead of directly from the client.  Normally, this should be &quot;stream&quot;, which means to load the vertex buffer using GL_STREAM_DRAW.  If this is set to &quot;dynamic&quot;, or &quot;static&quot;, then only usage hints at that level or higher will be loaded as a vertex buffer, and stream or lower will be rendered directly from the client array.  If changing this results in a remarkable performance improvement, you may have code that is creating and destroying vertex buffers every frame, instead of reusing the same buffers.  Consider increasing released-vbuffer-cache-size instead.
|-
| gl-parallel-arrays
| bool
| 0
| Set this true to convert OpenGL geometry such that each data column is a separate array, or false to render geometry as it appears in the GeomVertexData.  See also gl-interleaved-arrays.
|-
| gl-show-texture-usage
| bool
| 0
| If you set this true, the screen will flash with textures drawn in a special mode that shows the mipmap detail level and texture size for each texture.  Textures will be drawn in blue for mipmap level 0, gray for mipmap level 1, and red for all higher mipmap levels.  Brighter colors represent larger textures.
|-
| gl-show-texture-usage-max-size
| int
| 1024
| Specifies the texture size (along one side) of the largest texture expected to be loaded.  This controls the assignment of the texture color in gl-show-texture-usage mode; colors will be fully bright for textures of this size or larger.
|-
| gl-support-clamp-to-border
| bool
| 1
| Configure this true to enable the use of the clamp_to_border extension if the GL claims to support it, or false not to use it even if it appears to be available.  (On some OpenGL drivers, enabling this mode can force software rendering.)
|-
| gl-support-occlusion-query
| bool
| 1
| Configure this true to enable the use of the occlusion_query extension if the GL claims to support it, or false not to use it even if it appears to be available.  (On some OpenGL drivers, enabling this mode can force software rendering.)
|-
| gl-support-rescale-normal
| bool
| 1
| Configure this true to enable the use of the rescale_normal extension if the GL claims to support it, or false not to use it even if it appears to be available.  (This appears to be buggy on some drivers.)
|-
| glx-get-os-address
| bool
| 1
| Set this to true to allow Panda to query the OpenGL library directly using standard operating system calls to locate addresses of extension functions.  This will be done only if glxGetProcAddress() cannot be used for some reason.
|-
| glx-get-proc-address
| bool
| 1
| Set this to true to allow the use of glxGetProcAddress(), if it is available, to query the OpenGL extension functions.  This is the standard way to query extension functions.
|-
| glx-support-pbuffer
| bool
| 0
| Set this true to enable the use of X pbuffer-based offscreen buffers, if available.  This is usually preferred over pixmap-based buffers, but not all drivers support them.
|-
| glx-support-pixmap
| bool
| 0
| Set this true to enable the use of X pixmap-based offscreen buffers.  This is false by default because pixmap-based buffers are usually slower than pbuffer-based buffers, and because at least one driver is known to crash (crash!) when it attempts to create a pixmap-based buffer.
|-
| graphics-memory-limit
| int
| -1
| This is a default limit that is imposed on each GSG at GSG creation time.  It limits the total amount of graphics memory, including texture memory and vertex buffer memory, that will be consumed by the GSG, regardless of whether the hardware claims to provide more graphics memory than this.  It is useful to put a ceiling on graphics memory consumed, since some drivers seem to allow the application to consume more memory than the hardware can realistically support.  Set this to -1 to have no limit other than the normal hardware-imposed limit.
|-
| handle-datagrams-internally
| bool
| 1
| When this is true, certain datagram types can be handled directly by the C++ cConnectionRepository implementation, for performance reasons.  When it is false, all datagrams are handled by the Python implementation.
|-
| hardware-animated-vertices
| bool
| #f  (from /etc/Config.prc); 0 hardcoded
| Set this true to allow the transforming of soft-skinned animated vertices via hardware, if supported, or false always to perform the vertex animation via software within Panda.  If you have a card that supports this, and your scene does not contain too many vertices already, this can provide a performance boost by offloading some work from your CPU onto your graphics card.  It may also help by reducing the bandwidth necessary on your computer's bus.  However, in some cases it may actually reduce performance.
|-
| hardware-point-sprites
| bool
| 1
| Set this true to allow the use of hardware extensions when rendering perspective-scaled points and point sprites.  When false, these large points are always simulated via quads computed in software, even if the hardware claims it can support them directly.
|-
| hardware-points
| bool
| 1
| Set this true to allow the use of hardware extensions when rendering large points.  When false, large points (even if untextured) will be simulated via quads computed in software.
|-
| http-connect-timeout
| double
| 10
| This is the default amount of time to wait for a TCP/IP connection to be established, in seconds.
|-
| http-idle-timeout
| double
| 5
| This the amount of time, in seconds, in which a previously-established connection is allowed to remain open and unused.  If a previous connection has remained unused for at least this number of seconds, it will be closed and a new connection will be opened; otherwise, the same connection will be reused for the next request (for a particular HTTPChannel).
|-
| http-max-connect-count
| int
| 10
| This is the maximum number of times to try reconnecting to the server on any one document attempt.  This is just a failsafe to prevent the code from attempting runaway connections; this limit should never be reached in practice.
|-
| http-proxy-tunnel
| bool
| 0
| This specifies the default value for HTTPChannel::set_proxy_tunnel().  If this is true, we will tunnel through a proxy for all connections, instead of asking the proxy to serve documents normally.
|-
| http-skip-body-size
| int
| 8192
| This is the maximum number of bytes in a received (but unwanted) body that will be skipped past, in order to reset to a new request.  See HTTPChannel::set_skip_body_size().
|-
| http-timeout
| double
| 20
| This is the default amount of time to wait for the HTTP server (or proxy) to finish sending its response to our request, in seconds. It starts counting after the TCP connection has been established (http_connect_timeout, above) and the request has been sent.
|-
| icon-filename
| filename
| -
| -
|-
| img-header-type
| enum
| short
| IMG format is just a sequential string of r, g, b bytes.  However, it may or may not include a &quot;header&quot; which consists of the xsize and the ysize of the image, either as shorts or as longs.  Specify that with this variable, either 'short', 'long', or 'none' for no header at all (in which case you should also set img-size).
|-
| img-size
| int
| 0
| If an IMG file without a header is loaded (e.g. img-header-type is set to 'none', this specifies the fixed x y size of the image.
|-
| inactivity-timeout
| double
| 0
| -
|-
| interpolate-frames
| bool
| 0
| Set this true to interpolate character animations between frames, or false to hold each frame until the next one is ready.  This can also be changed on a per-character basis with PartBundle::set_frame_blend_flag().
|-
| interrogatedb-path
| search-path
| -
| The search path for interrogate's *.in files.
|-
| interval-precision
| double
| 1000
| Set this to the default value for set_precision() for each CMetaInterval created.
|-
| jpeg-quality
| int
| 95
| Set this to the quality percentage for writing JPEG files.  95 is the highest useful value (values greater than 95 do not lead to significantly better quality, but do lead to significantly greater size).
|-
| keep-temporary-files
| bool
| 0
| Set this true to keep around the temporary files from downloading, decompressing, and patching, or false (the default) to delete these.  Mainly useful for debugging when the process goes wrong.
|-
| keep-texture-ram
| bool
| 0
| Set this to true to retain the ram image for each texture after it has been prepared with the GSG.  This will allow the texture to be prepared with multiple GSG's, or to be re-prepared later after it is explicitly released from the GSG, without having to reread the texture image from disk; but it will consume memory somewhat wastefully.
|-
| load-display
| string
| pandagl  (from /etc/Config.prc); * hardcoded
| Specify the name of the default graphics display library or GraphicsPipe to load.  It is the name of a shared library (or * for all libraries named in aux-display), optionally followed by the name of the particular GraphicsPipe class to create.
|-
| load-file-type
| list
| egg pandaegg  (from /etc/Confauto.prc), p3ptloader  (from /etc/Confauto.prc)
| List the model loader modules that Panda will automatically import when a new, unknown model type is loaded.  This may be either the name of a module, or a space-separate list of filename extensions, followed by the name of the module.
|-
| loader-num-threads
| int
| 1
| The number of threads that will be started by the Loader class to load models asynchronously.  These threads will only be started if the asynchronous interface is used, and if threading support is compiled into Panda.  The default is one thread, which allows models to be loaded one at a time in a single asychronous thread.  You can set this higher, particularly if you have many CPU's available, to allow loading multiple models simultaneously.
|-
| loader-thread-priority
| enum
| low
| The default thread priority to assign to the threads created for asynchronous loading.  The default is 'low'; you may also specify 'normal', 'high', or 'urgent'.
|-
| lod-fade-bin-draw-order
| int
| 0
| The default bin draw order to assign the fading part of a FadeLODNode transition.
|-
| lod-fade-bin-name
| string
| fixed
| The default bin name in which to place the fading part of a FadeLODNode transition.
|-
| lod-fade-state-override
| int
| 1000
| The default override value to assign to the fade attribs in order to effect a FadeLODNode transition.
|-
| lod-fade-time
| double
| 0.5
| The default amount of time (in seconds) over which a FadeLODNode transitions between its different levels.
|-
| m-dual
| bool
| 1
| Set this false to disable TransparencyAttrib::M_dual altogether (and use M_alpha in its place).
|-
| m-dual-flash
| bool
| 0
| Set this true to flash any objects that use M_dual, for debugging.
|-
| m-dual-opaque
| bool
| 1
| Set this false to disable just the opaque part of M_dual.
|-
| m-dual-transparent
| bool
| 1
| Set this false to disable just the transparent part of M_dual.
|-
| matrix-palette
| bool
| 0
| Set this true to allow the use of the matrix palette when animating vertices in hardware.  The matrix palette is not supported by all devices, but if it is, using it can allow animation of more sophisticated meshes in hardware, and it can also improve the performance of animating some simpler meshes.  Without this option, certain meshes will have to be animated in software.  However, this option is not enabled by default, because its support seems to be buggy in certain drivers (ATI FireGL T2 8.103 in particular.)
|-
| max-attribs
| int
| 32
| This specifies the maximum number of different RenderAttrib types that may be defined at runtime.  Normally you should never need to change this, but if the default value is too low for the number of attribs that Panda actually defines, you may need to raise this number.
|-
| max-collect-indices
| int
| 65535
| Specifies the maximum number of vertex indices that are allowed to be accumulated into any one GeomPrimitive as a result of collecting objects together during a flatten operation.  This prevents the accidental generation of large index buffers from lots of smaller index buffers, while not imposing a limit on the original size of any one GeomPrimitive.
|-
| max-collect-vertices
| int
| 65534
| Specifies the maximum number of vertices that are allowed to be accumulated into any one GeomVertexData structure as a result of collecting objects together during a flatten operation.  This prevents the accidental generation of large vertex buffers from lots of smaller vertex buffers, while not imposing a limit on the original size of any one GeomVertexData structure.
|-
| max-compressed-vertex-data
| int
| 0
| Specifies the maximum number of bytes of all vertex data that is allowed to remain compressed in system RAM at one time. If more than this number of bytes of vertices are created, the least-recently-used ones will be temporarily flushed to disk until they are needed.  Set it to -1 for no limit.
|-
| max-disk-vertex-data
| int
| -1
| Specifies the maximum number of bytes of vertex data that is allowed to be written to disk.  Set it to -1 for no limit.
|-
| max-dt
| double
| -1
| Sets a limit on the value returned by ClockObject::get_dt().  If this value is less than zero, no limit is imposed; otherwise, this is the maximum value that will ever be returned by get_dt(), regardless of how much time has actually elapsed between frames.  See ClockObject::set_dt().
|-
| max-heap-size
| int64
| 0 
| If this is nonzero, it is the maximum number of bytes expected to be allocated on the heap before we enter report-memory-usage mode automatically.  The assumption is that once this limit has been crossed, we must be leaking.
|-
| max-independent-vertex-data
| int
| -1
| Specifies the maximum number of bytes of all vertex data that is independent of the paging system.  This is an initial buffer before max-ram-vertex-data, specifically designed for vertex datas that are dynamic in nature and may change size or be created and destroyed frequently.
|-
| max-lag
| double
| 0
| This represents the time in seconds by which to artificially lag inbound messages.  It is useful to test a game's tolerance of network latency.
|-
| max-lenses
| int
| 100
| Specifies an upper limit on the maximum number of lenses and the maximum lens index number) that may be associated with a single LensNode.  There is no technical reason for this limitation, but very large numbers are probably a mistake, so this can be used as a simple sanity check.  Set it larger or smaller to suit your needs.
|-
| max-occlusion-vertices
| int
| 3000
| The maximum number of vertices that may be included in a PandaNode and its descendents in order to perform an occlusion query for it.  Subgraphs whose total vertex count exceeds this number will be subdivided further before performing an occlusion test--the hope is that we can eventually get to a finer-grained answer.  GeomNodes and Geoms will not be subdivided, regardless of this limit.
|-
| max-resident-vertex-data
| int
| -1
| Specifies the maximum number of bytes of all vertex data that is allowed to remain resident in system RAM at one time. If more than this number of bytes of vertices are created, the least-recently-used ones will be temporarily compressed in system RAM until they are needed.  Set it to -1 for no limit.
|-
| max-texture-dimension
| int
| -1
| Set this to the maximum size a texture is allowed to be in either dimension.  This is generally intended as a simple way to restrict texture sizes for limited graphics cards.  When this is greater than zero, each texture image loaded from a file (but only those loaded from a file) will be automatically scaled down, if necessary, so that neither dimension is larger than this value.  If this is less than zero, the size limit is taken from the primary GSG.  If this is exactly zero, there is no limit.
|-
| max-texture-stages
| int
| -1
| Set this to a positive integer to limit the number of texture stages reported by the GSG.  This can be used to limit the amount of multitexturing Panda will attempt to use.  If this is zero or less, the GSG will report its honest number of texture stages, allowing Panda the full use of the graphics card; if it is 1 or more, then Panda will never allow more than this number of texture stages simultaneously, regardless of what the GSG says it can do.
|-
| min-lag
| double
| 0
| This represents the time in seconds by which to artificially lag inbound messages.  It is useful to test a game's tolerance of network latency.
|-
| min-occlusion-vertices
| int
| 300
| The minimum number of vertices a PandaNode or Geom must contain in order to perform an occlusion query for it.  Nodes and Geoms smaller than this will be rendered directly, without bothering with an occlusion query.
|-
| model-path 
| ?
| ?
| 
sometimes used with vfs-mount-url &lt;br&gt; 
e.g. &lt;br&gt; 
vfs-mount-url http://localhost/mydir /mydir &lt;br&gt; 
model-path /mydir
|-
| multi-sleep
| bool
| 0
| DConfig
|-
| multifile-encryption-iteration-count
| int
| 0
| This is a special value of encryption-iteration-count used to encrypt subfiles within a multifile.  It has a default value of 0 (just one application), on the assumption that the files from a multifile must be loaded quickly, without paying the cost of an expensive hash on each subfile in order to decrypt it.
|-
| multisamples
| int
| 0  (from /etc/Config.prc); 0 hardcoded
| The minimum number of samples requested.
|-
| name-deleted-mutexes
| bool
| 0
| Set this true to allocate a name to each Mutex object that destructs, so if the Mutex is locked after destruction, we can print out its name to aid debugging.  This is only available when compiled with DEBUG_THREADS.  Enabling this variable will cause a memory leak, so you should only enable it when you are specifically tracking down an operation on a deleted Mutex.  It is not guaranteed to work, of course, because the memory for a deleted Mutex may become reused for some other purpose.
|-
| newline-mode
| enum
| native
| Controls how newlines are written by Panda applications writing to a text file.  The default, &quot;native&quot;, means to write newlines appropriate to the current platform.  You may also specify &quot;binary&quot;, to avoid molesting the file data, or one of &quot;msdos&quot;, &quot;unix&quot;, or &quot;mac&quot;.
|-
| no-unsupported-copy
| bool
| 0
| Set this true to make an attempt to copy an unsupported type generate an assertion failure instead of just a warning (which can then be trapped with assert-abort).
|-
| notify-level-BufferViewer
| string
| -
| DConfig
|-
| notify-level-BulletinBoard
| string
| -
| DConfig
|-
| notify-level-ClassicFSM
| string
| -
| DConfig
|-
| notify-level-DirectScrolledList
| string
| -
| DConfig
|-
| notify-level-DirectScrolledListItem
| string
| -
| DConfig
|-
| notify-level-EventManager
| string
| -
| DConfig
|-
| notify-level-ExceptionVarDump
| string
| -
| DConfig
|-
| notify-level-FunctionInterval
| string
| -
| DConfig
|-
| notify-level-GarbageReport
| string
| -
| DConfig
|-
| notify-level-InputState
| string
| -
| DConfig
|-
| notify-level-JobManager
| string
| -
| DConfig
|-
| notify-level-LerpFunctionInterval
| string
| -
| DConfig
|-
| notify-level-LerpFunctionNoStateInterval
| string
| -
| DConfig
|-
| notify-level-Loader
| string
| -
| DConfig
|-
| notify-level-Messenger
| string
| -
| DConfig
|-
| notify-level-MetaInterval
| string
| -
| DConfig
|-
| notify-level-ShowBase
| string
| -
| DConfig
|-
| notify-level-State
| string
| -
| DConfig
|-
| notify-level-TaskManager
| string
| -
| DConfig
|-
| notify-output
| filename
| -
| The filename to which to write all the output of notify
|-
| occlusion-depth-bits
| int
| 1
| The minimum number of depth bits requested for the occlusion buffer.
|-
| occlusion-size
| int
| 256 256
| Specify the x y size of the buffer used for occlusion testing.
|-
| on-screen-debug-enabled
| bool
| 0
| DConfig
|-
| paranoid-compose
| bool
| 0
| Set this true to double-check the componentwise transform compose (or invert) operation against the equivalent matrix-based operation.  This has no effect if NDEBUG is defined.
|-
| paranoid-const
| bool
| 0
| Set this true to double-check that nothing is inappropriately modifying the supposedly const structures like RenderState, RenderAttrib, TransformState, and RenderEffect.  This has no effect if NDEBUG is defined.
|-
| paranoid-hpr-quat
| bool
| 0
| Set this true to doublecheck the quaternion-hpr compose and decompose operations against the quaternion-matrix and matrix-hpr operations.  This only has effect if NDEBUG is not defined.
|-
| parent-window-handle
| int
| 0
| The window handle of the parent window to attach the Panda window to, for the purposes of creating an embedded window.  This is an HWND on Windows, or the NSWindow pointer or XWindow pointer converted to an integer, on OSX and X11.
|-
| particle-path
| search-path
| -
| The directories to search for particle files to be loaded.
|-
| patcher-buffer-size
| int
| 16384
| Limits the size of the buffer used in a single call to Patcher::run().  Increasing this may help the Patcher perform more work before returning.
|-
| patchfile-buffer-size
| int
| 4096
| -
|-
| patchfile-increment-size
| int
| 8
| -
|-
| patchfile-window-size
| int
| 16
| -
|-
| patchfile-zone-size
| int
| 10000
| -
|-
| physics_manager_random_seed
| int
| 139
| -
|-
| pipeline-stages
| int
| 1
| The initial number of stages in the render pipeline.  This is only meaningful if threaded pipelining is compiled into Panda.  In most cases, you should not set this at all anyway, since the pipeline can automatically grow stages as needed, but it will not remove stages automatically, and having more pipeline stages than your application requires will incur additional runtime overhead.
|-
| pixel-zoom
| double
| 1
| The default pixel_zoom factor for new windows.
|-
| playback-session
| string
| -
| DConfig
|-
| plugin-path
| search-path
| -
| The directories to search for plugin shared libraries.
|-
| polylight-info
| bool
| 0
| Set this true to view some info statements regarding the polylight. It is helpful for debugging.
|-
| prefer-parasite-buffer
| bool
| 0
| Set this true to make GraphicsOutput::make_texture_buffer() try to create a ParasiteBuffer before it tries to create an offscreen buffer (assuming it could not create a direct render buffer for some reason).  This may reduce your graphics card memory requirements by sharing memory with the framebuffer, but it can cause problems if the user subsequently resizes the window smaller than the buffer.
|-
| prefer-single-buffer
| bool
| 1
| Set this true to make GraphicsOutput::make_render_texture() first try to create a single-buffered offscreen buffer, before falling back to a double-buffered one (or whatever kind the source window has).  This is true by default to reduce waste of framebuffer memory, but you might get a performance benefit by setting it to false (since in that case the buffer can share a graphics context with the window).
|-
| prefer-texture-buffer
| bool
| 1
| Set this true to make GraphicsOutput::make_texture_buffer() always try to create an offscreen buffer supporting render-to-texture, if the graphics card claims to be able to support this feature.  If the graphics card cannot support this feature, this option is ignored.  This is usually the fastest way to render to a texture, and it presumably does not consume any additional framebuffer memory over a copy-to-texture operation (since the texture and the buffer share the same memory).
|-
| preload-simple-textures
| bool
| 0
| When this is true, every texture image will have a simple image generated for it at load time.  (Normally, textures get a simple image at egg2bam time.)  This slows the initial loading time of textures, but allows you to take advantage of gsg::set_incomplete_render() to load textures on-the-fly in a sub-thread.  It's not generally necessary if you are loading bam files that were generated via egg2bam.
|-
| preload-textures
| bool
| 1
| When this is true, texture images are loaded from disk as soon as the Texture is created from the TexturePool.  When this is false, the Texture is created immediately, but the image data is not loaded from disk until the Texture is actually rendered (or otherwise prepared) on the GSG.  This can help reduce wasted memory from Textures that are created but never used to render.
|-
| premunge-data
| bool
| 1
| Set this true to preconvert vertex data at model load time to match the data requirements of the current GSG.  For instance, color columns are pre-converted to match OpenGL or DirectX encoding requirements, as appropriate.  When this is false, the data will be munged at render time instead.
|-
| preserve-geom-nodes
| bool
| 0
| This specifies the default value for the &quot;preserved&quot; flag on every GeomNode created.  When this is true, GeomNodes will not be flattened, so setting this true effectively disables the use of flatten to combine GeomNodes.
|-
| preserve-triangle-strips
| bool
| 0
| Set this true to indicate a preference for keeping triangle strips when possible, instead of decomposing them into triangles.  When this is true, flatten_strong and unify operations may be less effective at combining multiple Geoms together, but they will not implicitly decompose triangle strips.
|-
| profile-frames
| bool
| 0
| -
|-
| profile-task-spikes
| bool
| 0
| -
|-
| project-invert-uvs
| bool
| 0
| If this is true, the UV's generated by all ProjectionScreens are inverted top-to-bottom.  This used to be required to compensate for buggy graphics drivers that rendered to a texture upside-down in this manner, but nowadays Panda should be able to autodetect these graphics drivers.  If it fails to do this, you should probably set copy-texture-inverted instead, which is more general.
|-
| pstats-average-time
| double
| 3
| -
|-
| pstats-history
| double
| 60
| -
|-
| pstats-host
| string
| localhost
| -
|-
| pstats-max-queue-size
| int
| 1
| If pstats-threaded-write is true, this specifies the maximum number of packets (generally, frames of data) that may be queued up for the thread to process.  If this is large, the writer thread may fall behind and the output of PStats will lag.  Keep this small to drop missed packets on the floor instead, and ensure that the frame data does not grow stale.
|-
| pstats-max-rate
| double
| 1000
| The maximum number of packets per second, per thread, to send to the remote PStats server.  A packet is defined as a single UDP packet, or each 1024 bytes of a TCP message.
|-
| pstats-mem-other
| bool
| 1
| Set this true to collect memory categories smaller than 0.1% of the total into a single &quot;Other&quot; category, or false to show each nonzero memory category.
|-
| pstats-name
| string
| Panda Stats
| -
|-
| pstats-port
| int
| 5185
| -
|-
| pstats-scroll-mode
| bool
| 1
| -
|-
| pstats-target-frame-rate
| double
| 30
| Specify the target frame rate to highlight on the PStats graph.  This frame rate is marked with a different-colored line; otherwise, this setting has no effect.
|-
| pstats-tasks
| bool
| 0
| DConfig
|-
| pstats-tcp-ratio
| double
| 0.01
| This specifies the ratio of frame update messages that are eligible for UDP that are sent via TCP instead.  It does not count messages that are too large for UDP and must be sent via TCP anyway.  1.0 means all messages are sent TCP; 0.0 means all are sent UDP.
|-
| pstats-threaded-write
| bool
| 1
| Set this true to write to the PStats channel in a sub-thread, if threading is available.  Can't think of any reason why you wouldn't want this set true, unless you suspect something is broken with the threaded network interfaces.
|-
| pstats-unused-states
| bool
| 0
| Set this true to show the number of unused states in the pstats graph for TransformState and RenderState counts.  This adds a bit of per-frame overhead to count these things up.
|-
| read-compressed-channels
| bool
| 1
| Set this false to disable reading of compressed animation channels, even if the decompression code is available.  The only reason you might want to do this would be to speed load time when you don't care about what the animation looks like.
|-
| read-raw-mice
| bool
| 0
| DConfig
|-
| record-gui-creation-stack
| bool
| 1
| DConfig
|-
| record-session
| string
| -
| DConfig
|-
| red-blue-stereo
| bool
| 0
| Set this true to create windows with red-blue stereo mode enabled by default, if the framebuffer does not support true stereo rendering.
|-
| red-blue-stereo-colors
| string
| red cyan
| This defines the color channels that are used for the left and right eye, respectively, for red-blue-stereo mode.  This should be a two-word string, where each word is one of 'red', 'blue', 'green', 'cyan', 'magenta', 'yellow', or 'alpha', or a union of two or more words separated by a vertical pipe (|).
|-
| released-ibuffer-cache-size
| int
| 102400
| Specifies the size in bytes of the cache of index buffers that have recently been released.  If a new index buffer is prepared while a recently-released one of the same size is still in the cache, that same buffer is recycled.  This cuts down on the overhead of creating and destroying index buffers on the graphics card.
|-
| released-vbuffer-cache-size
| int
| 1048576
| Specifies the size in bytes of the cache of vertex buffers that have recently been released.  If a new vertex buffer is prepared while a recently-released one of the same size is still in the cache, that same buffer is recycled.  This cuts down on the overhead of creating and destroying vertex buffers on the graphics card.
|-
| report-memory-interval
| double
| 5
| This is the interval, in seconds, for reports of currently allocated memory, when report-memory-usage is true.
|-
| report-memory-usage
| bool
| 0
| Set this true to enable automatic reporting of allocated objects at the interval specified by report-memory-interval.  This also requires track-memory-usage.
|-
| require-window
| bool
| 1
| DConfig
|-
| rescale-normals
| enum
| auto
| Specifies the kind of RescaleNormalAttrib that should be created for the top of the scene graph.  This can automatically ensure that your lighting normals are unit-length, which may be particularly necessary in the presence of scales in the scene graph.  Turning it off ('none') may produce a small performance benefit.
|-
| respect-effective-normal
| bool
| 1
| This should be true to support the effective_normal interface of polygons.  Set it false to disable this feature, so that all collision solids (including polygons and planes) use their actual normal for intersection and physics tests.
|-
| respect-prev-transform
| bool
| 0
| Set this true to have all CollisionTraversers in the world respect the previous frame's transform (position) for a given object when determining motion for collision tests.  If this is false, you must explicitly enable motion detection for a particular traverser.  It is false by default to force programmers to decide on a case-by-case basis whether they really need this feature.
|-
| restore-initial-pose
| bool
| 1
| When this is true, setting all control effects on an Actor to 0 causes it to return to its default, unanimated pose.  When false, it retains whatever its last-computed pose was (which may or may not be the default pose).
|-
| retransform-sprites
| bool
| 1
| To render sprite-based particle effects, Panda must convert the sprite points from object space into clip space, and compute the corners of the quads in clip space.  When this variable is false, the resulting quads are then sent to the graphics hardware in clip space.  When this is true, the quads are re-transformed back into the original object space, which is necessary in order for fog to work correctly on the sprites.
|-
| scene-graph-analyzer-meter-layer-sort
| int
| 1000
| -
|-
| scene-graph-analyzer-meter-scale
| double
| 0.05
| -
|-
| scene-graph-analyzer-meter-side-margins
| double
| 0.5
| -
|-
| scene-graph-analyzer-meter-update-interval
| double
| 2
| -
|-
| screenshot-extension
| string
| jpg
| DConfig
|-
| screenshot-filename
| string
| %~p-%a-%b-%d-%H-%M-%S-%Y-%~f.%~e
| This specifies the filename pattern to be used to generate screenshots captured via save_screenshot_default().  See DisplayRegion::save_screenshot().
|-
| scroll-continued-delay
| double
| 0.1
| This is the amount of time, in seconds, to delay between lines scrolled while the user is continuing to hold down the scrollbar button.
|-
| scroll-initial-delay
| double
| 0.3
| This is the amount of time, in seconds, to delay after the user first clicks and holds on a scrollbar button before the scrolling continues automatically.
|-
| sgi-imagename
| string
| -
| This string is written to the header of an SGI (*.rgb) file.  It seems to have documentation purposes only.
|-
| sgi-storage-type
| enum
| rle
| Use either 'rle' or 'verbatim' to indicate how SGI (*.rgb) files are written.
|-
| shader-auto-utilization
| bool
| 0
| If this is true, then panda will wait until you open a window, and then ask the window if it supports basic or advanced shaders. If so, then the config variable shader-utilization will automatically be adusted.  The pitfall of doing this is that if you then open a second window that doesn't support the same capabilities, it will have no choice but to print an error message.
|-
| shader-utilization
| enum
| none
| At times, panda may generate shaders.  This variable controls what kinds of shaders can be generated.  If you set it to SUT_none, shader generation will be be disabled.  If you set it to SUT_basic, then DX9 shaders may be generated, if you set it to SUT_advanced, then DX10 shaders may be generated.
|-
| show-buffers
| bool
| 0
| -
|-
| show-frame-rate-meter
| bool
| #f  (from /etc/Config.prc); 0 hardcoded
| DConfig
|-
| show-occlusion
| bool
| 0
| Set this true to visualize the efforts of the occlusion test.
|-
| show-tex-mem
| bool
| 0
| DConfig
|-
| show-transparency
| bool
| 0
| Set this true to flash any objects that are rendered in some transparency mode.  The color chosen is based on the  particular transparency mode in effect.  This only has effect when NDEBUG is not defined.
|-
| show-vertex-animation
| bool
| 0
| Set this true to flash any objects whose vertices are animated by Panda on the CPU (flash red) or by hardware (flash blue).  This only has effect when NDEBUG is not defined.
|-
| simple-image-size
| int
| 16 16
| This is an x y pair that specifies the maximum size of an automatically-generated texture simple image.  The simple image can displayed before the texture has been loaded from disk.
|-
| simple-image-threshold
| double
| 0.1
| This is a value that indicates how closely a texture's generated simple image should approximate the original image.  The smaller the number, the closer the match; small numbers will result in simple images close to the maximum size specified by simple-image-size.  Larger numbers will result in smaller simple images.  Generally the value should be considerably less than 1.
|-
| simple-thread-epoch-timeslice
| double
| 0.05
| When SIMPLE_THREADS is defined, this defines the amount of time, in seconds, that should be considered the typical timeslice for one epoch (to run all threads once).
|-
| simple-thread-high-weight
| double
| 5
| When SIMPLE_THREADS is defined, this determines the relative amount of time that is given to threads with priority TP_high.
|-
| simple-thread-low-weight
| double
| 0.2
| When SIMPLE_THREADS is defined, this determines the relative amount of time that is given to threads with priority TP_low.
|-
| simple-thread-normal-weight
| double
| 1
| When SIMPLE_THREADS is defined, this determines the relative amount of time that is given to threads with priority TP_normal.
|-
| simple-thread-urgent-weight
| double
| 10
| When SIMPLE_THREADS is defined, this determines the relative amount of time that is given to threads with priority TP_urgent.
|-
| simple-thread-volunteer-delay
| double
| 0
| When SIMPLE_THREADS is defined, this defines the amount of time, in seconds, for which a task that voluntarily yields should be delayed.
|-
| simple-thread-window
| double
| 1
| When SIMPLE_THREADS is defined, this defines the amount of time, in seconds, over which to average all the threads' runtimes, for the purpose of scheduling threads.
|-
| singular-points
| bool
| 1
| Set this true to insist that when RenderModeAttrib::M_points is used, each point appears only once in the result, even if the vertex is referenced multiple times.  This is particularly important when rendering points from a triangle mesh and you don't want the points to appear repeatedly.
|-
| skel-sample-config-variable
| int
| 3
| -
|-
| sleep-precision
| double
| 0.01
| This is the accuracy within which we can expect select() to return precisely.  That is, if we use select() to request a timeout of 1.0 seconds, we can expect to actually sleep for somewhere between 1.0 and 1.0 + sleep-precision seconds.
|-
| ssl-certificates
| list
| -
| -
|-
| state-cache
| bool
| 1
| Set this true to enable the cache of RenderState objects, similar to the TransformState cache controlled via transform-cache.
|-
| stencil-bits
| int
| 0  (from /etc/Config.prc); 0 hardcoded
| The minimum number of stencil buffer bits requested.
|-
| subprocess-window
| filename
| -
| The filename of a SubprocessWindowBuffer's temporary mmap file, used for opening a window in a child process and rendering to a different window in the parent process.  This is specifically used for OSX when the plugin is compiled, and is not used or needed in other environments.  See WindowProperties::set_subprocess_window().
|-
| subprocess-window-max-wait
| double
| 0.2
| This is the amount of time, in seconds, that the SubprocessWindow will wait in begin_flip for the parent process to remove the previously-rendered frame.  When this time is exceeded, the next frame will be rendered without having flipped the previous one.  This is designed to allow the Python process some time to run even when the parent window is offscreen or minimized.
|-
| support-fade-lod
| bool
| 1
| Set this false to make FadeLOD nodes behave like regular LOD nodes (ignoring the fade time).  This may be useful, for instance, to test the performance impact of using FadeLOD nodes.
|-
| support-render-texture
| bool
| 1
| Set this true allow use of the render-to-a-texture feature, if it is supported by your graphics card.  Without this enabled, offscreen renders will be copied to a texture instead of directly rendered there.
|-
| support-rescale-normal
| bool
| 1
| Set this true to allow use of the rescale-normal feature, if it is supported by your graphics card.  This allows lighting normals to be uniformly counter-scaled, instead of re-normalized, in the presence of a uniform scale, which should in principle be a bit faster.  This feature is only supported by the OpenGL API.
|-
| support-stencil
| bool
| 1
| Set this true to allow use of the stencil buffer, if it is supported by your graphics card.  If this is false, stencil buffer support will not be enabled, even if it is supported.  Generally, only very old cards do not support some kind of stencil buffer operations; but it is also not supported by our tinydisplay renderer.  The main reason to set this false is to test your code in the absence of stencil buffer support.
|-
| support-threads
| bool
| 1
| Set this false to disallow the creation of threads using Panda's Thread interface, even if threading support is compiled in.  This does not affect the operation of mutexes and other synchronization primitives, just the creation of threads.
|-
| sync-flip
| bool
| 1
| Set this true to attempt to flip all windows at the same time, or false to flip each window as late as possible.  Setting this false can improve parallelization.  This is a temporary variable; it will later be replaced with a more explicit control over synchronizing window flip.
|-
| sync-video
| bool
| 1
| Configure this true to request the rendering to sync to the video refresh, or false to let your frame rate go as high as it can, irrespective of the video refresh.  Usually you want this true, but it may be useful to set it false during development for a cheesy estimate of scene complexity.  Some drivers may ignore this request.
|-
| task-timer-verbose
| bool
| 0
| DConfig
|-
| temp-hpr-fix
| bool
| 1
| Set this true to compute hpr's correctly.  Historically, Panda has applied these in the wrong order, and roll was backwards relative to the other two.  Set this false if you need compatibility with Panda's old hpr calculations.
|-
| text-anisotropic-degree
| int
| 1
| This is the default anisotropic-degree that is set on dynamic font textures.  Setting this to a value greater than 1 can help smooth out the antialiasing for small letters.
|-
| text-default-font
| filename
| -
| This names a filename that will be loaded at startup time as the default font for any TextNode that does not specify a font otherwise.  The default is to use a special font that is compiled into Panda, if available.
|-
| text-default-underscore-height
| double
| -0.2
| Specifies the default height of the underscore line, relative to the text baseline, when underscoring is enabled.
|-
| text-dynamic-merge
| bool
| 1
| Set this true to merge generated glyphs into the GeomVertexData as the text is assembled, or false to wait for the flatten operation.  Usually it's a performance advantage to keep this true.  See TextNode::set_flatten_flags().
|-
| text-embed-graphic-key
| int
| 5
| This is the decimal character number that, embedded in a string, is used to bracket the name of a model added to the TextPropertiesManager object, to embed an arbitrary graphic image within a paragraph.
|-
| text-encoding
| enum
| iso8859
| Specifies how international characters are represented in strings of 8-byte characters presented to Panda.  See TextEncoder::set_encoding().
|-
| text-flatten
| bool
| 1
| Set this true to flatten text when it is generated, or false to keep it as a deep hierarchy.  Usually it's a performance advantage to keep this true, but this also depends on the setting of text-dynamic-merge.  See TextNode::set_flatten_flags().
|-
| text-hyphen-ratio
| double
| 0.7
| If the rightmost whitespace character falls before this fraction of the line, hyphenate a word to the right of that if possible.
|-
| text-magfilter
| enum
| linear
| The default texture magfilter type for dynamic text fonts
|-
| text-max-never-break
| int
| 3
| If we have more than this number of text-never-break-before characters in a row, do not treat any of them as special and instead break the line wherever we can.
|-
| text-minfilter
| enum
| linear_mipmap_linear
| The default texture minfilter type for dynamic text fonts
|-
| text-native-antialias
| bool
| 1
| -
|-
| text-page-size
| int
| 256 256
| This is the default size for new textures created for dynamic fonts.
|-
| text-pixels-per-unit
| double
| 30
| -
|-
| text-point-size
| double
| 10
| -
|-
| text-poly-margin
| double
| 0
| This is the amount by which to make each glyph polygon larger than strictly necessary, in screen units that are added to each margin.  Increasing this value will decrease the tendency for letters to get chopped off at the edges, but it will also increase the tendency for adjacent glyphs to bleed into each other (unless you also increase text-texture-margin).
|-
| text-pop-properties-key
| int
| 2
| This is the decimal character number that undoes the effect of a previous appearance of text_push_properties_key.
|-
| text-push-properties-key
| int
| 1
| This is the decimal character number that, embedded in a string, is used to bracket the name of a TextProperties structure added to the TextPropertiesManager object, to control the appearance of subsequent text.
|-
| text-quality-level
| enum
| best
| The default quality level for dynamic text fonts; see Texture::set_quality_level().
|-
| text-render-mode
| enum
| texture
| The default render mode for dynamic text fonts
|-
| text-scale-factor
| double
| 2
| -
|-
| text-small-caps
| bool
| 0
| This controls the default setting for TextNode::set_small_caps().
|-
| text-small-caps-scale
| double
| 0.8
| This controls the default setting for TextNode::set_small_caps_scale().
|-
| text-soft-break-key
| int
| 4
| This is similar to text-soft-hyphen-key, except that when it is used as a break point, no character is introduced in its place.
|-
| text-soft-hyphen-key
| int
| 3
| This is the decimal character number that, embedded in a string, is identified as the soft-hyphen character.
|-
| text-tab-width
| double
| 5
| This controls the default setting for TextNode::set_tab_width().
|-
| text-texture-margin
| int
| 2
| This is the number of texels of empty space reserved around each glyph in the texture.  Setting this value larger will decrease the tendency for adjacent glyphs to bleed into each other at small sizes, but it will increase amount of wasted texture memory.
|-
| text-wrap-mode
| enum
| border_color
| The default wrap mode for dynamic text fonts
|-
| texture-anisotropic-degree
| int
| 1
| This specifies the default anisotropic degree that is applied to a texture in the absence of a particular anisotropic degree setting (that is, a texture for which the anisotropic degree is 0, meaning the default setting).  It should be 1 to disable anisotropic filtering, or a higher number to enable it.  Note if this variable is changed at runtime, you may need to reload textures explicitly in order to change their visible properties.
|-
| texture-filter
| list
| -
| Names one or more external libraries that should be loaded for the purposes of performing texture filtering.  This variable may be repeated several times.  As in load-display, the actual library filename is derived by prefixing 'lib' to the specified name.
|-
| texture-magfilter
| enum
| linear
| This specifies the default magfilter that is applied to a texture in the absence of a specific magfilter setting.  Normally this is 'linear' (since mipmapping does not apply to magfilters).  This does not apply to depth textures.  Note if this variable is changed at runtime, you may need to reload textures explicitly in order to change their visible properties.
|-
| texture-minfilter
| enum
| linear
| This specifies the default minfilter that is applied to a texture in the absence of a specific minfilter setting.  Normally this is either 'linear' to disable mipmapping by default, or 'mipmap', to enable trilinear mipmapping by default.  This does not apply to depth textures.  Note if this variable is changed at runtime, you may need to reload textures explicitly in order to change their visible properties.
|-
| texture-quality-level
| enum
| normal
| This specifies a global quality level for all textures.  You may specify either fastest, normal, or best.  This actually affects the meaning of Texture::set_quality_level(QL_default), so it may be overridden on a per-texture basis.  This generally only has an effect when using the tinydisplay software renderer; it has little or no effect on normal, hardware-accelerated renderers.  See Texture::set_quality_level().
|-
| texture-scale
| double
| 1
| This is a global scale factor that is applied to each texture as it is loaded from disk.  For instance, a value of 0.5 will reduce each texture to one-half its size in each dimension.  This scale factor is applied before textures-power-2 or max-texture-dimension.
|-
| texture-scale-limit
| int
| 4
| This specifies the limit below which texture-scale will not reduce a texture image.  This is a single dimension which applies to both X and Y.
|-
| textures-auto-power-2
| bool
| 0
| If this is true, then panda will wait until you open a window, and then ask the window if it supports non-power-of-two textures. If so, then the config variable textures_power_2 will automatically be adjusted.  The pitfall of doing this is that if you then open a second window that doesn't support the same capabilities, it will have no choice but to print an error message.
|-
| textures-header-only
| bool
| 0
| If this is true, texture images will not actually be loaded from disk, but the image header information will be consulted to verify number of channels and so forth.  The texture images themselves will be generated in a default blue color.
|-
| textures-power-2
| enum
| down
| Specify whether textures should automatically be constrained to dimensions which are a power of 2 when they are loaded from disk.  Set this to 'none' to disable this feature, or to 'down' or 'up' to scale down or up to the nearest power of 2, respectively.  This only has effect on textures which are not already a power of 2.
|-
| textures-square
| enum
| none
| Specify whether textures should automatically be constrained to a square aspect ratio when they are loaded from disk.  Set this to 'none', 'down', or 'up'.  See textures-power-2.
|-
| tga-colormap
| bool
| 0
| Set this true to write colormapped TGA files.
|-
| tga-grayscale
| bool
| 0
| Set this true to enable writing grayscale TGA files.
|-
| tga-rle
| bool
| 0
| Set this true to enable RLE compression when writing TGA files.
|-
| thread-stack-size
| int
| 4194304
| Specifies the minimum size, in bytes, of the stack that will be created for each newly-created thread.  Not all thread implementations respect this value.
|-
| threading-model
| string
| -
| This is the default threading model to use for new windows.  Use empty string for single-threaded, or something like &quot;cull/draw&quot; for a 3-stage pipeline.  See GraphicsEngine::set_threading_model(). EXPERIMENTAL and incomplete, do not use this!
|-
| track-memory-usage
| bool
| 0
| Set this to true to enable full-force tracking of C++ allocations and recordkeeping by type.  It's quite expensive.
|-
| transform-cache
| bool
| 1
| Set this true to enable the cache of TransformState objects.  Using the cache saves time computing transforms and inverse transforms, but imposes some overhead for maintaining the cache itself.
|-
| unambiguous-graph
| bool
| 0
| Set this true to make ambiguous path warning messages generate an assertion failure instead of just a warning (which can then be trapped with assert-abort).
|-
| undecorated
| bool
| 0
| -
|-
| uniquify-attribs
| bool
| 1
| Set this true to ensure that equivalent RenderAttribs are pointerwise equal.  This may improve caching performance, but also adds additional overhead to maintain the cache, including the need to check for a composition cycle in the cache.
|-
| uniquify-matrix
| bool
| 0
| Set this true to look up arbitarary 4x4 transform matrices in the cache, to ensure that two differently-computed transforms that happen to encode the same matrix (an unlikely occurrence) will be collapsed into a single pointer (a tiny benefit).  We're usually better off not paying the cost of this comparison, and just assuming that any two differently-computed transforms are essentially different.
|-
| uniquify-states
| bool
| 1
| Set this true to ensure that equivalent RenderStates are pointerwise equal.  This may improve caching performance, but also adds additional overhead to maintain the cache, including the need to check for a composition cycle in the cache.
|-
| uniquify-transforms
| bool
| 1
| Set this true to ensure that equivalent TransformStates are pointerwise equal.  This may improve caching performance, but also adds additional overhead to maintain the cache, including the need to check for a composition cycle in the cache.
|-
| use-movietexture
| bool
| #t  (from /etc/Config.prc); 0 hardcoded
| Panda contains a new animated texture class, MovieTexture. Because it is not yet fully tested, the texture loader will not use it unless this variable is set.  Eventually, this config variable will go away and the new code will be enabled all the time.
|-
| verify-intervals
| bool
| 0
| Set this true to generate an assertion failure if interval functions are called out-of-order.
|-
| verify-lods
| bool
| 0
| When this is true, LODNodes will test when they are rendered to ensure that each child's geometry fits entirely within the radius defined by its switch-out distance.  When it is false, LODNodes may have any switch in and out distances, regardless of the actual size of their geometry.  This test is only made in NDEBUG mode (the variable is ignored in a production build).
|-
| vertex-arrays
| bool
| 1
| Set this true to allow the use of vertex arrays for rendering OpenGL vertex data.  This, or vertex buffers, is the normal way of issuing vertices ever since OpenGL 1.1, and you almost always want to have this set to true.  However, some very buggy graphics drivers may have problems handling vertex arrays correctly, so if you are experiencing problems you might try setting this to false.  If this is false, Panda will fall back to using immediate-mode commands like glVertex3f(), etc., to issue the vertices, which is potentially much slower than vertex arrays.  Setting this false also disables vertex buffers, effectively ignoring the setting of the vertex-buffers variable (since vertex buffers are a special case of vertex arrays in OpenGL).  This variable is normally not enabled in a production build.  This has no effect on DirectX rendering.
|-
| vertex-buffers
| bool
| 1
| Set this true to allow the use of vertex buffers (or buffer objects, as OpenGL dubs them) for rendering vertex data.  This can greatly improve rendering performance on higher-end graphics cards, at the cost of some additional graphics memory (which might otherwise be used for textures or offscreen buffers).  On lower-end graphics cards this will make little or no difference.
|-
| vertex-data-compression-level
| int
| 1
| Specifies the zlib compression level to use when compressing vertex data.  The number should be in the range 1 to 9, where larger values are slower but give better compression.
|-
| vertex-data-page-size
| int
| 262144
| The number of bytes to allocate at a time for vertex data.  This also controls the page size that is compressed or written to disk when vertex data pages are evicted from memory.
|-
| vertex-data-page-threads
| int
| 1
| When this is nonzero (and Panda has been compiled with thread support) then this number of sub-threads will be spawned to evict vertex pages to disk and read them back again.  When this is 0, this work will be done in the main thread, which may introduce occasional random chugs in rendering.
|-
| vertex-data-small-size
| int
| 64
| When a GeomVertexArrayData is this number of bytes or smaller, it is deemed too small to pay the overhead of paging it in and out, and it is permanently retained resident.
|-
| vertex-save-file-directory
| filename
| -
| The directory in which the saved vertex data file is created for saving vertex buffers that have been evicted from RAM.  If this is the empty string, or an invalid directory, a system default directory will be chosen.
|-
| vertex-save-file-prefix
| string
| p3d_vdata_
| A prefix used to generate the filename for the saved vertex data file which is created for saving vertex buffers that have been evicted from RAM.  A uniquifying sequence number and filename extension will be appended to this string.
|-
| vfs-case-sensitive
| bool
| 1
| Set this true to make the VirtualFileSystem present the native OS-provided filesystem as if it were a case-sensitive file system, even if it is not (e.g. on Windows).  This variable has no effect if the native filesystem is already case-sensitive, and it has no effect on mounted multifile systems, which are always case-sensitive.
|-
| vfs-implicit-mf
| bool
| 0
| When this is true, the VirtualFileSystem will automatically mount multifiles on-the-fly when they are used as directories.  For instance, opening the file /c/files/foo.mf/dirname/mytex.jpg will implicitly retrieve a file named 'dirname/mytex.jpg' within the multifile /c/files/foo.mf, even if the multifile has not already been mounted.  This makes all of your multifiles act like directories.
|-
| vfs-implicit-pz
| bool
| 1
| When this is true, the VirtualFileSystem will pretend a named file exists even if it doesn't, as long as a filename with the same name and the additional extension .pz does exist.  In this case, the VirtualFileSystem will implicitly open the .pz file and decompress it on-the-fly.
|-
| vfs-mount
| list
| -
| vfs-mount system-filename mount-point [options]
|-
| vfs-mount-url
| list
| -
| vfs-mount-url http://site/path[:port] mount-point [options]
|-
| view-frustum-cull
| bool
| 1
| This is normally true; set it false to disable view-frustum culling (primarily useful for debugging).
|-
| want-dev
| bool
| 0
| DConfig
|-
| want-directtools
| bool
| #f  (from /etc/Config.prc); 0 hardcoded
| DConfig
|-
| want-e3-hacks
| bool
| 0
| DConfig
|-
| want-env-debug-info
| bool
| 0
| DConfig
|-
| want-fog
| bool
| 1
| DConfig
|-
| want-new-tasks
| bool
| 1
| -
|-
| want-pstats
| bool
| #f  (from /etc/Config.prc); 0 hardcoded
| DConfig
|-
| want-render2dp
| bool
| 1
| DConfig
|-
| want-tk
| bool
| #f  (from /etc/Config.prc)
| DConfig
|-
| want-uberdog
| bool
| 1
| DConfig
|-
| want-variable-dump
| bool
| 0
| DConfig
|-
| want-verify-pdb
| bool
| 0
| DConfig
|-
| want-wx
| bool
| 0
| DConfig
|-
| win-origin
| int
| 50 50  (from /etc/Config.prc)
| This is the default position at which to open a new window.  This replaces the deprecated win-origin-x and win-origin-y variables.
|-
| win-size
| int
| 800 600  (from /etc/Config.prc), 640 480 hardcoded
| This is the default size at which to open a new window.  This replaces the deprecated win-width and win-height variables.
|-
| window-inverted
| bool
| 0
| Set this true to create all windows with the inverted flag set, so that they will render upside-down and backwards.  Normally this is useful only for debugging.
|-
| window-title
| string
| Panda
| -
|-
| window-type
| string
| onscreen
| DConfig
|-
| x-error-abort
| bool
| 0
| Set this true to trigger and abort (and a stack trace) on receipt of an error from the X window system.  This can make it easier to discover where these errors are generated.
|-
| x-wheel-down-button
| int
| 5
| This is the mouse button index of the wheel_down event: which mouse button number does the system report when the mouse wheel is rolled one notch down?
|-
| x-wheel-left-button
| int
| 6
| This is the mouse button index of the wheel_left event: which mouse button number does the system report when one scrolls to the left?
|-
| x-wheel-right-button
| int
| 7
| This is the mouse button index of the wheel_right event: which mouse button number does the system report when one scrolls to the right?
|-
| x-wheel-up-button
| int
| 4
| This is the mouse button index of the wheel_up event: which mouse button number does the system report when the mouse wheel is rolled one notch up?
|-
| yield-timeslice
| bool
| 0
| Set this true to yield the timeslice at the end of the frame to be more polite to other applications that are trying to run.
|-
| z-order
| enum
| normal
| -
|}</text>
    </revision>
  </page>
  <page>
    <title>List of All Libraries</title>
    <ns>0</ns>
    <id>2662</id>
      <sha1>fcvfrkui4ie3omfflovamwln0f73fwy</sha1>
    <revision>
      <id>7537</id>
      <timestamp>2011-12-29T08:20:19Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>oops</comment>
      <text xml:space="preserve" bytes="3836">The following is a complete list of libraries (*.dll files in Windows, *.so files in Linux) used by Panda, located in Panda's &quot;bin&quot; folder.
List last updated for Panda3D 1.8.0.

{| class=&quot;wikitable sortable&quot; border=&quot;1&quot; cellpadding=&quot;5&quot; cellspacing=&quot;0&quot;
 List of Panda3D libraries:
! Name
! Description
|-
| avcodec-53
| Part of ffmpeg, linked into the core, so don't remove it.
|-
|-
| avdevice-53
| Part of ffmpeg.  We don't use this one.
|-
|-
| avfilter-2
| Part of ffmpeg.  We don't use this one. 
|-
|-
| avformat-53
| Part of ffmpeg, linked into the core, so don't remove it.
|-
|-
| avutil-51
| Part of ffmpeg, linked into the core, so don't remove it.
|-
|-
| cg
| Cg runtime.
|-
|-
| cgD3D10
| Cg+DX10, you can remove this.
|-
|-
| cgD3D11
| Cg+DX11, you can remove this.
|-
|-
| cgD3D8
| Cg+DX8, you can remove this.
|-
|-
| cgD3D9
| Cg for DirectX 9.
|-
|-
| cgGL
| Cg for OpenGL.
|-
|-
| cv100
| Part of OpenCV, linked into the p3vision module.
|-
|-
| cvaux100
| Part of OpenCV, linked into the p3vision module.
|-
|-
| cvcam100
| Part of OpenCV, linked into the p3vision module.
|-
|-
| cxcore100
| Part of OpenCV, linked into the p3vision module.
|-
|-
| cxts001
| I have no idea.
|-
|-
| d3dx9_37
| Part of DirectX 9 runtime.
|-
|-
| fmodex
| FMOD EX sound system.
|-
|-
| fmodexL
| Same, but I don't think we use this one
|-
|-
| highgui100
| Part of OpenCV, linked into p3vision.
|-
|-
| libguide40
| I don't remember.  Maya? Or OpenCV?
|-
|-
| libp3direct
| Contains various modules like the interval system.
|-
|-
| libp3dtool
| Core of Panda, don't remove.
|-
|-
| libp3dtoolconfig
| Part of Panda's core.
|-
|-
| libp3fmod_audio
| Panda's FMOD module.
|-
|-
| libp3framework
| Not 100% sure if Python users need this one.
|-
|-
| libp3glstuff
| Important for OpenGL stuff.
|-
|-
| libp3mayaloader2008
| obvious
|-
|-
| libp3mayaloader2009
| &quot;
|-
|-
| libp3mayaloader2010
| &quot;
|-
|-
| libp3mayaloader2011
| &quot;
|-
|-
| libp3mayaloader2012
| &quot;
|-
|-
| libp3mayaloader6
| &quot;
|-
|-
| libp3mayaloader65
| &quot;
|-
|-
| libp3mayaloader7
| &quot;
|-
|-
| libp3mayaloader8
| &quot;
|-
|-
| libp3mayaloader85
| &quot;
|-
|-
| libp3openal_audio
| OpenAL audio library wrapper.
|-
|-
| libp3ptloader
| Allows you to load .x, ,dxf, etc using loader.loadModel().
|-
|-
| libp3pystub
| Only needed for the binary tools to run, not the libraries.
|-
|-
| libp3vision
| Webcam stuff, and OpenCV integration.
|-
|-
| libp3windisplay
| Needed by display modules on Windows.
|-
|-
| libpanda
| Contains the gist of the Panda3D stuff.
|-
|-
| libpandaai
| PandaAI.
|-
|-
| libpandabullet
| Bullet physics integration.
|-
|-
| libpandadx8
| Panda3D DirectX 8 renderer.
|-
|-
| libpandadx9
| Panda3D DirectX 9 renderer.
|-
|-
| libpandaegg
| Egg loader, you can remove this if you don't load eggs.
|-
|-
| libpandaexpress
| Part of Panda's core.
|-
|-
| libpandafx
| Some esoteric stuff like special lenses.
|-
|-
| libpandagl
| Panda3d OpenGL renderer.
|-
|-
| libpandaode
| ODE physics engine wrapper.
|-
|-
| libpandaphysics
| Panda3D's internal physics engine.
|-
|-
| libpandaphysx
| PhysX physics engine integration.
|-
|-
| libpandaskel
| Example module, you don't need this.
|-
|-
| libpandatiff
| Loads tiff images, I think it's linked into the core.
|-
|-
| libtinydisplay
| Panda3D software renderer.
|-
|-
| mfc90
| Microsoft Foundation Class.
|-
|-
| mfc90u
| &quot;
|-
|-
| mfcm90
| &quot;
|-
|-
| mfcm90u
| &quot;
|-
|-
| ml100
| OpenCV stuff again.
|-
|-
| msvcm80
| MS standard library.
|-
|-
| msvcm90
| &quot;
|-
|-
| msvcp80
| &quot;
|-
|-
| msvcp90
| &quot;
|-
|-
| msvcr80
| &quot;
|-
|-
| msvcr90
| &quot;
|-
|-
| msvcrt
| &quot;
|-
|-
| ode
| ODE physics engine.
|-
|-
| OpenAL32
| OpenAL audio library.
|-
|-
| postproc-51
| An ffmpeg library we don't use.
|-
|-
| python2X
| Just a copy snatched from the Python installation.
|-
|-
| swscale-2
| Part of ffmpeg, we do use this.
|-</text>
    </revision>
  </page>
  <page>
    <title>List of GLSL Shader Inputs</title>
    <ns>0</ns>
    <id>51876</id>
      <sha1>59lm5yy5nynhhnkypnyhxrdqxpivw4l</sha1>
    <revision>
      <id>60525</id>
      <timestamp>2015-07-17T19:57:19Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <text xml:space="preserve" bytes="6229">In general, especially as of Panda3D version 1.9.0, the majority of GLSL shader input types can be specified from a Panda3D application using a call to &lt;code&gt;set_shader_input()&lt;/code&gt;.  However, it is often desirable to let Panda3D automatically fill in the values of shader inputs, especially for inputs that derive their values from the render state or 3-D transformation of the currently rendered model. 

This page demonstrates which shader input names have a special meaning and will be automatically filled in by Panda3D when the shader is used.  Note that the names and types have to be copied verbatim.

== Vertex shader attributes ==

The following attributes are only permissible in vertex shaders.

These inputs use GLSL 1.40 syntax and above.  In versions below that, it may be necessary to replace the &quot;in&quot; keyword with &quot;attribute&quot;.

&lt;syntaxhighlight lang=&quot;glsl&quot;&gt;
// The position, normal vector and color of the currently processed vertex.
in vec4 p3d_Vertex;
in vec3 p3d_Normal;
in vec4 p3d_Color;

// The texture coordinates associated with the Nth texture.
in vec2 p3d_MultiTexCoord0;
in vec2 p3d_MultiTexCoord1;
in vec2 p3d_MultiTexCoord2;

// These are the tangent and binormal vectors, if present.  If an index is appended,
// it will use the set of binormals and tangents associated with the Nth texture.
in vec3 p3d_Binormal;
in vec3 p3d_Binormal0;
in vec3 p3d_Binormal1;
in vec3 p3d_Tangent;
in vec3 p3d_Tangent0;
in vec3 p3d_Tangent1;

// A vertex column named &quot;anything&quot;.  The number of components should match up with
// that of the vertex array.  &quot;uvec&quot; and &quot;ivec&quot; variants are allowed in Panda3D 1.9.0
// and above for integer vertex arrays to access un-normalized data.
in vec4 anything;
&lt;/syntaxhighlight&gt;

=== A special note about vertex colors ===

Before Panda3D 1.10, if p3d_Color was used but no vertex color information was present on the model, the values would be undefined (but usually (0, 0, 0, 0)).  This means that you could not use the same shader on objects with and without vertex colors, since objects without vertex colors would appear black instead of white.

In 1.10, p3d_Color respects the ColorAttrib rules that also applied to the fixed-function pipeline: p3d_Color will contain a white color if the vertex colors are absent or if colors are disabled using &lt;code&gt;set_color_off()&lt;/code&gt;, and a flat color if one is applied using &lt;code&gt;set_color()&lt;/code&gt;, even if vertex colors are present.

If you are absolutely certain that the model does not have vertex colors, you may also declare p3d_Color as a uniform instead of a vertex attribute.

If you would like to treat the color column as a generic vertex attribute with no special handling, you should use the name &quot;color&quot; instead of &quot;p3d_Color&quot;, which will bind it without any special handling.

== Uniform shader inputs ==

The following shader inputs are ''uniform'', which means that they are constant across the entire piece of geometry, rather than changing from vertex to vertex.  They have to be declared with the &lt;code&gt;uniform&lt;/code&gt; qualifier, and may be accessed in any shader stage.

&lt;syntaxhighlight lang=&quot;glsl&quot;&gt;
// This is probably the most important uniform.  It transforms a model-space coordinate
// into a clip-space (ie. relative to the window) coordinate.  This is usually used in
// the vertex shader to transform p3d_Vertex and store the result in gl_Position.
uniform mat4 p3d_ModelViewProjectionMatrix;

// These are parts of the above matrix.
uniform mat4 p3d_ModelViewMatrix;
uniform mat4 p3d_ProjectionMatrix;

// This is the upper 3x3 of the inverse transpose of the ModelViewMatrix.  It is used
// to transform the normal vector into view-space coordinates.
uniform mat3 p3d_NormalMatrix;

// These were added in Panda3D 1.9.0 and complement the existing range of matrices:
uniform mat4 p3d_ModelMatrix;
uniform mat4 p3d_ViewMatrix;
uniform mat4 p3d_ViewProjectionMatrix;

// It is possible to append Inverse, Transpose, or InverseTranspose to any of the above
// matrix names to get an inverse and/or transpose version of the respective matrix.
uniform mat4 p3d_ProjectionMatrixInverse;
uniform mat4 p3d_ProjectionMatrixTranspose;
uniform mat4 p3d_ModelViewMatrixInverseTranspose;

// These access the Nth texture applied to the model.  The index matches up with the
// index used by p3d_MultiTexCoordN, p3d_TangentN, and p3d_BinormalN.
// The sampler type should be adjusted to match the type of the texture.
uniform sampler2D p3d_Texture0;
uniform sampler2DArray p3d_Texture1;
uniform sampler3D p3d_Texture2;
uniform samplerCube p3d_Texture3;

// Like above, but &quot;Shadow&quot; should be appended if the texture has a shadow filter.
uniform sampler2DShadow p3d_Texture0;

// New in 1.9.0.  Access the color scale applied to the node.
uniform vec4 p3d_ColorScale;

// New in 1.9.0.  Access the material attributes assigned via a Material object.
// Unused struct parameters may be omitted without consequence.
uniform struct {
  vec4 ambient;
  vec4 diffuse;
  vec4 emission;
  vec3 specular;
  float shininess;
} p3d_Material;

// New in 1.9.0.  The sum of all active ambient light colors.
uniform struct {
  vec4 ambient;
} p3d_LightModel;

// New in 1.9.0.  Active clip planes, in apiview space.  If there is no clip
// plane for a given index, it is guaranteed to contain vec4(0, 0, 0, 0).
uniform vec4 p3d_ClipPlane[...];

// New in 1.9.0.  Reports the frame time of the current frame, for animated shaders.
uniform float osg_FrameTime;
// The time elapsed since the previous frame.
uniform float osg_DeltaFrameTime;
// New in 1.10.0.  Contains the number of frames elapsed since the start of the program.
uniform int osg_FrameNumber;

// New in 1.10.0.  If hardware skinning is enabled, this contains the transform of each
// joint.  Superfluous array entries will contain the identity matrix.
uniform mat4 p3d_TransformTable[...];
&lt;/syntaxhighlight&gt;

Besides these predefined uniform inputs, it is possible to use most of the types available in GLSL in conjunction with &lt;code&gt;set_shader_input()&lt;/code&gt; to pass custom data, including arrays and structs, to a certain named shader input.  You may not use &lt;code&gt;set_shader_input&lt;/code&gt; to override any of the inputs with the &lt;code&gt;p3d_&lt;/code&gt; prefix.</text>
    </revision>
  </page>
  <page>
    <title>List of Panda3D Executables</title>
    <ns>0</ns>
    <id>1139</id>
      <sha1>1x3w3hty6ijb580k9t1nrj2p2lqq48e</sha1>
    <revision>
      <id>7399</id>
      <timestamp>2011-12-03T16:40:22Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>lots of typos in this page :/</comment>
      <text xml:space="preserve" bytes="7098">This is meant to be a list of the executables in the /bin/ folder of Panda 3D. You can get a detailed synopsis of what the executables do by running them with -h as the argument.

&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Filename&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Description&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;bam-info.exe&lt;/td&gt;&lt;td&gt;Scans one or more .bam files and outputs their contents. See executable for more information.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;bam2egg.exe&lt;/td&gt;&lt;td&gt;Converts models in the .bam format to the .egg format.  For more information see [[Converting Egg to Bam]].&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;bin2c.exe&lt;/td&gt;&lt;td&gt;Reads a file from disk and produces a table that when compiled by C compiler reproduces the same data. See executable for more information.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;cgc.exe&lt;/td&gt;&lt;td&gt;A compiler for NVidia's Cg language. For more information see [[Using Cg Shaders]].&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;check_md5.exe&lt;/td&gt;&lt;td&gt;Outputs the MD5 hash for one or more files. See Executable for more information.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;dxf-points.exe&lt;/td&gt;&lt;td&gt;Reads in an AutoCad .dxf file and prints out the points contained in it. See executable for more information.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;dxf2egg.exe&lt;/td&gt;&lt;td&gt;Converts models from the AutoCad format to the .egg format. For more information see [[Converting from other Formats]]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;egg-crop.exe&lt;/td&gt;&lt;td&gt;Strips an .egg file of all parts that fall outside the given bounding volume. See executable for more information.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;egg-make-tube.exe&lt;/td&gt;&lt;td&gt;Creates an .egg file representing a &quot;tube&quot; model. See executable for more information.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;egg-mkfont.exe&lt;/td&gt;&lt;td&gt;Makes a .egg file from a FreeType (.ttf) font. For more information see [[Text Fonts]].&lt;/td&gt;&lt;/tr&gt; 
&lt;tr&gt;&lt;td&gt;egg-optchar.exe&lt;/td&gt;&lt;td&gt;Optimizes models by removing unused joints. Also allow you to label parts of the model. For more information see [[Manipulating a Piece of a Model]].&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;egg-palettize.exe&lt;/td&gt;&lt;td&gt;Tries to combine textures in an egg file. Also performs some texture manipulation. See executable for more information.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;egg-qtess.exe&lt;/td&gt;&lt;td&gt;Performs a tesselation on all of the NURBS surfaces in a .egg file. See executable for more information.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;egg-texture-cards.exe&lt;/td&gt;&lt;td&gt;Creates an egg that automatically rotates through multiple textures. For more information see [[Automatic Texture Animation]].&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;egg-topstrip.exe&lt;/td&gt;&lt;td&gt;Unapplies the animations from one of the top joints in a model. Useful for character models that stack on top of each other. See executable for more information&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;egg-trans.exe&lt;/td&gt;&lt;td&gt;Produces out essentially the same .egg file. Useful for applying rotational and positional transformations. See executable for more information.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;egg2bam.exe&lt;/td&gt;&lt;td&gt;Converts files in the .egg format to the .bam format. For more information see [[Converting Egg to Bam]].&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;egg2c.exe&lt;/td&gt;&lt;td&gt; Reads a .egg file and produce C/C++ code that will almost compile. See executable for more information.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;egg2dxf.exe&lt;/td&gt;&lt;td&gt;Converts files in the .egg format to the AutoCad format.For more information see [[Converting from other Formats]].&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;egg2flt.exe&lt;/td&gt;&lt;td&gt;Converts files in the .egg format to the Open Flight format.For more information see [[Converting from other Formats]].&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;egg2x.exe&lt;/td&gt;&lt;td&gt;Converts files in the .egg format to the DirectX format. Especially useful because it holds bone, joint and animation data. For more information see [[Converting from other Formats]].&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;flt-info.exe&lt;/td&gt;&lt;td&gt;Reads an OpenFlight file and prints out information about its contents. See executable for more information.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;flt-trans.exe&lt;/td&gt;&lt;td&gt;Produces essentially the same .flt file. Useful for positional and rotational transformations. See executable for more information.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;flt2egg.exe&lt;/td&gt;&lt;td&gt;Converts files in the OpenFlight format to the .egg format. For more information see [[Converting from other Formats]].&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;genpycode.exe&lt;/td&gt;&lt;td&gt;Generates the Python wrappings necessary to interface with the C++ libraries that are the backbone of Panda. Also generates the API Reference Manual in &lt;code&gt;&lt;Panda Directory&gt;/pandac/docs&lt;/code&gt;. For more information see [[API Reference Materials]]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;image-info.exe&lt;/td&gt;&lt;td&gt;Reports the sizes of one or more images. See executable for more information.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;image-resize.exe&lt;/td&gt;&lt;td&gt;Resizes an image. See executable for more information.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;image-trans.exe&lt;/td&gt;&lt;td&gt;Produces an identical picture. Can also be used for file format conversion. See executable for more information.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;interrogate.exe&lt;/td&gt;&lt;td&gt;Parses C++ code and creates wrappers so that it can be called in a Scripting language. For more information see [[Interrogate]]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;lwo-scan.exe&lt;/td&gt;&lt;td&gt;Prints the contents of a .lwo file. See executable for more information.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;lwo2egg.exe&lt;/td&gt;&lt;td&gt;Converts files in the LightWave 3D format to the .egg format. For more information see [[Converting from other Formats]].&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;make-prc-key.exe&lt;/td&gt;&lt;td&gt;Generates one or more new key to be used for signing a prc file. See executable for more information.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;maya2egg5.exe&lt;/td&gt;&lt;td&gt;Converts files in the Maya 5 format to the .egg format. For more information see [[Converting from Maya]].&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;maya2egg6.exe&lt;/td&gt;&lt;td&gt;Converts files in the Maya 6 format to the .egg format. For more information see [[Converting from Maya]].&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;maya2egg65.exe&lt;/td&gt;&lt;td&gt;Converts files in the Maya 6.5 format to the .egg format. For more information see [[Converting from Maya]].&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;multify.exe&lt;/td&gt;&lt;td&gt;Stores and extracts files from a Panda MultiFile. Can also extract file in program using the &lt;code&gt;VirtualFileSystem&lt;/code&gt; (see API for usage). For more information see executable.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;pdecrypt.exe&lt;/td&gt;&lt;td&gt;Decompress a file compressed by pencrypt. See executable for more inforamtion.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;pencrypt.exe&lt;/td&gt;&lt;td&gt;Runs an encryption algorithm on the specified file. The original file can only be recovered by using pdecrypt. See executable for more information.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;python.exe&lt;/td&gt;&lt;td&gt;Used to start Panda 3D. For more information see [[Starting Panda3D]]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;pstats.exe&lt;/td&gt;&lt;td&gt;Panda's built in performance tool. For more information see [[Measuring Performance with PStats]]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;pview.exe&lt;/td&gt;&lt;td&gt;Used to view models in the .egg or .bam format without having to create a Panda program. For more information see [[Previewing 3D Models in Pview]].&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;vrml2egg.exe&lt;/td&gt;&lt;td&gt;Converts files in the Virtual Reality Modeling Language format to the .egg format. For more information see [[Converting from other Formats]].&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;x2egg.exe&lt;/td&gt;&lt;td&gt;Converts files in the Direct X format to the .egg format. Especially useful because it holds bone, joint and animation data. For more information see [[Converting from other Formats]].&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;</text>
    </revision>
  </page>
  <page>
    <title>List of Panda Executables</title>
    <ns>0</ns>
    <id>2468</id>
    <redirect title="List of Panda3D Executables" />
      <sha1>2i9v6u38nllkbz71odmf510jbz9m60k</sha1>
    <revision>
      <id>6628</id>
      <timestamp>2010-02-07T04:44:12Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>[[List of Panda Executables]] moved to [[List of Panda3D Executables]]: Panda3D is the name of the engine; not Panda.</comment>
      <text xml:space="preserve" bytes="41">#REDIRECT [[List of Panda3D Executables]]</text>
    </revision>
  </page>
  <page>
    <title>List of Possible Cg Shader Inputs</title>
    <ns>0</ns>
    <id>1719</id>
      <sha1>hm3fqezvakmot25hsebvtiz7sif2241</sha1>
    <revision>
      <id>60250</id>
      <timestamp>2014-07-27T12:39:59Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>few updates</comment>
      <text xml:space="preserve" bytes="13552">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

In many cases, it is desirable to access information from the render state or from the 3-D transformation of the node that is currently being rendered.  Instead of having to pass all this information manually, it is possible to name your variables in a special way that Panda3D will recognize and automatically populate with the relevant data.

The following table describes the inputs that can be used in Cg shaders.

{|
! width=&quot;40%&quot; | CG Input
! Description
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform sampler2D tex_0 : TEXUNIT0&lt;/pre&gt;
| The model's first texture.  This requires that the model be textured in the normal manner.  You may also use tex_1, tex_2, and so forth, if the model is multitextured.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;sampler3D or samplerCUBE&lt;/pre&gt;
| If the model uses a 3D texture or a cubemap, use tex3D and texCUBE to access the color.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;float3 vtx_position: POSITION&lt;/pre&gt;
| Vertex Position. Vertex shader only.  You may also use float4, in which case (w==1).
|-
| &lt;pre class=&quot;codeblock&quot;&gt;float3 vtx_normal: NORMAL&lt;/pre&gt;
| Vertex Normal. Vertex shader only.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;float4 vtx_color : COLOR&lt;/pre&gt;
| Vertex color. Vertex shader only.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;float2 vtx_texcoord0: TEXCOORD0&lt;/pre&gt;
| UV(W) coordinate set associated with the model's first texture.  This requires that the model be textured in the normal manner.  You may also use vtx_texcoord1, vtx_texcoord2, and so forth if the model is multitextured.  Vertex shader only.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;float2 vtx_texcoord: TEXCOORD0&lt;/pre&gt;
| From Panda3D 1.9 onward, this refers to the default (unnamed) set of UV(W) coordinates, if present, rather than being an alias for vtx_texcoord0.  Vertex shader only.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;float2 vtx_texcoord_x: TEXCOORD0&lt;/pre&gt;
| From Panda3D 1.9 onward, this refers to a set of UV(W) coordinates with the given name.  Vertex shader only.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;float3 vtx_tangent0&lt;/pre&gt;
| Tangent vector associated with the model's first texture.  This can only be used if the model has been textured in the normal manner, and if binormals have been precomputed.  You may also use vtx_tangent1, vtx_tangent2, and so forth if the model is multitextured.  Vertex shader only.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;float3 vtx_binormal0&lt;/pre&gt;
| Binormal vector associated with vtx_texcoord0.  This can only be used if the model has been textured in the normal manner, and if binormals have been precomputed.  You can also use vtx_binormal1, vtx_binormal2, and so forth if the model has been multitextured.  Vertex shader only.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;floatX vtx_anything&lt;/pre&gt;
| Panda makes it possible to store arbitrary columns of user-defined data in the vertex table; see [[GeomVertexData]].  You can access this data using this syntax.  For example, vtx_chicken will look for a column named &quot;chicken&quot; in the vertex array.  Vertex shader only.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4x4 trans_x_to_y&lt;/pre&gt;
| A matrix that transforms from coordinate system X to coordinate system Y.  See the section on [[Shaders and Coordinate Spaces]] for more information.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4x4 tpose_x_to_y&lt;/pre&gt;
| Transpose of trans_x_to_y
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4 row0_x_to_y&lt;/pre&gt;
| Row 0 of trans_x_to_y.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4 row1_x_to_y&lt;/pre&gt;
| Row 1 of trans_x_to_y.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4 row2_x_to_y&lt;/pre&gt;
| Row 2 of trans_x_to_y.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4 row3_x_to_y&lt;/pre&gt;
| Row 3 of trans_x_to_y.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4 col0_x_to_y&lt;/pre&gt;
| Col 0 of trans_x_to_y.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4 col1_x_to_y&lt;/pre&gt;
| Col 1 of trans_x_to_y.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4 col2_x_to_y&lt;/pre&gt;
| Col 2 of trans_x_to_y.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4 col3_x_to_y&lt;/pre&gt;
| Col 3 of trans_x_to_y.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4x4 mstrans_x&lt;/pre&gt;
| Model-Space Transform of X, aka trans_x_to_model
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4x4 cstrans_x&lt;/pre&gt;
| Clip-Space Transform of X, aka trans_x_to_clip
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4x4 wstrans_x&lt;/pre&gt;
| World-Space Transform of X, aka trans_x_to_world
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4x4 vstrans_x&lt;/pre&gt;
| View-Space Transform of X, aka trans_x_to_view
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4 mspos_x&lt;/pre&gt;
| Model-Space Position of X, aka row3_x_to_model
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4 cspos_x&lt;/pre&gt;
| Clip-Space Position of X, aka row3_x_to_clip
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4 wspos_x&lt;/pre&gt;
| World-Space Position of X, aka row3_x_to_world
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4 vspos_x&lt;/pre&gt;
| View-Space Position of X, aka row3_x_to_view
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4x4 mat_modelview&lt;/pre&gt;
| Modelview matrix, transforming model-space coordinates to camera-space coordinates.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4x4 inv_modelview&lt;/pre&gt;
| Inverse of the model-view Matrix
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4x4 tps_modelview&lt;/pre&gt;
| Transposed Modelview Matrix
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4x4 itp_modelview&lt;/pre&gt;
| Inverse Transposed Modelview Matrix
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4x4 mat_projection&lt;/pre&gt;
| Projection Matrix
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4x4 inv_projection&lt;/pre&gt;
| Inverse Projection Matrix
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4x4 tps_projection&lt;/pre&gt;
| Transposed Projection Matrix
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4x4 itp_projection&lt;/pre&gt;
| Inverse Transposed Projection Matrix
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4x4 mat_modelproj&lt;/pre&gt;
| Composed Modelview/Projection Matrix
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4x4 inv_modelproj&lt;/pre&gt;
| Inverse ModelProj Matrix
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4x4 tps_modelproj&lt;/pre&gt;
| Transposed ModelProj Matrix
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4x4 itp_modelproj&lt;/pre&gt;
| Inverse Transposed ModelProj Matrix
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4 anything&lt;/pre&gt;
| A constant vector that was stored using &lt;code&gt;setShaderInput&lt;/code&gt;.  Parameter &lt;i&gt;anything&lt;/i&gt; would match data supplied by the call &lt;i&gt;setShaderInput(&quot;anything&quot;, Vec4(x,y,z,w))&lt;/i&gt;
|-
| &lt;pre class=&quot;codeblock&quot;&gt;
uniform sampler2D anything
uniform sampler3D anything
uniform sampler2DArray anything
&lt;/pre&gt;
| A constant texture that was stored using &lt;code&gt;setShaderInput&lt;/code&gt;.  Parameter ''anything'' would match data supplied by the call &lt;code&gt;setShaderInput(&quot;anything&quot;, myTex)&lt;/code&gt;
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4x4 anything&lt;/pre&gt;
| A constant matrix that was stored using &lt;code&gt;setShaderInput&lt;/code&gt;.  Parameter &lt;i&gt;anything&lt;/i&gt; would match data supplied by the call &lt;i&gt;setShaderInput(&quot;anything&quot;, myNodePath)&lt;/i&gt;.  The matrix supplied is the nodepath's &lt;i&gt;local&lt;/i&gt; transform.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4 texpad_x&lt;/pre&gt;
| X must be the name of a texture specified via shaderInput. Contains the U,V coordinates of the center of the texture.  This will be (0.5,0.5) if the texture is not padded, but it will be less if the texture is padded.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4 texpix_x&lt;/pre&gt;
| X must be the name of a texture specified via shaderInput. Contains the U,V offset of a single pixel in the texture (ie, the reciprocal of the texture size).
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4x4 attr_material&lt;/pre&gt;
| The contents of the material attribute.  Row 0 is ambient, Row 1 is diffuse, Row 2 is emission, Row 3 is specular, with shininess in W.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4 attr_color&lt;/pre&gt;
| The contents of the color attribute.  This is white unless the model has a flat color applied.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4 attr_colorscale&lt;/pre&gt;
| The contents of the color scale attribute.  This is white unless the model has a color scale applied using nodePath.setColorScale.&lt;br&gt;This variable is only available in 1.6.2 and above.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4 attr_fog&lt;/pre&gt;
| The fog parameters, where applicable.  The values are in order: density, start, end, scale.  The density is for exponential fog only, the start, end and scale are for linear fog only.  The scale is equal to 1 / (end - start).&lt;br&gt;New in Panda3D 1.8.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4 attr_fogcolor&lt;/pre&gt;
| The fog color, if applicable.  New in Panda3D 1.8.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4 alight_x&lt;/pre&gt;
| X must be an AmbientLight specified via a shaderInput.  Contains the color of the light.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4x4 dlight_x&lt;/pre&gt;
| X must be an DirectionalLight specified via a shaderInput.  Row 0 is color, row 1 is specular, row 2 is model-space direction, row 3 is model-space pseudo half-angle.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4 plane_x&lt;/pre&gt;
| X must be an PlaneNode specified via a shaderInput.  Contains the four terms of the plane equation.&lt;br&gt;This variable is only available in 1.6.2 and above.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;uniform float4 clipplane_0&lt;/pre&gt;
| Contains the parameters of the first clipplane (also: clipplane_1, clipplane_2, etc. for subsequent clip planes) in world-space coordinates.&lt;br&gt;This variable is only available in 1.6.2 and above.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;floatX l_position: POSITION&lt;/pre&gt;
| Linearly interpolated Position, as supplied by the vertex shader to the fragment shader. Declare &quot;out&quot; in the vertex shader, &quot;in&quot; in the fragment shader.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;floatX l_color0: COLOR0&lt;/pre&gt;
| Linearly interpolated Primary color, as supplied by the vertex shader to the fragment shader. Declare &quot;out&quot; in the vertex shader, &quot;in&quot; in the fragment shader.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;floatX l_color1: COLOR1&lt;/pre&gt;
| Linearly interpolated Secondary color, as supplied by the vertex shader to the fragment shader. Declare &quot;out&quot; in the vertex shader, &quot;in&quot; in the fragment shader.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;floatX l_texcoord0: TEXCOORD0&lt;/pre&gt;
| Linearly interpolated Texture Coordinate 0, as supplied by the vertex shader to the fragment shader. You may also use l_texcoord1, l_texcoord2, and so forth. Declare &quot;out&quot; in the vertex shader, &quot;in&quot; in the fragment shader.
|-
| &lt;pre class=&quot;codeblock&quot;&gt;out floatX o_color: COLOR&lt;/pre&gt;
| Output Color, as supplied by the fragment shader to the blending units. Fragment shader only. (COLOR0 is also accepted.)
|-
| &lt;pre class=&quot;codeblock&quot;&gt;out floatX o_aux: COLOR1&lt;/pre&gt;
| Output auxiliary color. Only available if an auxiliary was obtained for the shaders target buffer/window. Fragment shader only.
|}


== Using Custom Shader Inputs == 

As of Panda3D 1.8.0, the capabilities for passing numeric shader inputs have been greatly enhanced.  The available input types are as follows:

&lt;pre class=&quot;codeblock&quot;&gt;
- Vec4
- Vec3
- Vec2
- Point4
- Point3
- Point2
- Mat4
- Mat3
- PTALMatrix4f
- PTALMatrix3f
- PTALVecBase4f
- PTALVecBase3f
- PTALVecBase2f
- PTAFloat
- PTADouble
&lt;/pre&gt;

(In Panda3D 1.9.0, the integer versions of these vectors and arrays are also supported.)

For definition let us consider the shader parameter float3. It's type is float and format is Vec3 (meaning it can hold 3 elements) and a float3x3 input is of type float and format Mat3 (meaning it can hold 9 elements)

The main concept of the shader inputs is that the Cg input format and type is independent to the Panda3D input. The only condition is that the number of elements passed by the user through the setShaderInput() function of Panda3D and the number of elements expected by the shader input should be the same. For example a parameter uniform float4x4 mat[4] (total of 16*4 elements) could be set with(the below list is just a sample and there are more ways to represent it): 

&lt;syntaxhighlight lang=&quot;python&quot;&gt;
setShaderInput(&quot;input_name&quot;,PTALMat4f[4])
setShaderInput(PTALVecBase4f[16])
setShaderInput(PTAFloat[16*4])
setShaderInput(PTADouble[16*4]) 
&lt;/syntaxhighlight&gt;

But for some Cg input types there is no corresponding Panda3D type such as float3x2(Panda3D does not have a corresponding Mat3x2 class) Hence these input types can be initiated row-wise as

1 2 3

4 5 6

This row wise input can be sent to the Cg shader in any of the following ways(Note that the below list is just a sample and there are more ways to represent it)

&lt;syntaxhighlight lang=&quot;python&quot;&gt; 
setShaderInput(PTAFloat[6])
setShaderInput(PTADouble[6])
setShaderInput(PTALVecBase3f[2])
setShaderInput(PTALVecBase2f[3])
&lt;/syntaxhighlight&gt;

Now, the issue of common input types such as float, double, int, long. The GPU registers generally can handle only floats. Hence even if we do send a double it will be automatically type casted into float. Hence for such type of inputs we can use above types. 

For example, input types such as 

&lt;syntaxhighlight lang=&quot;python&quot;&gt; 
float3 var
bool3 var
half3 var
double3 var
fixed3 var
int3 var
&lt;/syntaxhighlight&gt;

Can be sent to your Cg shader program by (the below list is just a sample and there are more ways to represent it)

&lt;syntaxhighlight lang=&quot;python&quot;&gt; 
setShaderInput(PTAFloat[3])
setShaderInput(PTADouble[3])
&lt;/syntaxhighlight&gt;

Below is a sample code snippet that shows how you can use the new shader inputs. 

&lt;syntaxhighlight lang=&quot;python&quot;&gt; 
from panda3d.core import Vec4
vec4 = Vec4(0.0,1.0,0.0,1.0)
myModel.setShaderInput(&quot;Inputs.vec4&quot;,vec4)
&lt;/syntaxhighlight&gt;

First import the necessary header to use the type of input. In our case it's Vec4. The next statement shows a Vec4 input type. Then set the Vec4 as a shader input to your model.</text>
    </revision>
  </page>
  <page>
    <title>List of Possible Shader Inputs</title>
    <ns>0</ns>
    <id>2451</id>
    <redirect title="List of Possible Cg Shader Inputs" />
      <sha1>fvlzzzuiowgcmknnl27ebu7b6htxb81</sha1>
    <revision>
      <id>6510</id>
      <timestamp>2010-01-07T08:46:52Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>[[List of Possible Shader Inputs]] moved to [[List of Possible Cg Shader Inputs]]: we have glsl support now</comment>
      <text xml:space="preserve" bytes="47">#REDIRECT [[List of Possible Cg Shader Inputs]]</text>
    </revision>
  </page>
  <page>
    <title>List of all config variables</title>
    <ns>0</ns>
    <id>2156</id>
    <redirect title="List of All Config Variables" />
      <sha1>5n20eobomtcn87pze1yponpyalz05o0</sha1>
    <revision>
      <id>4595</id>
      <timestamp>2007-11-10T19:35:57Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>redirected to the actual page</comment>
      <text xml:space="preserve" bytes="42">#REDIRECT [[List of All Config Variables]]</text>
    </revision>
  </page>
  <page>
    <title>Loading Actors and Animations</title>
    <ns>0</ns>
    <id>991</id>
      <sha1>gs9k5xhqv1l0elx5kqgcmuxcymbh5zh</sha1>
    <revision>
      <id>60518</id>
      <timestamp>2015-06-19T20:07:02Z</timestamp>
      <contributor>
        <username>Tmo</username>
        <id>22866</id>
      </contributor>
      <minor/>
      <comment>fix C++ includes</comment>
      <text xml:space="preserve" bytes="4674">&lt;h2&gt;Actor Basics&lt;/h2&gt;
[python]
The python class &lt;code&gt;Actor&lt;/code&gt; is designed to hold an animatable model and
a set of animations.  Since the Actor class inherits from the NodePath class,
all NodePath functions are applicable to actors.

Note, however, that Actor is a Python class that extends the C++ NodePath class.  For the most part, you don't have to think about this: Actor inherits sensibly from NodePath and generally does what you expect.  There are a few subtle oddities, though.  When you attach an Actor into a scene graph, the low-level C++ Panda constructs only records the NodePath part of the Actor in the scene graph, which is fine as long as you also keep a pointer to the Actor instance in your Python objects.  If you let the Actor destruct, however, its visible geometry will remain, but it will cease animating (because it is no longer an Actor).  Also, even if you keep the Actor object around, if you retrieve a new pointer to the Actor from the scene graph (for instance, as returned by the collision system), you will get back just an ordinary NodePath, not an Actor.

The Actor interface provides a high-level interface on the low-level Panda constructs.  In Panda, the low-level node that performs the animation is called Character.  You can see the Character node in the scene graph when you call &lt;code&gt;actor.ls()&lt;/code&gt;.

Do not confuse the Actor class with the [[Enabling physics on a node|ActorNode]] class, which is used for physics.  They are completely unrelated classes with similar names.

&lt;h2&gt;Using Actors&lt;/h2&gt;

The Actor class must be imported before any loading or manipulation of actors.

&lt;code python&gt;
from direct.actor.Actor import Actor
&lt;/code&gt;

Once the model is loaded, the actor object must be constructed, and the model and animations must be loaded:

Loading each animation requires a tuple: the name one is giving the animation and the path to the animation. This entire process can be shortened to a single command:

&lt;code python&gt;
nodePath = Actor('Model Path', {
  'Animation Name 1':'Animation Path 1',
  'Animation Name 2':'Animation Path 2',
})
&lt;/code&gt;

Note that it is also possible to store the animations and model in the same file. In that case, just create the Actor with just the model as parameter.
[/python]

[cxx]
The &lt;code&gt;Actor&lt;/code&gt; class which is available to python users is not available to C++ users. If you need such a class you have to create your own  class which at least should do the following:
&lt;ul&gt;&lt;li&gt;load the Actor Model&lt;/li&gt;
&lt;li&gt;load the animations&lt;/li&gt;
&lt;li&gt;bind the model and the animations using AnimControl or AnimControlCollection&lt;/li&gt;&lt;/ul&gt;

&lt;h5&gt;Required Includes&lt;/h5&gt;
&lt;code cxx&gt;
#include &lt;auto_bind.h&gt;
#include &lt;animControlCollection.h&gt;
&lt;/code&gt;

&lt;h5&gt;Load the Actor Model&lt;/h5&gt;&lt;code cxx&gt;
NodePath Actor = window-&gt;load_model(window-&gt;get_render(), &quot;panda-model&quot;);
&lt;/code&gt;

&lt;h5&gt;Load the Animation&lt;/h5&gt;&lt;code cxx&gt;
window-&gt;load_model(Actor, &quot;panda-walk&quot;);
&lt;/code&gt;

&lt;h5&gt;Bind the Model and the Animation&lt;/h5&gt;&lt;code cxx&gt;
// don't use PT or CPT with AnimControlCollection
AnimControlCollection anim_collection;

//bind the animations to the model
auto_bind(Actor.node(), anim_collection);
&lt;/code&gt;

&lt;h5&gt;Control the Animations&lt;/h5&gt;&lt;code cxx&gt;
// the name of an animation is preceded in the .egg file with &lt;Bundle&gt;:
// loop a specific animation
anim_collection.loop(&quot;panda_soft&quot;, true);

// loop all animations
anim_collection.loop_all(true);

// play an animation once:
anim_collection.play(&quot;panda_soft&quot;);

// pose
anim_collection.pose(&quot;panda_soft&quot;, 5);
&lt;/code&gt;


to display names of loaded animations you could use:&lt;code cxx&gt;
for(int n = 0; n &lt; anim_controls.get_num_anims(); ++n)
    cout &lt;&lt; anim_controls.get_anim_name(n) &lt;&lt; endl;
&lt;/code&gt;

If you add more animations to some node after calling: &lt;code&gt;auto_bind(...)&lt;/code&gt; they will not be controllable until &lt;code&gt;auto_bind(...)&lt;/code&gt; is called again with proper arguments.

Note that it is possible to store the animations and the model in the same file.
[/cxx]

Although this is a rarely-used technique, it is possible to assemble a
character model out of several separate pieces (separate models). This is further explained in the section [[Multi-Part Actors]].

Panda3D supports both skeletal animation and morph animations.

It is also possible to load animations asynchronously, if your build of Panda has [[Threading]] enabled (which is the case in version 1.6.1 and above).

&lt;h2&gt;Panda Filename Syntax&lt;/h2&gt;

The filenames used in the Actor constructor must follow Panda's filename
conventions.  See [[Loading Models]] for more information.  Loading actors
and animations utilizes the panda &lt;i&gt;model path&lt;/i&gt;, the same as for
static models.</text>
    </revision>
  </page>
  <page>
    <title>Loading Models</title>
    <ns>0</ns>
    <id>2189</id>
      <sha1>lk2am5qxo986vfjqxb6b6eft5qxbzux</sha1>
    <revision>
      <id>7621</id>
      <timestamp>2012-03-08T17:23:05Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <comment>new import system, also the final snippet didn't import DirectStart (loader)</comment>
      <text xml:space="preserve" bytes="4944">&lt;h2&gt;The Basics&lt;/h2&gt;

Loading static geometry is done using &lt;code&gt;[python]loader.loadModel[/python][cxx]window-&gt;load_model[/cxx]&lt;/code&gt;:

[python]&lt;code python&gt;
m = loader.loadModel(&quot;mymodel.egg&quot;)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
NodePath m = window-&gt;load_model(framework.get_models(), &quot;mymodel.egg&quot;);
&lt;/code&gt;[/cxx]

The path name specified in the loadModel can be an absolute path, or a relative
path.  Relative is recommended.  If a relative path is used, then Panda3D will search its &lt;i&gt;model path&lt;/i&gt; to find the egg file.  The &lt;i&gt;model path&lt;/i&gt; is controlled by panda's [[The Configuration File|configuration file]].

&lt;h2&gt;Inserting the Model into the Scene Graph&lt;/h2&gt;

Do not forget that loading the model does not, by itself, cause the
model to be visible.  To cause Panda3D to render the model, you must
insert it into the scene graph:

[python]&lt;code python&gt;
m.reparentTo(render)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
m.reparent_to(window-&gt;get_render());
&lt;/code&gt;[/cxx]

You can read more about [[The Scene Graph]].

&lt;h2&gt;Panda Filename Syntax&lt;/h2&gt;

The path used in the [python]loadModel[/python][cxx]load_model[/cxx] call must abide by Panda3D's filename
conventions.  For easier portability, Panda3D uses Unix-style pathnames,
even on Microsoft Windows.  This means that the directory separator character is always a forward slash, not the Windows backslash character, and there is no leading drive letter prefix.  (Instead of a leading drive letter, Panda uses an initial one-letter directory name to represent the drive.)

There is a fairly straightforward conversion from Windows filenames to panda filenames.  Always be sure to use Panda filename syntax when using a Panda3D library function, or one of the panda utility programs:

[python]&lt;code python&gt;
# WRONG:
loader.loadModel(&quot;c:\\Program Files\\My Game\\Models\\Model1.egg&quot;)

# RIGHT:
loader.loadModel(&quot;/c/Program Files/My Game/Models/Model1.egg&quot;)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
# WRONG:
window-&gt;load_model(framework.get_models(), &quot;c:\\Program Files\\My Game\\Models\\Model1.egg&quot;);

# RIGHT:
window-&gt;load_model(framework.get_models(), &quot;/c/Program Files/My Game/Models/Model1.egg&quot;);
&lt;/code&gt;[/cxx]

Panda uses the &lt;code&gt;Filename&lt;/code&gt; class to store Panda-style filenames; many Panda functions expect a Filename object as a parameter.  The Filename class also contains several useful methods for path manipulation and file access, as well as for converting between Windows-style filenames and Panda-style filenames; see the API reference for a more complete list.

To convert a Windows filename to a Panda pathname, use code similar to the following:

[python]&lt;code python&gt;
from panda3d.core import Filename
winfile = &quot;c:\\MyGame\\Model1.egg&quot;
pandafile = Filename.fromOsSpecific(winfile)
print pandafile
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
#include &quot;filename.h&quot;

const string winfile = &quot;c:\\MyGame\\Model1.egg&quot;;
Filename pandafile = Filename::from_os_specific(winfile);
std::cout &lt;&lt; pandafile.get_fullpath() &lt;&lt; &quot;\n&quot;;
&lt;/code&gt;[/cxx]

To convert a Panda filename into a Windows filename, use code not unlike this:

[python]&lt;code python&gt;
from panda3d.core import Filename
pandafile = Filename(&quot;/c/MyGame/Model1.egg&quot;)
winfile = pandafile.toOsSpecific()
print winfile
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
#include &quot;filename.h&quot;

Filename pandafile (&quot;/c/MyGame/Model1.egg&quot;);
const string winfile = pandafile.to_os_specific();
std::cout &lt;&lt; winfile &lt;&lt; &quot;\n&quot;;
&lt;/code&gt;[/cxx]

The Filename class can also be used in combination with [python]python's built-in path manipulation mechanisms[/python][cxx]Panda's ExecutionEnvironment utility class[/cxx].
Let's say, for instance, that you want to load a model, and the
model is in the &quot;model&quot; directory that is in the same directory as the main program's [python]&quot;py&quot;[/python][cxx]executable[/cxx] file.  Here is how you
would load the model:

[python]&lt;code python&gt;
import sys,os
import direct.directbase.DirectStart
from panda3d.core import Filename

# Get the location of the 'py' file I'm running:
mydir = os.path.abspath(sys.path[0])

# Convert that to panda's unix-style notation.
mydir = Filename.fromOsSpecific(mydir).getFullpath()

# Now load the model:
model = loader.loadModel(mydir + &quot;/models/mymodel.egg&quot;)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
#include &quot;filename.h&quot;
#include &quot;executionEnvironment.h&quot;

// Get the location of the executable file I'm running:
Filename mydir = ExecutionEnvironment::get_binary_name();
mydir = mydir.get_dirname();

// Now load the model:
window-&gt;load_model(framework.get_models(), mydir + &quot;/models/mymodel.egg&quot;);
&lt;/code&gt;[/cxx]

You need to keep in mind that the [cxx]Operating System's[/cxx] standard [python]python[/python] functions [python](like os.remove())[/python] work with OS specific paths. So do not forget to convert your OS Generic paths back to OS Specific paths when using built-in functions. In cases that Panda offers equivalent functions through the Filename class, it is recommended to use that instead.</text>
    </revision>
  </page>
  <page>
    <title>Loading Particle Systems</title>
    <ns>0</ns>
    <id>2226</id>
      <sha1>ff7j8vnwh2fctizoodu10km278sebps</sha1>
    <revision>
      <id>7761</id>
      <timestamp>2012-04-30T11:43:20Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>typo</comment>
      <text xml:space="preserve" bytes="1776">The Panda3D engine uses text files for storing particle configurations, which are usually created with the Particle Panel. Before being able to use particles, you'll need to tell Panda3D to enable particles:

&lt;code python&gt;
base.enableParticles()
&lt;/code&gt;

This function tells Panda3D to enable its built-in physics engine which is also used by particles.

To be able to create ParticleEffect objects, you'll need this import:
&lt;code python&gt;
from direct.particles.ParticleEffect import ParticleEffect
&lt;/code&gt;

Next, create a ParticleEffect object and tell it to use a particle configuration file.

&lt;code python&gt;
p = ParticleEffect()
p.loadConfig(filename)
&lt;/code&gt;

To start the ParticleEffect, do this:

&lt;code python&gt;
p.start(parent = render, renderParent = render)
&lt;/code&gt;

&lt;code&gt;start()&lt;/code&gt; takes two arguments: &lt;code&gt;parent&lt;/code&gt; is the node the particles will be &quot;birth-relative&quot; to. &lt;code&gt;renderParent&lt;/code&gt; is the node level the particles will be rendered at. If you want your particles to spawn from your node, but not follow it around, set &lt;code&gt;renderParent&lt;/code&gt; to something else like &lt;code&gt;render&lt;/code&gt;.

ParticleEffect inherits from NodePath, so you can use NodePath methods like &lt;code&gt;setPos()&lt;/code&gt; on it.

To reset the ParticleEffect, use:
&lt;code python&gt;
p.reset()
&lt;/code&gt;

To stop the ParticleEffect, use:
&lt;code python&gt;
p.disable()
&lt;/code&gt;

To completely remove the ParticleEffect, use:
&lt;code python&gt;
p.cleanup()
&lt;/code&gt;
Note that &lt;code&gt;cleanup()&lt;/code&gt; calls &lt;code&gt;disable()&lt;/code&gt; internally, so you don't need to call it yourself before calling &lt;code&gt;cleanup()&lt;/code&gt;

Like &lt;code&gt;loadConfig()&lt;/code&gt;, you can use &lt;code&gt;saveConfig()&lt;/code&gt; to save the ParticleEffect to a particle configuration file (*.ptf):
&lt;code python&gt;
p.saveConfig(filename)
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>Loading and Animating the Panda Model</title>
    <ns>0</ns>
    <id>938</id>
      <sha1>qy04c60pc6wmtr9bvsaquiylx64sxba</sha1>
    <revision>
      <id>7837</id>
      <timestamp>2012-08-15T11:21:04Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <text xml:space="preserve" bytes="5284">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;
== [[Loading_Actors_and_Animations | Actors]] ==
[python]&lt;p&gt;The &lt;code&gt;Actor&lt;/code&gt; class is for animated models. Note that we use &lt;code&gt;loadModel()&lt;/code&gt; for static models and &lt;code&gt;Actor&lt;/code&gt; only when they are
animated. The two constructor arguments for the &lt;code&gt;Actor&lt;/code&gt; class are the name of the file containing the model and a Python dictionary containing the names of
the files containing the animations.&lt;/p&gt;

== The Program ==
=== Update the Code ===
&lt;p&gt;Now that the scenery is in place, we will load an &lt;code&gt;Actor&lt;/code&gt;. Update your code to look like this:&lt;/p&gt;

&lt;code python&gt;
from math import pi, sin, cos

from direct.showbase.ShowBase import ShowBase
from direct.task import Task
from direct.actor.Actor import Actor

class MyApp(ShowBase):
    def __init__(self):
        ShowBase.__init__(self)

        # Load the environment model.
        self.environ = self.loader.loadModel(&quot;models/environment&quot;)
        # Reparent the model to render.
        self.environ.reparentTo(self.render)
        # Apply scale and position transforms on the model.
        self.environ.setScale(0.25, 0.25, 0.25)
        self.environ.setPos(-8, 42, 0)

        # Add the spinCameraTask procedure to the task manager.
        self.taskMgr.add(self.spinCameraTask, &quot;SpinCameraTask&quot;)

        # Load and transform the panda actor.
        self.pandaActor = Actor(&quot;models/panda-model&quot;,
                                {&quot;walk&quot;: &quot;models/panda-walk4&quot;})
        self.pandaActor.setScale(0.005, 0.005, 0.005)
        self.pandaActor.reparentTo(self.render)
        # Loop its animation.
        self.pandaActor.loop(&quot;walk&quot;)
 
    # Define a procedure to move the camera.
    def spinCameraTask(self, task):
        angleDegrees = task.time * 6.0
        angleRadians = angleDegrees * (pi / 180.0)
        self.camera.setPos(20 * sin(angleRadians), -20.0 * cos(angleRadians), 3)
        self.camera.setHpr(angleDegrees, 0, 0)
        return Task.cont

app = MyApp()
app.run()
&lt;/code&gt;[/python]

[cxx]
The &lt;code&gt;Actor&lt;/code&gt; class which is available to python users is not available to C++ users. you should create your own Actor class which at least should do the following:
&lt;ul&gt;&lt;li&gt;load the Actor Model&lt;/li&gt;
&lt;li&gt;load the animations&lt;/li&gt;
&lt;li&gt;bind the model and the animations using AnimControl or AnimControlCollection&lt;/li&gt;&lt;/ul&gt;

The next sample will load the panda model and the walk animation. the call: &lt;code&gt;window-&gt;loop_animations(0);&lt;/code&gt; does the magic of binding all the loaded models and their animations under the node path: render . it's very important to note that any animations loaded after the above call will not show until the same method is called again. also any animations loaded under a node path which doesn't belong to render (for example: render_2d) will not show even if the call: &lt;code&gt;window-&gt;loop_animations(0);&lt;/code&gt; is made. For such animations to show, other steps must be applied (more on this later).

&lt;code cxx&gt;#include &quot;pandaFramework.h&quot;
#include &quot;pandaSystem.h&quot;

#include &quot;genericAsyncTask.h&quot;
#include &quot;asyncTaskManager.h&quot;

// Global stuff
PT(AsyncTaskManager) taskMgr = AsyncTaskManager::get_global_ptr(); 
PT(ClockObject) globalClock = ClockObject::get_global_clock();
NodePath camera;

// Task to move the camera
AsyncTask::DoneStatus SpinCameraTask(GenericAsyncTask* task, void* data) {
    double time = globalClock-&gt;get_real_time();
    double angledegrees = time * 6.0;
    double angleradians = angledegrees * (3.14 / 180.0);
    camera.set_pos(20*sin(angleradians),-20.0*cos(angleradians),3);
    camera.set_hpr(angledegrees, 0, 0);

    return AsyncTask::DS_cont;
}

int main(int argc, char *argv[]) {
    // Open a new window framework and set the title
    PandaFramework framework;
    framework.open_framework(argc, argv);
    framework.set_window_title(&quot;My Panda3D Window&quot;);

    // Open the window
    WindowFramework *window = framework.open_window();
    camera = window-&gt;get_camera_group(); // Get the camera and store it

    // Load the environment model
    NodePath environ = window-&gt;load_model(framework.get_models(), &quot;models/environment&quot;);
    environ.reparent_to(window-&gt;get_render());
    environ.set_scale(0.25 , 0.25, 0.25);
    environ.set_pos(-8, 42, 0);

    // Load our panda
    NodePath pandaActor = window-&gt;load_model(framework.get_models(), &quot;panda-model&quot;);
    pandaActor.set_scale(0.005);
    pandaActor.reparent_to(window-&gt;get_render());
  
    // Load the walk animation
    window-&gt;load_model(pandaActor, &quot;panda-walk4&quot;);
    window-&gt;loop_animations(0); // bind models and animations
                                //set animations to loop

    // Add our task do the main loop, then rest in peace.
    taskMgr-&gt;add(new GenericAsyncTask(&quot;Spins the camera&quot;, &amp;SpinCameraTask, (void*) NULL));
    framework.main_loop();
    framework.close_framework();
    return (0);
}&lt;/code&gt;[/cxx]

&lt;p&gt;[python]The command &lt;code&gt;loop(&quot;walk&quot;)&lt;/code&gt; causes the walk animation to begin looping.[/python]
[cxx] We are first loading the model file and the animation file like ordinary models. Then, we are simply calling loop_animations(0) to loop all animations.[/cxx]&lt;/p&gt;

=== Run the Program ===
&lt;p&gt;The result is a panda walking in place as if on a treadmill:&lt;/p&gt;

[[Image:Tutorial3.jpg]]</text>
    </revision>
  </page>
  <page>
    <title>Loading and Animating the Panda Model (CXX)</title>
    <ns>0</ns>
    <id>2091</id>
      <sha1>kuj1dlf4jqulzm2oqhidehkzrpz7gjk</sha1>
    <revision>
      <id>4986</id>
      <timestamp>2008-03-14T21:46:13Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="2204">Now that the scenery is in place, we will now load an animated panda.  Update your code to look like this:

&lt;pre class=&quot;codeblock&quot;&gt;
#include &quot;pandaFramework.h&quot;
#include &quot;pandaSystem.h&quot;

PandaFramework framework;

int main(int argc, char *argv[]) {
    //open a new window framework and set title
  framework.open_framework(argc, argv);
  framework.set_window_title(&quot;My Panda3D Window&quot;);
  
    //open the window
  WindowFramework *window = framework.open_window();
  NodePath cam = window-&gt;get_camera_group(); //get the camera and store it
 
    //load the environment model
  NodePath environ = window-&gt;load_model(framework.get_models(),&quot;models/environment&quot;);
  environ.reparent_to(window-&gt;get_render());
  environ.set_scale(0.25,0.25,0.25);
  environ.set_pos(-8,42,0);

    //load our panda
  NodePath pandaActor = window-&gt;load_model(framework.get_models(),&quot;panda-model&quot;);
  pandaActor.set_scale(0.005,0.005,0.005);
  pandaActor.reparent_to(window-&gt;get_render());
  
    //load the walk animation
  window-&gt;load_model(pandaActor,&quot;panda-walk4&quot;);
  window-&gt;loop_animations(0);

    //do the main loop:
  ClockObject* clock; //create a clock object for time measurement
  clock=ClockObject::get_global_clock();
  Thread *current_thread = Thread::get_current_thread();
  while(framework.do_frame(current_thread)) {
    double time = clock-&gt;get_real_time(); //get the time in seconds
    double angledegrees = time * 6.0; //the angle of the camera in degrees
    double angleradians = angledegrees * (3.14 / 180.0); //in radians
    cam.set_pos(20*sin(angleradians),-20.0*cos(angleradians),3); //set the position
    cam.set_hpr(angledegrees, 0, 0); //set the hpr
  }

    //close the window framework
  framework.close_framework();
  return (0);
}

&lt;/pre&gt;


Different from Python, you have to load the animation file as a normal model and reparent it to &lt;code&gt;render&lt;/code&gt; just as you would do with a normal model.

The command &lt;code&gt;loop_animations(0)&lt;/code&gt; causes all animations to begin looping, since the walk animation is the only one at the moment. What that 0 is doing there is not necessary to know right now.
The result is a panda walking in place, as if on a treadmill:

[[Image:Tutorial3.jpg]]</text>
    </revision>
  </page>
  <page>
    <title>Loading and Playing Sounds and Music</title>
    <ns>0</ns>
    <id>1055</id>
      <sha1>149ug9sqg1m4ji4ro6jk5nkpzcj313x</sha1>
    <revision>
      <id>60225</id>
      <timestamp>2014-07-24T19:55:30Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="3108">== Architecture ==

The implementation of the sound system in Panda3d allows for a division of audio into two categories - Sound Effects and Music. This division is only a convenience for programmers as Panda3d allows these two audio groups to be treated individually. These differences are explained on the next page.

== Basics ==
=== Loading a Sound ===

[python]
Loading sound is done through the &lt;code&gt;Loader&lt;/code&gt; class by supplying the path to the sound file as a parameter for &lt;code&gt;loadSfx()&lt;/code&gt;. Here's an example:

&lt;code python&gt;
base = ShowBase()
mySound = base.loader.loadSfx(&quot;path/to/sound_file.ogg&quot;)
&lt;/code&gt;
[/python]

[cxx]
Loading sound is done through the &lt;code&gt;AudioManager&lt;/code&gt; class by supplying the path to the sound file as a parameter for &lt;code&gt;get_sound()&lt;/code&gt;. Here's an example:

&lt;code cxx&gt;
PT(AudioManager) AM = AudioManager::create_AudioManager();
PT(AudioSound) mySound = AM-&gt;get_sound(&quot;path/to/sound_file.ogg&quot;) ;
&lt;/code&gt;
[/cxx]

These will return an object of the type &lt;code&gt;AudioSound&lt;/code&gt;. It is necessary to put the extension in the sound filename. 


=== Playing/Stopping a Sound ===

To play sounds you can do the following:

[python]
&lt;code python&gt;
mySound.play()
&lt;/code&gt;
[/python]

[cxx]
&lt;code cxx&gt;
mySound-&gt;play();
&lt;/code&gt;
[/cxx]

To stop a sound:

[python]
&lt;code python&gt;
mySound.stop()
&lt;/code&gt;
[/python]

[cxx]
&lt;code cxx&gt;
mySound-&gt;stop();
&lt;/code&gt;
[/cxx]


=== Querying Sound Status ===

To check the status of a sound, call &lt;code&gt;status()&lt;/code&gt;:

[python]
&lt;code python&gt;
status = mySound.status()
&lt;/code&gt;
[/python]

[cxx]
&lt;code cxx&gt;
mySound-&gt;status();
&lt;/code&gt;
[/cxx]

&lt;code&gt;status()&lt;/code&gt; returns a constant depending on the status of the sound:
{| class=&quot;wikitable sortable&quot; border=&quot;1&quot; cellpadding=&quot;5&quot; cellspacing=&quot;0&quot;
!width=&quot;50px&quot;|Constant
!width=&quot;200px&quot;|Status
|-
| AudioSound.BAD
| The sound is not working properly.
|-
| AudioSound.READY
| The sound is not currently playing and is ready to be played on command.
|-
| AudioSound.PLAYING
| The sound is currently playing.
|}

Example usage of this would be to stop a sound from playing only if it's currently playing.

[python]
&lt;code python&gt;
if mySound.status() == mySound.PLAYING:
    mySound.stop()
&lt;/code&gt;
[/python]

=== Setting Volume ===

The volume can be set between 0 and 1 and will linearly scale between these.

[python]
&lt;code python&gt;
mySound.setVolume(0.5)
&lt;/code&gt;
[/python]

[cxx]
&lt;code cxx&gt;
mySound-&gt;set_volume(0.5);
&lt;/code&gt;
[/cxx]


=== Panning a Sound ===

You can change the balance of a sound. The range is between -1.0 to 1.0. Hard left is -1.0 and hard right is 1.0.

[python]
&lt;code python&gt;
mySound.setBalance(-0.5)
&lt;/code&gt;
[/python]

[cxx]
&lt;code cxx&gt;
mySound-&gt;set_balance(-0.5);
&lt;/code&gt;
[/cxx]

[python]

== Extra Note ==

[python]
If Panda3D is running from an interactive prompt, &lt;code&gt;update()&lt;/code&gt; after you play a sound.


&lt;code python&gt;
base.sfxManagerList[n].update()
&lt;/code&gt;

This is because the &lt;code&gt;update()&lt;/code&gt; command is called every frame to reset a sound's channel. 
[/python]

In interactive mode, Panda3D's frame update is suspended and does not run automatically.</text>
    </revision>
  </page>
  <page>
    <title>Loading resources from nonstandard sources</title>
    <ns>0</ns>
    <id>2294</id>
      <sha1>74ubazgqkriza3ucoal6lfdkyuegc6q</sha1>
    <revision>
      <id>6664</id>
      <timestamp>2010-02-09T09:51:36Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <text xml:space="preserve" bytes="977">If you have want to load a resource from a different spot then a hard drive or inside a multifile, say for instance database or network packet you can using a StringStream.

Here is an example that reads and image into data and then uses StringStream to feed that data into the image.

&lt;code python&gt;
data = open('my-image-file.png').read()
# send data over network or any other place and pass it on
p = PNMImage()
p.read(StringStream(data))
tex = Texture()
tex.load(p) 
&lt;/code&gt;

But, you can go one step further. Instead of just loading textures, models, sounds or other data one at a time this way, you can load an entire multifile, which as we learned in the previous section can contain any number of models, textures, sounds and other data.

&lt;code python&gt;
data = open('my-multifile.mf').read()
stream = StringStream(data)
mf = Multifile()
mf.openRead(stream)
vfs = VirtualFileSystem.getGlobalPtr()
vfs.mount(mf, '/mf', 0)
smiley = loader.loadModel('/mf/smiley.egg')
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>Loading the Grassy Scenery</title>
    <ns>0</ns>
    <id>936</id>
      <sha1>2w7adwaxbhpg5jch6v7rl9mta79efak</sha1>
    <revision>
      <id>60217</id>
      <timestamp>2014-07-24T18:25:32Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>cleanup wiki syntax</comment>
      <text xml:space="preserve" bytes="3699">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

== [[The Scene Graph]] ==
Panda3D contains a data structure called the ''Scene Graph''. The Scene Graph is a tree containing all objects that need to be rendered. At the root of the tree is an object named &lt;code&gt;render&lt;/code&gt;. [cxx]You can get the NodePath of render by calling &lt;code&gt;window-&gt;get_render()&lt;/code&gt;.[/cxx] Nothing is rendered until it is first
inserted into the Scene Graph.

To install the grassy scenery model into the Scene Graph, we use the method &lt;code&gt;[func]reparentTo[/func]()&lt;/code&gt;. This sets the parent of the model, thereby giving it a place in the Scene Graph. Doing so makes the model visible in the scene.

Finally, we adjust the position and scale of the model. In this particular case, the environment model is a little too large and somewhat offset for our purposes. The &lt;code&gt;[func]setScale[/func]()&lt;/code&gt; and &lt;code&gt;[func]setPos[/func]()&lt;/code&gt; procedures rescale and center the model.

Panda3D uses the &quot;geographical&quot; coordinate system where position &lt;code&gt;(-8, 42, 0)&lt;/code&gt; means map coordinates (8, 42) and height 0. If you are used to OpenGL/Direct3D coordinates, then hold up your right hand in the classical position with thumb as X, fingers as Y, and palm as Z facing toward you; then tilt backward until your hand is level with the fingers pointing away and palm facing up. Moving &quot;forward&quot; in Panda3D is a positive change in Y coordinate.

== The Program ==
=== Update the Code ===
With Panda3D running properly, it is now possible to
load some grassy scenery. Update your code as follows:

[python]&lt;syntaxhighlight lang=&quot;python&quot;&gt;
from direct.showbase.ShowBase import ShowBase

class MyApp(ShowBase):

    def __init__(self):
        ShowBase.__init__(self)

        # Load the environment model.
        self.environ = self.loader.loadModel(&quot;models/environment&quot;)
        # Reparent the model to render.
        self.environ.reparentTo(self.render)
        # Apply scale and position transforms on the model.
        self.environ.setScale(0.25, 0.25, 0.25)
        self.environ.setPos(-8, 42, 0)


app = MyApp()
app.run()
&lt;/syntaxhighlight&gt;[/python]
[cxx]&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
#include &quot;pandaFramework.h&quot;
#include &quot;pandaSystem.h&quot;

int main(int argc, char *argv[]) {
    // Load the window and set its title.
    PandaFramework framework;
    framework.open_framework(argc, argv);
    framework.set_window_title(&quot;My Panda3D Window&quot;);
    WindowFramework *window = framework.open_window();

    // Load the environment model.
    NodePath environ = window-&gt;load_model(framework.get_models(), &quot;models/environment&quot;);
    // Reparent the model to render.
    environ.reparent_to(window-&gt;get_render());
    // Apply scale and position transforms to the model.
    environ.set_scale(0.25, 0.25, 0.25);
    environ.set_pos(-8, 42, 0);

    // Run the engine.
    framework.main_loop();
    // Shut down the engine when done.
    framework.close_framework();
    return (0);
}
&lt;/syntaxhighlight&gt;[/cxx]

The ShowBase procedure [python]&lt;code&gt;loader.loadModel()&lt;/code&gt;[/python][cxx]&lt;code&gt;window-&gt;load_model(framework.get_models(), &quot;path&quot;)&lt;/code&gt;[/cxx]
loads the specified file, in this case the environment.egg file in the
models folder. The return value is an object of the &lt;code&gt;NodePath&lt;/code&gt; class, effectively a pointer to the model. Note that [[Panda Filename Syntax]] uses the
forward-slash, even under Windows.

=== Run the Program ===
Go ahead and run the program. You should see this:

[[Image:Tutorial1.jpg]]

The rock and tree appear to be hovering. The camera is slightly below ground, and back-face culling is making the ground invisible to us. If we reposition the camera, the terrain will look better.</text>
    </revision>
  </page>
  <page>
    <title>Loading the Grassy Scenery (CXX)</title>
    <ns>0</ns>
    <id>2088</id>
      <sha1>rsvlxmevr5ub56po19dmyus5zs1rbuc</sha1>
    <revision>
      <id>4984</id>
      <timestamp>2008-03-14T21:45:22Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="2176">With Panda3D running properly, it is now possible to
load some grassy scenery.  Update your code as follows:

&lt;pre class=&quot;codeblock&quot;&gt;
#include &quot;pandaFramework.h&quot;
#include &quot;pandaSystem.h&quot;

PandaFramework framework;

int main(int argc, char *argv[]) {
    //load the window and stuff
  framework.open_framework(argc, argv);
  framework.set_window_title(&quot;My Panda3D Window&quot;);
  WindowFramework *window = framework.open_window();

    //load the environment model
  NodePath environ = window-&gt;load_model(framework.get_models(),&quot;models/environment&quot;);
  environ.reparent_to(window-&gt;get_render());
  environ.set_scale(0.25,0.25,0.25);
  environ.set_pos(-8,42,0);

    //do the rest
  framework.main_loop();
  framework.close_framework();
  return (0);
}
&lt;/pre&gt;

The command &lt;code&gt;window-&gt;load_model(framework.get_models(),&lt;i&gt;path&lt;/i&gt;)&lt;/code&gt;
loads the specified file, in this case the environment.egg file in the
models folder.  The return value is a 'NodePath', effectively a
pointer to the model.  Note that [[Panda Filename Syntax]] uses the
forward-slash, even under Windows.

Panda3D contains a data structure called the &lt;i&gt;scene
graph&lt;/i&gt;.  The scene graph is a tree containing all objects
that need to be rendered.  At the root of the tree is an object named
&lt;code&gt;render&lt;/code&gt;. You can get the NodePath of render by calling &lt;code&gt;window-&gt;get_render()&lt;/code&gt;. Nothing is rendered until it is first
installed into the scene graph.

To install the grassy scenery model into the scene
graph, we use the method &lt;code&gt;reparent_to&lt;/code&gt;.  This sets the
parent of the model, thereby giving it a place in the scene graph.  Doing
so makes the model visible.

Finally, we adjust the position and scale of the model.
In this particular case, the environment model is a little too large
and somewhat offset for our purposes.  The &lt;code&gt;set_scale&lt;/code&gt;
and &lt;code&gt;set_pos&lt;/code&gt; rescale and recenter the model.

Go ahead and run the program.  You should see this:

[[Image:Tutorial1.jpg]]

The rock and tree appear to be hovering.  The camera
is slightly below ground, and backface culling is making the ground
invisible to us.  If we reposition the camera, the terrain will look
better.</text>
    </revision>
  </page>
  <page>
    <title>Log Messages</title>
    <ns>0</ns>
    <id>1742</id>
      <sha1>fmlrl5xfzmpby9n38fr2wzt0vsnglg9</sha1>
    <revision>
      <id>6215</id>
      <timestamp>2009-10-04T15:23:11Z</timestamp>
      <contributor>
        <username>Nemesis</username>
        <id>193</id>
      </contributor>
      <comment>added a big note about the two different notifiers; added the section about how to create own notifiers; added the logfile prc option;  converted the code blocks to the new python and prc specific</comment>
      <text xml:space="preserve" bytes="3746">Panda periodically outputs log messages for debugging purposes.  A typical log message might look like this:

&lt;pre class=&quot;codeblock&quot;&gt;
:util(warning): Adjusting global clock's real time by -3.3 seconds.
&lt;/pre&gt;

The first part of the message, &lt;code&gt;util&lt;/code&gt;, is the name of the module that generated the message. The second part, &lt;code&gt;warning&lt;/code&gt;, indicates the severity. The severity levels are, in decreasing order: fatal, error, warning, info, debug, and spam. The panda configuration file (Config.prc) contains these directives:

&lt;code prc&gt;
notify-level warning
default-directnotify-level warning
&lt;/code&gt;

Directives like these tell panda which messages to show, and which to suppress.  In the default configuration (shown above), all messages whose severity is &lt;code&gt;warning&lt;/code&gt; or above are shown, all messages whose severity is less are suppressed.

&lt;div style=&quot;border: 1px solid orange; padding: 1em;&quot;&gt;
&lt;big&gt;'''Note:'''&lt;/big&gt;There are two kinds of notifiers: the C++ one and a Pythonic (therefore 'direct'notify). You can distinguish them by the category name. Where C++ categories are always lowercase, Python categories are starting with a capital letter by convention (e.g. util, and ShowBase). The only differences in practice is that you set (all) Python notifiers with the prc option '''default-notify-level''' and C++ with '''notify-level''', and Pythonic notifiers don't know the ''spam'' and ''fatal'' levels.&lt;/div&gt;



Sometimes it is interesting and educational to change the configuration to this:
&lt;code prc&gt;
notify-level spam
default-directnotify-level info
&lt;/code&gt;

If you do this, panda will print out vast amounts of information while it runs. These informational messages can be useful for debugging.  However, there are so many print-statements that it slows panda down to a crawl.  So it may be desirable to tell panda to narrow it down a little.  The way to do that is to name a particular module in the panda config file.  For example, you might do this:

&lt;code prc&gt;
notify-level warning
notify-level-glgsg spam
default-directnotify-level warning
&lt;/code&gt;

This tells panda that module &quot;glgsg&quot; should print out everything it can, but that every other module should only print warnings and errors.  By the way, module &lt;code&gt;glgsg&lt;/code&gt; is a particularly interesting module to investigate.  This is the module that invokes OpenGL.  If you tell it to spam you, it will tell you what it's setting the MODELVIEW and PROJECTION matrices to, and lots of other interesting information.

== Generating your own Log Messages ==

You can use the &lt;code&gt;Notify&lt;/code&gt; class to output your own log messages.

In Python this would look something like this:
&lt;code python&gt;
from direct.directnotify.DirectNotify import DirectNotify
(...)
notify = DirectNotify().newCategory(&quot;MyCategory&quot;)
(...)
notify.warning(&quot;Put some informational text here.&quot;)
&lt;/code&gt;
First you create a new notify category, which may be whatever you want, e.g. &quot;PlayerMovement&quot;. It's a convention to have such a notifier for each bigger class or module. In the last line there is a warning() call, which indicates that the given text will be only printed if the severity level for this category is ''warning'' or ''debug''. If the severity isn't set for this particular category, then the default-directnotify-level setting is taken.

== Redirecting Log Messages to a File ==

If you wish, you can redirect all of panda's log messages into a file.  The following snippet will do the trick:

&lt;code python&gt;
nout = MultiplexStream()
Notify.ptr().setOstreamPtr(nout, 0)
nout.addFile(Filename(&quot;out.txt&quot;))
&lt;/code&gt;

Alternatively you may want to use the notify-output prc option, which expects a filename as argument:
&lt;code prc&gt;
notify-output mygame-log.txt
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>Low-Level Render to Texture</title>
    <ns>0</ns>
    <id>1264</id>
      <sha1>q9170upsuscewt97ielazu9fujld6yu</sha1>
    <revision>
      <id>7387</id>
      <timestamp>2011-12-01T19:33:58Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <comment>Fix omitted DisplayRegion creation</comment>
      <text xml:space="preserve" bytes="5527">&lt;b&gt;Render to Texture Basics&lt;/b&gt;

In Panda3D, rendering to a texture consists of three basic steps:

* Create a hidden window (class GraphicsBuffer).
* Render into the hidden window.
* Transfer the contents of the hidden window into a texture.

When I say &quot;transfer&quot; the contents of a window into a texture, I don't necessarily mean &quot;copy.&quot;  There are other ways to transfer the contents of a window into a texture that may be faster.  For example, if the OpenGL implementation supports the ARB_pbuffers extension, then the transfer might be achieved using wglBindTexImageARB.  The Panda user does not need to worry about how the transfer is done.  It is only important that you know that Panda will use the fastest means available to transfer the contents of the window into the texture.

To generalize that a bit, although render-to-texture is usually done with a hidden window (class GraphicsBuffer), it can also be done with a visible window (class GraphicsWindow).  You can transfer the contents of any window, hidden or not, into a texture.  That's potentially useful - for example, you can transfer the contents of the main window into a texture, which you can then use when rendering the next frame. This can be used to create accumulation-buffer-like effects without an accumulation buffer.

&lt;b&gt;The Simple API: makeTextureBuffer&lt;/b&gt;

Here is a short snippet of code that creates a hidden window, creates a camera that renders into that window, and creates a scene graph for that camera:

[python]&lt;code python&gt;
mybuffer = base.win.makeTextureBuffer(&quot;My Buffer&quot;, 512, 512)
mytexture = mybuffer.getTexture()
mybuffer.setSort(-100)
mycamera = base.makeCamera(mybuffer)
myscene = NodePath(&quot;My Scene&quot;)
mycamera.reparentTo(myscene)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
PT(GraphicsOutput) mybuffer;
PT(Texture) mytexture;
PT(Camera) mycamera;
PT(DisplayRegion) region;
NodePath mycameraNP;
NodePath myscene;

mybuffer = window-&gt;get_graphics_output()-&gt;make_texture_buffer(&quot;My Buffer&quot;, 512, 512);
mytexture = mybuffer-&gt;get_texture();
mybuffer-&gt;set_sort(-100);
mycamera = new Camera(&quot;my camera&quot;);
mycameraNP = window-&gt;get_render().attach_new_node(mycamera);
region = mybuffer-&gt;make_display_region();
region-&gt;set_camera(mycameraNP);
myscene = NodePath(&quot;My Scene&quot;);
mycameraNP.reparent_to(myscene)
&lt;/code&gt;[/cxx]

The &lt;code&gt;[func]makeTextureBuffer[/func]&lt;/code&gt; is the simple interface to the render-to-texture functionality.  It creates a new hidden window (usually a GraphicsBuffer), creates a texture to render into, and connects the texture to the hidden window.  The (512, 512) in the function call specifies the size of the hidden window and texture.  Of course, you need to use a power-of-two size.  The &lt;code&gt;[func]getTexture[/func]&lt;/code&gt; method retrieves the texture, which will be rendered into every frame.

The &lt;code&gt;[func]setSort[/func]&lt;/code&gt; method sets a window's sort order.  This controls the order in which panda renders the various windows.  The main window's sort order is zero.  By setting the sort order of mybuffer to a negative number, we ensure that mybuffer will be rendered first.  That, in turn, ensures that mytexture will be ready to use by the time that the main window is rendered.

The new hidden window is not automatically connected to the scene graph.  In this example, we create a separate scene graph rooted at myscene, create a camera to view that scene graph, and connect the camera to mybuffer.

The function &lt;code&gt;[func]makeTextureBuffer[/func]&lt;/code&gt; usually creates a GraphicsBuffer (hidden window), but if the video card is not powerful enough to create an offscreen window, it may not be able to do so.  In that case, &lt;code&gt;[func]makeTextureBuffer[/func]&lt;/code&gt; will create a &lt;code&gt;parasiteBuffer&lt;/code&gt; instead.  A parasite buffer is primarily a trick to emulate a GraphicsBuffer on video cards that are less powerful.  The trick is this: instead of rendering to an offscreen window and then transferring the data into a texture, panda renders into the &lt;i&gt;main&lt;/i&gt; window and then copies the data into the texture.  The limitations of this trick are self-evident.  First, it garbles the contents of the main window.  This is usually no big deal, since the main window is usually cleared and rendered from scratch every frame anyway.  The other problem with this trick is that it fails if the main window is smaller than the desired texture.  Since neither of these problems is common in practice, &lt;code&gt;[func]makeTextureBuffer[/func]&lt;/code&gt; will use parasite buffers transparently if GraphicsBuffers are not available.

There is a debugging mode in which &lt;code&gt;[func]makeTextureBuffer[/func]&lt;/code&gt; will create a &lt;i&gt;visible&lt;/i&gt; window (class GraphicsWindow) instead of a hidden one (class GraphicsBuffer). To enable this debugging mode, set the boolean variable &quot;show-buffers #t&quot; in your panda configuration file.

&lt;b&gt;The Advanced API: [func]addRenderTexture[/func]&lt;/b&gt;

The simple API is convenient, but there are a few things it can not do.  For instance, it can not:

* Copy the main window into a texture.
* Copy the Z-buffer into a depth texture.
* Copy the window into a texture, but not every frame.
* Limit or force the use of Parasite buffers.

If you need this level of control, you need to use a lower-level API.  The documentation for the lower-level API is not currently written.  However,
several of the [[Sample Programs in the Distribution|Sample Programs]] use
the lower-level API.

&lt;h2&gt;Incomplete Section&lt;/h2&gt;

Note: this section is incomplete.  It will be updated soon.</text>
    </revision>
  </page>
  <page>
    <title>Macros</title>
    <ns>0</ns>
    <id>1104</id>
      <sha1>gyc88jro8s422edle3zf0rvxi7c9yc6</sha1>
    <revision>
      <id>2385</id>
      <timestamp>2005-05-04T02:46:13Z</timestamp>
      <contributor>
        <username>Hughperkins</username>
        <id>10</id>
      </contributor>
      <comment>First created</comment>
      <text xml:space="preserve" bytes="873">== Summary ==

This page describes the macros that are used throughout the Panda3D C++ project

== Macros ==

=== PUBLISHED ===

The keyword PUBLISHED is used to mark methods that are to be made available to Python.

It is akin to C++'s public, private, and protected; think of it as an uber-public. With the Sources.pp tree in place properly, the PUBLISHED keyword is all you need to use to expose your methods, although you will also need to add your new dll to the genPyCode command line after you have run make install: 

&lt;pre&gt;
genPyCode mynewlib.dll
&lt;/pre&gt;

=== EXPCL_xxx ===

The EXPCL_xxx prefix on a class definition tells the compiler which DLL the class is compiled into, for example EXPCL_PANDA means to compile into libpanda.dll.

If you want to link a class into pview, or some other executable (not a dll), then you can just omit the EXPCL_ prefix altogether.</text>
    </revision>
  </page>
  <page>
    <title>Main Loop</title>
    <ns>0</ns>
    <id>1728</id>
      <sha1>r14nuq0f3h4jq3w8pdfrmyzlnp1cgdc</sha1>
    <revision>
      <id>6503</id>
      <timestamp>2010-01-05T17:36:51Z</timestamp>
      <contributor>
        <username>Nemesis13</username>
        <id>394</id>
      </contributor>
      <minor/>
      <comment>proper code tags</comment>
      <text xml:space="preserve" bytes="3883">A typical form of a Panda program might look like:

&lt;code python&gt;
from direct.showbase.DirectObject import DirectObject # To listen for Events 

class World(DirectObject):
   __init__(self):
      #initialize instance self. variables here
   method1(): 
      # Panda source goes here

w = World()
run() # main loop
&lt;/code&gt;

&lt;code&gt;run()&lt;/code&gt; is a function that never returns.  It is the main loop.

For an alternative, &lt;code&gt;run()&lt;/code&gt; could not be called at all. Panda doesn't really need to own the main loop. 

Instead, &lt;code&gt;taskMgr.step()&lt;/code&gt; can be called intermittently, which will run through one iteration of Panda's loop. In fact, &lt;code&gt;run()&lt;/code&gt; is basically just an infinite loop that calls &lt;code&gt;Task.step()&lt;/code&gt; repeatedly. 

&lt;code&gt;taskMgr.step()&lt;/code&gt; must be called quickly enough after the previous call to &lt;code&gt;taskMgr.step()&lt;/code&gt;. This must be done quick enough to be faster than the frame rate.  

This may useful when an imported third party python module that also has its own event loop wants and wants to be in control of program flow. A third party example may be Twisted, the event-driven networking framework.  

The solution to this problem is to let Panda3D's loop be controlled entirely by twisted's event loop. You will need to use the LoopingCall method to add Panda's &lt;code&gt;taskMgr.step()&lt;/code&gt; method to twisted's event loop. Then, you need to call &lt;code&gt;reactor.run()&lt;/code&gt; instead of Panda3D's &lt;code&gt;run()&lt;/code&gt; method to run twisted's event loop. Here's an example on how this will work:

&lt;code python&gt;
from twisted.internet.task import LoopingCall
from twisted.internet import reactor

LoopingCall(taskMgr.step).start(1 / Desired_FPS)
reactor.run()
&lt;/code&gt;

You will need to replace Desired_FPS by the desired framerate, that is, how many times you want Panda3D to redraw the frame per second.
Please note that &lt;code&gt;reactor.run()&lt;/code&gt; is blocking, just like Panda's run() method.

Another third party example is wxPython GUI, that is a blending of the wxWidgets C++ class library with the Python programming language. Panda's run() function, and wx's &lt;code&gt;app.MainLoop()&lt;/code&gt; method, both are designed to handle all events and never return. They are each supposed to serve as the one main loop of the application. Two main loops can not effectively run an application. 

wxPython also supplies a method that can be called occasionally, instead of a function that never returns. In wx's case, it's &lt;code&gt;app.Dispatch()&lt;/code&gt;.

A choice can be made whether or not to make wx handle the main loop, and call &lt;code&gt;taskMgr.step()&lt;/code&gt; intermittently, or whether or not to make Panda handle the main loop, and call &lt;code&gt;app.Dispatch()&lt;/code&gt; intermittently. The better performance choice is to have Panda handle the main loop.

In the case that Panda handles the main loop, a task needs to be started to call app.Dispatch() every frame, if needed. Instead of calling wxPython's &lt;code&gt;app.MainLoop()&lt;/code&gt;, do something like the following: 

&lt;code python&gt;
app = wx.App(0) 

def handleWxEvents(task): 
   while app.Pending(): 
      app.Dispatch() 
   return Task.cont 

taskMgr.add(handleWxEvents, 'handleWxEvents') 
run()  # Panda handles the main loop
&lt;/code&gt;


In the case that wxPython handles the main loop using &lt;code&gt;app.MainLoop()&lt;/code&gt;, to keep the framerate quick and reduce the CPU, add &lt;code&gt;sleep(0.001)&lt;/code&gt; in the body of the program. This will yield to Panda. After the sleep is over, control will return to wxPython. wxPython can then check for user events. wxPython's user generated callback events are generally generated only at infrequent intervals (based on when the user is interacting with the window). This is appropriate for a 2-D application that is completely response-driven, but not very useful for a 3-D application that continues to be active even when a user is not interacting with it.</text>
    </revision>
  </page>
  <page>
    <title>Main Page</title>
    <ns>0</ns>
    <id>1</id>
      <sha1>daawzgfz8o2soseygy65mjaks5ox51y</sha1>
    <revision>
      <id>60491</id>
      <timestamp>2015-05-07T22:57:01Z</timestamp>
      <contributor>
        <username>Eswartz</username>
        <id>22863</id>
      </contributor>
      <comment>/* Table of Contents */</comment>
      <text xml:space="preserve" bytes="12691">&lt;!-- Note: this table of contents is scanned and processed by
     a number of scripts.  It must be kept in a rigid format.
     Try not to put [cxx] and [python] tags here - it might
     confuse the automatic scripts. --&gt;
== Table of Contents ==

# [[Introduction to Panda3D]]
## [[Installing Panda3D in Windows]]
## [[Installing Panda3D in Linux]]
## [[General Preparation]]
## [[Running your Program]]
## [[A Panda3D Hello World Tutorial]]
### [[Starting Panda3D]]
### [[Loading the Grassy Scenery]]
### [[Controlling the Camera]]
### [[Loading and Animating the Panda Model]]
### [[Using Intervals to move the Panda]]
### [[Tutorial End]]
## [[User Contributed Tutorials and Examples]]
## [[Video Tutorials]]
# [[Programming with Panda3D]]
## [[ShowBase]]
## [[The Scene Graph]]
### [[Scene Graph Manipulations]]
### [[Common State Changes]]
### [[Manipulating a Piece of a Model]]
### [[Searching the Scene Graph]]
### [[Instancing]]
## [[The Configuration File]]
### [[Configuring Panda3D]]
### [[List of All Config Variables]]
### [[Accessing Config Vars in a Program]]
## [[Models and Actors]]
### [[Loading Models]]
### [[Loading Actors and Animations]]
### [[Actor Animations]]
### [[Multi-Part Actors]]
### [[Attaching an Object to a Joint]]
### [[Controlling a Joint Procedurally]]
### [[Level of Detail]]
## [[Render Attributes]]
### [[List of All Attributes]]
### [[Lighting]]
### [[Materials]]
### [[Depth Test and Depth Write]]
### [[Fog]]
### [[Alpha Testing]]
### [[Color Write Masks]]
### [[Antialiasing]]
### [[Clip Planes]]
### [[Tinting and Recoloring]]
### [[Backface Culling and Frontface Culling]]
### [[Occlusion Culling]]
#### [[Polygon Occluder Culling]]
#### [[Portal Culling]]
### [[Light Ramps]]
### [[Auxiliary Bitplane Control]]
### [[Stencil Test/Write Attribute]]
## [[Texturing]]
### [[Simple Texturing]]
### [[Choosing a Texture Size]]
### [[Texture Wrap Modes]]
### [[Texture Filter Types]]
### [[Simple Texture Replacement]]
### [[Multitexture Introduction]]
### [[Texture Modes]]
### [[Texture Order]]
### [[Texture Combine Modes]]
### [[Texture Transforms]]
### [[Multiple Texture Coordinate Sets]]
### [[Automatic Texture Coordinates]]
### [[Projected Textures]]
### [[Simple Environment Mapping]]
### [[3-D Textures]]
### [[Cube Maps]]
### [[Environment Mapping with Cube Maps]]
### [[Automatic Texture Animation]]
### [[Playing MPG and AVI files]]
### [[Stereo/Multiview Textures]]
### [[Transparency and Blending]]
### [[Texture Management]]
### [[Texture Compression]]
## [[Shaders]]
### [[Shader Basics]]
### [[List of Possible Cg Shader Inputs]]
### [[List of GLSL Shader Inputs]]
### [[Shaders and Coordinate Spaces]]
### [[Known Shader Bugs and Limitations]]
### [[The Shader Generator]]
### [[Cg Shader Tutorial]]
#### [[Cg Tutorial Part 1]]
#### [[Cg Tutorial Part 2]]
### [[Compute Shaders]]
## [[Camera Control]]
### [[The Default Camera Driver]]
### [[Lenses and Field of View]]
### [[Orthographic Lenses]]
## [[Sound]]
### [[Loading and Playing Sounds and Music]]
### [[Manipulating Sounds]]
### [[Audio Managers]]
### [[DSP Effects]]
### [[3D Audio]]
### [[Multi-Channel]]
## [[Intervals]]
### [[Lerp Intervals]]
### [[Function Intervals]]
### [[Actor Intervals]]
### [[Sound Intervals]]
### [[Motion Path and Particle Intervals]]
### [[Sequences and Parallels]]
### [[Position, Rotation and Scale Intervals]]
### [[Projectile Intervals]]
## [[Tasks and Event Handling]]
### [[Tasks]]
### [[Task Chains]]
### [[Event Handlers]]
### [[Main Loop]]
## [[Text and Image Rendering]]
### [[Text Fonts]]
### [[Text Node]]
### [[OnscreenText]]
### [[OnscreenImage]]
### [[Embedded Text Properties]]
## [[DirectGUI]]
### [[DirectButton]]
### [[DirectCheckButton]]
### [[DirectRadioButton]]
### [[DirectDialog]]
### [[DirectEntry]]
### [[DirectFrame]]
### [[DirectLabel]]
### [[DirectOptionMenu]]
### [[DirectScrolledList]]
### [[DirectWaitBar]]
### [[DirectSlider]]
### [[DirectScrollBar]]
### [[DirectScrolledFrame]]
## [[Render Effects]]
### [[Compass Effects]]
### [[Billboard Effects]]
## [[Finite State Machines]]
### [[FSM Introduction]]
### [[Simple FSM Usage]]
### [[FSM with input]]
### [[Advanced FSM Tidbits]]
## [[Terrain]]
### [[The Heightfield Tesselator]]
### [[Geometrical MipMapping]]
## [[Advanced operations with Panda3D's internal structures]]
### [[How Panda3D Stores Vertices and Geometry]]
#### [[GeomVertexData]]
#### [[GeomVertexFormat]]
#### [[GeomPrimitive]]
#### [[Geom]]
#### [[GeomNode]]
#### [[BoundingVolume]]
### [[Procedurally Generating 3D Models]]
#### [[Defining your own GeomVertexFormat]]
#### [[Pre-defined vertex formats]]
#### [[Creating and filling a GeomVertexData]]
#### [[Creating the GeomPrimitive objects]]
#### [[Putting your new geometry in the scene graph]]
### [[Other Vertex and Model Manipulation]]
#### [[Reading existing geometry data]]
#### [[Modifying existing geometry data]]
#### [[MeshDrawer]]
#### [[More about GeomVertexReader, GeomVertexWriter, and GeomVertexRewriter]]
#### [[Creating New Textures from Scratch]]
#### [[Writing 3D Models out to Disk]]
## [[Render-to-Texture and Image Postprocessing]]
### [[Common Image Filters]]
### [[Generalized Image Filters]]
### [[Dynamic Cube Maps]]
### [[Low-Level Render to Texture]]
## [[Panda3D Rendering Process]]
### [[Multithreaded Render Pipeline]]
### [[Introducing Graphics Classes]]
### [[The Graphics Pipe]]
### [[Creating Windows and Buffers]]
### [[Display Regions]]
### [[Creating New MouseWatchers for Display Regions]]
### [[Clearing Display Regions]]
### [[The 2D Display Region]]
### [[Stereo Display Regions]]
### [[Multi-Pass Rendering]]
### [[How to Control Render Order]]
## [[Panda3D Utility Functions]]
## [[Particle Effects]]
### [[Using the Particle Panel]]
### [[Loading Particle Systems]]
### [[Particle Effect Basic Parameters]]
### [[Particle Factories]]
### [[Particle Emitters]]
### [[Particle Renderers]]
## [[Collision Detection]]
### [[Collision Solids]]
### [[Collision Handlers]]
### [[Collision Entries]]
### [[Collision Traversers]]
### [[Collision Bitmasks]]
### [[Rapidly-Moving Objects]]
### [[Pusher Example]]
### [[Event Example]]
### [[Bitmask Example]]
### [[Clicking on 3D Objects]]
## [[Garbage Collection]]
### [[Removing Custom Class Instances]]
## [[Hardware support]]
### [[Keyboard Support]]
### [[Mouse Support]]
### [[Joystick Support]]
### [[VR Helmets and Trackers]]
## [[Math Engine]]
### [[Matrix Representation]]
## [[Physics]]
### [[Panda3D Physics Engine]]
#### [[Enabling physics on a node]]
#### [[Applying physics to a node]]
#### [[Types of forces]]
#### [[Notes and caveats]]
### [[Using ODE with Panda3D]]
#### [[Worlds, Bodies and Masses]]
#### [[Simulating the Physics World]]
#### [[Attaching Bodies using Joints]]
#### [[Collision Detection with ODE]]
### [[Using Bullet with Panda3D]]
#### [[Bullet Hello World]]
#### [[Bullet Debug Renderer]]
#### [[Bullet Collision Shapes]]
#### [[Bullet Collision Filtering]]
#### [[Bullet Continuous Collision Detection]]
#### [[Bullet Queries]]
#### [[Bullet Ghosts]]
#### [[Bullet Character Controller]]
#### [[Bullet Constraints]]
#### [[Bullet Vehicles]]
#### [[Bullet Softbodies]]
#### [[Bullet Softbody Rope]]
#### [[Bullet Softbody Patch]]
#### [[Bullet Softbody Triangles]]
#### [[Bullet Softbody Tetrahedron]]
#### [[Bullet Softbody Config]]
#### [[Bullet Config Options]]
#### [[Bullet FAQ]]
#### [[Bullet Samples]]
## [[Motion Paths]]
## [[Timing]]
### [[The Global Clock]]
## [[Networking]]
### [[Datagram Protocol]]
#### [[Client-Server Connection]]
#### [[Transmitting Data]]
### [[Downloading a File]]
### [[Distributed Networking]]
## [[Multifiles]]
### [[Creating Multifiles]]
### [[Patching]]
### [[Loading resources from nonstandard sources]]
## [[File Reading]]
## [[Threading]]
## [[Subclassing]]
## [[Table of features supported per graphic renderer]]
## [[Artificial Intelligence (PANDAI)]]
### [[Getting Started]]
### [[Steering Behaviors]]
#### [[Seek]]
#### [[Flee]]
#### [[Pursue]]
#### [[Evade]]
#### [[Wander]]
#### [[Flock]]
#### [[Obstacle Avoidance]]
#### [[Path Follow]]
### [[Pathfinding]]
#### [[Mesh Generation]]
#### [[Static Obstacles]]
#### [[Dynamic Obstacles]]
#### [[Uneven Terrain]]
### [[Source Codes]]
# [[Distributing Panda3D Applications]]
## [[Introduction to p3d files]]
### [[Using packp3d]]
### [[Referencing packages]]
### [[Running p3d files]]
## [[Distributing via the web]]
### [[Embedding with an object element]]
### [[Embedding with RunPanda3D]]
### [[About certificates]]
#### [[Public key, private key]]
#### [[Self-signed certificates]]
#### [[HTTPS (Apache) certificates]]
#### [[Email certificates]]
### [[Signing your p3d files]]
## [[P3D file config settings]]
## [[Distributing as a self-contained installer]]
## [[The runtime Panda3D directory]]
## [[The package system]]
### [[Standard packages]]
### [[Installing packages]]
### [[More about referencing packages]]
### [[Building and hosting your own packages]]
#### [[Using ppackage]]
#### [[The pdef syntax]]
#### [[Creating multiple packages]]
#### [[Hosting packages]]
#### [[SSL hosting]]
#### [[Building multiplatform packages]]
#### [[Building patches]]
## [[Advanced scripting techniques]]
### [[DetectPanda3D.js]]
### [[Advanced object tags]]
### [[Splash window tags]]
### [[Plugin notify callbacks]]
### [[AppRunner]]
#### [[The appRunner.main object]]
#### [[The appRunner.dom object]]
#### [[Reading the HTML tokens]]
#### [[Other appRunner members]]
### [[P3D origin security]]
### [[PackageInstaller]]
# [[Sample Programs in the Distribution]]
## [[Sample Programs: Asteroids]]
## [[Sample Programs: Ball in Maze]]
## [[Sample Programs: Boxing Robots]]
## [[Sample Programs: Carousel]]
## [[Sample Programs: Cartoon Shader]]
## [[Sample Programs: Chessboard]]
## [[Sample Programs: Disco Lights]]
## [[Sample Programs: Distortion]]
## [[Sample Programs: Fireflies]]
## [[Sample Programs: Fractal Plants]]
## [[Sample Programs: Glow Filter]]
## [[Sample Programs: Infinite Tunnel]]
## [[Sample Programs: Looking and Gripping]]
## [[Sample Programs: Media Player]]
## [[Sample Programs: Motion Trails]]
## [[Sample Programs: Mouse Modes]]
## [[Sample Programs: Music Box]]
## [[Sample Programs: Normal Mapping]]
## [[Sample Programs: Particles]]
## [[Sample Programs: Procedural Cube]]
## [[Sample Programs: Roaming Ralph]]
## [[Sample Programs: Shadows]]
## [[Sample Programs: Solar System]]
## [[Sample Programs: Teapot on TV]]
## [[Sample Programs: Texture Swapping]]
# [[Debugging]]
## [[Log Messages]]
## [[The Python Debugger]]
## [[Running Panda3D under the CXX Debugger]]
# [[Performance Tuning]]
## [[Basic Performance Diagnostics]]
## [[Measuring Performance with PStats]]
## [[The Rigid Body Combiner]]
## [[Performance Issue: Too Many Meshes]]
## [[Performance Issue: Too Many State Changes]]
## [[Performance Issue: Too Many Text Updates]]
## [[Performance Issue: Too Many Shader Instructions]]
## [[Performance Issue: Excessive Fill]]
## [[Performance Issue: Memory Full]]
## [[Performance Issue: Python Calculation]]
## [[Performance Issue: Failure to Garbage Collect]]
## [[Performance Issue: Collision System Misuse]]
## [[Performance Issue: Motherboard Integrated Video]]
## [[Performance Issue: Too Many Polygons]]
## [[Performance Issue: Miscellaneous]]
# [[Using CXX]]
## [[How to compile a CXX Panda3D program]]
### [[How to build a CXX Panda3D game using Microsoft Visual Studio 2008]]
### [[How to compile a CXX Panda3D program on Linux]]
### [[How to compile a CXX Panda3D program on Mac OS X]]
## [[The Window Framework]]
## [[Texturing in CXX]]
## [[Reference Counting]]
# [[Panda3D Tools]]
## [[The Scene Graph Browser]]
### [[Enhanced Mouse Navigation]]
## [[Interrogate]]
## [[Python Editors]]
### [[SPE]]
## [[Pipeline Tips]]
## [[Model Export]]
### [[Converting from 3D Studio Max]]
### [[Converting from Maya]]
### [[Converting from Blender]]
### [[Converting from SoftImage]]
### [[Converting from Milkshape 3D]]
### [[Converting from GMax]]
### [[Converting from other Formats]]
### [[Converting Egg to Bam]]
### [[Parsing and Generating Egg Files]]
### [[Egg Syntax]]
## [[Previewing 3D Models in Pview]]
## [[Building an installer using packpanda]]
## [[The Scene Editor]]
### [[Scene Editor Lectures]]
# [[Building Panda3D from Source]]
## [[Troubleshooting ppremake on Windows]]
## [[Troubleshooting ppremake on Linux]]
## [[Troubleshooting makepanda on Windows]]
## [[Troubleshooting makepanda on Linux]]
## [[Tutorial: Compiling the Panda3D Source on Windows]]

* [[Cheat Sheets]]
* [[List of Panda3D Executables]]
* [[Getting Started on OSX]]
* [[More Panda3D Resources]]
* [[Third-party dependencies and license info]]
* [[The IRC Channel]]
* [[FAQ]]</text>
    </revision>
  </page>
  <page>
    <title>Main page</title>
    <ns>0</ns>
    <id>2050</id>
    <redirect title="Main Page" />
      <sha1>modmu9pqjk76od7mzb24xgw5a8qpfof</sha1>
    <revision>
      <id>4033</id>
      <timestamp>2007-01-29T19:32:04Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>Redirecting to [[Main Page]]</comment>
      <text xml:space="preserve" bytes="23">#REDIRECT [[Main Page]]</text>
    </revision>
  </page>
  <page>
    <title>Manipulating Sounds</title>
    <ns>0</ns>
    <id>992</id>
      <sha1>dgbbligakr9l5aa4yeeeryads6yowmm</sha1>
    <revision>
      <id>60465</id>
      <timestamp>2015-01-23T08:12:24Z</timestamp>
      <contributor>
        <username>MRamesh</username>
        <id>22861</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="3773">&lt;h2&gt;Looping a Sound&lt;/h2&gt;

To cause a sound to loop (i.e., cause it to repeat once it is finished playing) do the following:

[python]
&lt;code python&gt;
mySound.setLoop(True)
mySound.play()
&lt;/code&gt;
[/python]

[cxx]
&lt;code cxx&gt;
mySound-&gt;set_loop(true);
mySound-&gt;play();
&lt;/code&gt;
[/cxx]

To stop a sound from looping pass False in the [python]&lt;code python&gt;setLoop&lt;/code&gt;[/python][cxx]&lt;code cxx&gt; set_loop&lt;/code&gt;[/cxx] function.

[python]
&lt;code python&gt;
mySound.setLoop(False)
&lt;/code&gt;
[/python]

[cxx]
&lt;code cxx&gt;
mySound-&gt;set_loop(false);
&lt;/code&gt;
[/cxx]

Sounds can also be looped for a certain number of times: 

[python]
&lt;code python&gt;
mySound.setLoopCount(n)
&lt;/code&gt;
[/python]

[cxx]
&lt;code cxx&gt;
mySound-&gt;set_loop_count(n);
&lt;/code&gt;
[/cxx]

Where 'n' can be any positive integer.
0 will cause a sound to loop forever.
1 will cause a sound to play only once.
&gt;1 will cause a sound to loop that many times.

&lt;i&gt;NOTE&lt;/i&gt;  Setting a sound's loop count will automatically set a sound's loop flag to 0 or &gt;1 will automatically &lt;code&gt;setLoop&lt;/code&gt; to TRUE.

&lt;h2&gt;Notes on Looping Sounds Seamlessly&lt;/h2&gt;

&lt;p&gt;Looping a sound seamlessly should be as simple as loading the sound, then calling &lt;code&gt;setLoop&lt;/code&gt; and &lt;code&gt;play&lt;/code&gt;.  However, occasionally Panda users have had difficulty getting sounds to loop seamlessly.  The problems have been traced to three(!) different causes:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Some MP3 encoders contain a bug where they add blank space at the end of the sound.  This causes a skip during looping.  Try using a wav instead.
&lt;li&gt;Some have tried using Sound Intervals to create a loop.  Unfortunately, sound intervals depend on Panda's Thread to restart the sound, and if the CPU is busy, there's a skip.  This is not a seamless method, in general.  Use &lt;code&gt;setLoop&lt;/code&gt; instead.
&lt;li&gt;There is a bug in Miles sound system, which requires a workaround in Panda3D.  At one time, the workaround was causing problems with FMOD, until we devised a new workaround.  This bug no longer exists, you can ignore it.
&lt;/ol&gt;

&lt;p&gt;So the easiest way to get a reliable looping sound is to use wav files, and to use &lt;code&gt;setLoop&lt;/code&gt;, not sound intervals.  Of course, when it comes time to ship your game, you can convert your sounds to mp3, but before you do, test your mp3 encoder to see if it contains the blank-space bug.&lt;/p&gt;

&lt;h2&gt;Cueing Time&lt;/h2&gt;

There are &lt;code&gt;getTime&lt;/code&gt;, &lt;code&gt;setTime&lt;/code&gt; and &lt;code&gt;length&lt;/code&gt; functions for sounds. These will respectively, report the current time position, set the current time position and report the length. All these are in seconds.

[python]
&lt;code python&gt;
mySound.length()
&lt;/code&gt;
[/python]

[cxx]
&lt;code cxx&gt;
mySound-&gt;length();
&lt;/code&gt;
[/cxx]

will return the length of a sound file in seconds.

[python]
&lt;code python&gt;
mySound.getTime()
&lt;/code&gt;
[/python]

[cxx]
&lt;code cxx&gt;
mySound-&gt;get_time();
&lt;/code&gt;
[/cxx]

will get the current time the 'playback head' of a sound is at in seconds.

[python]
&lt;code python&gt;
mySound.setTime(n)
&lt;/code&gt;
[/python]

[cxx]
&lt;code cxx&gt;
mySound-&gt;set_time(n);
&lt;/code&gt;
[/cxx]

will set the 'playhead head' of a sound to n (where is seconds).

&lt;i&gt;NOTE&lt;/i&gt;   Sounds will start playing IMMEDIATELY after the command is issued, and calling &lt;code&gt;play&lt;/code&gt; will cause the sound to start over from the beginning.

&lt;h2&gt;Changing Playback Speed&lt;/h2&gt;

To change a sound's playback speed, use:

[python]
&lt;code python&gt;
mySound.setPlayRate(n)
&lt;/code&gt;
[/python]

[cxx]
&lt;code cxx&gt;
mySound-&gt;set_play_rate(n);
&lt;/code&gt;
[/cxx]

Where &lt;code&gt;n&lt;/code&gt; is any float.

Negative numbers will play a sound backwards.  Passing the value 0 will pause the sound.

You can also get a sound's play rate with:

[python]
&lt;code python&gt;
mySound.getPlayRate()
&lt;/code&gt;
[/python]

[cxx]
&lt;code cxx&gt;
mySound-&gt;get_play_rate();
&lt;/code&gt;
[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Manipulating Sounds - Part 2</title>
    <ns>0</ns>
    <id>1783</id>
      <sha1>pge5j81qno1qlxjhnqwoinmrfyd604e</sha1>
    <revision>
      <id>3542</id>
      <timestamp>2006-10-10T01:53:56Z</timestamp>
      <contributor>
        <username>ForeverTangent</username>
        <id>45</id>
      </contributor>
      <text xml:space="preserve" bytes="16">Delete This Page</text>
    </revision>
  </page>
  <page>
    <title>Manipulating a Piece of a Model</title>
    <ns>0</ns>
    <id>1080</id>
      <sha1>afjzcba0fsq0jlfmnuoo3hbtaipwhz0</sha1>
    <revision>
      <id>7412</id>
      <timestamp>2011-12-07T09:16:28Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>typos</comment>
      <text xml:space="preserve" bytes="4366">Every model, when loaded, becomes a &lt;code&gt;ModelNode&lt;/code&gt; in the scene graph.  Beneath the &lt;code&gt;ModelNode&lt;/code&gt; are one or more &lt;code&gt;GeomNodes&lt;/code&gt; containing the actual polygons.  If you want to manipulate a piece of a model, for instance, if you want to change the texture of just part of a model, you need a pointer to the relevant GeomNode.

In order to obtain such a pointer, you must first ensure that the relevant geometry is in a &lt;code&gt;GeomNode&lt;/code&gt; of its own (and not merged with all the other geometry).  In other words, you must ensure that panda's optimization mechanisms do not cause the geometry to be merged with the geometry of the rest of the model. While normally this optimization is a good thing, if you want to change textures on a specific part of the model (for example, just a character's face) you will need this geometry to be separate.

There are two different ways that you should do this, according to the type of model it is.

&lt;h2&gt;Animated (skeleton animation) models&lt;/h2&gt;

If your model is animated via keyframe animation in a package such as 3DSMax or Maya--that is, the sort of model you expect to load in via the [[Actors and Characters|Actor]] interface--then Panda will be aggressive in combining all of the geometry into as few nodes as possible.  In order to mark particular geometry to be kept separate, you should use the &lt;code&gt;egg-optchar&lt;/code&gt; program.

The name &quot;optchar&quot; is short for &quot;optimize character&quot;, since the egg-optchar program is designed to optimize an animated character for runtime performance by removing unused and unneeded joints.  However, in addition to this optimization, it also allows you to label a section of a model for later manipulation.  Once you have labeled a piece of geometry, Panda's optimization mechanisms will not fold it in to the rest of the model.

Your first step is to note the name of the object in your modeling program.  For example, suppose you want to control the texture of a model's head, and suppose (hypothetically) the head is labeled &quot;Sphere01&quot; in your modeling program.  Use egg-optchar to tell panda that &quot;Sphere01&quot; deserves to be kept separate and labeled:

&lt;code bash&gt;
egg-optchar -d outputDir -flag Sphere01=theHead modelFile.egg anim1.egg anim2.egg
&lt;/code&gt;

Note that you must always supply the model file(s) and all of its animation files to egg-optchar at the same time.  This is so it can examine all of the joints and determine which joints are actually animated; and it can remove joints by operating on all the files at once.  The output of egg-optchar is written into the directory named by the &quot;-d&quot; parameter.

The &quot;-flag&quot; switch will ensure that panda does not rearrange the geometry for the named polyset, folding it into the model as a whole.  It also assigns the polyset a meaningful name.  Once you have labeled the relevant piece of geometry, you can obtain a pointer to it using the &lt;code&gt;find&lt;/code&gt; method:

[python]&lt;code python&gt;
myModelsHead = myModel.find(&quot;**/theHead&quot;)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
NodePath myModelsHead = myModel.find(&quot;**/theHead&quot;);
&lt;/code&gt;[/cxx]

With this NodePath, you can manipulate the head separately from the rest of the model.  For example, you can move the piece using &lt;code&gt;[func]setPos[/func]&lt;/code&gt;, or change its texture using &lt;code&gt;[func]setTexture[/func]&lt;/code&gt;, or for that matter, do anything that you would do to any other scene graph node.

&lt;h2&gt;Unanimated (environment) models&lt;/h2&gt;

Other kinds of models, those that do not contain any skeleton or animations, are not optimized as aggressively by the Panda loader, on the assumption that the model's hierarchy was structured the way it is intentionally, to maximize culling (see [[Pipeline Tips]]).  Thus, only certain nodes are combined with others, so it's quite likely that an object that you modeled as a separate node in your modeling package will still be available under the same name when you load it in Panda.  But Panda doesn't promise that it will never collapse together nodes that it thinks need to be combined for optimization purposes, unless you tell it not to.

In the case of an unanimated model, the way to protect a particular node is to insert the &lt;code&gt;&lt;Model&gt;&lt;/code&gt; flag into the egg file within the particular group.  The way to do this depends on your modeling package (and this documentation still needs to be written).</text>
    </revision>
  </page>
  <page>
    <title>Material</title>
    <ns>0</ns>
    <id>2251</id>
    <redirect title="Materials" />
      <sha1>d160i6ky6mwpqial4y0cdgzzrz7dwh1</sha1>
    <revision>
      <id>5355</id>
      <timestamp>2008-04-28T17:32:37Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[Materials]]</comment>
      <text xml:space="preserve" bytes="23">#REDIRECT [[Materials]]</text>
    </revision>
  </page>
  <page>
    <title>Materials</title>
    <ns>0</ns>
    <id>2219</id>
      <sha1>766onco7nlixshmfdld0fwuu6udrliv</sha1>
    <revision>
      <id>7627</id>
      <timestamp>2012-03-08T17:41:00Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <comment>new import system, python code tags and forgot to import DirectStart (loader)</comment>
      <text xml:space="preserve" bytes="8340">== Materials ==

Materials affect how the surfaces of models appear when lights are enabled in Panda. These have various effects such as how shiny an object appears, the brightness of it's colors etc. Material properties are combined with textures and lighting to get the final look of an object.

It must be emphasized that materials only work when lights are applied to an object. Otherwise, materials have no effect.

==Explanation of Lighting==

When light strikes a 3D model, light reflects off the model.  If there were no light reflecting off the model, the model would appear pitch black.  The light reflecting off the model is what causes it to have a non-black color onscreen.  In the real world, light is incredibly complicated --- so complicated, that it is infeasible to do realistic calculations.  Instead, Panda3D leaves it in your
hands, giving you some basic tools to express how much light you want
reflecting from each surface.

The tools provided are &lt;i&gt;lights&lt;/i&gt; and &lt;i&gt;materials.&lt;/i&gt; Lights are used
to express how much light is &lt;i&gt;striking&lt;/i&gt; the model.  Materials are used to express how much of the light striking the model is &lt;i&gt;reflected&lt;/i&gt;.

Panda3D separates the light striking the model into two general categories: nondirectional, and directional.  Directional light is light that comes straight from a particular lamp.  Because we know where it's coming from, we also know what direction it is coming from.  Nondirectional light is light that maybe came from somewhere, bounced around a bit, and then eventually hit the model.  Because we don't know exactly where it came from, we don't know what direction it is coming from.  Panda3D handles nondirectional and directional light separately.

There are four kinds of lights in Panda3D: ambient, point, diffuse, and directional.  The ambient light only creates nondirectional light.  The other three create directional light.

When light strikes the surface of the model, it is the Material that governs how much of it reflects.  The Material consists of four values:

* &lt;b&gt;Ambient Scattering&lt;/b&gt;: governs how much of the nondirectional light is reflected.  Nondirectional light is always assumed to come from all directions, and it always reflects in all directions equally.

* &lt;b&gt;Diffuse Scattering&lt;/b&gt;: governs how much of the directional light is scattered.  Scattering means that the light may have arrived from a particular direction, but it bounces off the model in all directions.  Scattering looks like light hitting a painted white wall.

* &lt;b&gt;Specular Reflection&lt;/b&gt;: governs how much of the directional light is reflected.  Specular reflection looks like light hitting a shiny piece of plastic: you can vaguely see a reflection of the lamp in the plastic, though the reflection just looks like a bright spot.

* &lt;b&gt;Emissivity&lt;/b&gt;: governs how much light the surface produces itself, for glowing surfaces like neon or glow sticks.

==Default Behavior and Explicit Behavior==

If the model does not have an explicit material, does not have a flat color, and does not have vertex colors, the behavior is this:

# All nondirectional light is reflected without being tinted.
# All directional light is scattered without being tinted.
# No specular reflection occurs.
# No emissivity occurs.

If the model does not have an explicit material, but it does have a flat color or a vertex color, the behavior is this:

# All nondirectional light is reflected after being modulated by the model's color.
# All directional light is scattered after being modulated by the model's color.
# No specular reflection occurs.
# No emissivity occurs.

When you set an explicit material on an object, the behavior is as follows:

# All nondirectional light is reflected after being modulated by the explicit ambient color.
# All directional light is scattered after being modulated by the explicit diffuse color.
# All directional light is reflected specularly after being modulated by the explicit specular color.
# The explicit emissive color is added to the light.

It is possible to mix-and-match explicit with default behavior.  For example, you can specify an explicit specular color, but not specify an explicit ambient, diffuse, or emissive color.  If you do that, the behavior would be:

# All nondirectional light is reflected after being modulated by the model's color.
# All directional light is scattered after being modulated by the model's color.
# All directional light is reflected specularly after being modulated by the explicit specular color.
# No emissivity occurs.

==Creating and Using Materials==

To use explicit materials, import the Materials module when you first begin your script. Then creating Materials is a matter of creating instances of the Material class and setting the relevant properties:

&lt;code python&gt;
import direct.directbase.DirectStart
from panda3d.core import Material
from panda3d.core import VBase4
#VBase4 has to be imported in order to set colors in the methods

myMaterial = Material()
myMaterial.setShininess(5.0) #Make this material shiny
myMaterial.setAmbient(VBase4(0,0,1,1)) #Make this material blue

myNode = loader.loadModel(&quot;panda&quot;) #Load the model to apply the material to
myNode.setMaterial(myMaterial) #Apply the material to this nodePath
&lt;/code&gt;

==Material Properties==

The following table details the properties available in a material, its effects as well as the relevant setter method. Most of these properties have additional [[#Other Material Methods|get and clear methods]] as well.

&lt;table border=1 cellpadding=1 cellspacing=0&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;Property&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Effects&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Setter Method&lt;/b&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Ambient&lt;/td&gt;
&lt;td&gt;This is the color of the object as it appears in the absence of direct light. This will be the multiplied by any ambient lights in effect on the material to set its base color.&lt;/td&gt;
&lt;td class=&quot;code&quot;&gt;material.setAmbient(VBase4(R,G,B,A))&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Diffuse&lt;/td&gt;
&lt;td&gt;This is the primary color of an object; the color of the object as it appears in direct light, in the absence of highlights. This will be multiplied by any lights in effect on the material to get the color in the parts of the object illuminated by the lights.&lt;/td&gt;
&lt;td class=&quot;code&quot;&gt;material.setDiffuse(VBase4(R,G,B,A))&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Emission&lt;/td&gt;
&lt;td&gt;This is the color of the object as it appears in the absence of any light whatsover, including ambient light. It is as if the object is glowing by this color (although of course it will not illuminate neighboring objects)&lt;/td&gt;
&lt;td class=&quot;code&quot;&gt;material.setEmission(VBase4(R,G,B,A))&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Shininess&lt;/td&gt;
&lt;td&gt;This controls the size of the specular highlight spot. In general, larger number produce a smaller specular highlight, which makes the object appear shinier. Smaller numbers produce a larger highlight, which makes the object appear less shiny.&lt;/td&gt;
&lt;td class=&quot;code&quot;&gt;material.setShininess(&lt;float&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Specular&lt;/td&gt;
&lt;td&gt;This is the highlight color of an object: the color of small highlight reflections.&lt;/td&gt;
&lt;td class=&quot;code&quot;&gt;material.setSpecular(VBase4(R,G,B,A))&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

==Other Material Methods==

Besides the setter methods covered above, you can also get material properties using their get methods, such as &lt;code&gt;material.getShininess()&lt;/code&gt; , &lt;code&gt;material.getDiffuse()&lt;/code&gt;, etc.

Properties can also be reset by using the clear methods: &lt;code&gt;material.clearAmbient()&lt;/code&gt;,&lt;code&gt;material.clearSpecular()&lt;/code&gt;, etc. Shininess does not have a clear method.

Additionally you can check if a material has a property with the has methods: &lt;code&gt;material.hasAmbient()&lt;/code&gt; , &lt;code&gt;material.hasEmission()&lt;/code&gt;, etc.

Materials have two other methods that have not been covered yet, &lt;code&gt;setLocal(&lt;bool&gt;)&lt;/code&gt; and &lt;code&gt;setTwoside(&lt;bool&gt;)&lt;/code&gt;. setLocal controls whether to use camera-relative specular highlights or orthogonal specular highlights. This should be set to True unless an orthogonal projection camera is in use. setTwoside controls if lighting should appear on both sides of a polygon. Both these methods have equivalent get methods.

===Related Classes===
*[http://panda3d.net/apiref.php?page=Material Material]
*[http://panda3d.net/apiref.php?page=MaterialCollection MaterialCollection]

[[Category:Rendering]]
[[Category:RenderAttributes]]</text>
    </revision>
  </page>
  <page>
    <title>Math Engine</title>
    <ns>0</ns>
    <id>993</id>
      <sha1>l8b0yl7yz0ly7jp5vcuej6cjfnrbvu7</sha1>
    <revision>
      <id>5212</id>
      <timestamp>2008-03-15T05:42:14Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="166">Panda3D has a number of vector, matrix, and quaternion operations built-in. 

&lt;h2&gt;Incomplete Section&lt;/h2&gt;

Note: this section is incomplete.  It will be updated soon.</text>
    </revision>
  </page>
  <page>
    <title>Matrix Representation</title>
    <ns>0</ns>
    <id>1722</id>
      <sha1>hm767r3kyxzrtquu15q0sa6hh1ieuze</sha1>
    <revision>
      <id>5507</id>
      <timestamp>2008-10-08T05:33:53Z</timestamp>
      <contributor>
        <username>Jwatte</username>
        <id>194</id>
      </contributor>
      <comment>slight additions to clarify the conventions</comment>
      <text xml:space="preserve" bytes="7897">Periodically, the question arises: does Panda store matrices in column-major or row-major format?  Unfortunately, people who ask that question often fail to realize that there are four ways to represent matrices, two of which are called &quot;column major,&quot; and two of which are called &quot;row major.&quot;  So the answer to the question is not very useful.  This section explains the four possible ways to represent matrices, and then explains which one panda uses.

&lt;b&gt;The Problem&lt;/b&gt;

In graphics, matrices are mainly used to transform vertices.  So one way to write a matrix is to write the four transform equations that it represents.  Assuming that the purpose of a matrix is to transform an input-vector (Xi,Yi,Zi,Wi) into an output vector (Xo,Yo,Zo,Wo), the four equations are:

&lt;pre class=&quot;codeblock&quot;&gt;
Xo = A*Xi + B*Yi + C*Zi + D*Wi
Yo = E*Xi + F*Yi + G*Zi + H*Wi
Zo = J*Xi + K*Yi + L*Zi + M*Wi
Wo = N*Xi + O*Yi + P*Zi + Q*Wi
&lt;/pre&gt;

There are two different orders that you can store these coefficients in RAM:

&lt;pre class=&quot;codeblock&quot;&gt;
Storage Option 1: A,B,C,D,E,F,G,H,J,K,L,M,N,O,P,Q
Storage Option 2: A,E,J,N,B,F,K,O,C,G,L,P,D,H,M,Q
&lt;/pre&gt;

Also, when you're typesetting these coefficients in a manual (or printing them on the screen), there are two possible ways to typeset them:

&lt;table border=0 cellpadding=0 cellspacing=10&gt;&lt;tr&gt;&lt;td&gt;
&lt;pre class=&quot;codeblock&quot;&gt;
A  B  C  D
E  F  G  H
J  K  L  M
N  O  P  Q

Typesetting
 Option 1
&lt;/pre&gt;
&lt;/td&gt;&lt;td&gt;
&lt;pre class=&quot;codeblock&quot;&gt;
A  E  J  N
B  F  K  O
C  G  L  P
D  H  M  Q

Typesetting
Option 2
&lt;/pre&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

These are &lt;i&gt;independent choices&lt;/i&gt;!  There is no reliable relationship between the order that people choose to store the numbers, and the order in which they choose to typeset them.  That means that any given system could use one of four different notations.

So clearly, the two terms &quot;row major&quot; and &quot;column major&quot; are not enough to distinguish the four possibilities.  Worse yet, to my knowledge, there is no established terminology to name the four possibilities.  So the next part of this section is dedicated to coming up with a usable terminology.

&lt;b&gt;The Coefficients are Derivatives&lt;/b&gt;

The equations above contain sixteen coefficients.  Those coefficients are derivatives.  For example, the coefficient &quot;G&quot; could also be called &quot;the derivative of Yo with respect to Zi.&quot;

This gives us a handy way to refer to groups of coefficients.  Collectively, the coefficients &quot;A,B,C,D&quot; could also be called &quot;the derivatives of Xo with respect to Xi,Yi,Zi,Wi&quot; or just &quot;the derivatives of Xo&quot; for short.  The coefficients &quot;A,E,J,N&quot; could also be called &quot;the derivatives of Xo,Yo,Zo,Wo with respect to Xi&quot; or just &quot;the derivatives with respect to Xi&quot; for short.

This is a good way to refer to groups of four coefficients because it unambiguously names four of them without reference to which storage option or which typesetting option you choose.

An alternative that works just as well (and is usually the only way to reverse-engineer a document that was written without specifying these conventions) is to find the translation parts of the matrix. If the translation lives in the rightmost column, then the matrix is intended for column vectors on the right. If the translation lives in the bottom row, then the matrix is intended for row vectors on the left.

&lt;b&gt;What to Call the Two Ways of Storing a Matrix.&lt;/b&gt;

So here, again, are the two ways of storing a matrix.  But using this newfound realization that the coefficients are derivatives, I have a meaningful way to name the two different ways of storing a matrix:

[[Image:deriv-xo.png]]

[[Image:deriv-xi.png]]

In the first storage scheme, the derivatives of Xo are stored first.  In the second storage scheme, the derivatives with respect to Xi are stored first.

&lt;b&gt;What to Call the Two Ways of Printing a Matrix.&lt;/b&gt;

One way to write the four equations above is to write them out using proper mathematical notation.  There are two ways to do this, shown below:

[[Image:matrix-c.png]]

[[Image:matrix-r.png]]

Notice that the two matrices shown above are laid out differently.  The first layout is the appropriate layout for use with column vectors.  The second layout is the appropriate layout for use with row vectors.  So that gives me a possible terminology for the two different ways of typesetting a matrix: the &quot;row-vector-compatible&quot; notation, and the &quot;column-vector-compatible&quot; notation.

&lt;b&gt;The Four Possibilities&lt;/b&gt;

So now, the four possible representations that an engine could use are:

&lt;ol&gt;
&lt;li&gt;Store derivatives of Xo first, typeset in row-vector-compatible notation.&lt;/li&gt;
&lt;li&gt;Store derivatives of Xo first, typeset in column-vector-compatible notation.&lt;/li&gt;
&lt;li&gt;Store derivatives wrt Xi first, typeset in row-vector-compatible notation.&lt;/li&gt;
&lt;li&gt;Store derivatives wrt Xi first, typeset in column-vector-compatible notation.&lt;/li&gt;
&lt;/ol&gt;

&lt;b&gt;The Terms &quot;Column Major&quot; and &quot;Row Major&quot;&lt;/b&gt;

The term &quot;row-major&quot; means &quot;the first four coefficients that you store, are also the first row when you typeset.&quot;  So the four possibilities break down like this:

&lt;ol&gt;
&lt;li&gt;Store derivatives of Xo first, typeset in row-vector-compatible notation  (COLUMN MAJOR)&lt;/li&gt;
&lt;li&gt;Store derivatives of Xo first, typeset in column-vector-compatible notation (ROW MAJOR)&lt;/li&gt;
&lt;li&gt;Store derivatives wrt Xi first, typeset in row-vector-compatible notation (ROW MAJOR)&lt;/li&gt;
&lt;li&gt;Store derivatives wrt Xi first, typeset in column-vector-compatible notation  (COLUMN MAJOR)&lt;/li&gt;
&lt;/ol&gt;

That makes the terms &quot;row major&quot; and &quot;column major&quot; singularly useless, in my opinion.  They tell you nothing about the actual storage or typesetting order.

&lt;b&gt;Panda Notation&lt;/b&gt;

Now that I've established my terminology, I can tell you what panda uses.  If you examine the panda source code, in the method &quot;LMatrix4f::xform,&quot; you will find the four transform equations.  I have simplified them somewhat (ie, removed some of the C++ quirks) in order to put them here:

&lt;pre class=&quot;codeblock&quot;&gt;
define VECTOR4_MATRIX4_PRODUCT(output, input, M)  \
output._0 = input._0*M._00 + input._1*M._10 + input._2*M._20 + input._3*M._30;  \
output._1 = input._0*M._01 + input._1*M._11 + input._2*M._21 + input._3*M._31;  \
output._2 = input._0*M._02 + input._1*M._12 + input._2*M._22 + input._3*M._32;  \
output._3 = input._0*M._03 + input._1*M._13 + input._2*M._23 + input._3*M._33;
&lt;/pre&gt;

Then, if you look in the corresponding header file for matrices, you will see the matrix class definition:

&lt;pre class=&quot;codeblock&quot;&gt;
struct {
  FLOATTYPE  _00, _01, _02, _03;
  FLOATTYPE  _10, _11, _12, _13;
  FLOATTYPE  _20, _21, _22, _23;
  FLOATTYPE  _30, _31, _32, _33;
} m;
&lt;/pre&gt;

So this class definition shows not only how the coefficients of the four equations are stored, but also the layout in which they were intended to be typeset.  So from this, you can see that panda stores derivatives wrt Xi first, and it typesets in row-vector-compatible notation.

&lt;b&gt;Interoperability with OpenGL and DirectX&lt;/b&gt;

Panda is code-compatible with both OpenGL and DirectX.  All three use the same storage format: derivatives wrt Xi first.  You can pass a panda matrix directly to OpenGL's &quot;glLoadMatrixf&quot; or DirectX's &quot;SetTransform&quot;.

However, remember that typesetting format and data storage format are &lt;i&gt;independent choices&lt;/i&gt;.  Even though two engines are interoperable at the code level (because their data storage formats match), their manuals might disagree with each other (because their typesetting formats do not match).

The panda typesetting conventions and the OpenGL typesetting conventions are opposite from each other.  The OpenGL manuals use a column-vector-compatible notation.  The Panda manuals use a row-vector-compatible notation.

DirectX uses the same conventions as Panda for both typesetting and memory storage: row vectors on the left, row major storage with the translation in the bottom row.</text>
    </revision>
  </page>
  <page>
    <title>Measuring Performance with PStats</title>
    <ns>0</ns>
    <id>1064</id>
      <sha1>fa38mtei5auh4f8tfylrnu8vq2aonx6</sha1>
    <revision>
      <id>60513</id>
      <timestamp>2015-06-13T17:47:18Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <text xml:space="preserve" bytes="23119">&lt;h2&gt;QUICK INTRODUCTION&lt;/h2&gt;

PStats is Panda's built-in performance analysis tool.  It can graph
frame rate over time, and can further graph the work spent within each
frame into user-defined subdivisions of the frame (for instance, app,
cull and draw), and thus can be an invaluable tool in identifying
performance bottlenecks.  It can also show frame-based data that
reflects any arbitrary quantity other than time intervals, for
instance, texture memory in use or number of vertices drawn.

The performance graphs may be drawn on the same computer that is running the Panda client, or they may be drawn on another computer on
the same LAN, which is useful for analyzing fullscreen applications.
The remote computer need not be running the same operating system as
the client computer.

To use PStats, you first need to build the PStats server program,
which is part of the Pandatool tree (it's called pstats.exe on
Windows, and pstats on a Unix platform).  Start by running the
PStats server program (it runs in the background), and then start your
Direct/Panda client with the following in your [python]Config.prc file:

&lt;code prc&gt;want-pstats 1&lt;/code&gt;

Or, at runtime, issue the Python command:

&lt;code python&gt;PStatClient.connect()&lt;/code&gt;

[/python][cxx]startup code:

&lt;code cxx&gt;
// Includes: pStatClient.h

if (PStatClient::is_connected()) {
  PStatClient::disconnect();
}

string host = &quot;&quot;; // Empty = default config var value
int port = -1; // -1 = default config var value
if (!PStatClient::connect(host, port)) {
  std::cout &lt;&lt; &quot;Could not connect to PStat server.&quot; &lt;&lt; std::endl;
}
&lt;/code&gt;

[/cxx]

Or if you're running pview, press shift-S.

Any of the above will contact your running PStats server program,
which will proceed to open a window and start a running graph of your
client's performance.  

If you have multiple computers available for development, it can be advantageous to run the pstats server on a separate computer so that the processing time needed to maintain and update the pstats user interface isn't taken from the program you are profiling. If you wish to run the server on a different machine than the client, start the server on the profiling machine and add the following variable to your client's Config.prc file, naming the hostname or IP address of the profiling machine:

&lt;code prc&gt;pstats-host profiling-machine-ip-or-hostname&lt;/code&gt;

If you are developing Python code, you may be interested in reporting
the relative time spent within each Python task (by subdividing the
total time spent in Python, as reported under &quot;Show Code&quot;).  To do
this, add the following lines to your Config.prc file before you start
ShowBase:

&lt;code prc&gt;
task-timer-verbose 1
pstats-tasks 1
&lt;/code&gt;

&lt;h3&gt;Caveats&lt;/h3&gt;

OpenGL is asynchronous, which means that function calls aren't guaranteed to execute right away.  This can make performance analysis of OpenGL operations difficult, as the graphs may not accurately reflect the actual time that the GPU spends doing a certain operation.  However, if you wish to more accurately track down rendering bottlenecks, you may set the following configuration variable:

&lt;code prc&gt;
pstats-gpu-timing 1
&lt;/code&gt;

This will enable a new set of graphs that use timer queries to measure how much time each task is actually taking on the GPU.

If your card does not support it or does not give reliable timer query information, a crude way of working around this and getting more accurate timing breakdown, you can set this:

&lt;code prc&gt;
gl-finish 1
&lt;/code&gt;

Setting this option forces Panda to call glFinish() after every major graphics operation, which blocks until all graphics commands sent to the graphics processor have finished executing. This is likely to slow down rendering performance substantially, but it will make PStats graphs more accurately reflect where the graphics bottlenecks are.

&lt;h2&gt;THE PSTATS SERVER (The user interface)&lt;/h2&gt;

The GUI for managing the graphs and drilling down to view more detail
is entirely controlled by the PStats server program.  At the time of
this writing, there are two different versions of the PStats server,
one for Unix and one for Windows, both called simply
pstats.  The interfaces are similar but not identical; the following
paragraphs describe the Windows version.

When you run pstats.exe, it adds a program to the taskbar but does not
immediately open a window.  The program name is typically &quot;PStats
5185&quot;, showing the default PStats TCP port number of 5185; see &quot;HOW IT
WORKS&quot; below for more details about the TCP communication system.  For
the most part you don't need to worry about the port number, as long
as server and client agree (and the port is not already being used by
another application).

Each time a client connects to the PStats server, a new monitor window
is created.  This monitor window owns all of the graphs that you
create to view the performance data from that particular connection.
Initially, a strip chart showing the frame time of the main thread is
created by default; you can create additional graphs by selecting from
the Graphs pulldown menu.

&lt;h3&gt;Time-based Strip Charts&lt;/h3&gt;

This is the graph type you will use most frequently to examine
performance data.  The horizontal axis represents the passage of time;
each frame is represented as a vertical slice on the graph.  The
overall height of the colored bands represents the total amount of
time spent on each frame; within the frame, the time is further
divided into the primary subdivisions represented by different color
bands (and labeled on the left).  These subdivisions are called
&quot;collectors&quot; in the PStats terminology, since they represent time
collected by different tasks.

Normally, the three primary collectors are App, Cull, and Draw, the
three stages of the graphics pipeline.  Atop these three colored
collectors is the label &quot;Frame&quot;, which represents any remaining time
spent in the frame that was not specifically allocated to one of the
three child collectors (normally, there should not be significant time
reported here).

The frame time in milliseconds, averaged over the past three seconds,
is drawn above the upper right corner of the graph.  The labels on the
guide bars on the right are also shown in milliseconds; if you prefer
to think about a target frame rate rather than an elapsed time in
milliseconds, you may find it useful to select &quot;Hz&quot; from the Units
pulldown menu, which changes the time units accordingly.

The running Panda client suggests its target frame rate, as well as
the initial vertical scale of the graph (that is, the height of the
colored bars).  You can change the scale freely by clicking within the
graph itself and dragging the mouse up or down as necessary.  One of
the horizontal guide bars is drawn in a lighter shade of gray; this
one represents the actual target frame rate suggested by the client.
The other, darker, guide bars are drawn automatically at harmonic
subdvisions of the target frame rate.  You can change the target frame
rate with the Config.prc variable pstats-target-frame-rate on the
client.

You can also create any number of user-defined guide bars by dragging
them into the graph from the gray space immediately above or below the
graph.  These are drawn in a dashed blue line.  It is sometimes useful
to place one of these to mark a performance level so it may be
compared to future values (or to alternate configurations).

The primary collectors labeled on the left might themselves be further
subdivided, if the data is provided by the client.  For instance, App
is often divided into Show Code, Animation, and Collisions, where Show
Code is the time spent executing any Python code, Animation is the
time used to compute any animated characters, and Collisions is the
time spent in the collision traverser(s).

To see any of these further breakdowns, double-click on the
corresponding colored label (or on the colored band within the graph
itself).  This narrows the focus of the strip chart from the overall
frame to just the selected collector, which has two advantages.
Firstly, it may be easier to observe the behavior of one particular
collector when it is drawn alone (as opposed to being stacked on top
of some other color bars), and the time in the upper-right corner will
now reflect just the total time spent within just this collector.
Secondly, if there are further breakdowns to this collector, they will
now be shown as further colored bars.  As in the Frame chart, the
topmost label is the name of the parent collector, and any time shown
in this color represents time allocated to the parent collector that
is not accounted for by any of the child collectors.

You can further drill down by double-clicking on any of the new
labels; or double-click on the top label, or the white part of the
graph, to return back up to the previous level.

&lt;h3&gt;Value-based Strip Charts&lt;/h3&gt;

There are other strip charts you may create, which show arbitrary
kinds of data per frame other than elapsed time.  These can only be
accessed from the Graphs pulldown menu, and include things such as
texture memory in use and vertices drawn.  They behave similarly to
the time-based strip charts described above.

&lt;h3&gt;Piano Roll Charts&lt;/h3&gt;

This graph is used less frequently, but when it is needed it is a
valuable tool to reveal exactly how the time is spent within a frame.
The PStats server automatically collects together all the time spent
within each collector and shows it as a single total, but in reality
it may not all have been spent in one continuous block of time.

For instance, when Panda draws each display region in single-threaded
mode, it performs a cull traversal followed by a draw traversal for
each display region.  Thus, if your Panda client includes multiple
display regions, it will alternate its time spent culling and drawing
as it processes each of them.  The strip chart, however, reports only
the total cull time and draw time spent.

Sometimes you really need to know the sequence of events in the frame,
not just the total time spent in each collector.  The piano roll chart
shows this kind of data.  It is so named because it is similar to the
paper music roll for an old-style player piano, with holes punched
down the roll for each note that is to be played.  The longer the
hole, the longer the piano key is held down.  (Think of the chart as
rotated 90 degrees from an actual piano roll.  A player piano roll
plays from bottom to top; the piano roll chart reads from left to
right.)

Unlike a strip chart, a piano roll chart does not show trends; the
chart shows only the current frame's data.  The horizontal axis shows
time within the frame, and the individual collectors are stacked up in
an arbitrary ordering along the vertical axis.

The time spent within the frame is drawn from left to right; at any
given time, the collector(s) that are active will be drawn with a
horizontal bar.  You can observe the CPU behavior within a frame by
reading the graph from left to right.  You may find it useful to
select &quot;pause&quot; from the Speed pulldown menu to freeze the graph on
just one frame while you read it.

Note that the piano roll chart shows time spent within the frame on
the horizontal axis, instead of the vertical axis, as it is on the
strip charts.  Thus, the guide bars on the piano roll chart are
vertical lines instead of horizontal lines, and they may be dragged in
from the left or the right sides (instead of from the top or bottom,
as on the strip charts).  Apart from this detail, these are the same
guide bars that appear on the strip charts.

The piano roll chart may be created from the Graphs pulldown menu.

&lt;h3&gt;Additional threads&lt;/h3&gt;

If the panda client has multiple threads that generate PStats data,
the PStats server can open up graphs for these threads as well.  Each
separate thread is considered unrelated to the main thread, and may
have the same or an independent frame rate.  Each separate thread will
be given its own pulldown menu to create graphs associated with that
thread; these auxiliary thread menus will appear on the menu bar
following the Graphs menu.  At the time of this writing, support for
multiple threads within the PStats graph is largely theoretical and
untested.

&lt;h3&gt;Color and Other Optional Collector Properties&lt;/h3&gt;

If you do not specify a color for a particular collector, it will be
assigned a random color at runtime.  At present, the only way to
specify a color is to modify
panda/src/pstatclient/pStatProperties.cxx, and add a line to the table
for your new collector(s).  You can also define additional properties
here such as a suggested initial scale for the graph and, for
non-time-based collectors, a unit name and/or scale factor.  The order
in which these collectors are listed in this table is also relevant;
they will appear in the same order on the graphs.  The first column
should be set to 1 for your new collectors unless you wish them to be
disabled by default.  You must recompile the client (but not the
server) to reflect changes to this table.

&lt;h2&gt;HOW TO DEFINE YOUR OWN COLLECTORS&lt;/h2&gt;

The PStats client code is designed to be generic enough to allow users
to define their own collectors to time any arbitrary blocks of code
(or record additional non-time-based data), from either the C++ or the
Python level.

The general idea is to create a PStatCollector for each separate block
of code you wish to time.  The name which is passed to the
PStatCollector constructor is a unique identifier: all collectors that
share the same name are deemed to be the same collector.

Furthermore, the collector's name can be used to define the
hierarchical relationship of each collector with other existing
collectors.  To do this, prefix the collector's name with the name of
its parent(s), followed by a colon separator.  For instance,
PStatCollector(&quot;Draw:Flip&quot;) defines a collector named &quot;Flip&quot;, which is
a child of the &quot;Draw&quot; collector, defined elsewhere.

You can also define a collector as a child of another collector by
giving the parent collector explicitly followed by the name of the
child collector alone, which is handy for dynamically-defined
collectors.  For instance, PStatCollector(draw, &quot;Flip&quot;) defines the
same collector named above, assuming that draw is the result of the
PStatCollector(&quot;Draw&quot;) constructor.

Once you have a collector, simply bracket the region of code you wish
to time with collector.start() and collector.stop().  It is important
to ensure that each call to start() is matched by exactly one call to
stop().  If you are programming in C++, it is highly recommended that
you use the PStatTimer class to make these calls automatically, which
guarantees the correct pairing; the PStatTimer's constructor calls
start() and its destructor calls stop(), so you may simply define a
PStatTimer object at the beginning of the block of code you wish to
time.  If you are programming in Python, you must call start() and
stop() explicitly.

When you call start() and there was another collector already started,
that previous collector is paused until you call the matching stop()
(at which time the previous collector is resumed).  That is, time is
accumulated only towards the collector indicated by the innermost
start() .. stop() pair.

Time accumulated towards any collector is also counted towards that
collector's parent, as defined in the collector's constructor
(described above).

It is important to understand the difference between collectors nested
implicitly by runtime start/stop invocations, and the static hierarchy
implicit in the collector definition.  Time is accumulated in parent
collectors according to the statically-defined parents of the
innermost active collector only, without regard to the runtime stack
of paused collectors.

For example, suppose you are in the middle of processing the &quot;Draw&quot;
task and have therefore called start() on the &quot;Draw&quot; collector.  While
in the middle of processing this block of code, you call a function
that has its own collector called &quot;Cull:Sort&quot;.  As soon as you start
the new collector, you have paused the &quot;Draw&quot; collector and are now
accumulating time in the &quot;Cull:Sort&quot; collector.  Once this new
collector stops, you will automatically return to accumulating time in
the &quot;Draw&quot; collector.  The time spent within the nested &quot;Cull:Sort&quot;
collector will be counted towards the &quot;Cull&quot; total time, not the
&quot;Draw&quot; total time.

If you wish to collect the time data for functions, a simple decorator pattern can be used below, as below:

&lt;code python&gt;
from panda3d.core import PStatCollector
def pstat(func):
    collectorName = &quot;Debug:%s&quot; % func.__name__
    if hasattr(base, 'custom_collectors'):
        if collectorName in base.custom_collectors.keys():
            pstat = base.custom_collectors[collectorName]
        else:
            base.custom_collectors[collectorName] = PStatCollector(collectorName)
            pstat = base.custom_collectors[collectorName]
    else:
        base.custom_collectors = {}
        base.custom_collectors[collectorName] = PStatCollector(collectorName)
        pstat = base.custom_collectors[collectorName]
    def doPstat(*args, **kargs):
        pstat.start()
        returned = func(*args, **kargs)
        pstat.stop()
        return returned
    doPstat.__name__ = func.__name__
    doPstat.__dict__ = func.__dict__
    doPstat.__doc__ = func.__doc__
    return doPstat
&lt;/code&gt;

To use it, either save the function to a file and import it into the script you wish to debug. Then use it as a decorator on the function you wish to time. A collection named Debug will appear in the Pstats server with the function as its child.

&lt;code python&gt;
from pstat_debug import pstat

@pstat
def myLongRunFunction():
    &quot;&quot;&quot; This function does something long &quot;&quot;&quot;
&lt;/code&gt;

&lt;h2&gt;HOW IT WORKS (What's actually happening)&lt;/h2&gt;

The PStats code is divided into two main parts: the client code and
the server code.

&lt;h3&gt;The PStats Client&lt;/h3&gt;

The client code is in panda/src/pstatclient, and is available to run
in every Panda client unless it is compiled out.  (It will be compiled
out if OPTIMIZE is set to level 4, unless DO_PSTATS is also explicitly
set to non-empty.  It will also be compiled out if NSPR is not
available, since both client and server depend on the NSPR library to
exchange data, even when running the server on the same machine as the
client.)

The client code is designed for minimal runtime overhead when it is
compiled in but not enabled (that is, when the client is not in
contact with a PStats server), as well as when it is enabled (when the
client is in contact with a PStats server).  It is also designed for
zero runtime overhead when it is compiled out.

There is one global PStatClient class object, which manages all of the
communications on the client side.  Each PStatCollector is simply an
index into an array stored within the PStatClient object, although the
interface is intended to hide this detail from the programmer.

Initially, before the PStatClient has established a connection, calls
to start() and stop() simply return immediately.

When you call PStatClient.connect(), the client attempts to contact
the PStatServer via a TCP connection to the hostname and port named in
the pstats-host and pstats-port Config.prc variables, respectively.
(The default hostname and port are localhost and 5185.)  You can also
pass in a specific hostname and/or port to the connect() call.  Upon
successful connection and handshake with the server, the PStatClient
sends a list of the available collectors, along with their names,
colors, and hierarchical relationships, on the TCP channel.

Once connected, each call to start() and stop() adds a collector
number and timestamp to an array maintained by the PStatClient.  At
the end of each frame, the PStatClient boils this array into a
datagram for shipping to the server.  Each start() and stop() event
requires 6 bytes; if the resulting datagram will fit within a UDP
packet (1K bytes, or about 84 start/stop pairs), it is sent via UDP;
otherwise, it is sent on the TCP channel.  (Some fraction of the
packets that are eligible for UDP, from 0% to 100%, may be sent via
TCP instead; you can specify this with the pstats-tcp-ratio Config.prc
variable.)

Also, to prevent flooding the network and/or overwhelming the PStats
server, only so many frames of data will be sent per second.  This
parameter is controlled by the pstats-max-rate Config.prc variable and
is set to 30 by default.  (If the packets are larger than 1K, the max
transmission rate is also automatically reduced further in
proportion.)  If the frame rate is higher than this limit, some frames
will simply not be transmitted.  The server is designed to cope with
missing frames and will assume missing frames are similar to their
neighbors.

The server does all the work of analyzing the data after that.  The
client's next job is simply to clear its array and prepare itself for
the next frame.


&lt;h3&gt;The PStats Server&lt;/h3&gt;

The generic server code is in pandatool/src/pstatserver, and the
GUI-specific server code is in pandatool/src/gtk-stats and
pandatool/src/win-stats, for Unix and Windows, respectively.  (There
is also an OS-independent text-stats subdirectory, which builds a
trivial PStats server that presents a scrolling-text interface.  This
is mainly useful as a proof of technology rather than as a usable
tool.)

The GUI-specific code is the part that manages the interaction with
the user via the creation of windows and the handling of mouse input,
etc.; most of the real work of interpreting the data is done in the
generic code in the pstatserver directory.

The PStatServer owns all of the connections, and interfaces with the
NSPR library to communicate with the clients.  It listens on the
specified port for new connections, using the pstats-port Config.prc
variable to determine the port number (this is the same variable that
specifies the port to the client).  Usually you can leave this at its
default value of 5185, but there may be some cases in which that port
is already in use on a particular machine (for instance, maybe someone
else is running another PStats server on another display of the same
machine).

Once a connection is received, it creates a PStatMonitor class (this
class is specialized for each of the different GUI variants) that
handles all the data for this particular connection.  In the case of
the windows pstats.exe program, each new monitor instance is
represented by a new toplevel window.  Multiple monitors can be
active at once.

The work of digesting the data from the client is performed by the
PStatView class, which analyzes the pattern of start and stop
timestamps, along with the relationship data of the various
collectors, and boils it down into a list of the amount of time spent
in each collector per frame.

Finally, a PStatStripChart or PStatPianoRoll class object defines the
actual graph output of colored lines and bars; the generic versions of
these include virtual functions to do the actual drawing (the GUI
specializations of these redefine these methods to make the
appropriate calls).</text>
    </revision>
  </page>
  <page>
    <title>MeshDrawer</title>
    <ns>0</ns>
    <id>2474</id>
      <sha1>angvkx6z202qgqpo6uyebxdjekzuid5</sha1>
    <revision>
      <id>8026</id>
      <timestamp>2013-05-28T12:27:47Z</timestamp>
      <contributor>
        <username>Pataua101</username>
        <id>665</id>
      </contributor>
      <text xml:space="preserve" bytes="4773">MeshDrawer is a class with which you can draw geometry from [python]python[/python][cxx]c++[/cxx] every frame as fast as possible.  Common cases where you might want to use it include: projectiles such as bullets, trails, and laser beams; and UI elements such as health bars, labels, icons, and motion lines.

You create a MeshDrawer like this:
[python]&lt;code python&gt;
generator = MeshDrawer()
generator.setBudget(1000)
generatorNode = generator.getRoot()
generatorNode.reparentTo(render)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
#include &quot;meshDrawer.h&quot;
...
MeshDrawer generator = MeshDrawer();
generator.set_budget(1000);
NodePath generatorNode = generator.get_root();
generatorNode.reparent_to(window-&gt;get_render());
&lt;/code&gt;[/cxx]
Basically this creates a MeshDrawer that will draw at most 1000 triangles or 500 billboarded quads on screen.  Then it gets the root node inside the MeshDrawer that has the geom that will be morphed into any thing you like.

You might also disable depth write, enable transparency, set two sided, add a texture and re parent the geom to a fixed bin and render without lights.  What this code does is outside the mesh drawer and is done strictly to the node and you probably had to do this to the special FX node's you have any ways.
[python]&lt;code python&gt;
generatorNode.setDepthWrite(False)
generatorNode.setTransparency(True)
generatorNode.setTwoSided(True)
generatorNode.setTexture(loader.loadTexture(&quot;radarplate.png&quot;))
generatorNode.setBin(&quot;fixed&quot;,0)
generatorNode.setLightOff(True)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
generatorNode.set_depth_write(false);
generatorNode.set_transparency(TransparencyAttrib::M_alpha);
generatorNode.set_two_sided(true);
generatorNode.set_texture(TexturePool::load_texture(&quot;radarplate.png&quot;));
generatorNode.set_bin(&quot;fixed&quot;,0);
generatorNode.set_light_off();
&lt;/code&gt;[/cxx]
The MeshDrawer is used in kind of an old style draw loop.  I recommend creating a specific task for MeshDrawer so that you can see how much time it eats up using pstats.  To the begin call you need to pass the render and base.cam so that mesh drawer can figure out correct facing for billboards.  A lot of FX require billboards so it makes sense to precompute some of this facing stuff at the start.
[python]&lt;code python&gt;
def drawtask(taks):
    generator.begin(base.cam,render)
    
    ... your draw code ...    
    
    generator.end()
    return taks.cont
taskMgr.add(drawtask, &quot;meshdrawer task&quot;)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
void drawTask(){
    //you'll need access to the window and the generator
    //call this method in your update or use a task.
    generator.begin(window-&gt;get_camera_group(),window-&gt;get_render());
    
    ... your draw code ...    
    
    generator.end()
}
&lt;/code&gt;[/cxx]
Inside it you can call many different MeshDrawer functions see:[python]
http://www.panda3d.org/reference/1.8.1/python/classpanda3d.core.MeshDrawer.php[/python][cxx]http://www.panda3d.org/reference/1.8.1/cxx/classMeshDrawer.php[/cxx] This is for version 1.8.1

Many of the calls take a frame of Vec4() type.  The frame is the Vec4(x,y,width,height) coordinates inside the texture. Frame of Vec4(0,0,1,1) would be the entire texture while Vec4(0,0,.5.5) would be NW quarter of the texture. Note that the Vec4 coordinates starts counting from the bottom left, counting to the top right. If you had a  16x16 plate, the 15th field in the 11th row would be:  Vec4(14.0/16,5.0/16,1.0/16,1.0/16.)

This is use full to create palletized textures and show only small parts of the texture per billboard.  For instance you might have a images of the entire forest in one texture and only render the trees you want by specifying their UV cords.

MeshDrawer works by using calls similar to Panda3d's animation system and basically creates a buffer of undefined vertices which is then morphed into the shape you specify. Triangles which don't get used are turned into micro (0,0,0) triangles so that they will not be visible. Then those vertices are shipped to the GPU every frame, it's good to keep a low count of triangles in this buffer. This is also why the &lt;b&gt;begin&lt;/b&gt; and &lt;b&gt;end&lt;/b&gt; are needed to mark the vertex as being edited and then submit them back to Panda3d when finished.

You can also take a look at MeshDrawer2D.

It follows a similar pattern as MeshDrawer but has stuff that is useful to draw in 2d. Major differences is that its begin() takes no arguments and it deals mostly with rectangles and borders around them. It also has a setClip function which clips rectangles as they are drawn. This is very useful to draw rectangles that appear to be inside other rectangles and be clipped by their parents. It has only the low level abstraction on which you would have to build your own UI components, or you can take a look at TreeGUI.</text>
    </revision>
  </page>
  <page>
    <title>Mesh Generation</title>
    <ns>0</ns>
    <id>2592</id>
      <sha1>1ji4nnj32cz8dyqnxauj0qu9vuelfg0</sha1>
    <revision>
      <id>7102</id>
      <timestamp>2011-02-06T01:19:15Z</timestamp>
      <contributor>
        <username>NNair</username>
        <id>515</id>
      </contributor>
      <text xml:space="preserve" bytes="1740">&lt;b&gt;Navigation Mesh&lt;/b&gt;

To create a navigation mesh, you need a 3D software such as 3DS Max, Maya or Blender. Please follow the tutorial videos below to understand the process:

&lt;b&gt;Step 1:&lt;/b&gt;

{{#ev:youtube|ACLuXWkpJhU}}

&lt;b&gt;Step 2:&lt;/b&gt;

{{#ev:youtube|Rug0eYBa88M}}



&lt;b&gt;Note:&lt;/b&gt; There are separate versions of the mesh generation tool for &quot;Maya/Max&quot; users and &quot;Blender&quot; users. Make sure you download the correct version.

-----

&lt;b&gt;Maya Users (IMPORTANT)&lt;/b&gt;

Since the egg file produced by Maya uses a different format from 3DSMax, you will need to first convert them into the same format (triangles) by using the following command:
&lt;code&gt;
C:\Panda3D-1.6.2\bin\egg-trans -C -o out.egg in.egg
&lt;/code&gt;
The egg file that is thus generated should be passed to the Mesh Generation Tool.

------

&lt;b&gt;Blender Users (IMPORTANT)&lt;/b&gt;

- Creation of the full and collision meshes is to be done on the x-y plane. This makes it much easier to just get in to Blender and create a mesh since the starting view is a top view of the x-y plane. 

* &lt;b&gt;NOTE :&lt;/b&gt; We advice to make meshes with a scale of 50 or above for best results. It would be wise to make your world based on this scale. Much smaller meshes bug out a bit. 

* &lt;b&gt;NOTE :&lt;/b&gt; To make faces on your plane mesh, use the subdivide utility in Blender in Edit Mode and to delete faces option when you enter Face Selection Mode while you are in Edit Mode. 

-----

&lt;b&gt;PLEASE NOTE :&lt;/b&gt; Download the mesh generators from here :

1. Maya and Max :  

https://sites.google.com/site/etcpandai/download/meshgen_v1.0_exec.zip?attredirects=0&amp;d=1

2. Blender : (source also available in the Open Source section)

https://sites.google.com/site/etcpandai/download/BlenderMeshGen.zip?attredirects=0&amp;d=1</text>
    </revision>
  </page>
  <page>
    <title>Model Export</title>
    <ns>0</ns>
    <id>994</id>
      <sha1>juln72o53kpsncrhklqhdjzv40ghrbt</sha1>
    <revision>
      <id>6474</id>
      <timestamp>2010-01-01T17:28:44Z</timestamp>
      <contributor>
        <username>Nemesis13</username>
        <id>394</id>
      </contributor>
      <comment>clarifying paths</comment>
      <text xml:space="preserve" bytes="896">Panda3D uses a custom file format for its models, called egg.  To create an egg file, you will need to use a modeling program (like 3D Studio Max, Blender or Maya) combined with either an export plugin or a file format converter. You can read more about this process in the following sections. Panda3D also provides a binary file format bam, which is quicker to load.

Both file formats contain:

&lt;ul&gt;
&lt;li&gt;Vertices
&lt;li&gt;Triangles and larger polygons
&lt;li&gt;Joints (aka Bones)
&lt;li&gt;Vertex weights
&lt;li&gt;Texture pathnames (textures are not stored)
&lt;li&gt;Bone-based animation keyframes
&lt;li&gt;Morph targets (aka Blend targets)
&lt;li&gt;Morph animation keyframes
&lt;li&gt;Many control flags
&lt;/ul&gt;


The paths (e.g. for textures) can be either relative (as seen from the egg file) or absolute (full path). See [[Loading Models]] for more info about Panda's Filename Syntax. In most cases the relative path makes more sense.</text>
    </revision>
  </page>
  <page>
    <title>Models and Actors</title>
    <ns>0</ns>
    <id>949</id>
      <sha1>1sr69jpv0mgb244fkfgwje808nyjeym</sha1>
    <revision>
      <id>5706</id>
      <timestamp>2009-03-03T18:12:48Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>corrected</comment>
      <text xml:space="preserve" bytes="3286">&lt;h2&gt;Geometry Basics&lt;/h2&gt;

There are two classes in Panda3D for 3D Geometry: the 'Model', which is 
for non-animated geometry, and the 'Actor', which is for animated geometry.

Note that a geometry is only considered animated if it changes shape.  So
for example, a baseball wouldn't be considered animated: it may fly all
over the place, but it stays a sphere.  A baseball would be a model,
not an actor.

Panda does not distinguish between big stuff and small stuff.  For example,
if a virtual world contains a coffee cup on a table, and the table is in the
middle of a small island, then the coffee cup, the table, and the island are all
models: each is a piece of static non-animated geometry.

Many engines provide tools to create terrain, and store that terrain into heightmap images. Panda3D can generate geometry for kind of heightmap terrains, refer to the [[Terrain]] section for more information. For many simple terrains, though, many people prefer to use a static model rather than a heightmap image.

The following sections of the manual assume that you have a valid egg file which has an animatable
model, and some additional egg files containing animations.
To learn how to convert a model into an egg file see the [[Model Export]] section.

&lt;h2&gt;Panda's Primary File Format&lt;/h2&gt;

In Panda3D, geometry is generally stored in EGG files.  An EGG file can contain:

&lt;ul&gt;
&lt;li&gt;A Model (static geometry)
&lt;li&gt;An Actor (dynamic geometry)
&lt;li&gt;An Animation (to be applied to an actor)
&lt;li&gt;Both an Actor and an Animation.
&lt;/ul&gt;

EGG files are created by exporting models from 3D modeling programs like
Maya, Max, or Blender.  Currently, the support for Maya is very strong,
since the developers of Panda3D mostly use Maya.  The
Max exporter is not very reliable right now.  There is a third-party
exporter for Blender, which is said to be quite good.

It is not recommended to pack both an actor and an animation into an EGG file:
this tends to result in developer confusion.

&lt;h2&gt;Panda's Other File Format&lt;/h2&gt;

The EGG file is optimized for debugging, not speed.  The first time
you load an EGG file, it loads slowly.  However, the second time
you use that same EGG file, it loads fast.

This is possible because Panda3D is quietly translating the EGG file into
a performance-optimized form: the BAM file.  It stores these BAM files in a
directory called the model cache.  When developing a game, this works great:
the only time you notice a delay is if you just created the EGG file
for the first time.  Otherwise, it runs blazing fast.

However, there is one situation where this doesn't work so well: if you
are shipping your game to a customer.  You don't want your customer's first
experience with your game to have delays caused by egg file loading.
In that case, it may make sense to ship BAM files instead of EGG files to
the user.  To do this, you would use a tool like &lt;code&gt;egg2bam&lt;/code&gt; or
&lt;code&gt;packpanda&lt;/code&gt; to convert your EGG files into BAM files manually.

&lt;i&gt;CAUTION:&lt;/i&gt; A BAM file only functions with the one version of Panda3D that
created it!  By contrast, EGG files will work with any version of Panda3D. 
Because of this, is is NOT recommended that you use BAM files for your
day-to-day development.  They should only be used when shipping to
customers.</text>
    </revision>
  </page>
  <page>
    <title>Modifying existing geometry data</title>
    <ns>0</ns>
    <id>1774</id>
      <sha1>e6num4vq2ryzaqka2i1rbqf1fwxmo8c</sha1>
    <revision>
      <id>8022</id>
      <timestamp>2013-05-28T11:59:16Z</timestamp>
      <contributor>
        <username>Pataua101</username>
        <id>665</id>
      </contributor>
      <text xml:space="preserve" bytes="3454">If you want to load a model and operate on its vertices, you can walk
through the vertices as shown in [[Reading existing geometry data|the previous section]], but you should
substitute modifyGeom(), modifyVertexData(), and modifyPrimitive() for
getGeom(), getVertexData(), and getPrimitive(), respectively.  These
calls ensure that, in case the data happens to be shared between
multiple different GeomNodes, you will get your own unique copy to
modify, without inadvertently affecting other nodes.

If you want to modify the vertex data, you have two choices.  The
simplest option is to create a new [[GeomVertexData]] and fill it up with
your new vertex data (as described in [[Creating and filling a GeomVertexData]]), and
then assigning this data to the geom with the call
geom.setVertexData().  You must ensure that you add enough vertices to
the new GeomVertexData to satisfy the GeomPrimitives that reference
it.

Your second choice is to modify the vertex data in-place, by operating
on the existing vertices.  You can do this with a [[More about GeomVertexReader, GeomVertexWriter, and GeomVertexRewriter|GeomVertexWriter]].
For instance, if you want to copy the (X, Y) position of each vertex
to its (U, V) texture coordinate, you could do something like this:

[python]&lt;code python&gt;
texcoord = GeomVertexWriter(vdata, 'texcoord')
vertex = GeomVertexReader(vdata, 'vertex')

while not vertex.isAtEnd():
  v = vertex.getData3f()
  texcoord.setData2f(v[0], v[1])
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
GeomVertexWriter texcoord = GeomVertexWriter(vdata,&quot;texcoord&quot;);
GeomVertexReader vertex = GeomVertexReader(vdata,&quot;vertex&quot;);

while(!vertex.is_at_end()){
  LVector3f v = vertex.get_data3f();
  texcoord.set_data2f(v[0], v[1]);
}
&lt;/code&gt;[/cxx]

&lt;p style=&quot;display: block; text-indent: -2em; padding-left: 2em&quot;&gt;
&lt;b&gt;Important!&lt;/b&gt; When you are simultaneously reading from and writing
to the same GeomVertexData object, you should create all of the
GeomVertexWriters you need before you create any GeomVertexReader.
This is because of Panda's internal referencing-counting mechanism;
creating a GeomVertexWriter may automatically (and transparently)
force a copy of the data in the GeomVertexData, which could invalidate
any GeomVertexReaders you have already created.
&lt;/p&gt;

Writing to a column with a GeomVertexWriter does require that the
GeomVertexData's format already has the appropriate columns to handle
the data you are writing (in the above example, for instance, the
format must already have a 'texcoord' column, or the above code will
fail).  Furthermore, the columns must have the appropriate format.
For instance, if you wanted to upgrade a model's texture coordinates
from 2-D texture coordinates to 3-D texture coordinates, simply
calling texcoord.setData3f(u, v, w) wouldn't change the fact that the
existing texcoord column is a 2-component format; you would just be
trying to stuff a 3-component value into a 2-component column.

If you want to add a new column to a GeomVertexData, or modify the
format of an existing column, you will have to create a new
[[GeomVertexFormat]] that includes the new column (see [[Defining your own GeomVertexFormat]]), and then change the format on the GeomVertexData
via vdata.setFormat(format).  This call will internally adjust all of
the data to match the new format.  (Because of this internal
adjustment, it is important to do this before you create the first
GeomVertexWriter or GeomVertexReader.)</text>
    </revision>
  </page>
  <page>
    <title>More Panda3D Resources</title>
    <ns>0</ns>
    <id>1153</id>
      <sha1>09d346gt5dsg8350g0fbywqwejijz9c</sha1>
    <revision>
      <id>60291</id>
      <timestamp>2014-11-11T10:04:14Z</timestamp>
      <contributor>
        <username>Redgui</username>
        <id>22857</id>
      </contributor>
      <comment>old links</comment>
      <text xml:space="preserve" bytes="2948">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

== Panda3D Related Books ==

{| style=&quot;border: 0px;&quot; border=&quot;0&quot;
|[https://www.packtpub.com/panda3d-16-game-engine-beginners-guide/book https://www.packtpub.com/sites/default/files/imagecache/productview/2725OS_Panda3D%201.jpg]
|[https://www.packtpub.com/panda3d-16-game-engine-beginners-guide/book Panda3D 1.6 Game Engine Beginner's Guide].  This book, written by Dave Mathews, guides the reader through creating a complete game with Panda3D.  It only focuses on Windows users.
|-
|[https://www.packtpub.com/panda3d-17-game-developers-cookbook/book https://www.packtpub.com/sites/default/files/imagecache/productview/2923OS_Panda3D%20game%20developer%E2%80%99s%20cookbook.jpg]
|[https://www.packtpub.com/panda3d-17-game-developers-cookbook/book Panda3D 1.7 Game Developer's Cookbook].  This book, written by Christoph Lang, goes deeper into Panda3D's advanced features by providing a set of recipes with step-by-step instructions.  It is useful for people who want to achieve more advanced rendering effects with Panda3D, or want to extend the engine.  This book is also aimed at Windows users.
|}

== Panda3D Tutorial Series ==

[http://www.mygamefast.com/ MyGameFast].  This tutorial aims to teach you how to make a game with Panda3D within a very short period of time.  Each volume focuses on a particular type of game, and is subdivided into individual issues.  The issues cover individual aspects of the task and are short and to the point.

== Panda3D Specific Resources ==

[http://alice.org/pandagallery/  Alice Gallery]. This site holds many of the models  created for use with [http://alice.org/  Alice] but exported into the .egg format. Be advised though, some of these models may not work properly.

== Python Libraries ==

[http://www.pygame.org/wiki/about Pygame.] GNU LGPL. Pygame is a set of Python modules designed for writing games. It includes Python bindings for SDL. Recommended for joystick support. Sound support is another free alternative to FMOD alongside Panda3D's implementation of OpenAL.

[http://twistedmatrix.com/trac/ Twisted] MIT-style license. An event-driven networking framework.

== Useful Tools ==

[http://www.blender.org Blender.] 3D modeling and animation. Extensible in Python. Very fast user interface. The [http://chicken-export.sourceforge.net/ Chicken] and [https://code.google.com/p/yabee/ YABEE] Egg exporters are available.

[http://www.gimp.org The GIMP.] A very capable free software raster image editor. Useful for converting image formats, creating and editing textures.

[http://audacity.sourceforge.net/ Audacity.] Audacity is free, open source software for recording and editing sounds. It is available for Mac OS X, Microsoft Windows, GNU/Linux, and other operating systems.

[http://www.swig.org/ SWIG.] A software development tool that connects programs written in C and C++ with a variety of high-level programming languages including Python.</text>
    </revision>
  </page>
  <page>
    <title>More Panda Resources</title>
    <ns>0</ns>
    <id>2469</id>
    <redirect title="More Panda3D Resources" />
      <sha1>282oy5haql7o5jv7k2rvujb7fl8q7a1</sha1>
    <revision>
      <id>6630</id>
      <timestamp>2010-02-07T04:44:28Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>[[More Panda Resources]] moved to [[More Panda3D Resources]]: Panda3D is the name of the engine; not Panda.</comment>
      <text xml:space="preserve" bytes="36">#REDIRECT [[More Panda3D Resources]]</text>
    </revision>
  </page>
  <page>
    <title>More about GeomVertexReader, GeomVertexWriter, and GeomVertexRewriter</title>
    <ns>0</ns>
    <id>1775</id>
      <sha1>h4ioq6zonhzausmw8z2sixbz8l2xs2z</sha1>
    <revision>
      <id>7664</id>
      <timestamp>2012-03-08T18:55:02Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="9892">The classes &lt;b&gt;GeomVertexReader&lt;/b&gt; and &lt;b&gt;GeomVertexWriter&lt;/b&gt; together represent
the core interface for reading and writing the numeric data stored
within a [[GeomVertexData]] object.

These two classes work similarly.  Both are designed to get a
temporary pointer to the data for a particular column when they are
constructed, and they increment that pointer as you walk through the
vertices.  Initially, they start at row number 0 (the first vertex in
the table), and after each setData/getData operation, they
automatically increment to the next row (the next vertex).

You construct a GeomVertexReader or GeomVertexWriter with a pointer to the [[GeomVertexData]] object you are operating on, and the name of the column you wish to process, e.g.:

&lt;code python&gt;
color = GeomVertexReader(vdata, 'color')
&lt;/code&gt;

Because the GeomVertexReader and GeomVertexWriter classes only store a
temporary pointer, which might become invalid between frames or even
between different tasks within a frame, these objects should not be
stored in any persistent object.  Instead, they are designed to be
temporary objects that are constructed locally, used immediately to
iterate through a list of vertices, and then released.  If you need to
keep a persistent iterator for your vertex data, to be used over a
long period of time (e.g. over several frames), then you should store
just the GeomVertexData pointer (along with the current vertex index
number if you require this), and construct a temporary
GeomVertexReader/Writer each time you need to access it.

The following methods are available to read and write data in a
column:

&lt;center&gt;&lt;table style=&quot;border-collapse: collapse&quot;&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: center; padding-left: 5pt; padding-right: 5pt&quot;&gt;&lt;b&gt;GeomVertexReader&lt;/b&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center; padding-left: 5pt; padding-right: 5pt&quot;&gt;&lt;b&gt;GeomVertexWriter&lt;/b&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: left; padding-left: 5pt; padding-right: 5pt&quot;&gt;x = getData1f()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: left; padding-left: 5pt; padding-right: 5pt&quot;&gt;setData1f(x)addData1f(x)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: left; padding-left: 5pt; padding-right: 5pt&quot;&gt;v2 = getData2f()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: left; padding-left: 5pt; padding-right: 5pt&quot;&gt;setData2f(x, y)setData2f(v2)addData2f(x, y)addData2f(v2)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: left; padding-left: 5pt; padding-right: 5pt&quot;&gt;v3 = getData3f()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: left; padding-left: 5pt; padding-right: 5pt&quot;&gt;setData3f(x, y, z)setData3f(v3)addData3f(x, y, z)addData3f(v3)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: left; padding-left: 5pt; padding-right: 5pt&quot;&gt;v4 = getData4f()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: left; padding-left: 5pt; padding-right: 5pt&quot;&gt;setData4f(x, y, z, w)setData4f(v4)addData4f(x, y, z, w)addData4f(v4)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: left; padding-left: 5pt; padding-right: 5pt&quot;&gt;x = getData1i()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: left; padding-left: 5pt; padding-right: 5pt&quot;&gt;setData1i(x)addData1i(x)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: left; padding-left: 5pt; padding-right: 5pt&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: left; padding-left: 5pt; padding-right: 5pt&quot;&gt;setData2i(x, y)addData2i(x, y)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: left; padding-left: 5pt; padding-right: 5pt&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: left; padding-left: 5pt; padding-right: 5pt&quot;&gt;setData3i(x, y, z)addData3i(x, y, z)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; border-bottom: 1px solid black; text-align: left; padding-left: 5pt; padding-right: 5pt&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; border-bottom: 1px solid black; text-align: left; padding-left: 5pt; padding-right: 5pt&quot;&gt;setData4i(x, y, z, w)addData4i(x, y, z, w)&lt;/td&gt;
&lt;/tr&gt;

&lt;/table&gt;&lt;/center&gt;

Each of the getData family of functions supported by GeomVertexReader
returns the value of the data in the current column, converted to the
requested type.  The 'f' suffix indicates a floating-point value,
while 'i' indicates an integer value; the digit indicates the number
of components you expect to receive.

For instance, getData2f() always returns a VBase2, regardless of the
type of data actually stored in the column.  If the column contains a
2-component value such as a 2-D texture coordinate, then the returned
value will represent the (U, V) value in that column.  However, if the
column type does not match the requested type, a conversion is quietly
made; for instance, if you call getData2f() but the column actually
contains a 3-D texture coordinate, the third component will be omitted
from the return value, which will still be a VBase2.

Similarly, the setData and addData family of functions supported by
GeomVertexWriter accept a value in the indicated format, and convert
it to whatever format is required by the column.  So if you call
setData3f(), and the column has three components, you will set all
three components with the x, y, z parameters of setData3f(); but if
the column has only two components, only the x, y parameters will be
used to set those two components, and the third parameter will be
ignored.

Certain kinds of numeric conversions are performed automatically,
according to the column's designated contents.  For instance, if you
store a floating-point value into an integer column, the fractional
part of the value is usually truncated.  However, if the column
contents indicates that it represents a color value, then the
floating-point value is automatically scaled from the range
0.0 .. 1.0 into the full numeric range of the column's
integer value.  This allows you to store color components in the range
0.0 .. 1.0, and get the expected result (that is, the value
is scaled into the range 0 .. 255).  A similar conversion
happens when data is read.

There are no getData2i, 3i, or 4i methods available, simply because
Panda does not currently define a multi-component integer value that
can be returned to Python.  Since most multi-component column types
are floating-point, or can be expressed as floating-point, this is not
generally a limitation.

Each GeomVertexReader keeps track of the current read row, which is
initially 0; the current value can be retrieved by getReadRow().  Each
call to a getData function returns the value of the column at the
current read row, and then increments the current read row.  It is an
error to call getData when the read row has reached the end of the
data, but you can call isAtEnd(), which returns true when the reader
has reached the end.  Thus, you can iterate through all the rows of a
vertex table by repeatedly calling getData until isAtEnd() returns
true.

Similarly, each GeomVertexWriter keeps track of the current write row,
which is initially 0, and can be retrieved by getWriteRow().  Each
call to setData or addData stores the given value in the current write
row, and then increments the current write row.  It is an error to
call setData when the write row has reached the end of the data; but
as with the GeomVertexReader, you can call isAtEnd() to determine when
you have reached the end of the data.

The addData family of functions work exactly like the setData
functions, except that addData &lt;em&gt;can&lt;/em&gt; be called when the
GeomVertexWriter has reached its end.  In this case, addData will add
a new row to the table, and then fill in the specified data in that
row (and then increment the current write row).  If addData is called
when the current write row already exists, it behaves exactly the same
as setData.

With either GeomVertexReader or GeomVertexWriter, you can set the
current read or write row at any time with the call setRow().  This
sets the current read row (GeomVertexReader) or current write row
(GeomVertexWriter) to the indicated value; the next call to getData or
setData/addData will then operate on the specified row, and increment
from there.

&lt;h2&gt;GeomVertexRewriter&lt;/h2&gt;

The GeomVertexRewriter class exists as a convenience for code that
needs to alternately read and write the data on a column.
GeomVertexRewriter multiply inherits from GeomVertexReader and
GeomVertexWriter, so it supports the getData family of functions, as
well as the setData and addData family of functions.  It also has both
a current read row and a current write row, which might be different.

Normally, you would use a GeomVertexRewriter to walk through the list
of vertices from the beginning to end, reading and writing as it goes.
For instance, to set all of the Z components of a piece of geometry to
0.0, while preserving the X and Y components, you might write a loop such as:

&lt;code python&gt;
vertex = GeomVertexRewriter(vdata, 'vertex')
while not vertex.isAtEnd():
  v = vertex.getData3f()
  vertex.setData3f(v[0], v[1], 0.0)
&lt;/code&gt;

Note that this example code calls getData3f() and setData3f() exactly
once through each iteration, which increments the current read row and
current write row, respectively; so the current read row and current
write row are kept in sync with each other.

&lt;p style=&quot;display: block; text-indent: -2em; padding-left: 2em&quot;&gt;
&lt;b&gt;Important!&lt;/b&gt; When you are simultaneously reading from and writing
to the same GeomVertexData object, you should create all of the
GeomVertexWriters and GeomVertexRewriters you need before you create
any GeomVertexReader.  This is because of Panda's internal
referencing-counting mechanism; creating a GeomVertexWriter may
automatically (and transparently) force a copy of the data in the
GeomVertexData, which could invalidate any GeomVertexReaders you have
already created.
&lt;/p&gt;</text>
    </revision>
  </page>
  <page>
    <title>More about referencing packages</title>
    <ns>0</ns>
    <id>2408</id>
      <sha1>ljjsh16bn68wc3aqrkh6jxivm9qb7jr</sha1>
    <revision>
      <id>6293</id>
      <timestamp>2009-10-25T21:21:53Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="665">A p3d file may include a reference to one or more packages, which means that those package(s) will be downloaded and installed before the application even begins.  This is specified with the -r parameter to packp3d, or with the requires() call in a pdef file.

It is also possible to download and install one or more packages at runtime, after the application has already started.  To do this, instead of referencing the package with the -r parameter, you can call [[Other appRunner members|base.appRunner.installPackage()]] at runtime, or you can use the [[PackageInstaller|PackageInstaller or DWBPackageInstaller]] class to download and install it asynchronously.</text>
    </revision>
  </page>
  <page>
    <title>Motion Path and Particle Intervals</title>
    <ns>0</ns>
    <id>995</id>
      <sha1>m5mvz3hvmh5s9yvaeqcjkw0ltnayyq7</sha1>
    <revision>
      <id>5969</id>
      <timestamp>2009-07-12T21:14:01Z</timestamp>
      <contributor>
        <username>Chroipahtz</username>
        <id>297</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="736">&lt;h2&gt;MopathInterval&lt;/h2&gt;

Motion paths are an advanced feature of Panda3D, and they are discussed later. Still, motion paths have their own intervals. A motion path interval is much like a function interval in that there are no additional parameters other than the motion path and the NodePath it is affecting.

&lt;code python&gt;
intervalName = MopathInterval(&quot;Motion Path Name&quot;, NodePath, &quot;Interval Name&quot;)
&lt;/code&gt;

Read more about [[Motion Paths]].

&lt;h2&gt;ParticleInterval&lt;/h2&gt;

Particle effects can be run from inside intervals as well:

&lt;code python&gt;
intervalName = ParticleInterval(
    &quot;Particle Effect Name&quot;,
    parent,
    worldRelative = 1,
    loop = 0 or 1,
    duration = myDuration
)
&lt;/code&gt;

Read more about [[Particle Effects]].</text>
    </revision>
  </page>
  <page>
    <title>Motion Paths</title>
    <ns>0</ns>
    <id>996</id>
      <sha1>5hljrxuoopk24krgdm0ni36boo21hzh</sha1>
    <revision>
      <id>5971</id>
      <timestamp>2009-07-14T14:46:26Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>Formatting</comment>
      <text xml:space="preserve" bytes="1149">Motion paths in Panda3D are splines created by a modeler that are then exported to egg files. These egg files are then imported into a program, and various nodes can then use the motion path for complex movement. A viable egg file for a motion path has the “curve” tag.

First, the Mopath and MopathInterval modules must be loaded. While motion paths come with their own play functions, a motion path interval allows for more functionality.

&lt;code python&gt;
from direct.directutil import Mopath
from direct.interval.MopathInterval import *
&lt;/code&gt;

With the modules loaded, the motion path is loaded much like an actor is loaded. A NodePath is created with the knowledge that it will be used for a motion path, and then the file is loaded.

&lt;code python&gt;
myMotionPathName = Mopath.Mopath()
myMotionPathName.loadFile(&quot;File Path&quot;)
&lt;/code&gt;

Finally, the motion path interval may be created, and played like any interval can. The interval requires not only the name of the motion path, but also the NodePath that will be affected by it.

&lt;code python&gt;
myInterval = MopathInterval(myMotionPathName, myNodePath, name = &quot;Name&quot;)
myInterval.start()
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>Mouse Support</title>
    <ns>0</ns>
    <id>997</id>
      <sha1>oe7nsqfo7727s4v9q8r18i4j65qk0bb</sha1>
    <revision>
      <id>60489</id>
      <timestamp>2015-05-07T22:27:10Z</timestamp>
      <contributor>
        <username>Eswartz</username>
        <id>22863</id>
      </contributor>
      <comment>Switch to &lt;syntaxhighlight&gt;</comment>
      <text xml:space="preserve" bytes="11045">Panda3D has mouse support built in.
[python]
In Python, the default action of the mouse is to control the camera. If you want to disable this functionality you can use the command:

&lt;syntaxhighlight lang=&quot;python&quot;&gt;
base.disableMouse()
&lt;/syntaxhighlight&gt;

This function's name is slightly misleading.  It only disables the task that drives the camera around, it doesn't disable the mouse itself. You can still get the position of the mouse, as well as the mouse clicks.

[/python]
[cxx]
In C++, you need to do the following if you want the mouse to control the camera:

&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
window-&gt;setup_trackball();
&lt;/syntaxhighlight&gt;

You don't need to do this to enable the mouse itself, only to enable a task that drives the camera around. You can still get the position of the mouse, as well as the mouse clicks, even if you don't enable this &quot;trackball mode&quot;.
[/cxx]

To get the position:

[python]&lt;syntaxhighlight lang=&quot;python&quot;&gt;
if base.mouseWatcherNode.hasMouse():
  x=base.mouseWatcherNode.getMouseX()
  y=base.mouseWatcherNode.getMouseY()
&lt;/syntaxhighlight&gt;[/python]
[cxx]&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
if (mouseWatcher-&gt;has_mouse()){
  if (window-&gt;get_graphics_window()){
    int x = window-&gt;get_graphics_window()-&gt;get_pointer(0).get_x();
    int y = window-&gt;get_graphics_window()-&gt;get_pointer(0).get_y();
  }
}
&lt;/syntaxhighlight&gt;[/cxx]

The mouse clicks generate &quot;events.&quot; To understand what events are, and how to process them, you will need to read the [[Event Handling]] section.  The names of the events generated are:

&lt;table&gt;
&lt;tr&gt;&lt;td width=100&gt;mouse1&lt;/td&gt;&lt;td&gt;Mouse Button 1 Pressed&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;mouse2&lt;/td&gt;&lt;td&gt;Mouse Button 2 Pressed&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;mouse3&lt;/td&gt;&lt;td&gt;Mouse Button 3 Pressed&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;mouse1-up&lt;/td&gt;&lt;td&gt;Mouse Button 1 Released&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;mouse2-up&lt;/td&gt;&lt;td&gt;Mouse Button 2 Released&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;mouse3-up&lt;/td&gt;&lt;td&gt;Mouse Button 3 Released&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;wheel_up&lt;/td&gt;&lt;td&gt;Mouse Wheel rolled upwards&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;wheel_down&lt;/td&gt;&lt;td&gt;Mouse Wheel rolled downwards&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

If you want to hide the mouse cursor, you want the line: &quot;cursor hidden #t&quot; in your [[Configuring Panda|Config.prc]] or this section of code:

[python]&lt;syntaxhighlight lang=&quot;python&quot;&gt;
from pandac.PandaModules import WindowProperties
props = WindowProperties()
props.setCursorHidden(True) 
base.win.requestProperties(props)
&lt;/syntaxhighlight&gt;[/python]

&lt;b&gt;Re-enabling mouse control&lt;/b&gt;

If you need to re-enable the mouse control of the camera, you have to adjust mouseInterfaceNode to the current camera transformation :
[python]&lt;syntaxhighlight lang=&quot;python&quot;&gt;
mat=Mat4(camera.getMat())
mat.invertInPlace()
base.mouseInterfaceNode.setMat(mat)
base.enableMouse()
&lt;/syntaxhighlight&gt;[/python]

Otherwise the camera would be placed back to the last position when the mouse control was enabled.

&lt;b&gt;Mouse modes&lt;/b&gt;

You may configure the &lt;i&gt;mouse mode&lt;/i&gt;, which controls how the mouse cursor operates in the window.

&lt;b&gt;Absolute mouse mode&lt;/b&gt;

By default, the mouse is in &quot;absolute&quot; mode, meaning the cursor can freely move outside the window.  This mode is typical for desktop applications.  

In a first person game where the mouse controls the camera (&quot;mouselook&quot;), thouh, you usually want the mouse cursor to stay inside the window, so you can get movement events no matter how far the user moves the mouse.

Two other mouse modes can help with this.

&lt;b&gt;Relative mouse mode&lt;/b&gt;

In relative mode, the mouse cursor is kept at the center of the window, and only relative movement events are reported.  

Typically you want to hide the mouse cursor in this case, since otherwise it distractingly &quot;sticks&quot; to the center of the window.

[cxx]
&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
// To set relative mode and hide the cursor:
WindowProperties props = window-&gt;get_graphics_window()-&gt;get_properties();
props.set_cursor_hidden (true);
props.set_mouse_mode (WindowProperties::M_relative);
window-&gt;get_graphics_window()-&gt;request_properties (props);

// To revert to normal mode:
WindowProperties props = window-&gt;get_graphics_window()-&gt;get_properties();
props.set_cursor_hidden (false);
props.set_mouse_mode (WindowProperties::M_absolute);
window-&gt;get_graphics_window()-&gt;request_properties (props);    
&lt;/syntaxhighlight&gt;[/cxx]
[python]&lt;syntaxhighlight lang=&quot;python&quot;&gt;
# To set relative mode and hide the cursor:
props = WindowProperties()
props.setCursorHidden(True)
props.setMouseMode(WindowProperties.M_relative)
self.base.win.requestProperties(props)

# To revert to normal mode:
props = WindowProperties()
props.setCursorHidden(False)
props.setMouseMode(WindowProperties.M_absolute)
self.base.win.requestProperties(props)
&lt;/syntaxhighlight&gt;[/python]

&lt;b&gt;Confined mouse mode&lt;/b&gt;

In Panda3D version 1.9.1 there is a new mode called &quot;confined.&quot;  In this mode, panda will try to use the desktop's native facilities to constrain the mouse to the borders of the window.

This is effectively the same as &quot;absolute&quot; mode, but you can be assured the mouse will remain within the window as long as the mode is in effect and the window remains open.

The mouse will report events continuously, but it will stick to the edges of the window.  So, for a game, this is probably still not desirable.  

To accommodate this, you can schedule a Task to fetch the current mouse position, manually re-center the mouse afterward, and otherwise behave as if the mouse events were generated by the relative mode.  

For example:
[python]&lt;syntaxhighlight lang=&quot;python&quot;&gt;
mw = base.mouseWatcherNode

if mw.hasMouse():
  # get the position, which at center is (0, 0) 
  x, y = mw.getMouseX(), mw.getMouseY()

  # move mouse back to center
  props = base.win.getProperties()
  base.win.movePointer(0, 
            int(props.getXSize() / 2),
            int(props.getYSize() / 2))
  # now, x and y can be considered relative movements
&lt;/syntaxhighlight&gt;[/python]

Of course, the mouse must initially be centered, or else the first event will yield a large &quot;movement&quot; depending where the cursor happened to be at program start.

&lt;b&gt;Validating mouse mode&lt;/b&gt;

Note that not all desktops support relative or confined modes.  Unfortunately, you cannot tell in a portable way if a given mode is supported; also, since the window properties request is asynchronous, you will not be able to immediately detect if it took effect.

The way to test this is to check whether your request was honored, after events have been processed, using [python]TaskManager.doMethodLater()[/python][cxx]TaskManager::doMethodLater()[/cxx].

[python]
For example:

&lt;syntaxhighlight lang=&quot;python&quot;&gt;
def setMouseMode(...):
  ...
  base.win.requestProperties(props)
  base.taskMgr.doMethodLater(0, resolveMouse, &quot;Resolve mouse setting&quot;)
 ...
        
def resolveMouse(task):
    props = self.base.win.getProperties()
       
    actualMode = props.getMouseMode()
    if actualMode != WindowProperties.M_relative:
        # did not get requested mode... perhaps try another.
&lt;/syntaxhighlight&gt;[/python]

&lt;b&gt;Multiple Mice&lt;/b&gt;

If you have multiple mice connected to a single machine, it is possible to get mouse movements and buttons for each individual mouse.  This is called &lt;i&gt;raw mouse input&lt;/i&gt;.  It is really only useful if you are building an arcade machine that has lots of trackballs or spinners.

In order to use raw mouse input, you first need to enable it.  To do so, add the following line to your panda configuration file:

&lt;pre class=&quot;codeblock&quot;&gt;
read-raw-mice #t
&lt;/pre&gt;

This causes the panda main window to be created with the &quot;raw_mice&quot; window property.  That window property, in turn, causes the window to track and store the positions and buttons of the raw mice.  Then, that data is extracted from the main window by objects of class MouseWatcher.  The application program can fetch the mouse data from the MouseWatchers.  The global variable &lt;code&gt;base.pointerWatcherNodes&lt;/code&gt; contains the &lt;code&gt;MouseWatcher&lt;/code&gt;s.

The first MouseWatcher on the list always represents the system mouse pointer - a virtual mouse that moves around whenever any of the physical mice do.  Usually, you do not want to use this virtual mouse.  If you're accessing raw mice, you usually want to access the real, physical mice.  The list &lt;code&gt;base.pointerWatcherNodes&lt;/code&gt; always contains the virtual system mouse first, followed by all the physical mice.

So to print out the positions of the mice, use this:

[python]&lt;syntaxhighlight lang=&quot;python&quot;&gt;
for mouse in base.pointerWatcherNodes:
  print &quot;NAME=&quot;, mouse.getName()
  print &quot;X=&quot;, mouse.getMouseX()
  print &quot;Y=&quot;, mouse.getMouseY()
&lt;/syntaxhighlight&gt;[/python]

Each mouse will have a name-string, which might be something along the lines of &quot;Micrologic High-Precision Gaming Mouse 2.0 #20245/405&quot;.  The name is the only way to tell the various mice apart.  If you have two different mice of different brands, you can easily tell them apart by the names.  If you have two mice of the same make and manufacture, then their names will be very similar, but still unique.  This is not because the mice contain serial numbers, but rather because they are uniquefied based on the USB port into which they are plugged.  That means that if you move a mouse from one USB port to another, it will have a new name.  For all practical purposes, that means that you will need to store a config file that maps mouse name to intended purpose.

Raw mouse buttons generate events.  The event names are similar to the ones for the system mouse, except that they have a &quot;mousedevX&quot; prefix.  Ie, an example event might be &lt;code&gt;mousedev3-mouse1-up&lt;/code&gt;.  In this example, the &quot;mousedev3&quot; specifier means that the mouse sending the event is &lt;code&gt;base.pointerWatcherNode[3]&lt;/code&gt;.

&lt;b&gt;Multiple Mice under Linux&lt;/b&gt;

To use raw mouse input under Linux, the panda program needs to open the device files &lt;i&gt;/dev/input/event*&lt;/i&gt;.  On many Linux distributions, the permission bits are set such that this is not possible.  This is a flaw in these distributions.

It is not a good idea to just change the permission bits.  Doing so introduces a huge security hole in which any logged in user can monitor the mice, the joysticks, and the keyboard --- including any passwords that may be typed.  The correct solution is to change the ownership of the input devices whenever a user sits down at the console. There is a module, pam_console, that does this, but it is now obsoleted, and has been removed from several distros. The [http://fedoraproject.org/wiki/Releases/FeatureRemovePAMConsole Fedora pam_console removal] page states that ACLs set by the HAL should replace pam_console's functionality. Currently, since it does not seem that HAL provides this yet, the best course of action is to make an 'input' group as described on [http://gizmod.wiki.sourceforge.net/HOWTO+-+Setting+Input+Device+Permissions+-+Creating+a+udev+Rule the Gizmod wiki].

If you are building a stand-alone arcade machine that does not allow remote login and probably doesn't even have a net connection, then changing the permission bits isn't going to hurt you.</text>
    </revision>
  </page>
  <page>
    <title>Multi-Channel</title>
    <ns>0</ns>
    <id>1786</id>
      <sha1>avdkc29mm0w81ulvd96gygbt63inyro</sha1>
    <revision>
      <id>7648</id>
      <timestamp>2012-03-08T18:28:08Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <text xml:space="preserve" bytes="250">&lt;h2&gt;Summary&lt;/h2&gt;

To Enable FMOD to use 5.1 Surround Sound uncomment/add the following line in the config.prc file:

&lt;code&gt;
fmod-use-surround-sound true
&lt;/code&gt;

&lt;h2&gt;Incomplete Section&lt;/h2&gt;

Note: this section is incomplete.  It will be updated soon.</text>
    </revision>
  </page>
  <page>
    <title>Multi-Part Actors</title>
    <ns>0</ns>
    <id>2049</id>
      <sha1>ooao8vu53b1dpmtzemlr9masp97oi3y</sha1>
    <revision>
      <id>60224</id>
      <timestamp>2014-07-24T19:53:55Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="4159">It is possible to assemble a character model out of several separate pieces (separate models). If this is the case, then the pieces must contain bones that can be attached to each other. For example, if you have a robot consisting of a set of legs and a swappable torso, and if you want to glue them together at the waist, then the legs model should contain a bone &quot;waist&quot;, and the torso model should also contain a bone &quot;waist&quot;. You can then attach them together: 

&lt;code python&gt;
nodePath = Actor.Actor({
    'legs':'RobotLegs.egg',
    'torso':'RobotTorso1.egg',
  },{'legs':{'dance':'RobotLegs-Dance.egg'},
     'torso':{'dance':'RobotTorso1-Dance.egg'}})
nodePath.attach('torso','legs','waist')
&lt;/code&gt;

Multi-part actors are fairly complicated.  Each part is loaded from a separate egg file, and each part has its own set of animations that are applied to it.  For each animation you want to play, you will need to have a corresponding egg file for each part.

In the Actor constructor, you specify the list of model files with a dictionary of part name to egg file, as shown above.  The list of animation files is more complicated; it's a dictionary of dictionaries.  The outer dictionary maps part names to animation dictionaries.  Each animation dictionary maps animation name to animation egg file for the corresponding part.

Here's another example:

&lt;code python&gt;
myactor = Actor(

    # part dictionary
    {&quot;head&quot;:&quot;char/dogMM/dogMM_Shorts-head-mod&quot;, 
     &quot;torso&quot;:&quot;char/dogMM/dogMM_Shorts-torso-mod&quot;, 
     &quot;legs&quot;:&quot;char/dogMM/dogMM_Shorts-legs-mod&quot;}, 

    # dictionary of anim dictionaries
    {&quot;head&quot;:{&quot;walk&quot;:&quot;char/dogMM/dogMM_Shorts-head-walk&quot;, 
             &quot;run&quot;:&quot;char/dogMM/dogMM_Shorts-head-run&quot;}, 
     &quot;torso&quot;:{&quot;walk&quot;:&quot;char/dogMM/dogMM_Shorts-torso-walk&quot;, 
              &quot;run&quot;:&quot;char/dogMM/dogMM_Shorts-torso-run&quot;}, 
     &quot;legs&quot;:{&quot;walk&quot;:&quot;char/dogMM/dogMM_Shorts-legs-walk&quot;, 
             &quot;run&quot;:&quot;char/dogMM/dogMM_Shorts-legs-run&quot;} 
     })
&lt;/code&gt;

In addition multipart actor parts need to be connected together in a meaningful fashion:

&lt;code python&gt;
myactor.attach(&quot;head&quot;, &quot;torso&quot;, &quot;joint-head&quot;)
myactor.attach(&quot;torso&quot;, &quot;legs&quot;, &quot;joint-hips&quot;)
&lt;/code&gt;

The attach() call names two parts, and reparents the part named by the first parameter onto the part named by the second parameter, at the node named by the third parameter, which should be an exposed joint (that is, a joint in the part named by the second parameter).  You must have already exposed the joint before this call, either with the egg-optchar command line tool, or by calling actor.exposeJoint() at runtime.

After calling attach(), the stacked part will inherit the animation from the attachment joint, by virtue of the scene graph relationship.

&lt;h2&gt;Animation&lt;/h2&gt;

You can animate the parts as normal animations, but you need to supply the partname, like this:
&lt;code python&gt;
myactor.play('Animation Name', 'Part Name')
&lt;/code&gt;

If you want to use AnimControl, as explained in [[Actor Animations|this section]], you must supply the partname as second parameter in getAnimControl():

&lt;code python&gt;
# you can see you just need to call
# actor.getAnimControl('Animation Name','Part Name')
# to get access to the AnimControl of that part.

ac=actor.getAnimControl('Animation Name','Part Name')
ac.isPlaying() #returns a boolean whether the animation is playing or not
ac.getFrame() #returns the current frame number
ac.getFrameRate() #returns the speed of the animation, in frames per second
ac.getFullFframe() #returns a floating-point frame number. Note: This number keeps counting and may exceed the total number of frames.
ac.getFullFrame() #returns an integer frame number. Note: This number keeps counting and may exceed the total number of frames.
ac.getNextFrame() #returns the number of the next frame on the queue.
ac.getNumFrames() #returns the total number of frames
ac.getPlayRate() #returns the playrate. explained further below
ac.loop() #starts playing the animation in a loop
ac.play() #starts playing the animation
ac.pose(frame) #poses at frame frame
ac.setPlayRate(rate) #sets the playrate.  explained further below
ac.stop() #stops the animation
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>Multi-Pass Rendering</title>
    <ns>0</ns>
    <id>1155</id>
      <sha1>l82bxexln0gk3mf0njzuuwpkuhzq65e</sha1>
    <revision>
      <id>58868</id>
      <timestamp>2014-04-16T05:52:25Z</timestamp>
      <contributor>
        <username>Jdfreder</username>
        <id>22272</id>
      </contributor>
      <comment>Clarify base.cam vs base.camera</comment>
      <text xml:space="preserve" bytes="2929">&lt;h2&gt;Multi-Pass Rendering&lt;/h2&gt;

Sometimes you may need to draw the same scene more than once per frame, each view looking different. This is where multi-pass rendering comes into play.


The easiest way to do implement multi-pass rendering is to render offscreen to a separate buffer. You:

# setup a GraphicsBuffer object
# create a camera for it and
# place the camera in the scene.

However, this method assumes you have two independent scene graphs. If you use this method to render the same scene graph, it is only useful for showing the scene from a different camera view. To actually make the scenes have different [[Render Objects|RenderStates]] (i.e. one without lighting, one with lighting) you must also change how each Camera renders the scene.

Each Camera node has a function called &lt;code&gt;setInitialState(state)&lt;/code&gt;. It makes every object in the scene get drawn as if the top node in its scene graph has &lt;code&gt;state&lt;/code&gt; as its [[Render Attributes|RenderState]]. This still means that [[Render Attributes|attributes]] can be changed/overridden after the Camera has been put on a scene.

&lt;code python&gt;
# This makes everything drawn by the default camera use myNodePath's 
# RenderState.  Note:  base.cam is not base.camera.  If you have an 
# reference to base.camera, use base.camera.node().
base.cam.setInitialState(myNodePath.getState())
&lt;/code&gt;

You may, however, want more control over what RenderState gets assigned to each node in the scene. You can do this using the Camera class methods &lt;code&gt;setTagStateKey(key)&lt;/code&gt; and &lt;code&gt;setTagState(value, state)&lt;/code&gt;. For any NodePaths that you want to recieve special treatment you call &lt;code&gt;setTag(key, value)&lt;/code&gt;(See [[Common State Changes]]). Now, anytime the Camera sees a NodePath with a tag named &lt;code&gt;key&lt;/code&gt; the Camera assigns it whatever RenderState is associated with &lt;code&gt;value&lt;/code&gt;.

&lt;code python&gt;
    
# Assume we have Shader instances toon_shader and blur_shader
# and we have a Camera whose NodePath is myCamera

# Create a temporary node in order to create a usable RenderState.
tempnode = NodePath(&quot;temp node&quot;)
tempnode.setShader(toon_shader)
base.cam.setTagStateKey(&quot;Toon Shading&quot;)
base.cam.setTagState(&quot;True&quot;, tempnode.getState())

tempnode = NodePath(&quot;temp node&quot;)
tempnode.setShader(blur_shader)
myCamera.node().setTagStateKey(&quot;Blur Shading&quot;)
myCamera.node().setTagState(&quot;True&quot;, tempnode.getState())

# this makes myNodePath and its children get toonShaded
# when rendered by the default camera
myNodePath.setTag(&quot;Toon Shading&quot;, &quot;True&quot;)
# ....
# now if you want myNodePath to be blurred when seen by myCamera,
# it's as easy as adding a tag
myNodePath.setTag(&quot;Blur Shading&quot;, &quot;True&quot;)
&lt;/code&gt;

For a full guide about Multi-Pass rendering in Panda3D, please read the [http://panda3d.cvs.sourceforge.net/*checkout*/panda3d/panda/src/doc/howto.use_multipass.txt Howto on Multipass Rendering] of the original Panda3D documentation.</text>
    </revision>
  </page>
  <page>
    <title>Multifiles</title>
    <ns>0</ns>
    <id>2209</id>
      <sha1>dfm26730pvk3x3vg7v5cjctg0h1i7ii</sha1>
    <revision>
      <id>5651</id>
      <timestamp>2008-12-10T20:25:11Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>some typos</comment>
      <text xml:space="preserve" bytes="775">This section describes that Multifiles are, how to use them and patch them.  The multifiles can store multiple resources like models, textures, sounds, shaders, and so on, and Panda can load them from directly from the multifiles without having to unpack them first.

Multifiles can also be used in patching, zipping and encrypting your data. Multifiles are similar to &quot;.egg&quot; for python libraries or .jar files for java platform. Many games employ a similar concept of &quot;data&quot; file such as .upk for Unreal Engine and .pak for Quake Engine.

The key to Multifiles is that they are very easy to use.  Almost none of the game loading logic has to change when switching to multifiles except for a few lines at the top to mount some multifiles into the Panda3D virtual file system.</text>
    </revision>
  </page>
  <page>
    <title>Multiple Texture Coordinate Sets</title>
    <ns>0</ns>
    <id>1192</id>
      <sha1>p9d37luq64ph2cy17gtsw2fg1lb3h8q</sha1>
    <revision>
      <id>7771</id>
      <timestamp>2012-06-24T18:42:11Z</timestamp>
      <contributor>
        <username>Eadthem</username>
        <id>561</id>
      </contributor>
      <text xml:space="preserve" bytes="1807">In addition to simple texture transforms, it is also possible to have
more than one set of texture coordinates on a model.  Panda allows you
to define as many different sets of texture coordinates as you like,
and each set can be completely unrelated to all of the others.

When you have &lt;b&gt;multiple texture coordinate sets&lt;/b&gt; (sometimes
called &lt;b&gt;multiple UV sets&lt;/b&gt;) on a model, each set will have its own
name, which is any arbitrary string.  The default texture coordinate
set has no name (its name is the empty string).

Normally, you create multiple texture coordinate sets in the same
modeling package that you use to create the model.  Not all modeling
packages, and not all Panda converters, support multiple texture
coordinates.  In fact, as of the time of this writing, only the
Panda3D 1.1 version (or newer) of the maya2egg converter is known to
convert multiple texture coordinates into Panda.

If you happen to have a model with multiple texture coordinate sets,
you can specify which set a particular texture should use by calling
&lt;code&gt;TextureStage.setTexcoordName(&quot;name&quot;)&lt;/code&gt;.
&lt;br&gt;&lt;br&gt;
&lt;strong&gt;WARNING&lt;/strong&gt;&lt;br&gt;
&lt;code&gt;TextureStage.setTexcoordName(&quot;texcoord.name&quot;)&lt;/code&gt; Will cause the default unnamed texcoord to be used.&lt;br&gt;
&lt;code&gt;TextureStage.setTexcoordName(&quot;name&quot;)&lt;/code&gt; Is correct.&lt;br&gt;
&lt;br&gt;
Remember, a TextureStage is used to apply a texture to a model, and so every
texture will have an associated TextureStage (though most textures
just use the default TextureStage).  If you do not call this method
for a particular TextureStage, the default behavior is to use the
default, unnamed texture coordinate set.

The different TextureStages on a model might share the same texture
coordinate sets, or they might each use a different texture coordinate
set, or any combination.</text>
    </revision>
  </page>
  <page>
    <title>Multitexture Introduction</title>
    <ns>0</ns>
    <id>1178</id>
      <sha1>ebjvjmzt1g48ymyk10m4yam08ofbja6</sha1>
    <revision>
      <id>7635</id>
      <timestamp>2012-03-08T17:57:36Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="3903">Panda3D provides the ability to apply more than one texture image at a time to the polygons of a model.  The textures are applied on top of each other, like coats of paint; very much like the &quot;layers&quot; in a popular photo-paint program.

To layer a second texture on a model, you will have to understand Panda's concept of a &lt;b&gt;TextureStage&lt;/b&gt;.  Think of a TextureStage as a slot to hold a single texture image.  You can have as many different TextureStages as you want in your scene, and each TextureStage might be used on one, several, or all models.

When you apply a texture to a model, for instance with the &lt;code&gt;setTexture()&lt;/code&gt; call, you are actually binding the texture to a particular TextureStage.  If you do not specify a TextureStage to use, Panda assumes you mean the &quot;default&quot; TextureStage object, which is a global pointer which you can access as &lt;code&gt;TextureStage.getDefault()&lt;/code&gt;.

Each TextureStage can hold one texture image for a particular model.  If you assign a texture to a particular TextureStage, and then later (or at a lower node) assign a different texture to the same TextureStage, the new texture completely replaces the old one.  (Within the overall scene, a given TextureStage can be used to hold any number of different textures for different nodes; but it only holds one texture for any one particular node.)

However, you can have as many different TextureStages as you want.  If you create a new TextureStage and use it to assign a second texture to a node, then the node now has both textures assigned to it.

Although there is no limit to the number of TextureStages you assign this way, your graphics card will impose some limit on the number it can render on any one node.  Modern graphics cards will typically have a limit of 4 or 8 textures at once; some older cards can only do 2, and some very old cards have a limit of 1 (only one texture at a time).  You can find out the multitexture limit on your particular card with the call &lt;code&gt;base.win.getGsg().getMaxTextureStages()&lt;/code&gt;.

Remember, however, that this limit only restricts the number of different TextureStages you can have on any one particular node; you can still have as many different TextureStages as you like as long as they are all on different nodes.

Let's revisit the example from [[Simple Texture Replacement]], where we replaced the normal texture on smiley.egg with a new texture image that contains a random color pattern.  This time, instead of assigning the new texture to the default TextureStage, we'll create a new TextureStage for it, so that both textures will still be in effect:

&lt;code python&gt;
smiley = loader.loadModel('smiley.egg')
smiley.reparentTo(render)
tex = loader.loadTexture('maps/noise.rgb')
ts = TextureStage('ts')
smiley.setTexture(ts, tex)
&lt;/code&gt; 

Note that we can create a new TextureStage object on the fly; the only parameter required to the TextureStage parameter is a name, which is significant only to us.  When we pass the TextureStage as the first parameter to &lt;code&gt;setTexture()&lt;/code&gt;, it means to assign the indicated texture to that TextureStage.  Also note that we no longer need to specify an override to the setTexture() call, since we are not overriding the texture specified at the Geom level, but rather we are adding to it.

And the result is this:

[[Image:Multitex smiley noise.png|Description]]

To undo a previous call to add a texture, use:

&lt;pre class=&quot;codeblock&quot;&gt;
smiley.clearTexture(ts)
&lt;/pre&gt; 

passing in the same TextureStage that you used before.  Or, alternatively, you may simply use:

&lt;pre class=&quot;codeblock&quot;&gt;
smiley.clearTexture()
&lt;/pre&gt; 

to remove &lt;i&gt;all&lt;/i&gt; texture specifications that you previously added to the node smiley.  This does not remove the original textures that were on the model when you loaded it; those textures are assigned at a different node level, on the Geom objects that make up the model.</text>
    </revision>
  </page>
  <page>
    <title>Multitexturing</title>
    <ns>0</ns>
    <id>1066</id>
    <redirect title="Multitexture Introduction" />
      <sha1>ngq8lz2j30wducytr9va7jmng2fycrx</sha1>
    <revision>
      <id>4100</id>
      <timestamp>2007-02-15T17:53:20Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>already exists. redirected</comment>
      <text xml:space="preserve" bytes="39">#REDIRECT [[Multitexture Introduction]]</text>
    </revision>
  </page>
  <page>
    <title>Multithreaded Render Pipeline</title>
    <ns>0</ns>
    <id>2649</id>
      <sha1>p4rkjsh21co5ibco9u9wnygw7kij0er</sha1>
    <revision>
      <id>7341</id>
      <timestamp>2011-09-28T20:37:53Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="9444">As of Panda3D version 1.8, Panda supports a multithreaded render pipeline for optimal performance on multiprocessor machines.  If your computer has at least two CPU cores (for instance, because you have a dual-core or quad-core CPU), then you can direct Panda to utilize up to three different CPU cores for rendering the scene, which can lead to a theoretical performance improvement of up to 3 times faster than a simple single-CPU approach.  (In practice, an improvement of 3x is rare; improvements of 1.5x to 2x are far more common.)

This feature isn't enabled all the time, partly because it is still somewhat new and experimental, and partly because it is not always the best idea to enable this feature, depending on your precise needs.

To use this feature successfully, you will need to understand something about how it works.  First, consider Panda's normal, single-threaded render pipeline.  The time spent processing each frame can be subdivided into three separate phases, called &quot;App&quot;, &quot;Cull&quot;, and &quot;Draw&quot;:

[[Image:appculldraw.png]]

In Panda's nomenclature, &quot;App&quot; is any time spent in the application yourself, i.e. your program.  This is your main loop, including any Python code (or C++ code) you write to control your particular game's logic.  It also includes any Panda-based calculations that must be performed synchronously with this application code; for instance, the collision traversal is usually considered to be part of App.

&quot;Cull&quot; and &quot;Draw&quot; are the two phases of Panda's main rendering engine.  Once your application code finishes executing for the frame, then Cull takes over.  The name &quot;Cull&quot; implies view-frustum culling, and this is part of it; but it is also much more.  This phase includes all processing of the scene graph needed to identify the objects that are going to be rendered this frame and their current state, and all processing needed to place them into an ordered list for drawing.  Cull typically also includes the time to compute character animations.  The output of Cull is a sorted list of objects and their associated states to be sent to the graphics card.

&quot;Draw&quot; is the final phase of the rendering process, which is nothing more than walking through the list of objects output by Cull, and sending them one at a time to the graphics card.  Draw is designed to be as lightweight as possible on the CPU; the idea is to keep the graphics command pipe filled with as many rendering commands as it will hold.  Draw is the only phase of the process during which graphics commands are actually being issued.

You can see the actual time spent within these three phases if you inspect your program's execution via the PStats tool.  Every application is different, of course, but in many moderately complex applications, the time spent in each of these three phases is similar to the others, so that the three phases roughly divide the total frame time into thirds.

Now that we have the frame time divided into three more-or-less equal pieces, the threaded pipeline code can take effect, by splitting each phase into a different thread, so that it can run (potentially) on a different CPU, like this:

[[Image:app_cull_draw.png]]

Note that App remains on the first, or main thread; we have only moved Cull and Draw onto separate threads.  This is important, because it means that all of your application code can continue to be single-threaded (and therefore much easier and faster to develop).  Of course, there's also nothing preventing you from using additional threads in App if you wish (and if you have enough additional CPU's to make it worthwhile).

If separating the phases onto different threads were all that we did, we wouldn't have accomplished anything useful, because each phase must still wait for the previous phase to complete before it can proceed.  It's impossible to run Cull to figure out what things are going to be rendered before the App phase has finished arranging the scene graph properly.  Similarly, it's impossible to run Draw until the Cull phase has finished processing the scene graph and constructing the list of objects.

However, once App has finished processing frame 1, there's no reason for that thread to sit around waiting for the rest of the frame to be finished drawing.  It can go right ahead and start working on frame 2, at the same time that the Cull thread starts processing frame 1.  And then by the time Cull has finished processing frame 1, it can start working on culling frame 2 (which App has also just finished with).  Putting it all in graphical form, the frame time now looks like this:

[[Image:full_pipeline.png]]

So, we see that we can now crank out frames up to three times faster than in the original, single-threaded case.  Each frame now takes the same amount of time, total, as the longest of the original three phases.  (Thus, the theoretical maximum speedup of 3x can only be achieved in practice if all three phases are exactly equal in length.)

It's worth pointing out that the only thing we have improved here is frame *throughput*--the total number of frames per second that the system can render.  This approach does nothing to improve frame *latency*, or the total time that elapses between the time some change happens in the game, and the time it appears onscreen.  This might be one reason to avoid this approach, if latency is more important than throughput.  However, we're still talking about a total latency that's usually less than 100ms or so, which is faster than human response time anyway; and most applications (including games) can tolerate a small amount of latency like this in exchange for a smooth, fast frame rate.

In order for all of this to work, Panda has to do some clever tricks behind the scenes.  The most important trick is that there need to be three different copies of the scene graph in different states of modification.  As your App process is moving nodes around for frame 3, for instance, Cull is still analyzing frame 2, and must be able to analyze the scene graph *before* anything in App started mucking around to make frame 3.  So there needs to be a complete copy of the scene graph saved as of the end of App's frame 2.  Panda does a pretty good job of doing this efficiently, relying on the fact that most things are the same from one frame to the next; but still there is some overhead to all this, so the total performance gain is always somewhat less than the theoretical 3x speedup.  In particular, if the application is already running fast (60fps or above), then the gain from parallelization is likely to be dwarfed by the additional overhead requirements.  And, of course, if your application is very one-sided, such that almost all of its time is spent in App (or, conversely, almost all of its time is spent in Draw), then you will not see much benefit from this trick.

Also, note that it is no longer possible for anything in App to contact the graphics card directly; while App is running, the graphics card is being sent the drawing commands from two frames ago, and you can't reliably interrupt this without taking a big performance hit.  So this means that OpenGL callbacks and the like have to be sensitive to the threaded nature of the graphics pipeline.  (This is why Panda's interface to the graphics window requires an indirect call: base.win.requestProperties(), rather than base.win.setProperties().  It's necessary because the property-change request must be handled by the draw thread.)

==Enabling the Multithreaded Render Pipeline==

To enable this feature, simply set the following variable in your Config.prc file:

&lt;code&gt;
threading-model Cull/Draw
&lt;/code&gt;

The names &quot;Cull&quot; and &quot;Draw&quot; in the above are used as the names of the threads that serve Cull and Draw, respectively.  It doesn't matter what you call them; the name before the slash will be the name of the thread that performs Cull, and the name following the slash will be the name of the thread that performs Draw.  (So setting this to Draw/Cull will not reverse the phases, but will instead just give your two threads very misleading and confusing names.)

The above string defines a different thread for each of App, Cull, and Draw.  You can also assign these three phases to threads in different ways:

&lt;code&gt;
threading-model /Draw
&lt;/code&gt;

Creates a two-thread model: assigns App and Cull together on the main thread, and puts Draw on its own thread.  This is most appropriate when the total amount of time for App + Cull in your application is similar to the total amount of time for Draw.

&lt;code&gt;
threading-model Cull/Cull&lt;br&gt;
threading-model Cull
&lt;/code&gt;

These two are equivalent and create a different two-thread model: App is on its own thread, and Cull and Draw are together on a separate thread.  This is most appropriate when the total amount of time for App in your application is similar to the total amount of time for Cull + Draw.

More generally, the threading model defines the names of the two threads that serve Cull and Draw.  A slash separates the two phases.  If the thread name for either phase is the empty string, then the name is understood to be the same name as the previous phase (or the App phase for the first one).  If two threads have the same name, they refer to the same thread, so &quot;Cull/Cull&quot; means to place both Cull and Draw on the same thread, named &quot;Cull&quot;.  The specific name is irrelevant; it could have been called &quot;Foo/Foo&quot; just as easily.</text>
    </revision>
  </page>
  <page>
    <title>Networking</title>
    <ns>0</ns>
    <id>1081</id>
      <sha1>h5o8ff3yeucra96ginbcpkj2h9vakta</sha1>
    <revision>
      <id>5685</id>
      <timestamp>2009-01-18T01:32:59Z</timestamp>
      <contributor>
        <username>TutTut89</username>
        <id>211</id>
      </contributor>
      <minor/>
      <comment>&quot;general&quot; was missing the &quot;r&quot;</comment>
      <text xml:space="preserve" bytes="398">Panda3D contains support for networked games.  This includes both a low-level stream based API, and a higher level distributed object API. The documentation in this section assumes some familiarity with the basic concepts of networking in general, and the IP protocol in particular. 

The documentation on these features is still in development. Read the forums for the most up-to-date information.</text>
    </revision>
  </page>
  <page>
    <title>NodePath</title>
    <ns>0</ns>
    <id>2250</id>
    <redirect title="The Scene Graph" />
      <sha1>2bzfp3zmf61rwkbz0docndz38qi1vyl</sha1>
    <revision>
      <id>5339</id>
      <timestamp>2008-04-07T18:31:21Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[The Scene Graph]]</comment>
      <text xml:space="preserve" bytes="29">#REDIRECT [[The Scene Graph]]</text>
    </revision>
  </page>
  <page>
    <title>NodePaths</title>
    <ns>0</ns>
    <id>942</id>
      <sha1>g99gb3o0rsefqdsj99xymtmzbcgc516</sha1>
    <revision>
      <id>4117</id>
      <timestamp>2007-02-17T13:42:55Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="26">This is a deprecated page.</text>
    </revision>
  </page>
  <page>
    <title>Node Paths</title>
    <ns>0</ns>
    <id>2063</id>
    <redirect title="NodePaths" />
      <sha1>jx15pwjnib4s8nme5gr75y2dnmzs6d2</sha1>
    <revision>
      <id>4102</id>
      <timestamp>2007-02-15T17:55:57Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>[[Node Paths]] moved to [[NodePaths]]: it's without a whitespace.</comment>
      <text xml:space="preserve" bytes="23">#REDIRECT [[NodePaths]]</text>
    </revision>
  </page>
  <page>
    <title>Notes and caveats</title>
    <ns>0</ns>
    <id>1782</id>
      <sha1>f6x7dgygzrdgukzw04hivbcd6y7edtc</sha1>
    <revision>
      <id>3482</id>
      <timestamp>2006-09-17T16:28:06Z</timestamp>
      <contributor>
        <username>Fixer</username>
        <id>52</id>
      </contributor>
      <comment>Listed some caveats and concerns when using the physics system</comment>
      <text xml:space="preserve" bytes="1223">Here are some caveats, quirks, and behaviors to be aware of when working with the physics engine:

&lt;ol&gt;
&lt;li&gt; You can add the same force to an object multiple times with repeated calls to addLinearForce or addAngularForce. The result will be that the total effect will be the effect of the force applied once times the number of times it is applied. Note, however, that to remove the force's effect on the object, you must call remove*Force the same number of times add*Force was called; each call to remove only removes one instance of the force. Of course, it is more efficient to use a single force with magnitude (n x # of copies) than to use the same force multiple times.&lt;br&gt;
&lt;br&gt;
&lt;li&gt;If a NodePath that is controlled by an ActorNode also needs collision calculations done upon it, be sure to use the PhysicsCollisionHandler instead of CollisionHandlerPusher. More info can be found in the section on [[Collision Handlers]]. If you intend to use a PhysicsCollisionHandler to prevent a model from falling through a floor (for example, if the scene has gravity applied), be sure to look at the friction coefficient options on the [http://panda3d.org/apiref.php?page=PhysicsCollisionHandler PhyicsCollisionHandler].
&lt;/ol&gt;</text>
    </revision>
  </page>
  <page>
    <title>Obstacle Avoidance</title>
    <ns>0</ns>
    <id>2588</id>
      <sha1>ag3n8a06yw3fa8ar4uxe7nb16bj6gds</sha1>
    <revision>
      <id>7705</id>
      <timestamp>2012-03-09T10:30:04Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>new import system</comment>
      <text xml:space="preserve" bytes="5093">&lt;b&gt;'Obstacle Avoidance'&lt;/b&gt; is a behavior where an AI Character steers away from obstacles in its path.


{{#ev:youtube|xZnuWRiKL6I}}


-----

In PandAI, obstacle avoidance is defined as :
&lt;code python&gt;
aiBehaviors.obstacleAvoidance(float feeler_length)
&lt;/code&gt;

&lt;b&gt;Feeler length&lt;/b&gt; is the range at which the obstacle can be detected by the AI Character 

(&lt;b&gt;Note&lt;/b&gt; : This does not correspond to actual length in render. The algorithm computes the feeler’s length based on AI Character’s speed and size and also the Obstacle size and the feeler length which is input to it simply a multiplier)

------

&lt;b&gt;For the algorithm to work, the obstacles need to be added to the world like this :&lt;/b&gt;
&lt;code python&gt;
aiWorld.addObstacle(NodePath  obstacle)
&lt;/code&gt;

&lt;b&gt;Also you can remove an obstacle at any time needed by using&lt;/b&gt;
&lt;code python&gt;
aiWorld.removeObstacle(NodePath obstacle)
&lt;/code&gt;

-----

&lt;b&gt;The full working code in Panda3D is :&lt;/b&gt;

&lt;code python&gt;
import direct.directbase.DirectStart
from panda3d.core import *
from direct.showbase.DirectObject import DirectObject
from direct.task import Task
from direct.actor.Actor import Actor
#for Pandai
from panda3d.ai import *
#for Onscreen GUI
from direct.gui.OnscreenText import OnscreenText

# Globals
speed = 0.75

# Function to put instructions on the screen.
font = loader.loadFont(&quot;cmss12&quot;)
def addInstructions(pos, msg):
    return OnscreenText(text=msg, style=1, fg=(1,1,1,1), font = font,
                        pos=(-1.3, pos), align=TextNode.ALeft, scale = .05)

class World(DirectObject):

    def __init__(self):
        base.disableMouse()
        base.cam.setPosHpr(0,0,55,0,-90,0)
        
        self.loadModels()
        self.setAI()
        self.setMovement()

    def loadModels(self):
        # Seeker
        ralphStartPos = Vec3(-10, 0, 0)
        self.pursuer = Actor(&quot;models/ralph&quot;,
                                 {&quot;run&quot;:&quot;models/ralph-run&quot;})
        self.pursuer.reparentTo(render)
        self.pursuer.setScale(0.5)
        self.pursuer.setPos(ralphStartPos)
        # Target
        self.target = loader.loadModel(&quot;models/arrow&quot;)
        self.target.setColor(1,0,0)
        self.target.setPos(5,0,0)
        self.target.setScale(1)
        self.target.reparentTo(render)
        # Obstacle 1
        self.obstacle1 = loader.loadModel(&quot;models/arrow&quot;)
        self.obstacle1.setColor(0,0,1)
        self.obstacle1.setPos(2,0,0)
        self.obstacle1.setScale(1)
        self.obstacle1.reparentTo(render)
        # Obstacle 2
        self.obstacle2 = loader.loadModel(&quot;models/arrow&quot;)
        self.obstacle2.setColor(0,0,1)
        self.obstacle2.setPos(5,5,0)
        self.obstacle2.setScale(1)
        self.obstacle2.reparentTo(render)        
        
        self.pursuer.loop(&quot;run&quot;)
      
    def setAI(self):
        #Creating AI World
        self.AIworld = AIWorld(render)
 
        self.AIchar = AICharacter(&quot;pursuer&quot;,self.pursuer, 100, 0.05, 5)
        self.AIworld.addAiChar(self.AIchar)
        self.AIbehaviors = self.AIchar.getAiBehaviors()
        
        self.AIbehaviors.pursue(self.target)
        
        # Obstacle avoidance
        self.AIbehaviors.obstacleAvoidance(1.0)
        self.AIworld.addObstacle(self.obstacle1)
        self.AIworld.addObstacle(self.obstacle2)

        #AI World update        
        taskMgr.add(self.AIUpdate,&quot;AIUpdate&quot;)
        
    #to update the AIWorld    
    def AIUpdate(self,task):
        self.AIworld.update()            
        return Task.cont

    #All the movement functions for the Target
    def setMovement(self):
        self.keyMap = {&quot;left&quot;:0, &quot;right&quot;:0, &quot;up&quot;:0, &quot;down&quot;:0}
        self.accept(&quot;arrow_left&quot;, self.setKey, [&quot;left&quot;,1])
        self.accept(&quot;arrow_right&quot;, self.setKey, [&quot;right&quot;,1])
        self.accept(&quot;arrow_up&quot;, self.setKey, [&quot;up&quot;,1])
        self.accept(&quot;arrow_down&quot;, self.setKey, [&quot;down&quot;,1])
        self.accept(&quot;arrow_left-up&quot;, self.setKey, [&quot;left&quot;,0])
        self.accept(&quot;arrow_right-up&quot;, self.setKey, [&quot;right&quot;,0])
        self.accept(&quot;arrow_up-up&quot;, self.setKey, [&quot;up&quot;,0])
        self.accept(&quot;arrow_down-up&quot;, self.setKey, [&quot;down&quot;,0])
        #movement task
        taskMgr.add(self.Mover,&quot;Mover&quot;)
        
        addInstructions(0.9, &quot;Use the Arrow keys to move the Red Target&quot;)

    def setKey(self, key, value):
        self.keyMap[key] = value
            
    def Mover(self,task):
        startPos = self.target.getPos()
        if (self.keyMap[&quot;left&quot;]!=0):
                self.target.setPos(startPos + Point3(-speed,0,0))
        if (self.keyMap[&quot;right&quot;]!=0):
                self.target.setPos(startPos + Point3(speed,0,0))
        if (self.keyMap[&quot;up&quot;]!=0):
                self.target.setPos(startPos + Point3(0,speed,0))
        if (self.keyMap[&quot;down&quot;]!=0):
                self.target.setPos(startPos + Point3(0,-speed,0))
                        
        return Task.cont
 
w = World()
run()
&lt;/code&gt;


&lt;b&gt;To get the full working demo, please visit :&lt;/b&gt;

https://sites.google.com/site/etcpandai/documentation/steering-behaviors/obstacle-avoidance/PandAIObstacleAvoidanceExample.zip?attredirects=0&amp;d=1</text>
    </revision>
  </page>
  <page>
    <title>Occlusion Culling</title>
    <ns>0</ns>
    <id>2601</id>
      <sha1>8898qteg3f5sznkeadp3c1nowi4a8jn</sha1>
    <revision>
      <id>7135</id>
      <timestamp>2011-04-18T04:50:26Z</timestamp>
      <contributor>
        <username>Teedee</username>
        <id>449</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="171">Occlusion Culling refers to the process of cutting out (culling) nodes which are hidden behind (occluded by) other nodes, and can be ignored before they ever get rendered.</text>
    </revision>
  </page>
  <page>
    <title>On Linux</title>
    <ns>0</ns>
    <id>2082</id>
    <redirect title="How to build a CXX Panda3D game on Linux" />
      <sha1>ovtft5k5ywkmsa1uumka8a0tsmma69o</sha1>
    <revision>
      <id>4198</id>
      <timestamp>2007-03-10T10:27:14Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>Redirecting to [[How to build a CXX Panda3D game on Linux]]</comment>
      <text xml:space="preserve" bytes="54">#REDIRECT [[How to build a CXX Panda3D game on Linux]]</text>
    </revision>
  </page>
  <page>
    <title>On Windows</title>
    <ns>0</ns>
    <id>2081</id>
    <redirect title="How to build a CXX Panda3D game on Windows" />
      <sha1>b1q84hvvy7gyobuxgsgfn7iw42seth8</sha1>
    <revision>
      <id>4197</id>
      <timestamp>2007-03-10T10:26:50Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>Redirecting to [[How to build a CXX Panda3D game on Windows]]</comment>
      <text xml:space="preserve" bytes="56">#REDIRECT [[How to build a CXX Panda3D game on Windows]]</text>
    </revision>
  </page>
  <page>
    <title>OnscreenImage</title>
    <ns>0</ns>
    <id>2047</id>
      <sha1>9aw3sm194k3yft78a5cf4niyo744qmi</sha1>
    <revision>
      <id>7861</id>
      <timestamp>2013-02-28T13:21:59Z</timestamp>
      <contributor>
        <username>Thaumaturge</username>
        <id>188</id>
      </contributor>
      <text xml:space="preserve" bytes="2276">Just like [[OnscreenText]], you can use OnscreenImage as a quick way to put an image onscreen. Use an OnscreenImage whenever you want a quick way to display an ordinary image without a lot of fancy requirements.

&lt;code python&gt;
from direct.gui.OnscreenImage import OnscreenImage
imageObject = OnscreenImage(image = 'myImage.jpg', pos = (-0.5, 0, 0.02))
&lt;/code&gt;

If you want, you can change the image into another one using setImage():

&lt;code python&gt;
imageObject.setImage('myImage2.jpg')
&lt;/code&gt;

When you want to take the image away, use:

&lt;code python&gt;
imageObject.destroy()
&lt;/code&gt;

The following keyword parameters may be specified to the constructor:

&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;image&lt;/td&gt;&lt;td&gt;the actual geometry to display or a file name. This may be omitted and specified later via setImage() if you don't have it available. &lt;br/&gt;
Note: Omitting this parameter results in the OnscreenImage being created as an empty NodePath, meaning that many NodePath methods (including setPos()) are not valid and should raise assertion errors until an image is specified via setImage().&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;pos&lt;/td&gt;&lt;td&gt;the x, y, z position of the geometry on the screen. This maybe a 3-tuple of floats or a vector. y should be zero&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;scale&lt;/td&gt;&lt;td&gt;the size of the geometry. This may either be a single float, a 3-tuple of floats, or a vector, specifying a different x, y, z scale. y should be 1&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;hpr&lt;/td&gt;&lt;td&gt;the h, p, r of the geometry on the screen. This maybe a 3-tuple of floats or a vector.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;color&lt;/td&gt;&lt;td&gt;the (r, g, b, a) color of the geometry. This is normally a 4-tuple of floats or ints.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;parent&lt;/td&gt;&lt;td&gt;the NodePath to parent the text to initially; the default is aspect2d.&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;

'''NOTE:''' To enable transparency in images, you must first set the TransparencyAttrib, otherwise the transparent parts of the image will be shown black:

&lt;code python&gt;
from panda3d.core import TransparencyAttrib
self.myImage=OnscreenImage(image = 'myImage.png', pos = (0, 0, 0))
self.myImage.setTransparency(TransparencyAttrib.MAlpha)
&lt;/code&gt;

Since GIF's are not supported you should use PNG or TGA if you need transparency.</text>
    </revision>
  </page>
  <page>
    <title>OnscreenText</title>
    <ns>0</ns>
    <id>1123</id>
      <sha1>n335idbcxmxmc28r17slcv2k7bps8n5</sha1>
    <revision>
      <id>6505</id>
      <timestamp>2010-01-05T17:44:10Z</timestamp>
      <contributor>
        <username>Nemesis13</username>
        <id>394</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="3286">The OnscreenText object is a convenience wrapper around [[Text Node|TextNode]].  You can use it as a quick way to put text onscreen without having to go through the trouble of creating a TextNode and setting properties on it.  However, it doesn't have the full range of rendering options that you can get with TextNode directly; and it doesn't support the DirectGUI features of a [[DirectLabel]].  Use an OnscreenText whenever you want a quick way to display some ordinary text without a lot of fancy requirements.

&lt;code python&gt;
from direct.gui.OnscreenText import OnscreenText
textObject = OnscreenText(text = 'my text string', pos = (-0.5, 0.02), scale = 0.07)
&lt;/code&gt;

The OnscreenText object inherits from NodePath, so all of the standard NodePath operations can be used on the text object.  When you are ready to take the text away, use:

&lt;code python&gt;
textObject.destroy()
&lt;/code&gt;

The following keyword parameters may be specified to the constructor:

&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;text&lt;/td&gt;&lt;td&gt;the actual text to display.  This may be omitted and specified later via setText() if you don't have it available, but it is better to specify it up front.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;style&lt;/td&gt;&lt;td&gt;one of the pre-canned style parameters defined at the head of OnscreenText.py.  This sets up the default values for many of the remaining parameters if they are unspecified; however, a parameter may still be specified to explicitly set it, overriding the pre-canned style.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;pos&lt;/td&gt;&lt;td&gt;the x, y position of the text on the screen.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;scale&lt;/td&gt;&lt;td&gt;the size of the text.  This may either be a single float (and it will usually be a small number like 0.07) or it may be a 2-tuple of floats, specifying a different x, y scale.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;fg&lt;/td&gt;&lt;td&gt;the (r, g, b, a) foreground color of the text.  This is normally a 4-tuple of floats or ints.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;bg&lt;/td&gt;&lt;td&gt;the (r, g, b, a) background color of the text.  If the fourth value, a, is nonzero, a card is created to place behind the text and set to the given color.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;shadow&lt;/td&gt;&lt;td&gt;the (r, g, b, a) color of the shadow behind the text. If the fourth value, a, is nonzero, a little drop shadow is created and placed behind the text.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;frame&lt;/td&gt;&lt;td&gt;the (r, g, b, a) color of the frame drawn around the text.  If the fourth value, a, is nonzero, a frame is created around the text.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;align&lt;/td&gt;&lt;td&gt;one of TextNode.ALeft, TextNode.ARight, or TextNode.ACenter.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;wordwrap&lt;/td&gt;&lt;td&gt;either the width to wordwrap the text at, or None to specify no automatic word wrapping.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;font&lt;/td&gt;&lt;td&gt;the font to use for the text.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;parent&lt;/td&gt;&lt;td&gt;the NodePath to parent the text to initially; the default is aspect2d.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td valign=&quot;top&quot;&gt;mayChange&lt;/td&gt;&lt;td&gt;pass true if the text or its properties may need to be changed at runtime, false if it is static once created (which leads to better memory optimization).  The default is false.&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;

[[OnscreenImage]] works similar, but it shows an image on the screen instead of text.</text>
    </revision>
  </page>
  <page>
    <title>Open Source Code</title>
    <ns>0</ns>
    <id>2590</id>
      <sha1>h9wwvdbjf665k7mnksgxw0pvu6mqgmx</sha1>
    <revision>
      <id>7097</id>
      <timestamp>2011-01-31T07:06:28Z</timestamp>
      <contributor>
        <username>NNair</username>
        <id>515</id>
      </contributor>
      <text xml:space="preserve" bytes="910">&lt;b&gt;PandAI is open source and in fact is meant as a learning tool for users wanting to learn AI too.&lt;/b&gt;

This means that the entire source for PandAI, which was written in C++ and the mesh generators for path finding is available here :


-----


&lt;b&gt;Source Codes :&lt;/b&gt;


1. &lt;b&gt;Pandai_v1.0_src.zip&lt;/b&gt;     - This is the entire source code of PandAI + Doxygen documentation.  (Open Source)

https://sites.google.com/site/etcpandai/download/Pandai_v1.0_src.zip?attredirects=0&amp;d=1


2. &lt;b&gt;meshgen_v1.0_src.zip&lt;/b&gt;  - This is the entire source code of the mesh generator for Maya and Max  (Open Source)

https://sites.google.com/site/etcpandai/download/meshgen_v1.0_src.zip?attredirects=0&amp;d=1


3. &lt;b&gt;BlenderMeshGen.zip&lt;/b&gt;   -  This is the python source code for the Blender mesh generator + few samples  (Open Source)

https://sites.google.com/site/etcpandai/download/BlenderMeshGen.zip?attredirects=0&amp;d=1


-----</text>
    </revision>
  </page>
  <page>
    <title>Orthographic Lenses</title>
    <ns>0</ns>
    <id>1163</id>
      <sha1>5lvdrbv0ueb1e0s4aixzc42n6othg1x</sha1>
    <revision>
      <id>6972</id>
      <timestamp>2010-11-30T18:42:20Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <comment>Z -&gt; Y</comment>
      <text xml:space="preserve" bytes="3116">The previous page described the PerspectiveLens class, and the various properties of a perspective lens, especially its field of view.  There is another kind of lens that is frequently used in 3-D rendering, but it doesn't have a field of view in the same sense at all.  This is an &lt;b&gt;orthographic lens&lt;/b&gt;.

[[Image:Lens tutorial orthographic.jpg|Lens tutorial, orthographic lenses]]

In an orthographic lens, there is no perspective--parallel lines viewed by the lens don't converge; instead, they remain absolutely parallel in the image.  While a &lt;code&gt;PerspectiveLens&lt;/code&gt; closely imitates the behavior of a real, physical camera lens, there is no real lens that does what an &lt;code&gt;OrthographicLens&lt;/code&gt; does.  An &lt;code&gt;OrthographicLens&lt;/code&gt;, therefore, is most useful for special effects, where you want that unnatural look, or to emulate the so-called 2½-D look of several popular real-time strategy games, or strictly to render 2-d objects that shouldn't have any perspective anyway.  In fact, the default camera created for the render2d scene graph, which is used to draw all of the onscreen GUI elements in Panda, uses an OrthographicLens.

Since an orthographic lens doesn't have a field of view angle, the &lt;code&gt;lens[-&gt;][func]setFov[/func]()&lt;/code&gt; method does nothing.  To adjust the amount that the orthographic lens sees, you must adjust its film size.  And unlike a PerspectiveLens, the film size units are not arbitrary--for an OrthographicLens, the film size should be specified in spatial units, the same units you used to model your scene.  For instance, the film size of the OrthographicLens in the above illustration was set with the call &lt;code&gt;lens[-&gt;][func]setFilmSize[/func](20, 15)&lt;/code&gt;, which sets the film size to 20 feet by 15 feet--because the scene is modeled in feet, and the panda is about 12 feet tall.

Another nice property of an orthographic lens is that the near distance does not have to be greater than zero.  In fact, it can be negative--you can put the near plane behind the camera plane, which means the camera will see objects behind itself.  The OrthographicLens for render2d is set up with &lt;code&gt;[-&gt;][func]setNearFar[/func](-1000, 1000)&lt;/code&gt;, so it will render any objects with a Y value between -1000 and 1000 (assuming the default Z-up coordinate system).  (Of course, in render2d almost all objects have a Y value of 0, so it doesn't matter much.)

If you like, you can change the default camera to use an orthographic lens with something like this:

[python]&lt;code python&gt;
lens = OrthographicLens()
lens.setFilmSize(20, 15)  # Or whatever is appropriate for your scene
base.cam.node().setLens(lens)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
PT(OrthographicLens) lens = new OrthographicLens();
lens-&gt;set_film_size(20, 15); // Or whatever is appropriate for your scene
window-&gt;get_camera(0)-&gt;set_lens(lens);
&lt;/code&gt;[/cxx]

Note that using an orthographic lens can be nonintuitive at times--for instance, objects don't get larger as you come closer to them, and they don't get smaller as you get farther away--so it may be impossible to tell your camera is even moving!</text>
    </revision>
  </page>
  <page>
    <title>Other Attributes</title>
    <ns>0</ns>
    <id>2215</id>
      <sha1>0887tk6qr549df32abb2q7kycrba9nj</sha1>
    <revision>
      <id>4902</id>
      <timestamp>2008-03-14T09:53:03Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="3835">
&lt;h2&gt;Where to Find Attrib Documentation&lt;/h2&gt;

There are three places to look for RenderAttrib documentation:

1. An attrib may have a section here in the manual under &quot;Render Attributes.&quot;

2. An attrib may be too minor to deserve its own section.  In that case, it will be listed here, under &quot;Other Attributes.&quot;

3. An attrib may be so complex that it warrants an entire chapter of the manual.  A good example would be the TextureAttrib.

Regardless, &lt;i&gt;all&lt;/i&gt; attribs should be listed in [[Render Attributes|the intro to this chapter.]]  From there, you can follow the link to the appropriate manual section.

&lt;h2&gt;List of All Attributes&lt;/h2&gt;

&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[Alpha Testing|AlphaTestAttrib]]&lt;/b&gt;: Hides part of the model, based on the texture's alpha channel.

&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[#AntialiasAttrib|AntialiasAttrib]]&lt;/b&gt;: Controls full-screen antialiasing and polygon-edge antialiasing.

&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[#AudioVolumeAttrib|AudioVolumeAttrib]]&lt;/b&gt;: Applies a scale to audio volume for positional sounds.

&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[Auxiliary Bitplanes|AuxBitplaneAttrib]]&lt;/b&gt;: Causes shader generator to produce extra data.

&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[Clip Planes|ClipPlaneAttrib]]&lt;/b&gt;: Slices off a piece of the model, using a clipping plane.

&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[Tinting and Recoloring|ColorAttrib]]&lt;/b&gt;: Tints the model.  Only works if the model is not illuminated.

&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[Transparency and Blending|ColorBlendAttrib]]&lt;/b&gt;: This specifies how colors are blended into the frame buffer, for special effects.

&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[Tinting and Recoloring|ColorScaleAttrib]]&lt;/b&gt;: Modulates vertex colors with a flat color.

&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[#ColorWriteAttrib|ColorWriteAttrib]]&lt;/b&gt;: Causes the model to not affect the R, G, B, or A channel of the framebuffer.

&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[#CullBinAttrib|CullBinAttrib]]&lt;/b&gt;: Controls the order in which Panda renders geometry.

&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[#CullFaceAttrib|CullFaceAttrib]]&lt;/b&gt;: Causes backfaces or frontfaces of the model to be visible.

&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[#DepthOffsetAttrib|DepthOffsetAttrib]]&lt;/b&gt;: Causes the Z-buffer to treat the object as if it were closer or farther.

&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[#DepthTestAttrib|DepthTestAttrib]]&lt;/b&gt;: Alters the way the Z-buffer affects the model.

&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[#DepthWriteAttrib|DepthWriteAttrib]]&lt;/b&gt;: Controls whether or not the model affects the Z-buffer.

&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[#DrawMaskAttrib|DrawMaskAttrib]]&lt;/b&gt;: Controls which cameras can see which objects.

&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[Fog|FogAttrib]]&lt;/b&gt;: Causes the model to be obscured by fog if it is far from the camera.

&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[Lighting|LightAttrib]]&lt;/b&gt;: Causes the model to be illuminated by certain lights.

&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[Light Ramps|LightRampAttrib]]&lt;/b&gt;: Enables HDR tone mapping or cartoon shading.

&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[Materials|MaterialAttrib]]&lt;/b&gt;: Changes the way the model reflects light.

&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[#RenderModeAttrib|RenderModeAttrib]]&lt;/b&gt;: Used to enable wireframe rendering.

&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[#RescaleNormalAttrib|RescaleNormalAttrib]]&lt;/b&gt;: Corrects non-unit length normals.

&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[#ShadeModelAttrib|ShadeModelAttrib]]&lt;/b&gt;: Can cause the model to appear faceted instead of smooth.

&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[Pixel and Vertex Shaders|ShaderAttrib]]&lt;/b&gt;: Gives almost unlimited control, but difficult to use.

&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[Stencil Test/Write Attribute|StencilAttrib]]&lt;/b&gt;: Causes the model to affect the stencil buffer, or be affected by the stencil buffer.

&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[Automatic Texture Coordinates|TexGenAttrib]]&lt;/b&gt;: Causes the system to synthesize texture coordinates for the model.

&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[Texture Transforms|TexMatrixAttrib]]&lt;/b&gt;: Alters the existing texture coordinates.

&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[Texturing|TextureAttrib]]&lt;/b&gt;: Applies a texture map to the model.

&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[Transparency and Blending|TransparencyAttrib]]&lt;/b&gt;: Causes the model to be partially transparent.</text>
    </revision>
  </page>
  <page>
    <title>Other Vertex and Model Manipulation</title>
    <ns>0</ns>
    <id>1777</id>
      <sha1>74wpl4ks4j2w6o9iupapx3snzd5gh06</sha1>
    <revision>
      <id>3385</id>
      <timestamp>2006-05-11T03:25:24Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="168">This section shows some other ways to manipulate low-level geometry and vertex information, including dynamically creating other kinds of Panda3D objects like Textures.</text>
    </revision>
  </page>
  <page>
    <title>Other appRunner members</title>
    <ns>0</ns>
    <id>2425</id>
      <sha1>j1j4w4ya62qzt27q7cr9cf7hkvkbrpi</sha1>
    <revision>
      <id>6297</id>
      <timestamp>2009-10-25T21:32:20Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="4733">* appRunner.Undefined

The JavaScript language has two different value types that are conceptually similar to Python's None type: the null type, and the void or undefined type.  The plugin system could convert both of these to Python's None, but sometimes it is important to make a distinction between them.

To solve this problem, the plugin converts the Javascript null type to Python's None, and the void/undefined type to base.appRunner.Undefined, which is a special singleton that has no properties, similar to None.  To check for undefined, you can use (object == base.appRunner.Undefined) or (object is base.appRunner.Undefined).  Since Undefined evaluates to false in a boolean test, you could also just use &quot;if object:&quot; to test for whether an object is neither None nor Undefined.

* appRunner.ConcreteStruct

Most Python objects are passed to JavaScript by reference, the same way Python deals with them internally.  This means that if you store an object on base.appRunner.main, the JavaScript code can query and update its members individually, and those changes are visible on the Python side.

Often, you only need to provide a read-only object to JavaScript, and you don't want the additional overhead that's required to make the object writable.  In this case, you can make your object an instance of (or inherit from) appRunner.ConcreteStruct.  This tells the plugin that there is no need for JavaScript to modify its contents, and it will copy all of its members to JavaScript once, at the time that JavaScript first accesses the overall object, and not have to go back-and-forth between Python and JavaScript with each individual member access.  Only the data members are transmitted; callable methods of ConcreteStruct are not supported.  This is a performance optimization only; everything will still work perfectly well if you don't do this.

Note that in order to gather the full benefit of this optimization, your JavaScript code should access the Python object only once and store it locally, rather than querying it repeatedly out of plugin.main.

* appRunner.multifileRoot

When the AppRunner mounts your p3d file into the VirtualFileSystem, it installs it in the directory named by appRunner.multifileRoot.  This directory, then, is the root directory of the contents of your p3d file.  If you need to load a file directly out of your p3d file, look for it here.  At the moment, this is a constant string; but future releases of Panda might need to install the multifile into a different place each time, so you should not write code that depends on this string being fixed.

* appRunner.exceptionHandler

You can assign a Python function object to this member.  This function will be called whenever a Python exception propagates to the top of the call stack; you can use this to deal appropriately with unexpected behavior in your application.  If you do not assign this, the default behavior for an uncaught exception will be to terminate the app.

* appRunner.windowProperties

This is the WindowProperties structure that is used for the initial window that is created when you import DirectStart; you can use this if you want to re-create a new window in the same place later (for instance, because you have an in-game option to switch between fullscreen and embedded mode).

* appRunner.installPackage()

Call this method to download and install a Panda3D package, as built by the ppackage.p3d utility, at runtime.  This allows you to install the package at your leisure, instead of requiring the package to be downloaded before starting the p3d application.

Note that this method runs synchronously: it will download the package on-the-spot, however long that takes, and not return until it has finished.  If you want to use an asynchronous download instead, downloading a package in the background while gameplay continues, you should use the [[PackageInstaller]] interface instead.

* appRunner.notifyRequest()

This allows you to define your own callback events, similar to the built-in ones described in [[Plugin notify callbacks]].  Simply call base.appRunner.notifyRequest(name), where name is the name of your callback event; for example base.appRunner.notifyRequest('onGameRestart').  There is no facility to pass parameters; if you need to call a JavaScript function with parameters, use a different mechanism, such as calling the function directly through appRunner.dom, or use appRunner.evalScript(), below.

* appRunner.evalScript()

Whatever string you pass to base.appRunner.evalScript() is evaluated and executed directly in the JavaScript environment.  By default, the return value, if any, is not preserved; but if you need the return value you can also pass needsResponse = True.</text>
    </revision>
  </page>
  <page>
    <title>P2</title>
    <ns>0</ns>
    <id>2520</id>
      <sha1>iihgajuqrkbiofbutpcou2ngekzjxon</sha1>
    <revision>
      <id>7019</id>
      <timestamp>2011-01-04T22:59:38Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>Made the first commit toward OpenCOLLADA integration.</comment>
      <text xml:space="preserve" bytes="862">&lt;ul&gt;
&lt;li class=&quot;complete&quot;&gt;New coding style - rdb&lt;/li&gt;
&lt;li class=&quot;started&quot;&gt;[[P2/General Interface]] - gogg&lt;/li&gt;
&lt;li class=&quot;started&quot;&gt;OpenCOLLADA integration - Xidram&lt;/li&gt;
&lt;li class=&quot;new&quot;&gt;OpenGL 3/4&lt;/li&gt;
&lt;li class=&quot;new&quot;&gt;DirectX 11&lt;/li&gt;
&lt;li class=&quot;new&quot;&gt;CEGUI&lt;/li&gt;
&lt;li class=&quot;started&quot;&gt;FX Pipeline - rdb&lt;/li&gt;
&lt;li class=&quot;new&quot;&gt;New shader system&lt;/li&gt;
&lt;li class=&quot;started&quot;&gt;Detour/Recast - Xidram/rdb&lt;/li&gt;
&lt;li class=&quot;started&quot;&gt;CMake - rdb&lt;/li&gt;
&lt;li class=&quot;complete&quot;&gt;[https://www.panda3d.org/forums/viewtopic.php?t=10062 librocket] - gogg&lt;/li&gt;
&lt;li class=&quot;new&quot;&gt;Unified physics API&lt;/li&gt;
  &lt;ul&gt;
  &lt;li class=&quot;started&quot;&gt;[https://www.panda3d.org/forums/viewtopic.php?t=10231 Bullet integration] - enn0x&lt;/li&gt;
  &lt;li class=&quot;complete&quot;&gt;[https://www.panda3d.org/forums/viewtopic.php?t=5067 PhysX integration] - enn0x&lt;/li&gt;
  &lt;/ul&gt;
&lt;li class=&quot;started&quot;&gt;Buffer system overhaul - rdb&lt;/li&gt;

&lt;/ul&gt;</text>
    </revision>
  </page>
  <page>
    <title>P2/General Interface</title>
    <ns>0</ns>
    <id>2479</id>
      <sha1>75pc7sp1bptvcjlwdin30bd39f0m0pi</sha1>
    <revision>
      <id>6975</id>
      <timestamp>2010-12-18T22:13:04Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>[[Draft A New Panda General Interface]] moved to [[P2/General Interface]]</comment>
      <text xml:space="preserve" bytes="2151">This is an illustration of an approach for a new language-neutral Panda general interface. 

The goal here is to achieve the same usage from C++ and Python, and while we are at it, make the methods more sensible-named and predictable.

In our prototype example we just open a window, load a model and register an event for a mouse click, although the callback isn't implemented for brevity. For reference, this is how it works currently:

&lt;code cxx&gt;
#include &quot;pandaFramework.h&quot;
#include &quot;pandaSystem.h&quot;
 
PandaFramework framework;
 
int main(int argc, char *argv[]) {

    framework.open_framework(argc, argv);
    framework.set_window_title(&quot;My Panda3D Window&quot;);

    WindowFramework *window = framework.open_window();
 
    framework.define_key(&quot;mouse1&quot;, &quot;leftclick&quot;, &amp;leftClick, (void*)0);

    NodePath box = window-&gt;load_model(window-&gt;get_render(), &quot;box&quot;);
 
    framework.main_loop();
    framework.close_framework();

    return (0);
}
&lt;/code&gt;
&lt;code python&gt;
from direct.showbase.ShowBase import ShowBase
 
class MyApp(ShowBase):
 
    def __init__(self):
        ShowBase.__init__(self)
 

        self.environ = self.loader.loadModel(&quot;models/environment&quot;)

        self.environ.reparentTo(self.render)
        self.accept(&quot;mouse1&quot;,leftClick)
 
app = MyApp()
app.run()
&lt;/code&gt;

&lt;h1&gt;The new approach&lt;/h1&gt;

&lt;code cxx&gt;
#include &quot;panda.h&quot;

Panda panda;

int main(int argc, char *argv[]) {

    panda.register_event(&quot;mouse1&quot;, &amp;leftClick);

    Window *window = panda.open_window(&quot;My Panda3D Window&quot;);
    NodePath box = window-&gt;load_model(&quot;box&quot;);
    box.reparent_to(window-&gt;get_render());

    panda.run();
    return 0;
}
&lt;/code&gt;
&lt;code python&gt;
from panda3d.core import Panda

panda = Panda()

panda.register_event(&quot;mouse1&quot;, leftClick)

window = panda.open_window(&quot;My Panda3D Window&quot;)
box = window.load_model(&quot;box&quot;)
box.reparent_to(window.get_render())

panda.run()
&lt;/code&gt;

&quot;Panda&quot; is just a tentative name for this facility, other names are PandaSystem (it's taken by dtool, but that one could be renamed to PandaPlatform I think), PandaFramework, Framework (it would collide temporarily), Manager, PandaManager, Controller, PandaController, etc.</text>
    </revision>
  </page>
  <page>
    <title>P3D file config settings</title>
    <ns>0</ns>
    <id>2430</id>
      <sha1>cd761o23f0uhqj0gwo8zxuv2feeb3mj</sha1>
    <revision>
      <id>7316</id>
      <timestamp>2011-09-01T05:07:32Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="3006">You can set certain config settings in a p3d file on the packp3d command line.  These control the way the p3d file may be used or embedded.

Some of these settings can also be set in the [[Advanced object tags|HTML object tags]] used when the p3d file is embedded on a web page.  If a config setting is specified in both places, the HTML page overrides.

{| border=&quot;1&quot;
! Setting !! Meaning 
|- 
| auto_start || &quot;1&quot; to launch the app without waiting for the green &quot;play&quot; button
|-
| hidden || &quot;1&quot; to avoid opening a Panda3D window
|-
| log_basename || Specifies the log file within Panda3D/log to write to for this app
|-
| prc_name || Specifies a directory name within Panda3D/prc from which user prc files custom to this app will be loaded
|-
| start_dir || Specifies a directory name within Panda3D/start which will be the current directory when this application starts.  This is not used if keep_user_env, below, is set &quot;1&quot;.
|-
| allow_python_dev || &quot;1&quot; to allow the user to break into and debug the Python code, with the &quot;-i&quot; option to panda3d.  The -D option to packp3d and ppackage is also provided as a convenient way to to set this option.
|-
| keep_user_env || &quot;1&quot; if the user's environment variables, and current working directory, should be preserved when running this app.  Normally, most environment variables are reset to default values, or cleared altogether.  You would normally specify this for a command-line app, where the user may want to preserve his or her environment; for instance, packp3d.p3d itself sets this option.  It doesn't make sense to set this for a p3d file that is intended to be run within a web page.
|-
| run_origin || The semicolon-separated list of hostnames that are allowed to embed this app in a web page.  The default is any hostname.  See [[P3D origin security]].
|-
| script_origin || The semicolon-separated list of hostnames that are allowed to directly call Python methods exposed by this app from JavaScript in a web page.  The default is &lt;em&gt;no&lt;/em&gt; hostname.  See [[P3D origin security]].
|-
| height&lt;br&gt;width || The default size of the window created for the p3d file, when it is run from the desktop (or via the panda3d application).  This is not used when the p3d file is embedded in a web page, because in that case the embed will specify the height and width.
|}

To specify a config option, use the command-line option &quot;-c setting=value&quot; on the packp3d command line, or use the config(setting = 'value') function in the pdef file.  You can repeat these options to set multiple config settings on a given file.

All of these config settings are actually stored in the p3d_info.xml file that is embedded within the p3d multifile.  Since they become part of the p3d file itself, the precise config settings are part of the date that is signed when you sign a p3d file; thus, changing any of these settings later (without re-signing) will invalidate your signature.  This prevents people from changing your app's config settings without your approval.</text>
    </revision>
  </page>
  <page>
    <title>P3D origin security</title>
    <ns>0</ns>
    <id>2471</id>
      <sha1>ogy3uml2oaxwcjh5o2yowmtjn0dbq7k</sha1>
    <revision>
      <id>6660</id>
      <timestamp>2010-02-08T22:02:11Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="3747">== script_origin ==

In order to make it harder for a malicious web page to take advantage of an inadvertent weakness in your p3d file's security, most JavaScript code is forbidden from calling Python methods exposed by your p3d file.

This is controlled by setting the &lt;i&gt;script origin&lt;/i&gt; of your p3d file.  The default script origin is empty, which means that no web pages are allowed to call Python functions in your p3d file from JavaScript.  You can set the script_origin string to a list of hostnames that are trusted; for instance, if you set it to &quot;www.mydomain.com&quot;, then web pages hosted at http://www.mydomain.com will be allowed to call your Python functions.

Note that this only affects calls &lt;i&gt;into&lt;/i&gt; Python from JavaScript.  Regardless of the setting of script_origin, your Python code is always allowed to call any JavaScript function.  Thus, you only need to worry about setting the script_origin if you need to write JavaScript code that calls Python functions directly.  If you are not certain whether you need this, you should leave the script_origin setting alone.

The term &quot;origin&quot; is taken from JavaScript's &quot;same-origin&quot; policy which normally limits the web pages that a given JavaScript program may operate on.  The origin is defined as the protocol, host, and port of the URL that hosts the p3d file.  If you omit the protocol, then any protocol is allowed; if you omit the port, then the default port is assumed.  You may define the host as either an explicit host, e.g. &quot;www.mydomain.com&quot;, or with one or more &quot;*&quot; characters, which stands for any one component of a domain, e.g. &quot;*.mydomain.com&quot; matches &quot;alpha.mydomain.com&quot; and &quot;beta.mydomain.com&quot; but not &quot;mydomain.com&quot; or &quot;www.alpha.mydomain.com&quot;.  The special code &quot;**&quot; stands for any zero or more components, e.g. &quot;**.mydomain.com&quot; matches any of the above, including &quot;mydomain.com&quot; and &quot;www.alpha.mydomain.com&quot;, but not &quot;yourdomain.com&quot;.

If you really wish to remove restrictions for the script_origin, you can set it to &quot;**&quot;, which means any host at all.  We strongly recommend &lt;i&gt;not&lt;/i&gt; doing this, for obvious reasons.

You can also set the script_origin to a semicolon-delimited set of origin strings; for instance, &quot;www.mydomain.com;mydomain.com&quot; would allow either www.mydomain.com or mydomain.com, but not any other variant.

If a p3d file is hosted on a page that doesn't match its script_origin, then that page's JavaScript code is forbidden from calling any Python methods exposed the p3d file.  It is also forbidden from accessing any attributes you assign to appRunner.main, even for read-only access.  (It is, however, allowed to query certain built-in properties of main, such as main.downloadProgress or main.read_system_log().)

You can set the script_origin with the -c parameter to packp3d, e.g. &quot;-c script_origin=www.mydomain.com&quot;.

== run_origin ==

A variant on the script_origin that is less often used is run_origin.  This is a stronger restriction than script_origin; if a p3d file is hosted on a page that doesn't match its run_origin, then the p3d file cannot be started at all.  You can do this to prevent third parties from deep-linking your p3d file or otherwise running it out of its intended context.  This is less of a security restriction, and more a usage restriction on your own content.  (Of course, a malicious individual may make a copy your p3d file and modify the run_origin setting, to allow it to run on their own page.  But they will have to re-sign it with their own certificate, since any modifications will invalidate your own signature.)

The default run_origin is &quot;**&quot;, which means there is no restriction.  You can set the run_origin with the -c parameter to packp3d, e.g. &quot;-c run_origin=www.mydomain.com&quot;.</text>
    </revision>
  </page>
  <page>
    <title>PGMM</title>
    <ns>0</ns>
    <id>2243</id>
    <redirect title="Geometrical MipMapping" />
      <sha1>jbxp11lcpy3gqjk2wpbxbm1mk9jtyus</sha1>
    <revision>
      <id>5311</id>
      <timestamp>2008-03-20T16:31:52Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[Geometrical MipMapping]]</comment>
      <text xml:space="preserve" bytes="36">#REDIRECT [[Geometrical MipMapping]]</text>
    </revision>
  </page>
  <page>
    <title>PNMImage</title>
    <ns>0</ns>
    <id>2192</id>
    <redirect title="Creating New Textures from Scratch" />
      <sha1>nhv7n5ohnsj55d6rynaf2dx42upa8y8</sha1>
    <revision>
      <id>4819</id>
      <timestamp>2008-03-12T14:14:33Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>redirected</comment>
      <text xml:space="preserve" bytes="48">#REDIRECT [[Creating New Textures from Scratch]]</text>
    </revision>
  </page>
  <page>
    <title>PStats</title>
    <ns>0</ns>
    <id>2247</id>
    <redirect title="Measuring Performance with PStats" />
      <sha1>kl051eqwl2uoiry6e195o1e47bnslrb</sha1>
    <revision>
      <id>5331</id>
      <timestamp>2008-04-03T18:22:41Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[Measuring Performance with PStats]]</comment>
      <text xml:space="preserve" bytes="47">#REDIRECT [[Measuring Performance with PStats]]</text>
    </revision>
  </page>
  <page>
    <title>PView</title>
    <ns>0</ns>
    <id>2317</id>
    <redirect title="Previewing 3D Models in Pview" />
      <sha1>t26m97xsrf0w4zn2gdf4w7xghwvrffz</sha1>
    <revision>
      <id>5727</id>
      <timestamp>2009-03-24T13:03:16Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[Previewing 3D Models in Pview]]</comment>
      <text xml:space="preserve" bytes="43">#REDIRECT [[Previewing 3D Models in Pview]]</text>
    </revision>
  </page>
  <page>
    <title>PackageInstaller</title>
    <ns>0</ns>
    <id>2426</id>
      <sha1>29pxyts7njbhxwdzsba4kz5jsps1uzp</sha1>
    <revision>
      <id>6299</id>
      <timestamp>2009-10-25T21:35:10Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="1671">The &lt;b&gt;PackageInstaller&lt;/b&gt; class is used to download and install a Panda3D package, as built by the ppackage.p3d utility, at runtime.  It is similar to base.appRunner.installPackage(), but it is capable of downloading a package in the background, while the rest of your game continues.  You can get notifications as the package is being downloaded.

PackageInstaller is itself an abstract class, and its callback notifications are defined as methods.  To use PackageInstaller, you should subclass from it and override any of the six callback methods: downloadStarted(), packageStarted(), packageProgress(), downloadProgress(), packageFinished(), downloadFinished().  See the generated API documentation for more information.

You might find the &lt;b&gt;DWBPackageInstaller&lt;/b&gt; class, which stands for &quot;DirectWaitBar PackageInstaller&quot;, even more convenient--it multiply inherits from PackageInstaller and DirectWaitBar, and defines the callback methods to update the GUI automatically as the package is downloading.  For example, the following code will automatically download and install a package, and call your method packageInstalled when the download has finished.  See the generated API documentation for more information.

&lt;code python&gt;
from direct.p3d.DWBPackageInstaller import DWBPackageInstaller

self.pi = DWBPackageInstaller(base.appRunner, 
                              parent = base.a2dTopRight,
                              scale = 0.5, pos = (-0.6, 0, -0.1),
                              finished = self.packageInstalled)
self.pi.addPackage('myPackage', 'myVersion',
                   hostUrl = 'http://myhost.com/packages')
self.pi.donePackages()
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>Packpanda</title>
    <ns>0</ns>
    <id>2245</id>
    <redirect title="Building a Self-Extracting EXE using packpanda" />
      <sha1>65ea9l25648xuee668jo91opo7xns1y</sha1>
    <revision>
      <id>5326</id>
      <timestamp>2008-03-29T10:11:02Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[Building a Self-Extracting EXE using packpanda]]</comment>
      <text xml:space="preserve" bytes="60">#REDIRECT [[Building a Self-Extracting EXE using packpanda]]</text>
    </revision>
  </page>
  <page>
    <title>Panda's Built-in Physics Engine</title>
    <ns>0</ns>
    <id>2463</id>
    <redirect title="Panda3D Physics Engine" />
      <sha1>en45ltpejy45toj2jww10l9xnigfz7s</sha1>
    <revision>
      <id>6618</id>
      <timestamp>2010-02-07T04:41:45Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>[[Panda's Built-in Physics Engine]] moved to [[Panda3D Physics Engine]]: Panda3D is the name of the engine; not Panda. Also, more sophisticated to just call it what it is - the Panda3D Physics Engine. &quot;Panda3D's Built-in&quot; sounds too casual and common.</comment>
      <text xml:space="preserve" bytes="36">#REDIRECT [[Panda3D Physics Engine]]</text>
    </revision>
  </page>
  <page>
    <title>Panda3D Development</title>
    <ns>0</ns>
    <id>1091</id>
      <sha1>svaeiho7h6ovg3ydg3m51sertx6v7t9</sha1>
    <revision>
      <id>2372</id>
      <timestamp>2005-05-06T03:50:39Z</timestamp>
      <contributor>
        <username>Hughperkins</username>
        <id>10</id>
      </contributor>
      <comment>added link to pointers</comment>
      <text xml:space="preserve" bytes="592">== Summary ==

This page is the head of an orphaned wiki hierarchy for Panda3D developers, that is for people who wish to directly modify the C++ code that comprises Panda3D.

If you want to learn how to use Panda3D within your own project, you probably want the main Panda3D manual at: [[Main Page]].

== Panda Development ==

=== Macros ===

*[[Macros]]

=== Pointers ===

*[[Pointers]]

=== Classes ===

*[[Geom]] (this also describes the GeomPrimitive, and its derivatives)
*[[GeomVertexWriter]]
*[[GeomVertexData]]

=== Instructions for specific tasks ===

*[[Creating a New Node Class]]</text>
    </revision>
  </page>
  <page>
    <title>Panda3D Features</title>
    <ns>0</ns>
    <id>2679</id>
    <redirect title="Features" />
      <sha1>q3i0q08d6m8ljpy41el7465v4pxjk8e</sha1>
    <revision>
      <id>7742</id>
      <timestamp>2012-03-13T08:18:44Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>[[Panda3D Features]] moved to [[Features]]</comment>
      <text xml:space="preserve" bytes="22">#REDIRECT [[Features]]</text>
    </revision>
  </page>
  <page>
    <title>Panda3D Physics Engine</title>
    <ns>0</ns>
    <id>1007</id>
      <sha1>c5pfia1s0q9jqq0lgw86n0zi3letwi1</sha1>
    <revision>
      <id>7682</id>
      <timestamp>2012-03-08T20:32:11Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="624">&lt;p&gt;Panda3D has a very basic physics engine that may apply forces to classes. The physics engine can handle angular or linear forces, as well as viscosity.&lt;/p&gt;

&lt;p&gt;To make use of the physics engine, first enable the particle system. The particle system relies upon the physics engine to move and update particles, so enabling the particle system adds the tasks in the engine that monitor and update the interactions of physics-enabled objects in the scene.&lt;/p&gt;

&lt;code python&gt;
base.enableParticles()
&lt;/code&gt;

The rest of this section will address how to prepare a model for physical interactions and apply forces to the model.</text>
    </revision>
  </page>
  <page>
    <title>Panda3D Rendering Process</title>
    <ns>0</ns>
    <id>1147</id>
      <sha1>bsqnlj76v8n2phoxgnngneihln66t8x</sha1>
    <revision>
      <id>6613</id>
      <timestamp>2010-02-07T04:40:04Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <minor/>
      <comment>[[Panda Rendering Process]] moved to [[Panda3D Rendering Process]]: Panda3D is the name of the engine; not Panda.</comment>
      <text xml:space="preserve" bytes="818">The rendering process in Panda is comprised by four classes and their interactions: GraphicsPipe, GraphicsEngine, GraphicsStateGaurdian, and GraphicsOutput. The following sections will explain the purpose of each of these classes in detail.

Note that the following interfaces are for the advanced user only.  If you are writing a simple application that only needs to open a window and perform basic 3-D rendering, there is no need to use any of these interfaces, as the appropriate calls to open a default window are made automatically when you &lt;code&gt;import direct.directbase.DirectStart&lt;/code&gt; at the start of your application.

At some point, however, you may wish to understand more deeply how to manage your windows and buffers, and to do this it will help you to understand how everything is connected together.</text>
    </revision>
  </page>
  <page>
    <title>Panda3D Tools</title>
    <ns>0</ns>
    <id>1000</id>
      <sha1>86rbjitcx9m70wd57w02z7lwkwksweg</sha1>
    <revision>
      <id>7725</id>
      <timestamp>2012-03-10T06:58:40Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>new import system</comment>
      <text xml:space="preserve" bytes="1064">This section lists a number of tools to support programming in Panda.

Many of the tools provided are invoked by pressing a
hot-key inside of the panda main window.  These hot-key driven tools
are called the &quot;direct tools.&quot;  The direct tools are initially disabled,
because the hot-keys used to invoke them might interfere with the program's
own keys and events.

To enable the hot-keys for the direct tools, you
need to set the 'want-directtools' variable in config.prc, the main
panda configuration file.  Additionally, set 'want-tk' to '#t' in order to enable the Direct Session Panel. More information about this configuration
file is available in the [[Configuring Panda]] section.

If you want to quickly enable the Direct Session browser, add the following code &lt;i&gt;before&lt;/i&gt; importing DirectStart:
&lt;code python&gt;
from panda3d.core import loadPrcFileData
loadPrcFileData(&quot;&quot;, &quot;want-directtools #t&quot;)
loadPrcFileData(&quot;&quot;, &quot;want-tk #t&quot;)
&lt;/code&gt;

After enabling direct tools and starting panda, the
Direct Session window should appear:
 
[[Image:directtools1.jpg]]</text>
    </revision>
  </page>
  <page>
    <title>Panda3D Utility Functions</title>
    <ns>0</ns>
    <id>1001</id>
      <sha1>b9agvph5nqcbspcw7echvvckdhn3x20</sha1>
    <revision>
      <id>7672</id>
      <timestamp>2012-03-08T20:07:33Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="2231">Panda3D has a set of utilities that may be used to learn more about various objects and methods within an application. To access these utilities you need to import the PythonUtil module as follows.

&lt;code python&gt;
from direct.showbase.PythonUtil import *
&lt;/code&gt;

The &lt;code&gt; * &lt;/code&gt; can be replaced by any of the utility functions in that module.

To get a detailed listing of a class or an object's attributes and methods, use the pdir() command. pdir() prints the information out to the command console. pdir() can take many arguments for formatting the output but the easiest way to use it is to provide it a NodePath.

pdir() will list all of the functions of the class of NodePath including those of its base classes

&lt;code python&gt;
pdir(NodePath)
# e.g. pdir(camera)
&lt;/code&gt;

There are many other useful functions in the PythonUtil module. All of these are not necessarily Panda specific, but utility functions for python.
There are random number generators, random number generator in a gaussian distribution curve, quadratic equation solver, various list functions, useful angle functions
etc. A full list can be found in the API.

An alternative command to &lt;code&gt; pdir&lt;/code&gt; is &lt;code&gt;inspect()&lt;/code&gt;. This command will create a window with methods and attributes on one side, and the details of a selected attribute on the other. &lt;code&gt;inspect()&lt;/code&gt; also displays the current values of a class’ attributes. If these attributes are changing, you may have to click on a value to refresh it. To use inspect() you have to do the following:

&lt;code python&gt;
from direct.tkpanels.inspector import inspect
inspect(NodePath)
# e.g. inspect(camera)
&lt;/code&gt;

While the directtools suite calls upon a number of tools, if the suite is disabled, the user may activate certain panels of the suite. The &lt;code&gt;place()&lt;/code&gt; command opens the object placer console. The &lt;code&gt;explore()&lt;/code&gt; opens the scene graph explorer, which allows you to inspect the hierarchy of a NodePath. Finally, in order to change the color of a NodePath, the &lt;code&gt;rgbPanel()&lt;/code&gt; command opens color panel.

&lt;code python&gt;
camera.place()
render.explore()
panda.rgbPanel()
&lt;/code&gt;

Useful DirectTool panels are explained in the [[Panda Tools]] section.</text>
    </revision>
  </page>
  <page>
    <title>Panda3D Wiki:Help</title>
    <ns>0</ns>
    <id>2054</id>
      <sha1>rajw44lf2l3njjm8chvbn41v4rrr2yb</sha1>
    <revision>
      <id>4065</id>
      <timestamp>2007-02-15T14:03:16Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>*sigh* removed some deadlinks</comment>
      <text xml:space="preserve" bytes="6193">On a wiki, it is customary to allow readers to edit content and structure. This is a brief overview of the editing and contributing process. The editing table of contents to the right contains more information on editing functions.

== Creating a new page ==
You can create a new page just by browsing to the non-existing page, automatically an edit form will appear (if you are logged in).
== Editing basics ==
===Review policy and conventions===

:Make sure that you submit information which is relevant to the specific purpose of the wiki, or your content might be deleted. You can always use the talk pages to ask questions or check to see if your idea will be accepted. Please make note of the license your contributions will be covered with.

=== Start editing ===
:To start editing a wiki page, click the '''Edit this page''' (or just '''edit''') link at one of its edges. This brings you to the edit page: a page with a text box containing the ''wikitext'' - the editable code from which the server produces the finished page.

===Type your changes===
:You can just type your text. However, also using basic wiki markup (described in the next section) to make links and do simple formatting adds to the value of your contribution. Wikis have style guidelines available. If you follow these, your contributions will be more valuable as they won't need to be cleaned up later.

===Summarize your changes===
:Write a short edit summary in the small field below the edit-box. You may use shorthand to describe your changes, as described in the edit summary legend.

===Preview before saving===
:When you have finished, click '''Show preview''' to see how your changes will look '''before''' you make them permanent.  Repeat the edit/preview process until you are satisfied, then click '''Save page''' and your changes will be immediately applied to the article.

==Most frequent wiki markup explained==
Here are the 6 most frequently used types of wiki markup. If you need more help see Wikitext examples.
&lt;br clear=&quot;right&quot; /&gt;
{| border=&quot;1&quot; cellpadding=&quot;2&quot; style=&quot;background:#FFFF99&quot;
!width=&quot;1000&quot; style=&quot;background:#FFFF99&quot;|What it looks like
!width=&quot;500&quot; style=&quot;background:#FFFF99&quot;|What you type
|-
|
You can ''italicize text'' by putting 2 
apostrophes on each side. 

3 apostrophes will embolden '''the text'''. 

5 apostrophes will embolden and italicize 
'''''the text'''''.

(4 apostrophes doesn't do anything special -- there's just ''''one left over''''.)
|&lt;pre&gt;
You can ''italicize text'' by putting 2 
apostrophes on each side. 

3 apostrophes will embolden '''the text'''. 

5 apostrophes will embolden and italicize 
'''''the text'''''.

(4 apostrophes doesn't do anything
special -- there's just ''''one left
over''''.)
&lt;/pre&gt;
|-
|
You should &quot;sign&quot; your comments on talk pages: &lt;br /&gt;
- Three tildes give your user name: [[User:Karl Wick|Karl Wick]] &lt;br /&gt;
- Four tildes give your user name plus date/time: [[User:Karl Wick|Karl Wick]] 07:46, 27 November 2005 (UTC) &lt;br /&gt;
- Five tildes give the date/time alone: 07:46, 27 November 2005 (UTC) &lt;br /&gt;
|&lt;pre&gt;
You should &quot;sign&quot; your comments 
on talk pages: &lt;br /&gt;
- Three tildes give your user
name: ~~~ &lt;br /&gt;
- Four tildes give your user 
name plus date/time: ~~~~ &lt;br /&gt;
- Five tildes give the 
date/time alone: ~~~~~ &lt;br /&gt;
&lt;/pre&gt;
|-
|
&lt;div style=&quot;font-size:150%;border-bottom:1px solid rgb(170,170,170);&quot;&gt;Section headings&lt;/div&gt;

''Headings'' organize your writing into sections.
The Wiki software can automatically generate
a table of contents from them.

&lt;div style=&quot;font-size:132%;font-weight:bold;&quot;&gt;Subsection&lt;/div&gt;
Using more equals signs creates a subsection.

&lt;div style=&quot;font-size:116%;font-weight:bold;&quot;&gt;A smaller subsection&lt;/div&gt;

Don't skip levels, like from two to four equals signs.

Start with 2 equals signs not 1 because 1 creates H1 tags which should be reserved for page title.
|&lt;pre&gt;
== Section headings ==

''Headings'' organize your writing into sections.
The Wiki software can automatically generate
a table of contents from them.

=== Subsection ===

Using more equals signs creates a subsection.

==== A smaller subsection ====

Don't skip levels, 
like from two to four equals signs.

Start with 2 equals signs not 1 
because 1 creates H1 tags
which should be reserved for page title.
&lt;/pre&gt;
|- id=&quot;lists&quot;
|
* ''Unordered lists'' are easy to do:
** Start every line with a star.
*** More stars indicate a deeper level.
*: Previous item continues.
** A newline
* in a list  
marks the end of the list.
*Of course you can start again.
|&lt;pre&gt;
* ''Unordered lists'' are easy to do:
** Start every line with a star.
*** More stars indicate a deeper level.
*: Previous item continues.
** A new line
* in a list  
marks the end of the list.
* Of course you can start again.
&lt;/pre&gt;
|-
|
# ''Numbered lists'' are:
## Very organized
## Easy to follow
A new line marks the end of the list.
# New numbering starts with 1.

|&lt;pre&gt;
# ''Numbered lists'' are:
## Very organized
## Easy to follow
A new line marks the end of the list.
# New numbering starts with 1.
&lt;/pre&gt;
|-
|
===Links===
Here's a link to the [[Main page]].
|&lt;pre&gt;
Here's a link to the [[Main page]].
&lt;/pre&gt;
|-
|
You can link to a page section by its title:

* [[Lighting#Point Lights]].

If multiple sections have the same title, add
a number. [[#Example section 3]] goes to the
third section named &quot;Example section&quot;.
|&lt;pre&gt;

You can link to a page section by its title:

* [[Lighting#Point Lights]].

If multiple sections have the same title, add
a number. [[#Example section 3]] goes to the
third section named &quot;Example section&quot;.
&lt;/pre&gt;
|-
|
You can link to non-existing pages, too.
Anyone can create that page by just clicking on the link.
|&lt;pre&gt;
You can link to non-existing pages, too.
Anyone can create that page by just clicking on the link.
&lt;/pre&gt;
|-
|
You can also link to an external page:

* [http://www.etc.cmu.edu Carnagie Mellon ETC].

If you do not supply a link name,
the link will show up like this:
* [http://www.etc.cmu.edu]
|&lt;pre&gt;

You can also link to an external page:

* [http://www.etc.cmu.edu Carnagie Mellon ETC].

If you do not supply a link name,
the link will show up like this:
* [http://www.etc.cmu.edu]
&lt;/pre&gt;

|}</text>
    </revision>
  </page>
  <page>
    <title>PandaTutDiagrams</title>
    <ns>0</ns>
    <id>2437</id>
      <sha1>5edwomcrsynkjfafz7ixsqch0egkm8v</sha1>
    <revision>
      <id>6439</id>
      <timestamp>2009-12-24T13:44:59Z</timestamp>
      <contributor>
        <username>Dotherwise</username>
        <id>415</id>
      </contributor>
      <minor/>
      <comment>Updated svg file on other server.</comment>
      <text xml:space="preserve" bytes="584">=Diagrams=
I have started some diagrams to try summarize the Panda concepts. On this wiki page are the png images from the Inkscape file. Below is a link to the source file so others can edit it.

I would appreciate any criticism, suggestions and bug fixes. If you scribble over the diagrams or edit the source, then send them to me at donn.ingle@gmail.com

[[Image:PandaNodes.png]]
[[Image:NodePaths.png]]
[[Image:GlobalVars.png]]
[[Image:SceneGraph.png]]

Source files (SVG) here:
http://otherwise.relics.co.za/media/otherwise/panda3d/tut.svg.tar.gz


[[User:Dotherwise|Dotherwise]]</text>
    </revision>
  </page>
  <page>
    <title>Panda 3D Video Tutorial Series</title>
    <ns>0</ns>
    <id>2059</id>
    <redirect title="User Contributed Video Tutorials" />
      <sha1>dcg0sl8xi77quyigt64cwg6cirtu836</sha1>
    <revision>
      <id>4076</id>
      <timestamp>2007-02-15T15:58:36Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>[[Panda 3D Video Tutorial Series]] moved to [[User Contributed Video Tutorials]]: to allow more videos to be posted</comment>
      <text xml:space="preserve" bytes="46">#REDIRECT [[User Contributed Video Tutorials]]</text>
    </revision>
  </page>
  <page>
    <title>Panda Bootstrap</title>
    <ns>0</ns>
    <id>1706</id>
      <sha1>m8l5rlvkn9vjyuyuk122m7s9a1874e6</sha1>
    <revision>
      <id>3142</id>
      <timestamp>2006-01-05T03:13:16Z</timestamp>
      <contributor>
        <username>Zpavlov</username>
        <id>16</id>
      </contributor>
      <text xml:space="preserve" bytes="1114">Though Panda3D is easy enough, it needs some getting used to before you can understand the manuals and examples.

Here are a few links, which should make understanding Panda3D easier:

&lt;ul&gt;
&lt;li&gt; http://www.python.org/pycon/dc2004/papers/29/
This link gives you a very broad overview of panda, which is helpful to more clearly understand the Introductory examples.
&lt;li&gt; http://www.etc.cmu.edu/bvw/scripting/index.html (Note, currently not functional with Panda3D-1.1.0)&lt;br&gt;
Read this example once you are done with the introduction example following this section. I found referring to the manual helpful and informative while working on this example.
&lt;li&gt; The samples that come with the installation are also very informative and well commented. They should be really helpful for people new to Panda3D.
&lt;li&gt; Have the Panda3D and BVW quick references handy while you are coding.
&lt;li&gt;http://www.gamasutra.com/features/20040128/goslin_pfv.htm A  postmortem of ToonTown built with Panda3D.
&lt;/ul&gt;

Having the API reference handy while reading the manual is also advisable, as the manual is lacking explanations at times.</text>
    </revision>
  </page>
  <page>
    <title>Panda Changes</title>
    <ns>0</ns>
    <id>1261</id>
      <sha1>b1y8d6q5kl34myhbg6j2jsviuqo1n6m</sha1>
    <revision>
      <id>2541</id>
      <timestamp>2005-10-18T15:48:54Z</timestamp>
      <contributor>
        <username>Zpavlov</username>
        <id>16</id>
      </contributor>
      <text xml:space="preserve" bytes="1413">&lt;h1&gt;Panda Version 1.0.903 (Not available to the public just yet)&lt;/h1&gt;

&lt;h2&gt;Issues&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;By default, the new Panda is case sensitive. To disable, add the following line to your config.prc file:
&lt;p&gt;&lt;code&gt; vfs-case-sensitive 0&lt;/code&gt;&lt;/p&gt;
&lt;/ul&gt;
&lt;h2&gt;Syntax Changes &lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;NodePath.setLight now only takes a NodePath containing a light. 
&lt;li&gt;You can now wrap a light in a NodePath without it crashing (no more upcasting)
&lt;li&gt;Traverser.addCollider now only takes NodePaths
&lt;li&gt;Panda Objects have been changed from python classes to python types. As a result, you cannot store variables on them.

   &lt;p&gt;  &lt;code&gt;
      #This will crash &lt;br&gt;
      a=NodePath(&quot;a&quot;)  &lt;br&gt;
      a.myVariable=5   &lt;br&gt;
       &lt;/code&gt;
   &lt;/p&gt; 
&lt;li&gt;You cannot import Panda objects from pandac
&lt;p&gt;
&lt;code&gt;
   #wrong &lt;br&gt;
   from pandac.Geom import * &lt;br&gt;
   #right &lt;br&gt;
   from pandac.PandaModules import *
&lt;/code&gt;
&lt;/p&gt;
&lt;/ul&gt;

&lt;h2&gt; New Features &lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;AVI movie textures are now supported through loader.loadTexture 
&lt;li&gt;Shaders now function differently. see Cg shader manual page for details

&lt;li&gt;There is new functionality on NodePaths for storing python objects.
&lt;p&gt;
&lt;code&gt;
   a=NodePath(&quot;a&quot;)&lt;br&gt;
   a.setPythonTag(&quot;myOBject&quot;,myPythonObject)&lt;br&gt;
   a.getPythonTag(&quot;myObject&quot;).doSomething()&lt;br&gt;
&lt;/code&gt;
&lt;/p&gt;
&lt;li&gt;Geometric data manipulation is now done using GeomVertexReader, GeomVertexWriter, and GeomVertexRewriter
&lt;/ul&gt;</text>
    </revision>
  </page>
  <page>
    <title>Panda Filename Syntax</title>
    <ns>0</ns>
    <id>998</id>
    <redirect title="Loading Models" />
      <sha1>audil56h8hd84cf5uxju5kg5nsbr5gp</sha1>
    <revision>
      <id>5480</id>
      <timestamp>2008-10-02T17:01:46Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>redirect to avoid confusion</comment>
      <text xml:space="preserve" bytes="50">#REDIRECT [[Loading Models#Panda Filename Syntax]]</text>
    </revision>
  </page>
  <page>
    <title>Panda License</title>
    <ns>0</ns>
    <id>999</id>
      <sha1>86g590v5xxpd2d9h75d8078yqzrv7aq</sha1>
    <revision>
      <id>3194</id>
      <timestamp>2006-02-02T18:06:57Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="64">The Panda License can be found at http://panda3d.org/license.txt</text>
    </revision>
  </page>
  <page>
    <title>Panda Rendering Process</title>
    <ns>0</ns>
    <id>2461</id>
    <redirect title="Panda3D Rendering Process" />
      <sha1>4q1oypdlonz19knftozttf2ort491u8</sha1>
    <revision>
      <id>6614</id>
      <timestamp>2010-02-07T04:40:04Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>[[Panda Rendering Process]] moved to [[Panda3D Rendering Process]]: Panda3D is the name of the engine; not Panda.</comment>
      <text xml:space="preserve" bytes="39">#REDIRECT [[Panda3D Rendering Process]]</text>
    </revision>
  </page>
  <page>
    <title>Panda Tools</title>
    <ns>0</ns>
    <id>2465</id>
    <redirect title="Panda3D Tools" />
      <sha1>ajwtzudx0h8kdy9xblsv6vl48asd7gs</sha1>
    <revision>
      <id>6622</id>
      <timestamp>2010-02-07T04:42:59Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>[[Panda Tools]] moved to [[Panda3D Tools]]: Panda3D is the name of the engine; not Panda.</comment>
      <text xml:space="preserve" bytes="27">#REDIRECT [[Panda3D Tools]]</text>
    </revision>
  </page>
  <page>
    <title>Panda Utility Functions</title>
    <ns>0</ns>
    <id>2462</id>
    <redirect title="Panda3D Utility Functions" />
      <sha1>ett8u8f7k088gpnfmrprh69cs0y6xfx</sha1>
    <revision>
      <id>6616</id>
      <timestamp>2010-02-07T04:40:30Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>[[Panda Utility Functions]] moved to [[Panda3D Utility Functions]]: Panda3D is the name of the engine; not Panda.</comment>
      <text xml:space="preserve" bytes="39">#REDIRECT [[Panda3D Utility Functions]]</text>
    </revision>
  </page>
  <page>
    <title>Parsing and Generating Egg Files</title>
    <ns>0</ns>
    <id>1158</id>
      <sha1>f9oh96dz6gywi1xzhmfseg998bn2g29</sha1>
    <revision>
      <id>4645</id>
      <timestamp>2008-02-04T19:28:54Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>removed another spam link</comment>
      <text xml:space="preserve" bytes="2331">&lt;h2&gt;Transforms and Vertices&lt;/h2&gt;

The egg syntax defines all transforms, including joint transforms, relative to the parent node only. When the animation is played, Panda accumulates the transforms for each joint.

Although joints are defined using a local transform, vertices are defined in an egg file using global coordinates, which is irrespective of transforms appearing within the egg file. This means when Panda loads the egg file is loaded, the vertex coordinates given in the egg file must be pre-transformed by the appropriate inverse matrix to compensate.

&lt;h2&gt;Custom .egg Readers/Writers&lt;/h2&gt;

When writing an importer or exporter for panda, you have two choices.

One option is to use the panda runtime library, which includes code
for reading, parsing, storing, and emitting Egg files.  This approach
can save you a great deal of effort.  However, it does require that you link
with the panda runtime system, which may be inconvenient if you wish
to distribute a small, standalone file translator.  

If you decide to use the panda runtime system, the classes you will need to
use are the ones whose names start with &quot;Egg,&quot; ie, &lt;code&gt;pandac.EggData&lt;/code&gt;, &lt;code&gt;pandac.EggVertex&lt;/code&gt;, &lt;code&gt;pandac.EggPolygon&lt;/code&gt;, &lt;code&gt;pandac.EggGroup&lt;/code&gt;, and
so forth.  Like all panda classes, these are documented in the [http://panda3d.net/apiref.php?page=classes API reference manual.]

The other alternative is to parse/generate the Egg file entirely by yourself.
In this case, you will need to read the
[http://panda3d.cvs.sourceforge.net/panda3d/panda/src/doc/eggSyntax.txt?view=markup syntax documentation for egg files].  This documentation is part of the source code on [http://sourceforge.net/projects/panda3d sourceforge].  The file
format is human-readable, and fairly straightforward.

If you are writing a program to &lt;i&gt;generate&lt;/i&gt; Egg files, either approach is equally good.  However, if you are writing a program to &lt;i&gt;parse&lt;/i&gt; Egg files, we do recommend using the panda runtime library, rather than writing your own parser, for the simple reason that it is difficult to write a parser that accepts all valid Egg files.  Also, the Egg syntax might be extended from time to time, and relying on the runtime library to parse the Egg syntax will ensure that your program continues to parse future Egg files.</text>
    </revision>
  </page>
  <page>
    <title>Particle Effect Basic Parameters</title>
    <ns>0</ns>
    <id>1002</id>
      <sha1>bv4v5wbfh0nnum46lkelfzmxs7ysbxy</sha1>
    <revision>
      <id>2290</id>
      <timestamp>2005-04-16T21:37:33Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="1421">&lt;p&gt;Every particle effect needs at least eleven parameters. These govern the overall properties, such as the number of particles on the screen, the birth and death rates, and the renderer, emitter, and factory that are used.&lt;/p&gt;
&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Variable&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Values&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;poolSize&lt;/td&gt;&lt;td&gt;Maximum number of simultaneous particles&lt;/td&gt;&lt;td&gt;[0, infinity)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;birthRate&lt;/td&gt;&lt;td&gt;Seconds between particle births&lt;/td&gt;&lt;td&gt;(0, infinity)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;litterSize&lt;/td&gt;&lt;td&gt;Number of particles created at each birth&lt;/td&gt;&lt;td&gt;[1, infinity)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;litterSpread&lt;/td&gt;&lt;td&gt;Variation of litter size&lt;/td&gt;&lt;td&gt;[0, infinity)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;localVelocityFlag&lt;/td&gt;&lt;td&gt;Whether or not velocities are absolute&lt;/td&gt;&lt;td&gt;Boolean&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;systemGrowsOlder&lt;/td&gt;&lt;td&gt;Whether or not the system has a lifespan&lt;/td&gt;&lt;td&gt;Boolean&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;systemLifespan&lt;/td&gt;&lt;td&gt;Age of the system in seconds&lt;/td&gt;&lt;td&gt;[0, infinity)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;BaseParticleRenderer* renderer&lt;/td&gt;&lt;td&gt;Pointer to particle renderer&lt;/td&gt;&lt;td&gt;Renderer type&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;BaseParticleRenderer* emitter&lt;/td&gt;&lt;td&gt;Pointer to particle emitter&lt;/td&gt;&lt;td&gt;Emitter type&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;BaseParticleRenderer* factory&lt;/td&gt;&lt;td&gt;Pointer to particle factory&lt;/td&gt;&lt;td&gt;Factory type&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;
&lt;p&gt;The renderer, emitter, and factory types will be discussed in the next three sections.&lt;/p&gt;</text>
    </revision>
  </page>
  <page>
    <title>Particle Effects</title>
    <ns>0</ns>
    <id>1003</id>
      <sha1>qjeybwccxaxejkks632zrcuwd4kt40z</sha1>
    <revision>
      <id>7289</id>
      <timestamp>2011-08-24T21:48:20Z</timestamp>
      <contributor>
        <username>AL.dev</username>
        <id>526</id>
      </contributor>
      <text xml:space="preserve" bytes="8769">[python]
&lt;p&gt;Particle effects involve the use of several small images acting on the same set of forces. These particles are created, they move, and they die out. These systems are dynamic and may be used for such effects as explosions, smoke, bubbling liquid and swarms.&lt;/p&gt;

&lt;p&gt;In essence, any particle effect needs three key parts: the renderer, the emitter, and the factory. The renderer translates the particle object into a visible object on the screen. The emitter assigns initial locations and velocity vectors for the particles. The factory generates particles and assigns their attributes. There are many different types of each part, and they each have their own parameters.&lt;/p&gt;

&lt;p&gt;Creating your own particle effects using code alone may be difficult. A particle effect panel is available to ease through this process. This section will discuss using the particle panel and the large number of variables associated with particle effects.&lt;/p&gt;
[/python]
[cxx]
&lt;p&gt;Fire,&amp;nbsp; smoke, glowing, explosion, water fountain, falling leaves, fur, hair 
and many other fuzzy effects are created procedurally using particle systems. 
It&amp;#39;s important not to make the assumption that particles must have the size of a 
&amp;#39;particle&amp;#39; that is very small, particles can have any size and any mass. 
Particles are physical entities which inherit PhysicsObject.&lt;/p&gt;
&lt;p&gt;Panda3D provides a tool which simplifies testing particle systems. The tool 
is called (Particle Panel) and is written in python. The link to run the 
particle panel is in the same folder as the particle sample which comes with 
Panda3D.&lt;/p&gt;
&lt;h3&gt;A particle system in Panda3D consists of 6 components:&lt;/h3&gt;
&lt;ol&gt;
	&lt;li&gt;Factory&lt;/li&gt;
	&lt;li&gt;Emitter&lt;/li&gt;
	&lt;li&gt;Physics engine&lt;/li&gt;
	&lt;li&gt;Renderer&lt;/li&gt;
	&lt;li&gt;Particle System Controller (Particle System)&lt;/li&gt;
	&lt;li&gt;Particle System Manager (Optional)&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Factory:&lt;/h3&gt;
&lt;p&gt;Particles are generated in this stage using the provided parameters. Panda3D 
Provides 2 Factories: &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;PointParticleFactory: Generates particles with default rotation.&lt;/li&gt;
	&lt;li&gt;ZspintParticleFactory:&amp;nbsp; [From Source Code] Generates particles which spin 
along their z-axis. this is kind of an intermediary class- if you&amp;#39;re using a 
SpriteParticleRenderer and you want your sprites to spin without having them be 
full-blown oriented (i.e. angry quat math), use this. Note:&amp;nbsp; &amp;#39;set_final_angle&amp;#39; 
and &amp;#39;angular_velocity&amp;#39; are mutually exclusive APIs &amp;nbsp;if angular-velocity is 
specified, final_angle is ignored.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;[Sample]&lt;/p&gt;
&lt;p&gt;&lt;code cxx&gt;PT(PointParticleFactory) pt_particle_factory = new PointParticleFactory();
pt_particle_factory-&gt;set_lifespan_base(0.5);
pt_particle_factory-&gt;set_lifespan_spread(0);
pt_particle_factory-&gt;set_mass_base(1.0);
pt_particle_factory-&gt;set_mass_spread(0);
pt_particle_factory-&gt;set_terminal_velocity_base(400);
pt_particle_factory-&gt;set_terminal_velocity_spread(0);&lt;/code&gt;&lt;/p&gt;
&lt;h3&gt;Emitter:&lt;/h3&gt;
&lt;p&gt;The emitter is used to emit the particles generated by the factory. The shape 
of the emitter determins the initial position and motion direction of the 
particles.&lt;/p&gt;
&lt;h4&gt;Available Emitters:&lt;/h4&gt;
&lt;ul&gt;
	&lt;li&gt;ArcEmitter&lt;/li&gt;
	&lt;li&gt;&amp;nbsp;BoxEmitter&lt;/li&gt;
	&lt;li&gt;&amp;nbsp;DiscEmitter&lt;/li&gt;
	&lt;li&gt;&amp;nbsp;LineEmitter&lt;/li&gt;
	&lt;li&gt;&amp;nbsp;RectangleEmitter&lt;/li&gt;
	&lt;li&gt;&amp;nbsp;RingEmitter&lt;/li&gt;
	&lt;li&gt;&amp;nbsp;SphereSurfaceEmitter&lt;/li&gt;
	&lt;li&gt;&amp;nbsp;SphereVolumeEmitter&lt;/li&gt;
	&lt;li&gt;&amp;nbsp;TangentRingEmitter&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each emitter is declared in a separate .h file with the same name as the 
emitter. For example: ArcEmitter is declared in arcEmitter.h&lt;/p&gt;
&lt;p&gt;[Sample]&lt;/p&gt;
&lt;p&gt;&lt;code cxx&gt;PT(SphereVolumeEmitter) sphere_emitter = new SphereVolumeEmitter;
sphere_emitter-&gt;set_emission_type(SphereVolumeEmitter::ET_RADIATE);
sphere_emitter-&gt;set_radius(3.0);
// negative values emit the particles toward the sphere center
sphere_emitter-&gt;set_amplitude(1);
sphere_emitter-&gt;set_amplitude_spread(0);
sphere_emitter-&gt;set_offset_force(LVector3f(0, 0, 0));
sphere_emitter-&gt;set_explicit_launch_vector(LVector3f(1, 0, 0));
sphere_emitter-&gt;set_radiate_origin(LPoint3f(0, 0, 0));&lt;/code&gt;&lt;/p&gt;
&lt;h3&gt;Renderer:&lt;/h3&gt;
&lt;p&gt;The renderer is used to specify how the particle appears on screen.&lt;/p&gt;
&lt;h4&gt;Available renderers:&lt;/h4&gt;
&lt;ul&gt;
	&lt;li&gt;GeomParticleRenderer: displays each particle on the shape of a selected 
	PandaNode&lt;/li&gt;
	&lt;li&gt;LineParticleRenderer: displays each particle as a line&lt;/li&gt;
	&lt;li&gt;PointParticleRenderer: displays each particle as a point&lt;/li&gt;
	&lt;li&gt;SparkleParticleRenderer displayes each particle as a plus (+)&lt;/li&gt;
	&lt;li&gt;SpriteParticleRenderer: &amp;nbsp;displays each particle as a sprite&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each renderer is declared in a separate .h file with the same name as the 
renderer. For example: GeomParticleRenderer is declared in 
geomParticleRenderer.h&lt;/p&gt;
&lt;p&gt;[Sample]&lt;/p&gt;
&lt;p&gt;&lt;code cxx&gt;PT(PointParticleRenderer) pt_particle_rend = new PointParticleRenderer();
pt_particle_rend-&gt;set_alpha_mode(BaseParticleRenderer::PR_ALPHA_OUT);
pt_particle_rend-&gt;set_user_alpha(1);
pt_particle_rend-&gt;set_point_size(2.0);
pt_particle_rend-&gt;set_start_color(Colorf(1, 0, 0, 1)); // alpha value is ignored
pt_particle_rend-&gt;set_end_color(Colorf(1, 1, 0, 1));
pt_particle_rend-&gt;set_blend_type(PointParticleRenderer::PointParticleBlendType::PP_BLEND_LIFE);
pt_particle_rend-&gt;set_blend_method(BaseParticleRenderer::ParticleRendererBlendMethod::PP_BLEND_LINEAR);
//pt_particle_rend-&gt;set_color_blend_mode(ColorBlendAttrib::Mode::M_inv_subtract);
//pt_particle_rend-&gt;set_ignore_scale(false);&lt;/code&gt;&lt;/p&gt;
&lt;h3&gt;ParticleSystem:&lt;/h3&gt;
&lt;p&gt;This class is the controller of the particle system. &amp;nbsp;The main parameters 
are:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Pool Size: the maximum number of particles the factory can generate
	Birth Rate: number of seconds between particle births, also it is the time 
	after which the first birth occurs. So if the value is 6 the first litter 
	will be born after 6 seconds.&lt;/li&gt;
	&lt;li&gt;Litter Size: number of particles created at each birth. If you want all 
	the particles to be born at the same time, set this value to the value of 
	(Pool Size)
	Litter Spread: this adds a random value in the range [-spread, +spread] to 
	the value of Litter Size.&lt;/li&gt;
	&lt;li&gt;Lifespan: &amp;nbsp;number of seconds the system will live.&lt;/li&gt;
	&lt;li&gt;System Grows Older: this flag must be set for the Lifespan value to be 
	used. It&amp;#39;s very important to remember that particle systems which reach the 
	end of their lifespan are automatically removed from the 
	ParticleSystemManager and if you want to reuse them, they should be added to 
	the ParticleSystemManager again.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;[Sample]&lt;/p&gt;
&lt;p&gt;&lt;code cxx&gt;PT(ParticleSystem) particle_sys = new ParticleSystem();
particle_sys-&gt;set_pool_size(100);
particle_sys-&gt;set_birth_rate(0.1);
particle_sys-&gt;set_litter_size(10);
particle_sys-&gt;set_litter_spread(0);
particle_sys-&gt;set_local_velocity_flag(true);
//particle_sys-&gt;set_spawn_on_death_flag(true); // this caused an exception!!
particle_sys-&gt;set_system_grows_older_flag(true);
particle_sys-&gt;set_system_lifespan(3.0);
particle_sys-&gt;set_active_system_flag(true);
// use it to advance system age, or start at some age
//particle_sys-&gt;set_system_age(5.0);
// system_age is updated only when set_system_grows_older_flag(true);
// get_system_age() returns 0 unless system_grows_older_flag is set&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The particle factory, emitter and renderer should be attached to the 
ParticleSystem and most important the render node should be set.&lt;/p&gt;
&lt;p&gt;&lt;code cxx&gt;particle_sys-&gt;set_factory(pt_particle_factory);
particle_sys-&gt;set_renderer(pt_particle_rend);
particle_sys-&gt;set_emitter(sphere_emitter);
// if spawn and render parents should be different
//particle_sys-&gt;set_spawn_render_node_path(window-&gt;get_render());
particle_sys-&gt;set_render_parent(window-&gt;get_render());&lt;/code&gt;&lt;/p&gt;
&lt;h3&gt;ParticleSystemManager:&lt;/h3&gt;
&lt;p&gt;This class is responsible for simplifying control of particle systems. 
Instead of stepping each particle system in the scene they are all added to the 
ParticleSystemManager and they can be all stepped using a single command or they 
can be stepped individually. This class is not count referenced so PT() and 
CPT() should not be used with it.&lt;/p&gt;
&lt;p&gt;To attach a particle system to the manager:&lt;code cxx&gt;particle_sys_mgr.attach_particlesystem(particle_sys);&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;To step all the particle systems:&lt;code cxx&gt;particle_sys_mgr.do_particles(ClockObject::get_global_clock()-&gt;get_dt());&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;To step a specific particle system:&lt;code cxx&gt;
particle_sys_mgr.do_particles(ClockObject::get_global_clock()-&gt;get_dt(), 
particle_sys);&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;NOTE: particle systems which reach the end of their lifespan are 
automatically removed from the ParticleSystemManager and if you want to reuse 
them, they should be added to the ParticleSystemManager again.&lt;/p&gt;
[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Particle Emitters</title>
    <ns>0</ns>
    <id>1004</id>
      <sha1>mie2e6j2hxap3afap7bw9yqdeyl7kxk</sha1>
    <revision>
      <id>4338</id>
      <timestamp>2007-05-30T17:15:19Z</timestamp>
      <contributor>
        <username>ShinjiHiko</username>
        <id>137</id>
      </contributor>
      <comment>Removed spam to Chinese websites.</comment>
      <text xml:space="preserve" bytes="4675">&lt;p&gt;There are a large number of particle emitters, each categorized by the volume of space they represent. Additionally, all emitters have three modes: explicit, radiate, and custom. Explicit mode emits the particles in parallel in the same direction. Radiate mode emits particles away from a specific point. Custom mode emits particles with a velocity determined by the particular emitter.&lt;/p&gt;
&lt;p&gt;All emitters have a number of common parameters.&lt;/p&gt;
&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Variable&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Values&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;emissionType&lt;/td&gt;&lt;td&gt;Emission mode&lt;/td&gt;&lt;td&gt;ET_EXPLICIT, ET_RADIATE, ET_CUSTOM&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;explicitLaunchVector&lt;/td&gt;&lt;td&gt;Initial velocity in explicit mode&lt;/td&gt;&lt;td&gt;(x, y, z)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;radiateOrigin&lt;/td&gt;&lt;td&gt;Point particles launch away from in radiate mode&lt;/td&gt;&lt;td&gt;(x, y, z)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;amplitude&lt;/td&gt;&lt;td&gt;Launch velocity multiplier&lt;/td&gt;&lt;td&gt;(-infinity, infinity)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;amplitudeSpeed&lt;/td&gt;&lt;td&gt;Spread for launch velocity multiplier&lt;/td&gt;&lt;td&gt;[0, infinity)&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;
&lt;p&gt;The following list contains the different types of emitters, their unique parameters, and the effect of the custom mode.&lt;/p&gt;
&lt;h3&gt;BoxEmitter&lt;/h3&gt;
&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Variable&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Values&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;minBound&lt;/td&gt;&lt;td&gt;Minimum point for box volume&lt;/td&gt;&lt;td&gt;(x, y, z)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;maxBound&lt;/td&gt;&lt;td&gt;Maximum point for box volume&lt;/td&gt;&lt;td&gt;(x, y, z)&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;
&lt;p&gt;Custom mode generates particles with no initial velocity.&lt;/p&gt;

&lt;h3&gt;DiscEmitter&lt;/h3&gt;
&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Variable&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Values&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;radius&lt;/td&gt;&lt;td&gt;Radius of disc&lt;/td&gt;&lt;td&gt;[0, infinity)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;outerAngle&lt;/td&gt;&lt;td&gt;Particle launch angle at edge of disc&lt;/td&gt;&lt;td&gt;[0, 360]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;innterAngle&lt;/td&gt;&lt;td&gt;Particle launch angle at center of disc&lt;/td&gt;&lt;td&gt;[0, 360]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;outerMagnitude&lt;/td&gt;&lt;td&gt;Launch velocity multiplier at edge of disc&lt;/td&gt;&lt;td&gt;(-infinity, infinity)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;innerMagnitude&lt;/td&gt;&lt;td&gt;Launch velocity multiplier at center of disc&lt;/td&gt;&lt;td&gt;(-infinity, infinity)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;cubicLerping&lt;/td&gt;&lt;td&gt;Whether or not magnitude/angle interpolation is cubic&lt;/td&gt;&lt;td&gt;Boolean&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;
&lt;p&gt;Custom mode uses the last five parameters. Particles emitted from areas on the inside use interpolated magnitudes and angles, either liner or cubic.&lt;/p&gt;

&lt;h3&gt;PointEmitter&lt;/h3&gt;
&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Variable&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Values&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;location&lt;/td&gt;&lt;td&gt;Location of outer point&lt;/td&gt;&lt;td&gt;(x, y, z)&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;
&lt;p&gt;Custom mode generates particles with no initial velocity.&lt;/p&gt;

&lt;h3&gt;RectangleEmitter&lt;/h3&gt;
&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Variable&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Values&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;minBound&lt;/td&gt;&lt;td&gt;2D point defining the rectangle&lt;/td&gt;&lt;td&gt;(x, z)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;maxBound&lt;/td&gt;&lt;td&gt;2D point defining the rectangle&lt;/td&gt;&lt;td&gt;(x, z)&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;
&lt;p&gt;Custom mode generates particles with no initial velocity.&lt;/p&gt;

&lt;h3&gt;RingEmitter&lt;/h3&gt;
&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Variable&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Values&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;radius&lt;/td&gt;&lt;td&gt;Radius of disc&lt;/td&gt;&lt;td&gt;[0, infinity)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;angle&lt;/td&gt;&lt;td&gt;Particle launch angle&lt;/td&gt;&lt;td&gt;[0, 360]&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;
&lt;p&gt;Custom mode uses the second parameter to emit particles at an angle with respect to the vector from the ring center to the spawn point. 0 degrees emits particles away from the center, and 180 degrees emits particles into the center.&lt;/p&gt;

&lt;h3&gt;SphereSurfaceEmitter&lt;/h3&gt;
&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Variable&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Values&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;radius&lt;/td&gt;&lt;td&gt;Radius of sphere&lt;/td&gt;&lt;td&gt;[0, infinity)&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;
&lt;p&gt;Custom mode generates particles with no initial velocity.&lt;/p&gt;

&lt;h3&gt;SphereVolumeEmitter&lt;/h3&gt;
&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Variable&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Values&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;radius&lt;/td&gt;&lt;td&gt;Radius of sphere&lt;/td&gt;&lt;td&gt;[0, infinity)&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;
&lt;p&gt;Custom mode emits particles away from the sphere center. Their velocity is dependent on their spawn location within the sphere. It is 0 at the center, of magnitude 1 at the outer edge of the sphere, and linearly interpolated in between.&lt;/p&gt;

&lt;h3&gt;TangentRingEmitter&lt;/h3&gt;
&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Variable&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Values&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;radius&lt;/td&gt;&lt;td&gt;Radius of ring&lt;/td&gt;&lt;td&gt;[0, infinity)&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;
&lt;p&gt;Custom mode emits particles tangentially to the ring edge, with a velocity magnitude of 1.&lt;/p&gt;</text>
    </revision>
  </page>
  <page>
    <title>Particle Factories</title>
    <ns>0</ns>
    <id>1005</id>
      <sha1>0mexjz20djfrrbjepzewh2sldjyq2kq</sha1>
    <revision>
      <id>2293</id>
      <timestamp>2005-04-16T21:38:09Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="1651">&lt;p&gt;There are two types of particle factories, Point and ZSpin. The particle panel shows a third, Oriented, but this factory does not currently work. The differences between these factories lie in the orientation and rotational abilities.&lt;/p&gt;
&lt;p&gt;First, there are some common variables to the factories.&lt;/p&gt;
&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Variable&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Values&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;lifespanBase&lt;/td&gt;&lt;td&gt;Average lifespan in seconds&lt;/td&gt;&lt;td&gt;[0, infinity)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;lifespanSpread&lt;/td&gt;&lt;td&gt;Variation in lifespan&lt;/td&gt;&lt;td&gt;[0, infinity)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;massBase&lt;/td&gt;&lt;td&gt;Average particle mass&lt;/td&gt;&lt;td&gt;[0, infinity)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;massSpread&lt;/td&gt;&lt;td&gt;Variation in particle mass&lt;/td&gt;&lt;td&gt;[0, infinity)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;terminalVelocityBase&lt;/td&gt;&lt;td&gt;Average particle terminal velocity&lt;/td&gt;&lt;td&gt;[0, infinity)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;terminalVelocitySpread&lt;/td&gt;&lt;td&gt;Variation in terminal velocity&lt;/td&gt;&lt;td&gt;[0, infinity)&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;
&lt;p&gt;Point particle factories generate simple particles. They have no additional parameters.&lt;/p&gt;
&lt;p&gt;ZSpin particle factories generate particles that spin around the Z axis, the vertical axis in Panda3D. They have some additional parameters.&lt;/p&gt;
&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Variable&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Values&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;initialAngle&lt;/td&gt;&lt;td&gt;Starting angle in degrees&lt;/td&gt;&lt;td&gt;[0, 360]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;initialAngleSpread&lt;/td&gt;&lt;td&gt;Spread of initial angle&lt;/td&gt;&lt;td&gt;[0, 360]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;finalAngle&lt;/td&gt;&lt;td&gt;Final angle in degrees&lt;/td&gt;&lt;td&gt;[0, 360]&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;fnalAngleSpread&lt;/td&gt;&lt;td&gt;Spread of final angle&lt;/td&gt;&lt;td&gt;[0, 360]&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;</text>
    </revision>
  </page>
  <page>
    <title>Particle Renderers</title>
    <ns>0</ns>
    <id>1006</id>
      <sha1>er8ndyryeueeqg8ngqlg37gqcd4cb85</sha1>
    <revision>
      <id>2294</id>
      <timestamp>2005-04-16T21:38:18Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="4431">&lt;p&gt;Particle renderers add particles to the visible scene graph according to the information stored in the particle objects and the type of renderer. All particle renderers have the following parameters:&lt;/p&gt;
&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Variable&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Values&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;alphaMode&lt;/td&gt;&lt;td&gt;Alpha setting over particle lifetime&lt;/td&gt;&lt;td&gt;PR_ALPHA_NONE, PR_ALPHA_OUT, PR_ALPHA_IN, PR_ALPHA_USER&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;userAlpha&lt;/td&gt;&lt;td&gt;Alpha value for ALPHA_USER alpha mode&lt;/td&gt;&lt;td&gt;Boolean&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;
&lt;p&gt;The following list contains the different types of renderers and their unique parameters.&lt;/p&gt;
&lt;h3&gt;PointParticleRenderer&lt;/h3&gt;
&lt;p&gt;Renders particles as pixel points.&lt;/p&gt;
&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Variable&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Values&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;pointSize&lt;/td&gt;&lt;td&gt;Width and height of points, in pixels&lt;/td&gt;&lt;td&gt;[0, infinity)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;startColor&lt;/td&gt;&lt;td&gt;Starting color&lt;/td&gt;&lt;td&gt;(r, g, b, a)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;endColor&lt;/td&gt;&lt;td&gt;Ending color&lt;/td&gt;&lt;td&gt;(r, g, b, a)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;blendType&lt;/td&gt;&lt;td&gt;How the particles blend from the start color to the end color&lt;/td&gt;&lt;td&gt;ONE_COLOR, BLEND_LIFE, BLEND_VEL&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;blendMethod&lt;/td&gt;&lt;td&gt;Interpolation method between colors&lt;/td&gt;&lt;td&gt;LINEAR, CUBIC&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;
&lt;p&gt;ONE_COLOR: point is always the starting color.&lt;br&gt;
BLEND_LIFE: color is interpolated from start to end according to the age of the point&lt;br&gt;
BLEND_VEL: color is interpolated between start to end according to the velocity/terminal velocity.&lt;/p&gt;

&lt;h3&gt;LineParticleRenderer&lt;/h3&gt;
&lt;p&gt;Renders particles as lines between their current position and their last position.&lt;/p&gt;
&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Variable&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Values&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;headColor&lt;/td&gt;&lt;td&gt;Color of leading end&lt;/td&gt;&lt;td&gt;(r, g, b, a)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;tailColor&lt;/td&gt;&lt;td&gt;Color of trailing end&lt;/td&gt;&lt;td&gt;(r, g, b, a)&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;

&lt;h3&gt;SparkleParticleRenderer&lt;/h3&gt;
&lt;p&gt;Renders particles star or sparkle objects, three equal-length perpendicular axial lines, much like jacks. Sparkle particles appear to sparkle when viewed as being smaller than a pixel.&lt;/p&gt;
&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Variable&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Values&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;centerColor&lt;/td&gt;&lt;td&gt;Color of center&lt;/td&gt;&lt;td&gt;(r, g, b, a)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;edgeColor&lt;/td&gt;&lt;td&gt;Color of edge&lt;/td&gt;&lt;td&gt;(r, g, b, a)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;birthRadius&lt;/td&gt;&lt;td&gt;Initial sparkle radius&lt;/td&gt;&lt;td&gt;[0, infinity)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;deathRadius&lt;/td&gt;&lt;td&gt;Final sparkle radius&lt;/td&gt;&lt;td&gt;[0, infinity)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;lifeScale&lt;/td&gt;&lt;td&gt;Whether or not sparkle is always of radius birthRadius&lt;/td&gt;&lt;td&gt;NO_SCALE, SCALE&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;

&lt;h3&gt;SpriteParticleRenderer&lt;/h3&gt;
&lt;p&gt;Renders particles as an image, using a Panda3D texture object. The image is always facing the user.&lt;/p&gt;
&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Variable&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Values&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;texture&lt;/td&gt;&lt;td&gt;Panda texture object to use as the sprite image&lt;/td&gt;&lt;td&gt;(r, g, b, a)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;color&lt;/td&gt;&lt;td&gt;Color&lt;/td&gt;&lt;td&gt;(r, g, b, a)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;xScaleFlag&lt;/td&gt;&lt;td&gt;If true, x scale is interpolated over particle’s life&lt;/td&gt;&lt;td&gt;Boolean&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;yScaleFlag&lt;/td&gt;&lt;td&gt;If true, y scale is interpolated over particle’s life&lt;/td&gt;&lt;td&gt;Boolean&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;animAngleFlag&lt;/td&gt;&lt;td&gt;If true, particles are set to spin on the Z axis&lt;/td&gt;&lt;td&gt;Boolean&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;initial_X_Scale&lt;/td&gt;&lt;td&gt;Initial x scaling factor&lt;/td&gt;&lt;td&gt;[0, infinity)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;final_X_Scale&lt;/td&gt;&lt;td&gt;Final x scaling factor&lt;/td&gt;&lt;td&gt;[0, infinity)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;initial_Y_Scale&lt;/td&gt;&lt;td&gt;Initial y scaling factor&lt;/td&gt;&lt;td&gt;[0, infinity)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;final_Y_Scale&lt;/td&gt;&lt;td&gt;Final y scaling factor&lt;/td&gt;&lt;td&gt;[0, infinity)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;nonAnimatedTheta&lt;/td&gt;&lt;td&gt;If false, sets the counterclockwise Z rotation of all sprites, in degrees&lt;/td&gt;&lt;td&gt;Boolean&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;alphaBlendMethod&lt;/td&gt;&lt;td&gt;Sets the interpolation blend method&lt;/td&gt;&lt;td&gt;LINEAR, CUBIC&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;alphaDisable&lt;/td&gt;&lt;td&gt;If true, alpha blending is disabled&lt;/td&gt;&lt;td&gt;Boolean&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;

&lt;h3&gt;GeomParticleRenderer&lt;/h3&gt;
&lt;p&gt;Renders particles as full 3D objects. This requires a geometry node.&lt;/p&gt;
&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Variable&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Definition&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;Values&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;geomNode&lt;/td&gt;&lt;td&gt;A geometry scene graph node&lt;/td&gt;&lt;td&gt;&lt;Node&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;</text>
    </revision>
  </page>
  <page>
    <title>Particles</title>
    <ns>0</ns>
    <id>2314</id>
    <redirect title="Particle Effects" />
      <sha1>1z3p5zry7xv78wpk247l9ahozywo2e7</sha1>
    <revision>
      <id>5697</id>
      <timestamp>2009-02-18T15:41:43Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[Particle Effects]]</comment>
      <text xml:space="preserve" bytes="30">#REDIRECT [[Particle Effects]]</text>
    </revision>
  </page>
  <page>
    <title>Patching</title>
    <ns>0</ns>
    <id>2211</id>
      <sha1>9nvok3gv5t1h22lb41cm7rbgl6napuz</sha1>
    <revision>
      <id>6665</id>
      <timestamp>2010-02-09T09:52:04Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <text xml:space="preserve" bytes="1762">Patching is a process of generating the difference between 2 files:

&lt;code python&gt;
p = Patchfile()
p.build(Filename('version_1.mf'), Filename('version_2.mf'), Filename('v1_to_v2.patch'))
&lt;/code&gt;

This will generate the file v1_to_v2.patch based on the differences between version_1.mf and version_2.mf.  Then when you have version_1.mf and v1_to_v2.patch, you can produce version_2.mf with:

&lt;code python&gt;
p = Patchfile()
p.apply(Filename('v1_to_v2.patch'), Filename('version_1.mf'))
&lt;/code&gt;

There are other, more esoteric options, for limiting memory usage during patching, or for patching in increments instead of all at once so you can update a progress bar.

In the example above the files are named *.mf. This example suggests that you might be patching files in Panda's Multifile format (*.mf). The multifiles can store multiple resources like bams, textures, mp3's, and so on, and Panda can load them from directly from the multifiles without having to unpack them first.

The Patchfile object works on any arbitrary binary files; you don't need to limit yourself to just patching multifiles. However, the Patchfile does recognize a multifile and treats it as a special case; it can build patches for large multifiles without running out of memory, while building a patch for a large generic binary file might require so much memory it brings your system to its knees. (Applying patches doesn't require much memory, however.)

Patchfiles are not automatically compressed. You can do that yourself. Also, I recommend patching uncompressed source files for best results. (You can build patches against compressed source files, but the resulting patchfiles will tend to be much larger than the same patchfiles built against the original uncompressed files.)</text>
    </revision>
  </page>
  <page>
    <title>Path Follow</title>
    <ns>0</ns>
    <id>2589</id>
      <sha1>eahjyyw1oj4angq70k49vektihgb2c8</sha1>
    <revision>
      <id>7706</id>
      <timestamp>2012-03-09T10:30:26Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>new import system</comment>
      <text xml:space="preserve" bytes="3612">&lt;b&gt;'Path Follow'&lt;/b&gt; is a behavior where an AICharacter moves from one path to the other without stopping at any path. It can be used for a patrolling type of behavior.


{{#ev:youtube|hIDyzUJgu2w}}


-----

&lt;b&gt;In PandAI, path follow is defined as :&lt;/b&gt;
&lt;code python&gt;
aiBehaviors.pathFollow(float priority)
aiBehaviors.addToPath(Vec3 position)

aiBehaviors.startFollow() // Required to start the follow
&lt;/code&gt;

&lt;b&gt;Position&lt;/b&gt; is a point in 3D space which falls on the path which the AI Character needs to traverse. 

(&lt;b&gt;Note:&lt;/b&gt; that you need to add multiple positions to create a path say for example Vec3(-10,10,0) Vec3(0,0,0) Vec3(10,10,0) Vec3(-10,10,0) will generate a rectangular path in the XY plane)

&lt;b&gt;Note:&lt;/b&gt; the addToPath works backwards. So, your last call to addToPath will be your first position your AICharacter will go to.

-----


&lt;b&gt;The full working code in Pand3D is :&lt;/b&gt;

&lt;code python&gt;
import direct.directbase.DirectStart
from panda3d.core import *
from direct.showbase.DirectObject import DirectObject
from direct.task import Task
from direct.actor.Actor import Actor
#for Pandai
from panda3d.ai import *

class World(DirectObject):

    def __init__(self):
        base.disableMouse()
        base.cam.setPosHpr(0,0,55,0,-90,0)
        
        self.loadModels()
        self.setAI()
       
    def loadModels(self):
        # Seeker
        ralphStartPos = Vec3(-10, 0, 0)
        self.seeker = Actor(&quot;models/ralph&quot;,
                                 {&quot;run&quot;:&quot;models/ralph-run&quot;})
        self.seeker.reparentTo(render)
        self.seeker.setScale(0.5)
        self.seeker.setPos(ralphStartPos)
        # Target1
        self.target1 = loader.loadModel(&quot;models/arrow&quot;)
        self.target1.setColor(1,0,0)
        self.target1.setPos(10,-10,0)
        self.target1.setScale(1)
        self.target1.reparentTo(render)
        # Target2
        self.target2 = loader.loadModel(&quot;models/arrow&quot;)
        self.target2.setColor(0,1,0)
        self.target2.setPos(10,10,0)
        self.target2.setScale(1)
        self.target2.reparentTo(render)
        # Target3
        self.target3 = loader.loadModel(&quot;models/arrow&quot;)
        self.target3.setColor(0,0,1)
        self.target3.setPos(-10,10,0)
        self.target3.setScale(1)
        self.target3.reparentTo(render)
        # Target4
        self.target4 = loader.loadModel(&quot;models/arrow&quot;)
        self.target4.setColor(1,0,1)
        self.target4.setPos(-10,-10,0)
        self.target4.setScale(1)
        self.target4.reparentTo(render)
        
        self.seeker.loop(&quot;run&quot;)
      
    def setAI(self):
        #Creating AI World
        self.AIworld = AIWorld(render)
 
        self.AIchar = AICharacter(&quot;seeker&quot;,self.seeker, 60, 0.05, 5)
        self.AIworld.addAiChar(self.AIchar)
        self.AIbehaviors = self.AIchar.getAiBehaviors()
        
        #Path follow (note the order is reveresed)
        self.AIbehaviors.pathFollow()
        self.AIbehaviors.addToPath(self.target4.getPos())
        self.AIbehaviors.addToPath(self.target3.getPos())
        self.AIbehaviors.addToPath(self.target2.getPos())
        self.AIbehaviors.addToPath(self.target1.getPos())

        self.AIbehaviors.startFollow()

        #AI World update
        taskMgr.add(self.AIUpdate,&quot;AIUpdate&quot;)
        
    #to update the AIWorld    
    def AIUpdate(self,task):
        self.AIworld.update()            
        return Task.cont
 
w = World()
run()
&lt;/code&gt;

&lt;b&gt;To get the full working demo, please visit :&lt;/b&gt;

https://sites.google.com/site/etcpandai/documentation/steering-behaviors/path-follow/PandAIPathFollowTutorial.zip?attredirects=0&amp;d=1</text>
    </revision>
  </page>
  <page>
    <title>Pathfinding</title>
    <ns>0</ns>
    <id>2591</id>
      <sha1>s33bgbg7o25dixef8uxvv37qn08gqzw</sha1>
    <revision>
      <id>7470</id>
      <timestamp>2011-12-24T12:43:31Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="2120">&lt;b&gt;Pathfinding&lt;/b&gt;

This deals with the NPC’s ability to calculate the best route between two traversable points in your Panda3D environment.  It requires the creation of a navigation mesh (see “Navigation Mesh” under &quot;Mesh Generator&quot; page), which is placed on the surface over which your NPC will be moving.  The navigation mesh allows the system to recognize “traversable nodes” around the mesh, as well as areas which cannot be traversed (areas occupied by an impediment or obstacle for instance).



&lt;b&gt;Using the PandAI pathfinding system:&lt;/b&gt;
&lt;code python&gt;
aiBehaviors.initPathFind(string filename)
&lt;/code&gt;

This function activates the path finding with A* for the AI Character. 
Filename is the name of the file that is generated by the &lt;b&gt;Mesh Generator&lt;/b&gt; (Covered in the next section of the manual).

(Note: The file is in .csv format)


&lt;code python&gt;
aiBehaviors.pathFindTo(NodePath np, string type)

aiBehaviors.pathFindTo(Vec3 pos, string type)
&lt;/code&gt;
This function finds the best path via A* algorithm (with Binary Heap optimizations) for the AI Character to reach the target destination and then invokes the path follower to make the object follow the path.

It can accept both NodePath and Vec3 as input position. NodePath is used when the destination is not static. Vec3 is used when the destination is going to be static.

If the AI Character needs to pathfind continuously(say after he has finished traversing to a position, a new destination is acquired ) then input string type as “addPath” else leave as default.


&lt;code python&gt;
addStaticObstacle(NodePath obstacle);
&lt;/code&gt;

This function is used if the programmer wants to add Obstacles after the mesh has been generated (Say a stack of boxes fall down and blocks the way) to trigger events. It adds a static obstacle to the navigation mesh and pathfinds around it.


&lt;code python&gt;
addDynamicObstacle(NodePath obstacle);
&lt;/code&gt;

This functions work similar to addStaticObstacle except that in this case the obstacles can move and are not static. This is more processor heavy so if your object is not moving, use the prior instead.</text>
    </revision>
  </page>
  <page>
    <title>Pdeploy</title>
    <ns>0</ns>
    <id>2452</id>
    <redirect title="Distributing as a self-contained installer" />
      <sha1>olebnwcxjva22oi5b64e328nejxtw6f</sha1>
    <revision>
      <id>6565</id>
      <timestamp>2010-01-24T19:08:40Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>Redirecting to [[Distributing as a self-contained installer]]</comment>
      <text xml:space="preserve" bytes="56">#REDIRECT [[Distributing as a self-contained installer]]</text>
    </revision>
  </page>
  <page>
    <title>Performance Issue: Collision System Misuse</title>
    <ns>0</ns>
    <id>2204</id>
      <sha1>l5zq7p6h61inkaktutc418sp57lihh4</sha1>
    <revision>
      <id>5102</id>
      <timestamp>2008-03-15T01:23:15Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="88">&lt;h2&gt;Incomplete Section&lt;/h2&gt;

Note: this section is incomplete.  It will be updated soon.</text>
    </revision>
  </page>
  <page>
    <title>Performance Issue: Excessive Fill</title>
    <ns>0</ns>
    <id>2200</id>
      <sha1>8d136g870m6gdavkcf5srhplrpbh6dm</sha1>
    <revision>
      <id>7844</id>
      <timestamp>2012-09-26T19:30:12Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>note about transparency modes</comment>
      <text xml:space="preserve" bytes="1088">&lt;h2&gt;Transparency&lt;/h2&gt;
In general, it is better for your graphics card to render the polygons front-to-back, because a depth test can be used to toss out the occluded fragments before they are written to the framebuffer.

When enabling the M_alpha or M_dual transparency modes, however, Panda forces the nodes with this transparency mode to be sorted back-to-front.  This is necessary for alpha blending to work correctly.  If you have many occluded polygons in view, for example thousands of blades of grass that are positioned behind each other, this may quickly consume your fill rate.

Do not enable transparency modes unless it is necessary, and when you do, consider using the M_binary mode, which does not require back-to-front sorting.   However, if alpha blending is required and if large areas of the polygons are fully transparent, using M_dual may provide an improvement over M_alpha.

For a more in-depth explanation on the various transparency modes, see [[Transparency and Blending]].

&lt;h2&gt;Incomplete Section&lt;/h2&gt;

Note: this section is incomplete.  It will be updated soon.</text>
    </revision>
  </page>
  <page>
    <title>Performance Issue: Failure to Garbage Collect</title>
    <ns>0</ns>
    <id>2203</id>
      <sha1>l5zq7p6h61inkaktutc418sp57lihh4</sha1>
    <revision>
      <id>5101</id>
      <timestamp>2008-03-15T01:23:05Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="88">&lt;h2&gt;Incomplete Section&lt;/h2&gt;

Note: this section is incomplete.  It will be updated soon.</text>
    </revision>
  </page>
  <page>
    <title>Performance Issue: Memory Full</title>
    <ns>0</ns>
    <id>2201</id>
      <sha1>l5zq7p6h61inkaktutc418sp57lihh4</sha1>
    <revision>
      <id>5099</id>
      <timestamp>2008-03-15T01:22:47Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="88">&lt;h2&gt;Incomplete Section&lt;/h2&gt;

Note: this section is incomplete.  It will be updated soon.</text>
    </revision>
  </page>
  <page>
    <title>Performance Issue: Miscellaneous</title>
    <ns>0</ns>
    <id>2207</id>
      <sha1>36j6kqah4tle65txpp49xbt4wkz9m0x</sha1>
    <revision>
      <id>5368</id>
      <timestamp>2008-05-05T10:24:04Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>added a bit info.</comment>
      <text xml:space="preserve" bytes="841">This page lists a number of miscellaneous things that can possibly be a cause of bad performance in your game.

* You are using textures with a width or height that is not a power of two. This could cause Panda3D to resize the textures, which can slow your game down a lot. Always try to stick to powers of two when [[choosing a Texture Size]].
* You are printing too much to the console every frame. Printing to the console, especially on windows, can cause a slow-down of your application. Always check your console whether its not flooded with errors or debug messages. You might want to consider output buffering or, on windows, using pythonw (python running with windows subsystem instead of console subsystem) if you are experiencing this issue.

&lt;h2&gt;Incomplete Section&lt;/h2&gt;

Note: this section is incomplete.  It will be updated soon.</text>
    </revision>
  </page>
  <page>
    <title>Performance Issue: Motherboard Integrated Video</title>
    <ns>0</ns>
    <id>2205</id>
      <sha1>l5zq7p6h61inkaktutc418sp57lihh4</sha1>
    <revision>
      <id>5103</id>
      <timestamp>2008-03-15T01:23:25Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="88">&lt;h2&gt;Incomplete Section&lt;/h2&gt;

Note: this section is incomplete.  It will be updated soon.</text>
    </revision>
  </page>
  <page>
    <title>Performance Issue: Python Calculation</title>
    <ns>0</ns>
    <id>2202</id>
      <sha1>3qycnvrs13z1n37s07z75ukoyk74j0s</sha1>
    <revision>
      <id>7564</id>
      <timestamp>2012-01-11T20:04:13Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <text xml:space="preserve" bytes="2778">&lt;h2&gt;Performance Issue: Python Calculation&lt;/h2&gt;

The Panda3D engine is mostly written in C++, not Python. It would be false to assume that Panda3D is always slower than other game engines when used with Python. When you call a function in Python, Python calls the C++ equivalent, same for classes. For example, when you load a model, Panda3D's C++ side does all the job of reading from the 3d file, creating the vertices, faces, applying the materials, textures and so on. The Python overhead is usually very small.
Many other games and game engines use scripting languages for writing the game logic code, because usually the difference in performance time is negligible and scripting languages clearly win when it comes to development time.

However there are certain situations when you need to do some heavy calculations yourself and Python can be up to 100x slower than C++. This does not mean you need to abandon Python and rewrite all your code in C++ for that single bottleneck. Only that single function or class can be ported to C++ and called from your Python code.

You might be able to get away with not using C++ at all though.

* See if you can optimize your code. The Python website has a [http://wiki.python.org/moin/PythonSpeed/PerformanceTips page] for various performance tips. Very often performance can be improved by simply writing better Python code.
* There are many Python libraries which can improve performance for certain tasks, like [http://numpy.scipy.org/ Numpy].
* The [http://cython.org/ Cython] language is also an option. Read [http://www.panda3d.org/blog/?p=173 this] blog entry to find out more about Cython and how it can be used with Panda3D.

If none of these options help you, you will have to write a C++ version of the bottleneck function or class and make it accessible from your Python code. [http://wiki.python.org/moin/IntegratingPythonWithOtherLanguages#C.2BAC8-C.2B-.2B- This] page from the Python website shows you the many options you have.

Note that unlike Python modules, C++ modules are not cross-platform and might not run on another OS or platform. This is why it's a good idea to save this option for last. You will have to have one compiled module for every platform your game is meant to run on. You can do something like this if you want to be really sure that your game will run on any platform out-of-the-box:

&lt;code python&gt;
try:
    import cVersionOfModule
except ImportError:
    import pythonVersionOfModule
&lt;/code&gt;

Then the game will use the Python version of the module if the C++ version will fail to load. Your game will use the slow Python version in that case, but at least it won't crash.

Note: unlike modifying Panda3D's source, compiling a C++ module doesn't require you to recompile the whole engine.</text>
    </revision>
  </page>
  <page>
    <title>Performance Issue: Too Many Meshes</title>
    <ns>0</ns>
    <id>2197</id>
      <sha1>9ygxu4gcreflpsiy8pznsgeyp5b2ldn</sha1>
    <revision>
      <id>7514</id>
      <timestamp>2011-12-25T09:47:51Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>added info on culling and flattenStrong()</comment>
      <text xml:space="preserve" bytes="1747">If you have too many nodes/meshes in your scene, this might result in slow performance. You can check your Geom count in [[PStats]], or by calling &lt;code&gt;NodePath.analyze()&lt;/code&gt; on your object or scene.

Panda3D provides a function to reduce the mesh count: NodePath.flattenStrong(). This will reduce the NodePath to only one node. Be careful with this function: Usage without care might cause your game to crash, since you will not be able to move individual subnodes of a flattened node around anymore. Also note that flattening your whole world like this is a bad idea, as you will break culling, which will cause your whole world to be rendered even if your camera is rendering only a small part of it. You will need to find a balance.

NodePath.flattenMedium() and flattenLight() are not as rigorous NodePath.flattenStrong(), but may be worth considering.

Though, if you have multiple independently-moving rigid nodes, the flattening functions might not suit your needs, because, since the flattening functions flatten everything to one node you won't be able to move individual sub-nodes around. An alternative is [[the Rigid Body Combiner]], which can combine multiple nodes while you can still change the transforms on the sub-nodes.

If you are using the [[GeoMipTerrain]] for terrain rendering, that might also result in a large mesh count. (You can check the block count by calling &lt;code&gt;terrain.getRoot().analyze()&lt;/code&gt;.) If it is too high, try increasing the block size, or enable AutoFlattening, which will reduce the block count to only one. The autoflatten function was created because normally you can't flatten a terrain using the normal flattenX methods, because this will interfere with the GeoMipTerrain's updating system.</text>
    </revision>
  </page>
  <page>
    <title>Performance Issue: Too Many Pixel Shader Instructions</title>
    <ns>0</ns>
    <id>2268</id>
    <redirect title="Performance Issue: Too Many Shader Instructions" />
      <sha1>d4aur5ungaucjwuznacyjxmi2716m85</sha1>
    <revision>
      <id>5468</id>
      <timestamp>2008-09-14T16:31:37Z</timestamp>
      <contributor>
        <username>Azraiyl</username>
        <id>190</id>
      </contributor>
      <comment>[[Performance Issue: Too Many Pixel Shader Instructions]] moved to [[Performance Issue: Too Many Shader Instructions]]: Page handles vertex and fragment shaders.</comment>
      <text xml:space="preserve" bytes="61">#REDIRECT [[Performance Issue: Too Many Shader Instructions]]</text>
    </revision>
  </page>
  <page>
    <title>Performance Issue: Too Many Polygons</title>
    <ns>0</ns>
    <id>2206</id>
      <sha1>1c9gks80c03ojdb4qixd6syos187pwz</sha1>
    <revision>
      <id>7539</id>
      <timestamp>2011-12-30T08:03:41Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <text xml:space="preserve" bytes="2716">&lt;h2&gt;Performance Issue: Too Many Polygons&lt;/h2&gt;

&lt;p&gt;Even though modern GPUs can handle millions of polygons and vertex data takes little space in RAM, there is still a limit and it's not very difficult to reach it.&lt;/p&gt;

First thing you should make sure is that your performance issue is indeed caused by too many polygons. Even though modern GPUs can render millions of polygons in realtime, they still can't render more than few hundred meshes (Geoms) at the same speed. So you won't have problem rendering 300 polygons as 1 Geom in realtime, but you will torture your GPU if you'll try to render 300 Geoms, even if each has a single polygon. There are few ways to find out the Geom count and many solutions for lowering it which are discussed in the [[Performance Issue: Too Many Meshes|appropriate page]].
&lt;p&gt;Another issue might be using too many polygons on animated meshes (Actors). When you play an animation, Panda or your GPU need to calculate the new position of each vertex associated with a joint, even though the GPU will render the mesh at the same speed, the calculations done for the animation can get expensive themselves. You can easily find out the time spent on skinning with PStats:&lt;/p&gt;

&lt;br&gt;&lt;br&gt;
[[Image:Pstats-skinning-time.png]]
&lt;br&gt;&lt;br&gt;

&lt;p&gt;Other factors might affect the performance which are not solely based on the polygon count. Is your mesh textured? is it shaded? Does it have the ShaderGenerator enabled on it or does it use custom shaders? Does it have normal/gloss/glow maps? Is backface culling enabled? These all can affect the performance.&lt;/p&gt;

&lt;p&gt;If you are sure that your performance issue is caused by too many polygons, there are few optimizations you can do.&lt;/p&gt;

*The first obvious solution is to just make your models lowpoly or not use two polygons where you can use one. However, you should also note that per-vertex lightning uses vertices to shade the mesh, so a wall consisting of one single quad won't shade the same way as a wall consisting of multiple quads. You'll need to find a balance or use per-pixel lightning.

*You can have [[Level of Detail|multiple levels of detail]] for your mesh.

*If you have a highpoly model, you can create a lowpoly version of it and generate a normal map from the highpoly model which you can assign to your lowpoly version in Panda. Normal mapping requires lightning and the ShaderGenerator or a custom shader.

*Sometimes it's possible to represent a mesh as a textured plane [[Billboard Effects|billboard]].

*See if you can lower the [[Lenses and Field of View|far distance or far plane]] of the camera lens. Anything farther than the far plane of the camera lens won't be rendered. You can use [[Fog|fog]] to hide the clipping.</text>
    </revision>
  </page>
  <page>
    <title>Performance Issue: Too Many Shader Instructions</title>
    <ns>0</ns>
    <id>2199</id>
      <sha1>c2yybx4fxfiw4p1trqjvxtbe1gu4ooj</sha1>
    <revision>
      <id>7758</id>
      <timestamp>2012-04-22T09:21:18Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>&quot;setShaderAuto&quot;, not &quot;setAutoShader&quot;</comment>
      <text xml:space="preserve" bytes="1677">This only can happen if you have at least one &lt;code&gt;NodePath.setShader&lt;/code&gt; or &lt;code&gt;NodePath.setShaderAuto&lt;/code&gt; method call in your application, or you are using a post processing filter from CommonManager.

&lt;h2&gt;Too Many Vertex Shader Instructions&lt;/h2&gt;

Try so simplify your scene. Objects that are far away don't need millions of vertices. Look at LODNode and FadeLODNode.

&lt;h2&gt;Too Many Fragment/Pixel Shader Instructions&lt;/h2&gt;

An easy way to detect whether this is a bottleneck in your application, try resizing the window. If the framerate heavily varies with the window size or screen resolution, you're most likely dealing with this problem.

If your frame rate strong depends on the window or screen resolution, this may be one hint that your fragment shader has too many instructions. Another problem is if your depth complexity is too high. Try to look at your scene from different angles and positions. If your frame rate varies then the overdraw from one specific view angle is to high.

Try to minimize the objects Panda3D needs to draw. Use &lt;code&gt;lens.setFar&lt;/code&gt;, or fallback to a simpler fragment shaders for objects that are far away. If an object is far away from the viewer it doesn't make sense to apply normal mapping. LODNode and FadeLODNode may help.

If your fragment shader is self made, then try to offload some work to your vertex shader.

There is a simple method to test your scene. Replace your whole fragment shader with the following snippet:

&lt;pre class=&quot;codeblock&quot;&gt;
o_color = float4(1.0, 0.0, 1.0, 0.0);
&lt;/pre&gt;

If the frame rate doesn't change, then it is the depth complexity. It if changes it may be the depth complexity or the shader.</text>
    </revision>
  </page>
  <page>
    <title>Performance Issue: Too Many State Changes</title>
    <ns>0</ns>
    <id>2198</id>
      <sha1>l5zq7p6h61inkaktutc418sp57lihh4</sha1>
    <revision>
      <id>5096</id>
      <timestamp>2008-03-15T01:22:20Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="88">&lt;h2&gt;Incomplete Section&lt;/h2&gt;

Note: this section is incomplete.  It will be updated soon.</text>
    </revision>
  </page>
  <page>
    <title>Performance Issue: Too Many Text Updates</title>
    <ns>0</ns>
    <id>2310</id>
      <sha1>6ldv9fmz5ei6lb4kilzkkezz8fuey35</sha1>
    <revision>
      <id>5667</id>
      <timestamp>2008-12-31T20:14:47Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <comment>clarify 1.6.0 rules</comment>
      <text xml:space="preserve" bytes="1168">If you are using the [[TextNode]] or [[OnscreenText]] (or similar) interfaces, and you have large chunks of text changing every frame, you might find it to be a big performance hit. Panda3D does a lot of work to assemble the text, so you will want to minimize unnecessary calls to &lt;code&gt;setText()&lt;/code&gt; or related functions that force the text to be recomputed.

On the other hand, if you really want to change your text frequently, you can try putting this in your [[Config.prc]] file:&lt;pre class=&quot;codeblock&quot;&gt;
text-flatten 0
&lt;/pre&gt;

this will remove the call to flattenStrong() within the text generation process. Changing the text will be much faster, but rendering the resulting text will be slower, since you will be dealing with [[Performance Issue: Too Many Meshes|a lot of meshes]] in your scene graph.

Panda3D 1.6.0 and later contain a performance optimization that speeds up the text generation. If you have this version, you will also need the following line in your Config.prc, in addition to the text-flatten line, to achieve the same effect (though this is not recommended, for the reason stated above):&lt;pre class=&quot;codeblock&quot;&gt;
text-dynamic-merge 0
&lt;/pre&gt;</text>
    </revision>
  </page>
  <page>
    <title>Performance Tuning</title>
    <ns>0</ns>
    <id>2196</id>
      <sha1>cb53hdn21u18xvl070izq0kbzv4taze</sha1>
    <revision>
      <id>7495</id>
      <timestamp>2011-12-24T13:18:06Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="8857">&lt;h2&gt;Modern Performance Tuning Introduction&lt;/h2&gt;

Inexperienced game programmers, when they see that their programs are running
slow, often react by trying to reduce the number of polygons.  This almost
never makes any difference whatsoever.  Back in the mid-90's, reducing polygon counts was a reasonable strategy to make games faster.  That strategy just
doesn't work any more.  The reason for this is that video card manufacturers
have been increasing the polygon limits of their video cards by leaps and
bounds.  In fact, they've raised the polygon limit so high that you
almost never hit that limit any more: you usually hit some &lt;i&gt;other&lt;/i&gt; limit
first.

That's the key to modern performance tuning: knowing all the limits
of the machine &lt;i&gt;other&lt;/i&gt; than the polygon limit, and figuring out &lt;i&gt;which&lt;/i&gt; of those limitations you've run into.  In other words,
the key to modern performance tuning is &lt;i&gt;diagnosis&lt;/i&gt;.

&lt;h2&gt;Most Common Problem: Silly Little Bugs&lt;/h2&gt;

When people start performance tuning, they often start with the assumption that
there's something serious wrong with the engine, or the design of
the game.  In my experience, however, 90% of the time the problem is that
the game contains a silly (but destructive) bug.  Here are some examples of bugs that I have seen:

* A game had a text readout in the corner of the screen, which got updated every frame.  But they updated the text by creating a new text object, and forgot to remove the old text object.  So the corner of the screen contained thousands of layers of accumulated messages.

* A shooter allowed you to fire bullets from your gun.  But they forgot to remove the bullet after it collided with a wall.  As a result, the bullets just kept going through the wall, and into outer space.  Every bullet you or anyone else had ever fired was still flying through space, and the animation system was working like crazy to animate tens of thousands of bullets.

* Think of another example here.

I cannot emphasize this too much: do &lt;i&gt;not&lt;/i&gt; redesign your game, until
you are &lt;i&gt;sure&lt;/i&gt; that the problem isn't a typo!  Imagine how irritated
you would be if you wrote an MMO, and then spent six months re-engineering
it to make it faster, only to discover that the entire performance problem
was an off-by-one error in a minor subroutine.

Catching performance problems that are bugs can be tricky.  The place to
begin is using the same performance diagnostics that you would use for
any other problem.  However, you will usually find a red flag somewhere:
if the performance monitoring tools say that you're rendering 50,000 models,
but you only count 50 models on the screen, you're dealing with a bug.
You need to be alert enough not to discount such red flags.  If you see
a stat that looks suspicious, don't assume that the performance monitoring
tool is telling you the wrong thing --- assume that there's a bug in the code.

&lt;h2&gt;How Fast Should it Run?&lt;/h2&gt;

One of the things that makes performance tuning difficult is that you 
need to find things that are running slower than they &quot;should&quot; - but how
do you know how fast something &quot;should&quot; run?  Experienced game programmers
have a gut feel for what their video card should be capable of, but
inexperienced ones often don't really know what to expect.  This makes
performance tuning that much harder.

However, you have an advantage.  We have a collection of 
[[Sample Programs in the Distribution|sample programs]]
demonstrating Panda3D features.  It is easy to turn on the frame-rate
meter to see how fast these samples run.  The screenshots in the manual
contain frame-rates, taken with a Radeon x700.  That should give you a
baseline.  It is even more informative to turn on the frame-rate meter
to see what your video card can deliver.

&lt;b&gt;Video Synchronisation&lt;/b&gt;&lt;br /&gt;
Panda3D sometimes caps the framerate to not exceed the monitor's refresh rate: this is called video synchronization. Panda3D knows that since the monitor can't refresh faster (the monitor refresh rate is usually between 60 and 85 Hz), everything above that rate is wasted, so Panda3D will not refresh faster than the monitor's refresh rate. To disable this and be able to see the 'true' framerate, set the config variable &lt;code&gt;sync-video&lt;/code&gt; to &lt;code&gt;#f&lt;/code&gt; in your [[Config.prc]].

&lt;h2&gt;List of Common Performance Issues&lt;/h2&gt;

Here is a list of things that can go wrong, roughly in order from most likely
to least likely.  Each of these has a section to explain it in greater detail.

&lt;li&gt;[[Performance Issue: Too Many Meshes]]. A well-made typical 3D model contains one mesh.  Huge 3D models, such as the model of an entire dungeon or an entire island, might contain multiple meshes. 3D models created by inexperienced modelers can contain dozens of meshes.  Most video cards can render about 300 meshes total for the entire scene.  Panda3D contains tools to coalesce multiple meshes into one, but they aren't fully automatic.

&lt;br&gt;&lt;br&gt;&lt;li&gt;[[Performance Issue: Too Many State Changes]].  The &lt;i&gt;state&lt;/i&gt; of an object is the sum of its color, material, light, fog, and other attributes.  It can be expensive, for a variety of reasons, to have too many different states in your scene.  It is better if many objects share the same state.

&lt;br&gt;&lt;br&gt;&lt;li&gt;[[Performance Issue: Too Many Text Updates]].  If you have lots of text in your game that gets updated every frame, it will often take a long time for Panda to keep regenerating the text. You need to minimize the amount of text to regenerate per frame.

&lt;br&gt;&lt;br&gt;&lt;li&gt;[[Performance Issue: Too Many Pixel Shader Instructions]]. If you are using per-pixel lighting, or hand-written shaders, you need to be conscious of how long your shaders are.  Adding one pixel shader instruction can slow the video card a lot.  Adding a texture lookup can slow it even more.  Professional pixel shaders contain 20-30 assembly-level instructions.

&lt;br&gt;&lt;br&gt;&lt;li&gt;[[Performance Issue: Excessive Fill]].  The fill rate of the video card is number of pixels it can render per second.  Objects that are occluded (behind other objects) still consume fill rate.  The total fill-consumption of
the scene is the total screen real estate of all objects, including the
occluded ones.  Particles, in particular, can consume fill-rate like crazy, especially if the camera gets close to the particles.

&lt;br&gt;&lt;br&gt;&lt;li&gt;[[Performance Issue: Memory Full]].  A floating point-number takes four bytes.  Just one vertex contains (X,Y,Z), and a normal, and a texture coordinate.  An RGBA color takes four bytes, so a 1024x1024 texture is four megabytes.  Do the math, and you'll see how fast it all adds up.

&lt;br&gt;&lt;br&gt;&lt;li&gt;[[Performance Issue: Python Calculation]].  Python is a very slow
language.  Most Panda3D programs only run a few thousand lines of python per frame, since all the real work is done in C++.  Sometimes, though, you
need to do some complex calculation, and Panda3D just doesn't contain any
C++ code to do it for you.  In that case, trying to write the calculation
in python can cause problems.  You may need a C++ plug-in.

&lt;br&gt;&lt;br&gt;&lt;li&gt;[[Performance Issue: Failure to Garbage Collect]].  It's easy
to get used to the fact that Python's garbage collector can automatically
clean up Panda3D data structures.  Unfortunately, there are a few structures
that can't be cleaned up automatically.  You need to know what they are,
or you may end up with a leak.

&lt;br&gt;&lt;br&gt;&lt;li&gt;[[Performance Issue: Collision System Misuse]].  The collision
system can detect most types of collisions very rapidly.  However, it is
possible to construct situations that the collision detection system just
can't handle.  Know what it's good at, and what it's not.

&lt;br&gt;&lt;br&gt;&lt;li&gt;[[Performance Issue: Motherboard Integrated Video]].  Motherboard
video is very misleading.  The chips have names like &quot;Radeon&quot; and &quot;GeForce&quot; that we have come to associate with speed, but these chips are an order of magnitude
slower than real video cards.  Programming for these chips requires special consideration.

&lt;br&gt;&lt;br&gt;&lt;li&gt;[[Performance Issue: Too Many Polygons]].  This is at the bottom of the likelihood list, but it can still happen. Usually this happens in combination with something else, e.g. if you have a large vertex shader, performance can be drastically reduced for each vertex you add.

&lt;br&gt;&lt;br&gt;&lt;li&gt;[[Performance Issue: Miscellaneous]].  There are a lot of small things that have a surprisingly large impact on performance.  For instance, printing messages on the console can be very slow in Windows.  This section lists a number of miscellaneous things that can bog you down.
&lt;br&gt;&lt;br&gt;
A recommended read about performance tuning is also chapter 28 of the book GPU Gems:&lt;br&gt;
http://developer.download.nvidia.com/books/HTML/gpugems/gpugems_ch28.html

&lt;h2&gt;Incomplete Section&lt;/h2&gt;

Note: this section is incomplete.  It will be updated soon.</text>
    </revision>
  </page>
  <page>
    <title>Physics</title>
    <ns>0</ns>
    <id>2281</id>
      <sha1>kpbdtrprsan3jq2cht5hmhqxnwo4z97</sha1>
    <revision>
      <id>60481</id>
      <timestamp>2015-04-12T15:07:59Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>update forum links</comment>
      <text xml:space="preserve" bytes="1411">Panda3D offers four built-in choices to use for Physics:

* &lt;b&gt;[[Panda's Built-in Physics Engine]]&lt;/b&gt;: Panda3D has a very basic physics engine built-in that may apply forces to classes. The physics engine can handle angular or linear forces, as well as viscosity.
* &lt;b&gt;[[The Open Dynamics Engine]]&lt;/b&gt;: This is a more extended physics engine that Panda3D offers good integration for, you will want to use this if you need more complex physics simulations. In Panda3D versions 1.5.3 and above, this is integrated in the binaries from the download page.
* &lt;b&gt;NVIDIA PhysX&lt;/b&gt;: New in 1.7.0. Not yet documented.
* &lt;b&gt;[http://www.panda3d.org/manual/index.php/Using_Bullet_with_Panda3D Bullet Physics Engine]&lt;/b&gt;: New in 1.8.0.

When you have a very simple simulation, you will most likely want to use the built-in physics, which works with Panda's collision system. Although, when the built-in engine doesn't offer enough functionality for you, you can switch to ODE, Bullet or PhysX.

Integration for various other physics engines have been provided by the community on the forums:
* Old wrappers for AGEIA PhysX: https://www.panda3d.org/forums/viewtopic.php?t=3108
* More recent wrappers: https://www.panda3d.org/forums/viewtopic.php?p=27906#27906
* Most recent wrappers: https://www.panda3d.org/forums/viewtopic.php?t=5067
* Wrappers for Newton Game Dynamics: https://www.panda3d.org/forums/viewtopic.php?t=2617</text>
    </revision>
  </page>
  <page>
    <title>Physics Engine</title>
    <ns>0</ns>
    <id>2280</id>
    <redirect title="Panda&#039;s Built-in Physics Engine" />
      <sha1>2g0zjr9wdoh05gugmkc30lzuzqbvfji</sha1>
    <revision>
      <id>5522</id>
      <timestamp>2008-10-14T11:15:35Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>[[Physics Engine]] moved to [[Panda's Built-in Physics Engine]]: so I can add ODE</comment>
      <text xml:space="preserve" bytes="45">#REDIRECT [[Panda's Built-in Physics Engine]]</text>
    </revision>
  </page>
  <page>
    <title>Picking</title>
    <ns>0</ns>
    <id>2257</id>
    <redirect title="Clicking on 3D Objects" />
      <sha1>mkucmgq3vlztet3whlshf13fstnd4k1</sha1>
    <revision>
      <id>5377</id>
      <timestamp>2008-05-05T16:28:19Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[Clicking on 3D Objects]]</comment>
      <text xml:space="preserve" bytes="36">#REDIRECT [[Clicking on 3D Objects]]</text>
    </revision>
  </page>
  <page>
    <title>Pipeline Tips</title>
    <ns>0</ns>
    <id>1008</id>
      <sha1>5r5tum5j7fuxz8sy28xgslnfayf2si4</sha1>
    <revision>
      <id>4272</id>
      <timestamp>2007-04-23T21:43:12Z</timestamp>
      <contributor>
        <username>Bb2</username>
        <id>50</id>
      </contributor>
      <comment>removed Dan Quayle quotes, they were funny but didn't belong in this manual</comment>
      <text xml:space="preserve" bytes="5064">&lt;p&gt;
This section isn't totally related to Panda3D. However, these are a few good pointers on how to keep the 'art to programmer' pipeline running smoothly.
&lt;/p&gt;

&lt;h2&gt;How artists can help programmers with the pipeline:&lt;/h2&gt;

&lt;p&gt;
&lt;b&gt;&quot;Keep renaming to a minimum, preferably with good names to start with, and especially for parts or joints that the programmer will have to manipulate.&quot;&lt;/b&gt;&lt;br&gt;

Programmers generally deal with objects by their names, not with a graphical tool like artists. Every time a name changes, a programmer has to make the change in his or her code, and often has to hunt through the egg to try and figure out what the name has changed to. In a large model, this can be very time-consuming. If you do have to change a name, make sure to let the programmer know when you give him or her the new model.
&lt;/p&gt;

&lt;p&gt;
&lt;b&gt;&quot;Check your model in pview before handing it off.&quot;&lt;/b&gt;&lt;br&gt;

The biggest delays in the pipeline come from the back and forth iterations between artist and programmer. A quick check with pview will often find missing textures, backward facing polygons, incorrect normals, mis-tagged collision solids, and a host of other problems.
&lt;/p&gt;

&lt;p&gt;
&lt;b&gt;&quot;Build models with good hierarchy, and don't change the hierarchy unnecessarily.&quot;&lt;/b&gt;&lt;br&gt;

A well organized hierarchy can make a model much easier for a programmer to work with, and can also have a significant effect on rendering performance. For rendering purposes, good hierarchies group objects that are close to each other together, and don't have more than a few hundred to a few thousand triangles (depending on the target hardware) in each node.  (Low-end hardware performs better with only a few hundred triangles per node; high-end hardware performs better with several thousand triangles per node.)
&lt;/p&gt;

&lt;p&gt;
&lt;b&gt;&quot;Put groups of objects that the programmer will have to deal with in a special way under a single node.&quot;&lt;/b&gt;&lt;br&gt;

For instance, if there's a section of an environment that will be hidden during some point in the game, put that entire section under a single node. The programmer might also like certain classes of collision solids to be under a single node.
&lt;/p&gt;

&lt;p&gt;
&lt;b&gt;&quot;Don't use lossy compression (i.e. jpeg) for textures.&quot;&lt;/b&gt;&lt;br&gt;

Although jpegs save space on disk, they also degrade your beautiful textures! If textures have to be manipulated later (i.e. downgraded), this degradation will only be compounded. Every time you edit and resave a jpeg, the image quality gets worse. Jpegs may need to be used in the finished product, but it's always best to make this conversion the last step in the process, not the first one. I recommend using the png format, which provides lossless compression and full support for all color depths as well as alpha.
&lt;/p&gt;

&lt;p&gt;
&lt;b&gt;&quot;If there's any chance that an object will be broken apart and used as separate pieces, give each piece a separate texture map.&quot;&lt;/b&gt;&lt;br&gt;

Nothing hurts worse than having to remap an object after its been painted, or wasting huge swaths of texture space.
&lt;/p&gt;

&lt;p&gt;
&lt;b&gt;&quot;If parts of an object are semi-transparent, make sure those pieces are separate parts in the hierarchy.&quot;&lt;/b&gt;&lt;br&gt;

Rendering semi-transparent objects is a little tricky. Each object with transparency needs to be sorted back-to-front each frame by the rendering engine. If things aren't going quite as planned, a programmer might need to get a handle on a transparent part in order to manipulate its render order.
&lt;/p&gt;

&lt;p&gt;
&lt;b&gt;&quot;If a semi-transparent object is very large, or you can see through multiple layers (like a glass sphere), break it up into separate pieces.&quot;&lt;/b&gt;&lt;br&gt;

Objects with multiple layers of transparency won't render correctly depending on which angle they're being view from, because some of the polygons will be drawn before others, and if it's all one object, the rendering engine can't sort them back-to-front.
&lt;/p&gt;

&lt;p&gt;
&lt;b&gt;&quot;Use quads, and higher-order polygons, for collision solids when possible, rather than triangles.  But make sure your quads are planar.&quot;&lt;/b&gt;&lt;br&gt;

In general, dividing a quad into two triangles doubles the time it takes to test a collision with it, so it is better to model collision polygons with quads when possible.  The same goes for five-sided and higher-order polygons as well.  However, there are two important requirements: (1) the collision polygons must be convex, not concave, and (2) they must be perfectly flat (all of the vertices must lie &lt;em&gt;exactly&lt;/em&gt; in the same plane).  If either of these is not met, Panda will triangulate the polygon anyway.
&lt;/p&gt;

&lt;p&gt;
&lt;h3&gt;Things that don't matter as much, but will give programmers warm-fuzzies:&lt;/h3&gt;
&lt;/p&gt;

&lt;p&gt;
&lt;b&gt;&quot;Use a consistent naming scheme.&quot;&lt;/b&gt;&lt;br&gt;

Programmers live in a world where names and naming conventions are incredibly important. Nothing makes them happier than when the names of art assets fit in well with their code. Common naming conventions are: mixedCaseNames, CapitalizedMixedCaseNames, names_with_underscores, names-with-hyphens. Pick one and stick with it.
&lt;/p&gt;
&lt;p&gt;
&lt;b&gt;&quot;Don't misspell things.&quot;&lt;/b&gt;
&lt;/p&gt;</text>
    </revision>
  </page>
  <page>
    <title>Pixel and Vertex Shaders</title>
    <ns>0</ns>
    <id>2363</id>
    <redirect title="Shaders" />
      <sha1>5dn24aoqarucl9klmm2d852drzroopn</sha1>
    <revision>
      <id>5932</id>
      <timestamp>2009-07-11T13:30:03Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>[[Pixel and Vertex Shaders]] moved to [[Shaders]]: Let's not exclude geometry shaders.</comment>
      <text xml:space="preserve" bytes="21">#REDIRECT [[Shaders]]</text>
    </revision>
  </page>
  <page>
    <title>Playing MPG and AVI files</title>
    <ns>0</ns>
    <id>1073</id>
      <sha1>f8wlt8gx2zy85yksy28qrpyrh4dmhbe</sha1>
    <revision>
      <id>7643</id>
      <timestamp>2012-03-08T18:09:25Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="1916">Panda now supports AVI format for textures in Panda. 

&lt;h2&gt;Usage&lt;/h2&gt;

&lt;code python&gt;
myMovieTexture=loader.loadTexture(&quot;myMovie.avi&quot;)
myObject.setTexture(myMovieTexture)
&lt;/code&gt;

The movie subsystem is implemented using FFMPEG.  Therefore, it supports all of the formats that FFMPEG supports.  The functions to control the movie are as follows:

&lt;code python&gt;
movie.play()
movie.stop()
movie.setTime(t)
movie.getTime()
movie.setLoopCount(n)
movie.getLoopCount()
movie.setPlayRate(speed)
movie.getPlayRate()
movie.isPlaying()
&lt;/code&gt;

If you want to hear the movie's audio as well, you need to load it twice: once as a texture, and once as a sound file:

&lt;code python&gt;
mySound=loader.loadSfx(&quot;myMovie.avi&quot;)
&lt;/code&gt;

Then, you can synchonize the video to the audio:

&lt;code python&gt;
myMovieTexture.synchronizeTo(mySound)
&lt;/code&gt;

From that point forward, playing the audio will cause the texture to update. This is more accurate than synchronizing the video manually.

&lt;h2&gt;For powers-of-two limited graphics hardware&lt;/h2&gt;

If your graphics hardware does not support non power-of-two texture, your movie texture size would be shifted up to the next larger power of two size. For example, it you have a movie of 640 x 360 in size, the generated texture would be actually 1024 x 512. The result is a texture that contains a movie in the lower-left corner, and a black pad region to the right and upper portion of the texture.

To work around this limit, you have to display just the lower-left portion of
the texture.  To see a complete demonstration of this process, see the &lt;i&gt;Media Player&lt;/i&gt; sample program.

&lt;h2&gt;Issues&lt;/h2&gt;

The video texture works by decoding on a frame by frame basis and copying into the texture buffer. As such, it is inadvisable to use more than a few high res video textures at the same time. 

Certain encoding formats do not work. So far, DV format has been determined incompatible with Panda.</text>
    </revision>
  </page>
  <page>
    <title>Plugin notify callbacks</title>
    <ns>0</ns>
    <id>2420</id>
      <sha1>essqd6w9vg67nl4fhxy7em2hfmcbtsu</sha1>
    <revision>
      <id>6658</id>
      <timestamp>2010-02-08T21:56:40Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="6348">At key points during application launch, the plugin will make optional callbacks into JavaScript code, so your page can respond to what the application is doing.  This is done using the &lt;object&gt; token system, as described in [[Advanced object tags]].

The following events may be sent:

{| border=&quot;1&quot;
! Token !! Meaning 
|-
| onPluginFail || The plugin cannot load for some reason, for instance because the browser is an incompatible version, or because the plugin is critically out-of-date with its associated Core API, and needs to be updated.  If you get this event, you will not receive any of the following.  Note that certain kinds of browser incompatibilities result in the plugin never running in the first place, so there exist incompatibility cases in which you will not receive any event at all.
|-
| onPluginLoad || The browser has activated the object tag, and initialized the plugin.  This usually happens after the standard JavaScript page load notification.  See below.
|-
| onUnath || The p3d file has been scanned and needs to be approved by the user.  There will be a red play button drawn in the plugin window (if it is visible); when the user clicks this button, it will pop up the certificate-approval dialog.  You can simulate the user clicking the button by calling plugin.main.play().
|-
| onAuth || The p3d file has been approved by the user as a result of going through the above dialog; or the p3d file was recognized as being already approved at startup.
|-
| onDownloadBegin || The packages referenced by the p3d file are beginning to download.  See below.
|-
| onDownloadNext || This event will be generated as each required package finishes downloading and the next one begins.  See below.
|- 
| onDownloadComplete || Generated when the download finishes, or when it is determined at startup time that all packages are already downloaded.
|-
| onReady || The application is ready to begin.  If you have auto_start=&quot;1&quot;, then it will launch immediately; otherwise, there will be a green play button drawn in the plugin window (if it is visible).  You can simulate the user clicking the button by calling plugin.main.play().
|-
| onPythonLoad || The Python part of the application has begun.  This is part of application startup.  At the time you receive this event, your application has only just begun to execute; there is no guarantee that it has assigned anything to appRunner.main at this point.
|-
| onWindowOpen || The application has successfully created a graphics window, and is now considered fully launched.  From the Python side, it means that your application has imported DirectStart by this point.
|-
| onWindowAttach || The application has attached its graphics window to the plugin frame, and the window is now embedded in the web page.  This may be called at initial startup (possibly before onWindowOpen), and also after a subsequent call to onWindowDetach.
|-
| onWindowDetach || The application has removed its game window from the plugin frame.  This may be called at application exit, or whenever the application itself removes the window from the frame (for instance, to go to a fullscreen or toplevel window instead).  The Panda plugin will display active_img in the plugin frame whenever it is not occupied by the graphics window.
|-
| onPythonStop || The application has exited, either normally or due to an error.
|}

In addition to the above list, a particular application may define its own custom callbacks, by calling base.appRunner.notify('token'), e.g. base.appRunner.notify('onLevelStart').

To use any of the above, assign the token to a JavaScript expression which should be evaluated when the event occurs.  Usually this is a call to one of your own JavaScript functions, e.g.:

&lt;code html4strict&gt;
&lt;object width=&quot;640&quot; height=&quot;480&quot;
  type=&quot;application/x-panda3d&quot; data=&quot;myapp.p3d&quot;
  onWindowOpen=&quot;MyWindowFunction()&quot;
&lt;/object&gt;
&lt;/code&gt;

You should use the appropriate embedding syntax as described in [[Advanced object tags]].

==Additional notes==

At each of the above events, certain properties of the plugin object become defined and available for access by JavaScript.  In the following, &quot;plugin&quot; is assumed to be the DOM object that refers to the embedding &lt;object&gt; element.

After onPluginLoad, you can query certain built-in properties on the plugin:

{|
|-
| plugin.main.status
|-
| plugin.main.pluginVersionString
|-
| plugin.main.pluginMajorVersion
|-
| plugin.main.pluginMinorVersion
|-
| plugin.main.pluginSequenceVersion
|-
| plugin.main.pluginNumericVersion
|-
| plugin.main.pluginDistributor
|-
| plugin.main.coreapiHostUrl
|-
| plugin.main.coreapiTimestamp
|-
| plugin.main.coreapiTimestampString
|}

You can also call plugin.main.get_system_log() at any point after this to query the current system log.  This is the log file generated by the plugin system.  You can specify an optional numeric parameter; this limits the return value to only the specified number of bytes at the end of the log.

Note that there appears to be a Firefox bug that sometimes causes the first reference to plugin.main to return undefined, even though it has actually been defined by this point.  This is especially likely after a page reload (F5) operation.  If this causes you trouble, you may need to work around this with a JavaScript timeout callback.

After onDownloadBegin, you can query the following properties to monitor the download:

{|
| plugin.main.numDownloadingPackages
|-
| plugin.main.totalDownloadSize
|-
| plugin.main.downloadProgress
|-
| plugin.main.downloadElapsedSeconds
|-
| plugin.main.downloadElapsedFormatted
|-
| plugin.main.downloadRemainingSeconds
|-
| plugin.main.downloadRemainingFormatted
|-
| plugin.main.downloadPackageName
|-
| plugin.main.downloadPackageDisplayName
|-
| plugin.main.downloadComplete
|}

After onDownloadNext, downloadPackageName and downloadPackageDisplayName will be updated with the currently-downloading package.  Note that plugin.main.downloadProgress tracks from 0 .. 1 throughout the entire download; it doesn't reset for each package.

After onPythonLoad, you can call plugin.main.get_game_log() to query the game log.  This is the output from the application itself.  Like get_system_log(), you can specify an optional numeric parameter to limit the return value to only the specified number of bytes at the end of the log.</text>
    </revision>
  </page>
  <page>
    <title>Point Light</title>
    <ns>0</ns>
    <id>1009</id>
      <sha1>lal5t4r445g5pye2rk53iiwz3mhxe3y</sha1>
    <revision>
      <id>2297</id>
      <timestamp>2005-04-16T21:40:57Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="317">&lt;p&gt;Point lights originate from one point in space, yet they shed light in all directions. As such, their direction may not be set, but point and color may.&lt;/p&gt;
&lt;table class=&quot;code&quot;&gt;&lt;tr&gt;&lt;td&gt;
NodePath = PointLight('Light Name')&lt;br&gt;
NodePath.setColor(Vec4(R,G,B,A))&lt;br&gt;
NodePath.setPoint(Point3(X,Y,Z))
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</text>
    </revision>
  </page>
  <page>
    <title>Pointers</title>
    <ns>0</ns>
    <id>1105</id>
      <sha1>gx82v4u91zafrq5b4udtu7q8dkj6eo4</sha1>
    <revision>
      <id>2386</id>
      <timestamp>2005-05-06T04:54:59Z</timestamp>
      <contributor>
        <username>Hughperkins</username>
        <id>10</id>
      </contributor>
      <comment>added Errors that can arise</comment>
      <text xml:space="preserve" bytes="4452">== Summary ==

This page describes the use of pointers in Panda3D sourcecode.

== Introduction ==

Pointers are dangerous, because they tend to be associated with new and delete operations, which can cause memory leaks if an object is forgotten by the program but not actually deleted from memory.

To mitigate this issue, Panda3D uses two macros which incorporate automatic reference counting:

&lt;pre&gt;
PT( ClassName ) pMyObjectPointer;  // pointer to ClassName, with reference counting
CPT( ClassName ) pMyConstObjectPointer;  // const pointer to ClassName with reference counting
&lt;/pre&gt;

== Pointers in Panda3D ==

Two macros are used for pointers in Panda:
&lt;pre&gt;
#define PT(type) PointerTo&lt; type &gt;
#define CPT(type) ConstPointerTo&lt; type &gt;
&lt;/pre&gt;

You can use these for example like this:
&lt;pre&gt;
PT( SomeClassName ) *pMyPointerToClassNameObject; // pMyPointerToClassNameObject is a pointer to SomeClassName, with reference counting
&lt;/pre&gt;

== Headerfile ==

Headerfile is at: panda/src/express/pointerTo.h:

== Key points for usage with existing classes ==

Basically, you can use the PT and CPT macros for objects which you create with new; and these objects will automatically be deleted when the variables go out of scope etc.

You dont need to call delete on these objects.  In fact, you probably shouldnt (?).

Dont use them for automatic variables or bad things will happen!

The classes used with these macros must inherit from ReferenceCount or equivalent (see Full description, below).

== Full description, notes on creating new classes ==

pointerTo.h defines the classes PointerTo and ConstPointerTo (and
their abbreviations, PT and CPT).  These should be used in place of
traditional C-style pointers wherever implicit reference counting
is desired.

&lt;pre&gt;
The syntax is:                   instead of:

PointerTo&lt;MyClass&gt; p;            MyClass *p;
PT(MyClass) p;

ConstPointerTo&lt;MyClass&gt; p;       const MyClass *p;
CPT(MyClass) p;
&lt;/pre&gt;

PointerTo and ConstPointerTo will automatically increment the
object's reference count while the pointer is kept.  When the
PointerTo object is reassigned or goes out of scope, the reference
count is automatically decremented.  If the reference count reaches
zero, the object is freed.

Note that const PointerTo&lt;MyClass&gt; is different from
ConstPointerTo&lt;MyClass&gt;.  A const PointerTo may not reassign its
pointer, but it may still modify the contents at that address.  On
the other hand, a ConstPointerTo may reassign its pointer at will,
but may not modify the contents.  It is like the difference between
(MyClass * const) and (const MyClass *).

In order to use PointerTo, it is necessary that the thing pointed
to--MyClass in the above example--either inherits from
ReferenceCount, or is a proxy built with RefCountProxy or
RefCountObj (see referenceCount.h).  However, also see
PointerToArray, which does not have this restriction.

It is crucial that the PointerTo object is only used to refer to
objects allocated from the free store, for which delete is a
sensible thing to do.  If you assign a PointerTo to an automatic
variable (allocated from the stack, for instance), bad things will
certainly happen when the reference count reaches zero and it tries
to delete it.

It's also important to remember that, as always, a virtual
destructor is required if you plan to support polymorphism.  That
is, if you define a PointerTo to some base type, and assign to it
instances of a class derived from that base class, the base class
must have a virtual destructor in order to properly destruct the
derived object when it is deleted.

== Observations on how this works ==

The PointerTo class overrides * and -&gt;, so that the pointer object behaves just like an actual pointer to your object would:

&lt;pre&gt;
INLINE To &amp;operator *() const;
INLINE To *operator -&gt; () const;
&lt;/pre&gt;

== Errors that can arise ==

*If you get wierd messages about iRef when you compile, the class to which you want to point probably doesnt inherit from ReferenceCount, or equivalent.
**You could patch the class to inherit from ReferenceCount, or
**You could just use a normal pointer (but be sure to call delete when you've finished using the object!)
*If you get messages about PointerTo&lt;T&gt; doesnt contain method xxx, check that you are correctly using the operator * or -&gt; on your pointer variable.  ie maybe you wrote:
&lt;pre&gt;
SomePointerObject.SomeMethod()
&lt;/pre&gt;
instead of:
&lt;pre&gt;
SomePointerObject-&gt;SomeMethod()
&lt;/pre&gt;</text>
    </revision>
  </page>
  <page>
    <title>Polygon Occluder Culling</title>
    <ns>0</ns>
    <id>2602</id>
      <sha1>j78b1oxt863ka5l4khb63kegn7mbkpw</sha1>
    <revision>
      <id>7137</id>
      <timestamp>2011-04-18T06:06:03Z</timestamp>
      <contributor>
        <username>Teedee</username>
        <id>449</id>
      </contributor>
      <text xml:space="preserve" bytes="2165">(Note that the OccluderNode is a new addition and is not available in the current release (1.7.2); it can be found in the snapshot builds.)

= Polygon Occluders =

== Introduction ==
One method of occlusion culling is to explicitly define a shape which will block out objects behind it. This is called a Polygon Occluder and is represented in Panda by the OccluderNode.

== Creating an OccluderNode ==
An occluder is defined by four vertices. The order of the vertices is important as this defines which way the normal of the polygon is facing.
&lt;code python&gt;
occluder = OccluderNode('my occluder', Point3(0, 0, 0), Point3(1, 0, 0), Point3(1, 1, 0), Point3(0, 1, 0))
occluder_nodepath = render.attachNewNode(occluder)
render.setOccluder(occluder_nodepath)
&lt;/code&gt;
It is hidden by default, but can be shown for debug purposes using the show method on its NodePath. The occluder only needs to be parented into the scene if you want to show it, or if it needs to move with an object in the scene.
Use the setOccluder method on any NodePath to make the occluder active on that NodePath and its children. It is much more efficient to call setOccluder on a parent node with children as opposed to calling setOccluder on many different nodes.

== Occluder Configuration ==
Besides the shape of the occluder, there are other settings which affect how the occluder behaves.
Use the setDoubleSided method on the OccluderNode to enable the occluder to work on both sides. This is desirable for example if the occluder is placed inside of a wall. A double-sided occluder is more efficient than creating two occluders with opposite normals.
Use the setMinCoverage method to ignore an occluder that doesn't take up at least a certain amount of screen space.

== General Occluder Advice ==
More is not always better. Occluders do have a cost, so use them sparingly where they will make the biggest difference.
If you have a lot of occluders, it might help to evaluate your occluders every once in a while and only use the closest ones.
The optimal amount and configuration of occluders depends on the makeup of your scene. Test different configurations and compare the frame rates.</text>
    </revision>
  </page>
  <page>
    <title>Portal Culling</title>
    <ns>0</ns>
    <id>2498</id>
      <sha1>4qj3kp2wa0awmikxh7f37avwh3hok2y</sha1>
    <revision>
      <id>7419</id>
      <timestamp>2011-12-08T14:47:39Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="2516">= Portal Culling =

== What is Portal Culling? ==
Portal culling is a method by which the 3D scene can be broken into areas called cells, which are linked together by portals. A portal is a window in 3D space that allows objects in one cell (the &quot;out&quot; cell) to be seen from another cell (the &quot;in&quot; cell). Portal culling works best in scenes where there is limited visibility from one area to another, for example a building or network of caves. It has very limited use in wide open scenes.

[[Image:portal_diagram.png]]

In this diagram the original camera frustum is seen in blue, this is used to cull the current cell. The shaded areas represent areas visible after culling. The camera is looking through a portal into the next cell, and so the frustum is reduced (seen in cyan) so as to render only that which is visible through the portal. This reduced frustum is then used to check visibility of additional portals in other cells, and it will be reduced again as it passed through more portals (seen in red and green). Note that even though more cells are visible to the original camera frustum, there is no direct line of visibility and so they are not even considered.

== How are Cells and Portals handled in Panda3D? ==
Cells in Panda3D are just NodePaths parented under the top level of the scene graph (usually render). Any object that is physically in that cell should be parented under the cell's NodePath. It is up to you to dynamically re-parent objects as they move from one cell to another, or not put them in a cell at all.

Portals are one-way and for this reason they are usually created in pairs. Portals get parented under the cell from which they are intended to be looked through. For example if this is a portal from cell A looking into cell B, it would get parented under cell A. Which side of the portal is the front or back is determined by winding order of the vertices, the same as with render geometry.

Application-level code is needed to show the cell the camera is currently in and hide the rest. During the culling stage any portal visible to the camera will be enabled, and render the objects that can be seen through the portal into its specified &quot;out&quot; cell. If another portal is visible through the previous one, the process continues. If multiple cameras are used, for example to do split screen play, hide the cells using the same mask set on the camera using camera.setCameraMask(mask).

&lt;h2&gt;Incomplete Section&lt;/h2&gt;

Note: this section is incomplete.  It will be updated soon.</text>
    </revision>
  </page>
  <page>
    <title>Position, Rotation and Scale Intervals</title>
    <ns>0</ns>
    <id>928</id>
      <sha1>au84p4ughzriafj9kyndbdqh5gbcjkh</sha1>
    <revision>
      <id>6490</id>
      <timestamp>2010-01-02T10:16:45Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>Replaced &lt;pre&gt; with &lt;code&gt;, added &lt;code&gt; to operation references, cleaned code style, fixed misrepresentation about posInterval() duration.</comment>
      <text xml:space="preserve" bytes="1245">Panda3D can automatically generate intervals for position to a certain point or a rotation to a certain HPR value.
You can do this by calling &lt;code&gt;posInterval()&lt;/code&gt; and &lt;code&gt;hprInterval()&lt;/code&gt; on the object.

&lt;code lang=&quot;python&quot;&gt;
# This lets the actor move to point 10, 10, 10 in 1.0 second.
myInterval1 = myActor.posInterval(1.0, Point3(10, 10, 10))

# This move takes 2.0 seconds to complete.
myInterval2 = myActor.posInterval(2.0, Point3(8, -5, 10))

# You can specify a starting position, too.
myInterval3 = myActor.posInterval(1.0, Point3(2, -3, 8), startPos=Point3(2, 4, 1))

# This rotates the actor 180 degrees on heading and 90 degrees on pitch.
myInterval4 = myActor.hprInterval(1.0, Vec3(180, 90, 0))
&lt;/code&gt;

You can easily create [[Sequences and Parallels]] from these intervals:
&lt;code lang=&quot;python&quot;&gt;
mySequence = Sequence(myInterval2, myInterval4)
mySequence.start()
myParallel = Parallel(myInterval3, myInterval1)
myParallel.loop()
&lt;/code&gt;

&lt;code&gt;scaleInterval()&lt;/code&gt;, &lt;code&gt;posHprInterval()&lt;/code&gt;, &lt;code&gt;posScaleInterval()&lt;/code&gt;, &lt;code&gt;hprScaleInterval()&lt;/code&gt;, and &lt;code&gt;posHprScaleInterval()&lt;/code&gt; work similarly.

&lt;b&gt;Note:&lt;/b&gt; The physics engine won't affect a Node that is moved using &lt;code&gt;posInterval()&lt;/code&gt;!</text>
    </revision>
  </page>
  <page>
    <title>Position and Rotation Intervals</title>
    <ns>0</ns>
    <id>2099</id>
    <redirect title="Position, Rotation and Scale Intervals" />
      <sha1>arn0rbwf5ycg0jusewh8fx2efo5gw29</sha1>
    <revision>
      <id>4279</id>
      <timestamp>2007-04-28T14:44:54Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>[[Position and Rotation Intervals]] moved to [[Position, Rotation and Scale Intervals]]: just found out that there were also scale intervals :)</comment>
      <text xml:space="preserve" bytes="52">#REDIRECT [[Position, Rotation and Scale Intervals]]</text>
    </revision>
  </page>
  <page>
    <title>Positioning DirectGUI Elements</title>
    <ns>0</ns>
    <id>2682</id>
      <sha1>k42fzm0eg0qa0uz9opyjdnhl5g70x1a</sha1>
    <revision>
      <id>7825</id>
      <timestamp>2012-07-08T12:54:59Z</timestamp>
      <contributor>
        <username>Sakurazaki</username>
        <id>576</id>
      </contributor>
      <minor/>
      <comment>Changing wrong wrote positions</comment>
      <text xml:space="preserve" bytes="2631">[[DirectGUI]] elements are usualy positioned in the XZ-plane (Z-up system).

The elements can be reparented to any NodePath, but they only work as intended when parented under [[Scene Graph Manipulations|render2d]], [[Scene Graph Manipulations|aspect2d]] or [[Scene Graph Manipulations|pixel2d]].

When reparenting them to [[Scene Graph Manipulations|render2d]], the origin &lt;i&gt;(0, 0)&lt;/i&gt; of your screen is the middle of the window, having the float values for X and Z -1 and 1 as the corners. Since it scales the coordinates to fit the window, it causes aspect-ratio errors such as making images squashed.

[[Scene Graph Manipulations|pixel2d]] is made to work with pixels, having your coordinate origin in &lt;i&gt;(0, 0, 0)&lt;/i&gt; which is your top left corner of the window. One panda unit equals one pixel so the bottom right corner equals your window resolution. When working with pixel-based-positioning [[Scene Graph Manipulations|pixel2d]] is a good choice.

[[Scene Graph Manipulations|aspect2d]] sets your origin to the center of the window too, but it is scaled to avoid the aspect-ratio trouble. Coordinate are no longer fixed to matches the -1 to 1 range. [[Scene Graph Manipulations|aspect2d]] is the most common choice for reparenting GUI elements.

&lt;i&gt;Refer to [[Scene Graph Manipulations]] for more information about these.&lt;/i&gt;

To change the position in the screen, there are two functions implemented in every [[DirectGUI]] element:

&lt;ul&gt;
&lt;li&gt; &lt;code&gt;pos = (x, z)&lt;/code&gt; keyword in the constructor.
&lt;li&gt; &lt;code&gt;myElement.setPos(x, y, z)&lt;/code&gt; function.
&lt;/ul&gt;

There are a number of useful variables available for positioning [[DirectGUI]] elements. Accessible under the &lt;code&gt;base&lt;/code&gt; module, named a2d*.

To access them call &lt;code&gt;base.a2d*&lt;/code&gt; where the * is related to the position of the screen:

&lt;ul&gt;
&lt;li&gt;Left
&lt;li&gt;Right
&lt;li&gt;TopCenter
&lt;li&gt;BottomCenter
&lt;li&gt;TopLeft
&lt;li&gt;TopRight
&lt;li&gt;BottomLeft
&lt;li&gt;BottomRight
&lt;/ul&gt;

They can be used as &lt;i&gt;x&lt;/i&gt; and &lt;i&gt;z&lt;/i&gt; coords in your functions.

&lt;code python&gt;
myElement(pos = (base.a2dLeft, base.a2dBottom))
myElement.setPos(base.a2dRight, 0, base.a2dTop)
&lt;/code&gt;

[[DirectGUI]] elements can also be reparented to &lt;i&gt;a2d&lt;/i&gt; so their coordinate system origin is at the position you chose.

&lt;code python&gt;
myElement.reparentTo(base.a2dBottomLeft)
&lt;/code&gt;

This will place your elements at the BottomLeft corner of your screen. All coordinates will relative to the Bottomleft corner, even if the window gets resized.

&lt;b&gt;Example&lt;/b&gt;

&lt;code python&gt;

myButton = DirectButton(text = (&quot;Text1&quot;, &quot;Text2&quot;, &quot;Text3&quot;, &quot;Text4&quot;), scale=0.1)

myButton.reparentTo(base.a2dBottomLeft)
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>Positioning DirectGUI Elements on Window</title>
    <ns>0</ns>
    <id>2685</id>
    <redirect title="Positioning DirectGUI Elements" />
      <sha1>rt7vi91llqmzs1q25eljx5c41rl7dsd</sha1>
    <revision>
      <id>7819</id>
      <timestamp>2012-07-07T19:27:57Z</timestamp>
      <contributor>
        <username>Sakurazaki</username>
        <id>576</id>
      </contributor>
      <comment>[[Positioning DirectGUI Elements on Window]] moved to [[Positioning DirectGUI Elements]]</comment>
      <text xml:space="preserve" bytes="44">#REDIRECT [[Positioning DirectGUI Elements]]</text>
    </revision>
  </page>
  <page>
    <title>Potential build issues and solutions</title>
    <ns>0</ns>
    <id>1082</id>
      <sha1>p2wfp8aqtnweo5e58oy77y9mz4fgfmy</sha1>
    <revision>
      <id>2364</id>
      <timestamp>2005-05-02T07:28:10Z</timestamp>
      <contributor>
        <username>Hughperkins</username>
        <id>10</id>
      </contributor>
      <comment>added link to Potential build issues and solutions, Windows platform</comment>
      <text xml:space="preserve" bytes="200">== Summary ==

This page describes potential build issues that may arise, and possible solutions

== Potential build issues and solutions ==

[[Potential build issues and solutions, Windows platform]]</text>
    </revision>
  </page>
  <page>
    <title>Potential build issues and solutions, Windows platform</title>
    <ns>0</ns>
    <id>1086</id>
    <redirect title="Troubleshooting ppremake on Windows" />
      <sha1>p4fyipqplwllzeyrth7bm0lcs70xgz5</sha1>
    <revision>
      <id>2366</id>
      <timestamp>2005-05-02T17:59:50Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <comment>Potential build issues and solutions, Windows platform moved to Troubleshooting ppremake on Windows</comment>
      <text xml:space="preserve" bytes="50">#REDIRECT [[Troubleshooting ppremake on Windows]]
</text>
    </revision>
  </page>
  <page>
    <title>Pre-defined vertex formats</title>
    <ns>0</ns>
    <id>1769</id>
      <sha1>b2t8na51bkla17lbu48k6o4fgf01p8u</sha1>
    <revision>
      <id>7438</id>
      <timestamp>2011-12-09T07:07:20Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="13033">Panda3D predefines a handful of standard [[GeomVertexFormat]] objects
that might be useful to you.  If you don't have any special format
needs, feel free to use any of these standard formats, which have
already been defined and registered, and are ready to use for rendering.

Each of these formats includes one or more of the standard columns
vertex, normal, color, and/or texcoord.  For the formats that include
a color column, there are two choices, since OpenGL and DirectX have
competing internal formats for color (but you can use either form
regardless of your current rendering API; Panda will automatically
convert the format at render time if necessary).

[python]
&lt;center&gt;&lt;table style=&quot;border-collapse: collapse&quot;&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;Standard format&lt;/b&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;b&gt;vertex&lt;/b&gt; (X,&amp;nbsp;Y,&amp;nbsp;Z)&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;b&gt;normal&lt;/b&gt; (X,&amp;nbsp;Y,&amp;nbsp;Z)&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;b&gt;color&lt;/b&gt;, 4-component RGBA (OpenGL&amp;nbsp;style)&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;b&gt;color&lt;/b&gt;, packed RGBA (DirectX&amp;nbsp;style)&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;b&gt;texcoord&lt;/b&gt; (U,&amp;nbsp;V)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; padding-right: 5pt&quot;&gt;GeomVertexFormat.getV3()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; padding-right: 5pt&quot;&gt;GeomVertexFormat.getV3n3()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; padding-right: 5pt&quot;&gt;GeomVertexFormat.getV3t2()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; padding-right: 5pt&quot;&gt;GeomVertexFormat.getV3n3t2()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; padding-right: 5pt&quot;&gt;GeomVertexFormat.getV3c4()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; padding-right: 5pt&quot;&gt;GeomVertexFormat.getV3n3c4()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; padding-right: 5pt&quot;&gt;GeomVertexFormat.getV3c4t2()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; padding-right: 5pt&quot;&gt;GeomVertexFormat.getV3n3c4t2()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; padding-right: 5pt&quot;&gt;GeomVertexFormat.getV3cp()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; padding-right: 5pt&quot;&gt;GeomVertexFormat.getV3n3cp()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; padding-right: 5pt&quot;&gt;GeomVertexFormat.getV3cpt2()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; border-bottom: 1px solid black; padding-right: 5pt&quot;&gt;GeomVertexFormat.getV3n3cpt2()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; border-bottom: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; border-bottom: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; border-bottom: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; border-bottom: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; border-bottom: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;
[/python]
[cxx]
&lt;center&gt;&lt;table style=&quot;border-collapse: collapse&quot;&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;Standard format&lt;/b&gt;&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;b&gt;vertex&lt;/b&gt; (X,&amp;nbsp;Y,&amp;nbsp;Z)&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;b&gt;normal&lt;/b&gt; (X,&amp;nbsp;Y,&amp;nbsp;Z)&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;b&gt;color&lt;/b&gt;, 4-component RGBA (OpenGL&amp;nbsp;style)&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;b&gt;color&lt;/b&gt;, packed RGBA (DirectX&amp;nbsp;style)&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;b&gt;texcoord&lt;/b&gt; (U,&amp;nbsp;V)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; padding-right: 5pt&quot;&gt;GeomVertexFormat::get_v3()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; padding-right: 5pt&quot;&gt;GeomVertexFormat::get_v3n3()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; padding-right: 5pt&quot;&gt;GeomVertexFormat::get_v3t2()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; padding-right: 5pt&quot;&gt;GeomVertexFormat::get_v3n3t2()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; padding-right: 5pt&quot;&gt;GeomVertexFormat::get_v3c4()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; padding-right: 5pt&quot;&gt;GeomVertexFormat::get_v3n3c4()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; padding-right: 5pt&quot;&gt;GeomVertexFormat::get_v3c4t2()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; padding-right: 5pt&quot;&gt;GeomVertexFormat::get_v3n3c4t2()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; padding-right: 5pt&quot;&gt;GeomVertexFormat::get_v3cp()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; padding-right: 5pt&quot;&gt;GeomVertexFormat::get_v3n3cp()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; padding-right: 5pt&quot;&gt;GeomVertexFormat::get_v3cpt2()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;border-top: 1px solid black; border-bottom: 1px solid black; padding-right: 5pt&quot;&gt;GeomVertexFormat::get_v3n3cpt2()&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; border-bottom: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; border-bottom: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; border-bottom: 1px solid black; text-align: center&quot;&gt;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; border-bottom: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;td style=&quot;border-top: 1px solid black; border-bottom: 1px solid black; text-align: center&quot;&gt;&amp;#10003;&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;
[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Preusser</title>
    <ns>0</ns>
    <id>2660</id>
      <sha1>5q7z862mfy64dra337a157zb2hznisp</sha1>
    <revision>
      <id>7867</id>
      <timestamp>2013-03-11T06:44:39Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="7743">&lt;h2&gt;Panda3D Basics&lt;/h2&gt;

Panda3D is a &lt;i&gt;3D engine&lt;/i&gt;: a library of subroutines for 3D rendering and game development.  The library is C++ with a set of Python bindings. Game development with Panda3D usually consists of writing a Python or C++ program that controls the Panda3D library.

Panda was created for commercial game development, and &lt;b&gt;its primary users
are still commercial game developers&lt;/b&gt;.  Because of this, Panda3D needs
to emphasize four areas: &lt;i&gt;power&lt;/i&gt;, &lt;i&gt;speed&lt;/i&gt;, &lt;i&gt;completeness&lt;/i&gt;,
and &lt;i&gt;error tolerance&lt;/i&gt;.  Everyone knows what power and speed
are.  But completeness and error tolerance deserve some extra commentary.

Completeness means that Panda3D contains tons of unexciting but essential
tools: scene graph browsing, performance monitoring, animation optimizers,
and so forth.  These things may not be sexy,
and as a result, open-source engines often don't have them.  But when
you're serious about getting work done, and not just playing, these
tools need to be there.

Error tolerance is about the fact that all game developers create bugs.
When you do, you want your engine to give you a clear error message
and help you find the mistake.  Too many engines will just crash if
you pass the wrong value to a function.  Panda3D almost never crashes,
and much code is dedicated to the problem of tracking and isolating
errors.

Finally, to come back to power and speed: &lt;b&gt;the best way to gauge Panda3D's
capabilities is to take a look at the  [[Sample Programs in the Distribution|Sample Programs]].&lt;/b&gt;  These are
short programs that demonstrate a sampling of Panda3D's capabilities.
The screenshots have frame-rates in the upper-right corner, taken on
a Radeon X700.

Panda3D was developed by Disney for their massively multiplayer online game, Toontown. It was released as free software in 2002. &lt;b&gt;Panda3D is now developed jointly by Disney and Carnegie Mellon University's Entertainment Technology Center.&lt;/b&gt;

You can read more about [http://panda3d.org/features.php Panda3D's Features].

&lt;h2&gt;Panda3D is not a Beginner's Tool or a Toy&lt;/h2&gt;

To successfully use Panda3D, you must be a skilled programmer.  If you do
not know what an &quot;API&quot; is, or if you don't know what a &quot;tree&quot; 
is, you will probably find Panda3D overwhelming.  This is no
point-and-click game-maker: this is a tool for professionals.  While It is important to point that out so you have accurate expectations, it's also relevant to be aware that Panda3d is one of the easiest and most powerful engines you will ever use, and we welcome your participation.

If you are just getting started with programming, 
we suggest that your best option is to start with a class on
programming.  Alternately, you could try teaching yourself using a training
tool like [http://alice.org Alice], also from CMU. While on the discussion of tools, it should be noted here for reference that &quot;Scene Editor&quot; is a very useful tool for constructing components of your panda app and should you wish to consider trying them once you are comfortable with using panda, then you can find information about them in the manual at section VIII: H .

Some people have seen screenshots of children's games written in Panda3D,
and concluded that Panda3D is graphically limited.  Not so.
Developers of children's games often choose not to use shaders or 
other advanced graphics, because children often own older hand-me-down
computers.  But Panda3D supports the full range of what modern engines
should: it provides convenient support for normal mapping, gloss mapping,
HDR, cartoon shading and inking, bloom, and a number of other things.
It also allows you to &lt;b&gt;write (Preusser: &quot;use&quot;, maybe?)&lt;/b&gt; your own shaders, &lt;b&gt;making it capable of anything. (Preusser: God?)&lt;/b&gt;

&lt;b&gt;People sometimes have the mistaken impression that Panda3D is written
in Python, which would make it very slow. But Panda3D is
not written in python - it's written in C++&lt;/b&gt;.  &lt;b&gt;The python&lt;/b&gt; is &lt;b&gt;just for
scripting (Preusser: well, I wouldn't say *only*)&lt;/b&gt;, developers usually write the performance-intensive bits in C++.  To see what kind of framerate a small Panda3D program typically gets, take a look at the screenshots
of the [[Sample Programs in the Distribution|Sample Programs]].
Those were taken using a Radeon x700.
Of course, only a sample program can run at 400fps like that, &lt;b&gt;but but&lt;/b&gt; for a real game, 60fps is quite attainable. One caveat, though:
to get that kind of performance, you need to understand 3D cards and
3D performance optimization.  It doesn't happen automatically.  Panda3D
includes profiling tools you need to &lt;b&gt;hit&lt;/b&gt; 60fps &lt;b&gt;(Preusser: &quot;not go below 60 fps&quot;, maybe?)&lt;/b&gt;.

&lt;h2&gt;Panda3D's Software License&lt;/h2&gt;

Since version 1.5.3, Panda3D has been released under the so-called &quot;Modified BSD license,&quot; which is a free software license with very few restrictions on usage.  In versions 1.5.2 and before, it used a proprietary license which was very similar in intention to the BSD and MIT licenses, though there was some disagreement about the freeness of two of &lt;b&gt;the (Preusser: &quot;its&quot;?)&lt;/b&gt; clauses. The old license can still be accessed [http://panda3d.cvs.sourceforge.net/viewvc/*checkout*/panda3d/doc/doc/LICENSE?revision=1.1 here].

Although the engine itself is completely free, it comes with various third-party libraries that are not free software. Some of them (like FMOD) even restrict you from using &lt;b&gt;it (Preusser: &quot;them&quot;?)&lt;/b&gt; in commercial games, unless you have a licensed copy of FMOD. Because of this reason, Panda3D makes it easy to disable or remove these restricted third-party libraries, and most of the time it offers an alternative. For example, instead of FMOD it also comes with OpenAL which you can use instead.

You can read [http://panda3d.org/license.php Panda3D's License].

&lt;h2&gt;Who is Working on Panda3D&lt;/h2&gt;

There are a number of developers in the commercial and open-source community. &lt;b&gt;Currently, the two most active members of the development community are Disney and the Entertainment Technology Center at Carnegie Mellon&lt;/b&gt;. Because both organizations have specific goals, &lt;b&gt;Panda3D must necessarily serve both&lt;/b&gt;:

&lt;ul&gt;
&lt;li&gt;Disney's primary interest in Panda3D is commercial. Panda3D is being used in the development of a number of Disney games and amusement-park exhibits. To serve Disney's needs, Panda3D must be a fully-featured engine, capable of all the performance and quality one expects in any 'A-grade' commercial title.
&lt;li&gt;The Entertainment Technology Center's primary goal is education. To serve the Entertainment Technology Center's needs, Panda3D must be well-suited for use in student projects. Since students have a unique talent for causing crashes, bulletproof reliability is needed. Since projects only last one semester, the learning curve must be very short, and prototyping must be very rapid.
&lt;/ul&gt;

As it turns out, the two sets of goals are complementary. The rapid development and high reliability needed by the Entertainment Technology Center are also highly advantageous in a game-development studio, since they lower development time and costs. The good visual quality and full feature set needed by Disney to make a professional-quality game also turn out to be useful in a university setting: with a broad range of features at their disposal, students can explore their creativity more fully than they could with a more limited engine.

The most supported language is Python. Though you can use C++ too, the documentation is mostly aimed at Python use.

&lt;h2&gt;The Introductory Chapter&lt;/h2&gt;

This introductory chapter of the manual is designed to walk you through
some of the basics of using Panda3D.  This chapter is structured as a
tutorial, not as a reference work.</text>
    </revision>
  </page>
  <page>
    <title>Previewing 3D Models in Pview</title>
    <ns>0</ns>
    <id>1010</id>
      <sha1>awhjl1dwjqi3gpgn8189j6dbaebubth</sha1>
    <revision>
      <id>6498</id>
      <timestamp>2010-01-03T23:40:56Z</timestamp>
      <contributor>
        <username>Nemesis</username>
        <id>193</id>
      </contributor>
      <minor/>
      <comment>code tags</comment>
      <text xml:space="preserve" bytes="2722">Pview or Panda Viewer is a model and animation viewer for egg and bam files. This allows users to see if their files have converted correctly without having to create a Panda3D program. Pview is accessed through a command prompt.

To view a model that has been converted to an egg or bam file, type the following:

&lt;code&gt;
pview modelFile.egg
&lt;/code&gt;

To view a character model with animations, simply add the name of the file with the animation.

&lt;code&gt;
pview modelFile.egg animationFile.egg
&lt;/code&gt;

Here's an example based on the panda model distributed with panda source.

&lt;code&gt;
pview panda.egg
&lt;/code&gt;

A new window should pop-up and here's what you should see -

[[Image:pviewsample.jpg]]

There are some controls and hotkeys available while using pview. To see the whole list press shift-question mark in the pview window. To turn this list off press shift-question mark again. For convenience here is the full list of as the time of writing:

&lt;table&gt;
&lt;tr&gt;&lt;td&gt;Left-click and drag Mouse&lt;/td&gt;&lt;td&gt;Moves the model up, down, left, and right relative to the camera&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Middle-click and drag Mouse&lt;/td&gt;&lt;td&gt;Rotates the model around its pivot&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Right-click and drag Mouse&lt;/td&gt;&lt;td&gt;Moves the model away and towards the camera&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;f&lt;/td&gt;&lt;td&gt;Report framerate. The current framerate is output on the console window.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;w&lt;/td&gt;&lt;td&gt;Toggle wireframe mode&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;t&lt;/td&gt;&lt;td&gt;Toggle texturing&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;b&lt;/td&gt;&lt;td&gt;Toggle back face (double-sided) rendering&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;i&lt;/td&gt;&lt;td&gt;Invert (reverse) single-sided faces&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;l&lt;/td&gt;&lt;td&gt;Toggle lighting&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;p&lt;/td&gt;&lt;td&gt;Toggle per-pixel lighting&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;c&lt;/td&gt;&lt;td&gt;Recenter view on object&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;shift-c&lt;/td&gt;&lt;td&gt;Toggle collision surfaces&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;shift-b&lt;/td&gt;&lt;td&gt;Report bounding volume&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;shift-l&lt;/td&gt;&lt;td&gt;List hierarchy&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;shift-a&lt;/td&gt;&lt;td&gt;Analyze hierarchy&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;h&lt;/td&gt;&lt;td&gt;Highight node&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;arrow-up&lt;/td&gt;&lt;td&gt;Move highlight to parent&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;arrown-down&lt;/td&gt;&lt;td&gt;Move highlight to child&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;arrow-left&lt;/td&gt;&lt;td&gt;Move highlight to sibling&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;arrow-right&lt;/td&gt;&lt;td&gt;Move highlight to sibling&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;shift-s&lt;/td&gt;&lt;td&gt;Activate PStats&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;f9&lt;/td&gt;&lt;td&gt;Take screenshot&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;,&lt;/td&gt;&lt;td&gt;Cycle through background colors&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;shift-w&lt;/td&gt;&lt;td&gt;Open new window&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;alt-enter&lt;/td&gt;&lt;td&gt;Toggle between full-screen and windowed mode&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;Split the window&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;W&lt;/td&gt;&lt;td&gt;Toggle wireframe&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;escape&lt;/td&gt;&lt;td&gt;Close Window&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;q&lt;/td&gt;&lt;td&gt;Close Window&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;</text>
    </revision>
  </page>
  <page>
    <title>Procedurally Generating 3D Models</title>
    <ns>0</ns>
    <id>1125</id>
      <sha1>eqx74iehxoc12eglpwvvg27j55pplkb</sha1>
    <revision>
      <id>3384</id>
      <timestamp>2006-05-11T03:23:24Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="198">Building on the fundamental concepts introduced in the last section, the following section explains how to use Panda's basic geometry building blocks to generate your own custom geometry at runtime.</text>
    </revision>
  </page>
  <page>
    <title>Programming in CXX</title>
    <ns>0</ns>
    <id>2083</id>
    <redirect title="Using Microsoft Visual Studio" />
      <sha1>qfh22qtlfpmllf3x9ml7v4ze6i51f5l</sha1>
    <revision>
      <id>4201</id>
      <timestamp>2007-03-10T10:40:30Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>[[Programming in CXX]] moved to [[Using Microsoft Visual Studio]]: there's already one.</comment>
      <text xml:space="preserve" bytes="43">#REDIRECT [[Using Microsoft Visual Studio]]</text>
    </revision>
  </page>
  <page>
    <title>Programming with Panda</title>
    <ns>0</ns>
    <id>2458</id>
    <redirect title="Programming with Panda3D" />
      <sha1>698rdze6kge4fqvnhpxyddrhkwemop6</sha1>
    <revision>
      <id>6608</id>
      <timestamp>2010-02-07T04:38:36Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>[[Programming with Panda]] moved to [[Programming with Panda3D]]: Panda3D is the name of the engine; not Panda.</comment>
      <text xml:space="preserve" bytes="38">#REDIRECT [[Programming with Panda3D]]</text>
    </revision>
  </page>
  <page>
    <title>Programming with Panda3D</title>
    <ns>0</ns>
    <id>940</id>
      <sha1>ouht4xlywq648997btzzucy5cabk4hn</sha1>
    <revision>
      <id>6607</id>
      <timestamp>2010-02-07T04:38:36Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <minor/>
      <comment>[[Programming with Panda]] moved to [[Programming with Panda3D]]: Panda3D is the name of the engine; not Panda.</comment>
      <text xml:space="preserve" bytes="738">The &lt;i&gt;Programming with Panda&lt;/i&gt; section of the manual attempts to
enumerate all the various functionality that Panda3D provides.

This manual does not attempt to be complete in the sense of listing every
class, function, and method provided by Panda3D.
If that's what you're looking for, go to the [http://panda3d.org/apiref.php?page=classes Reference Section] instead.

The purpose of this manual is to:

1. List all of Panda3D's broad capabilities,

2. Help you understand what purpose these serve,

3. Give you a general understanding of how to build games in Panda3D.

In time, though, you will need to supplement the knowledge provided
by this manual by studying the 
[http://panda3d.org/apiref.php?page=classes Reference Section].</text>
    </revision>
  </page>
  <page>
    <title>Project Hosting</title>
    <ns>0</ns>
    <id>2234</id>
      <sha1>qx16s15czkhp0t4pk96ag7gzn8897w3</sha1>
    <revision>
      <id>7512</id>
      <timestamp>2011-12-24T14:49:56Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="994">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

&lt;p&gt;If you want some webspace to host your Panda3D project, you can do so at Panda3DProjects. Panda3DProjects is a website set up by the community and for the community. It provides free hosting for any Panda3D user who wants some room to put their Panda3D-related stuff. It also provides a wiki for each user where the user can create pages and show their progress.&lt;/p&gt;

&lt;p&gt;You can visit Panda3DProjects at one of these links:&lt;/p&gt;
* [http://www.p3dp.com/ www.p3dp.com]
* [http://www.panda3dprojects.com/ www.panda3dprojects.com]

&lt;p&gt;An IRC channel exists for Panda3DProjects; &lt;em&gt;#panda3dprojects&lt;/em&gt; at &lt;em&gt;irc.freenode.net&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Finally, there is a TeamSpeak server available. The server name is &lt;em&gt;p3dp.com&lt;/em&gt; and the port settings are the default.&lt;/p&gt;

Open source projects can also be hosted for free at [http://sourceforge.net/ SourceForge], [http://code.google.com/ Google Code] or [https://github.com/ GitHub], among other places.</text>
    </revision>
  </page>
  <page>
    <title>Projected Textures</title>
    <ns>0</ns>
    <id>1234</id>
      <sha1>fo2fuafytfbgk94zlkv5fb9fm6k8nru</sha1>
    <revision>
      <id>7638</id>
      <timestamp>2012-03-08T18:03:49Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="5162">In a [[Texture Transforms|previous section]], we introduced ways to apply an explicit transformation to a model's texture coordinates, with methods like &lt;code&gt;setTexOffset()&lt;/code&gt; and &lt;code&gt;setTexScale()&lt;/code&gt;.  In addition to this explicit control, Panda3D offers a simple mechanism to apply an automatic texture transform each frame, as computed from the relative transform between any two nodes.

&lt;code python&gt;
nodePath.setTexProjector(textureStage, fromNodePath, toNodePath)
&lt;/code&gt;

When you have enabled this mode, the relative scene-graph transform
from &lt;code&gt;fromNodePath&lt;/code&gt; to &lt;code&gt;toNodePath&lt;/code&gt;--that is,
the result of &lt;code&gt;fromNodePath.getTransform(toNodePath)&lt;/code&gt;--is
automatically applied as a texture-coordinate transform to the
indicated textureStage.  The result is more-or-less as if you executed
the following command every frame:

&lt;code python&gt;
nodePath.setTexTransform(textureStage, fromNodePath.getTransform(toNodePath))
&lt;/code&gt;

There is no need for either &lt;code&gt;fromNodePath&lt;/code&gt; or
&lt;code&gt;toNodePath&lt;/code&gt; to have any relation to the nodePath that is
receiving the &lt;code&gt;setTexProjector()&lt;/code&gt; call; they can be any two
arbitrary NodePaths.  If either of them is just
&lt;code&gt;NodePath()&lt;/code&gt;, it stands for the top of the graph.

This has several useful applications.  We have already introduced
[[Automatic Texture Coordinates|one application]], in conjunction 
with &lt;code&gt;MWorldPosition&lt;/code&gt;, to move the generated texture
coordinates from the root of the graph to the model itself.

&lt;h2&gt;Interval-animated texture transforms&lt;/h2&gt;

Another handy application for a TexProjector is to enable the use of
the various [[Lerp Intervals|LerpIntervals]] to animate a texture
transform.  Although there are no LerpIntervals that directly animate
texture transforms, you can make a LerpInterval animate a
NodePath--and then set up a TexProjector effect to follow that
NodePath.  For example:

&lt;code python&gt;
smiley = loader.loadModel('smiley.egg')
lerper = NodePath('lerper')
smiley.setTexProjector(TextureStage.getDefault(), NodePath(), lerper)
i = lerper.posInterval(5, VBase3(0, 1, 0))
i.loop()
&lt;/code&gt;

Note that you don't even have to parent the animated NodePath into the
scene graph.  In the above example, we have set up the interval
&lt;code&gt;i&lt;/code&gt; to repeatedly move the standalone NodePath
&lt;code&gt;lerper&lt;/code&gt; from position (0, 0, 0) to (0, 1, 0) over 5
seconds.  Since &lt;code&gt;smiley&lt;/code&gt; is assigned a TexProjector that
copies the relative transform from &lt;code&gt;NodePath()&lt;/code&gt; to
&lt;code&gt;lerper&lt;/code&gt;--that is, the net transform of
&lt;code&gt;lerper&lt;/code&gt;--it means we are really animating the texture
coordinates on &lt;code&gt;smiley&lt;/code&gt; from (0, 0) to (0, 1) (the Z
coordinate is ignored for an ordinary 2-D texture).

&lt;h2&gt;Projected Textures&lt;/h2&gt;

Another useful application of the TexProjector is to implement
&lt;b&gt;projected textures&lt;/b&gt;--that is, a texture applied to geometry as
if it has been projected from a lens somewhere in the world, something
like a slide projector.  You can use this to implement a flashlight
effect, for instance, or simple projected shadows.

This works because the TexProjector effect does one additional trick:
if the second NodePath in the &lt;code&gt;setTexProjector()&lt;/code&gt; call
happens to be a LensNode, then the TexProjector automatically applies
the lens's projection matrix to the texture coordinates (in addition to applying the relative transform between the nodes).

To implement projected textures, you need to do three steps:

1. Apply the texture you want to the model you want to project it
onto, usually on its own TextureStage, so that it is [[Multitexture Introduction|multitextured]].

2. Put the &lt;code&gt;MWorldPosition&lt;/code&gt; TexGen mode on the model.  This
copies the model's vertex positions into its texture coordinates, for
your texture's TextureStage.

3. Call &lt;code&gt;model.setTexProjector(textureStage, NodePath(),
projector)&lt;/code&gt;, where &lt;code&gt;projector&lt;/code&gt; is the NodePath to
the LensNode you want to project from.

For your convenience, the NodePath class defines the following method
that performs these three steps at once:

&lt;code python&gt;
nodePath.projectTexture(textureStage, texture, lensNodePath)
&lt;/code&gt;

For instance, we could use it to project the bamboo texture
(&quot;envir-reeds.png&quot;) onto the ripple.egg model, like this:

[[Image:Projected bamboo.jpg|Bamboo projected onto ripple]]

You could move around the projector in the world, or even change the
lens field of view, and the bamboo image would follow it.  (In the
above image, the camera model and the projection lines are made
visible only for illustration purposes; normally you wouldn't see
them.)

This image was generated with the following code (excerpted; [[:Image:Projected bamboo.jpg|click here]] for the complete program):

&lt;code python&gt;
ripple = Actor.Actor('ripple.egg')
ripple.reparentTo(render)

proj = render.attachNewNode(LensNode('proj'))
lens = PerspectiveLens()
proj.node().setLens(lens)
proj.reparentTo(render)
proj.setPos(1.5, -7.3, 2.9)
proj.setHpr(22, -15, 0)

tex = loader.loadTexture('maps/envir-reeds.png')
ts = TextureStage('ts')
ripple.projectTexture(ts, tex, proj)
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>Projectile Intervals</title>
    <ns>0</ns>
    <id>1011</id>
      <sha1>n57x28revkzbhzex212f73px6gwy4ep</sha1>
    <revision>
      <id>7429</id>
      <timestamp>2011-12-08T15:31:00Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="1603">Projectile intervals are used to move a NodePath through the trajectory of a projectile under the influence of gravity.

&lt;code python&gt;
myInterval = ProjectileInterval(&lt;Node Path&gt;,
  startPos = Point3(X,Y,Z), endPos = Point3(X,Y,Z),
  duration = &lt;Time in seconds&gt;, startVel = Point3(X,Y,Z),
  endZ = Point3(X,Y,Z), gravityMult = &lt;multiplier&gt;, name = &lt;Name&gt;)
&lt;/code&gt;

All parameters don't have to be specified. Here are a combination of parameters that will allow you to create a projectile interval. (If startPos is not provided, it will be obtained from the node's position at the time that the interval is first started. Note that in this case you must provide a duration.)

&lt;ul&gt;
	&lt;li&gt;startPos, endPos, duration - go from startPos to endPos in duration seconds
	&lt;li&gt;startPos, startVel, duration - given a starting velocity, go for a specific time period
	&lt;li&gt;startPos, startVel, endZ - given a starting velocity, go until you hit a given Z plane
&lt;/ul&gt;

In addition you may alter gravity by providing a multiplier in 'gravityMult'. '2' will make gravity twice as strong, '.5' half as strong.'-1' will reverse gravity.

Here's a little snippet of code that will demonstrate projectile intervals:

&lt;code python&gt;
camera.setPos(0,-45,0)

# load the ball model
self.ball = loader.loadModel(&quot;smiley&quot;)
self.ball.reparentTo(render)
self.ball.setPos(-15,0,0)

# setup the projectile interval
self.trajectory = ProjectileInterval(self.ball,
                                     startPos = Point3(-15,0,0),
                                     endPos = Point3(15,0, 0), duration = 1)
self.trajectory.loop()
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>Pstats</title>
    <ns>0</ns>
    <id>2246</id>
    <redirect title="Measuring Performance with PStats" />
      <sha1>kl051eqwl2uoiry6e195o1e47bnslrb</sha1>
    <revision>
      <id>5330</id>
      <timestamp>2008-04-03T18:22:18Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[Measuring Performance with PStats]]</comment>
      <text xml:space="preserve" bytes="47">#REDIRECT [[Measuring Performance with PStats]]</text>
    </revision>
  </page>
  <page>
    <title>Public key, private key</title>
    <ns>0</ns>
    <id>2399</id>
      <sha1>bdebohsyi91advqulf5sp2s8nwah7x7</sha1>
    <revision>
      <id>6240</id>
      <timestamp>2009-10-17T15:34:41Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="692">A certificate has two components: the public key, which is copied into
each p3d file you sign and is visible to everyone; and the private
key, which you must keep secret and safe.  If anyone gains access to
your private key, they can use it to sign p3d files in your name,
which means that users could legitimately blame you for installing a
virus on their computer!

Depending on the source that provided your certificate, you may have
the public key and private key saved in two separate files, or they
may be combined into the same file.  Whichever way you store them, you
must keep the private key safe; it's best to keep it encrypted with a
password, and decrypt it only when you use it.</text>
    </revision>
  </page>
  <page>
    <title>Pursue</title>
    <ns>0</ns>
    <id>2584</id>
      <sha1>4tlbri9snsu8wozzl0yvhkwomb379qt</sha1>
    <revision>
      <id>7697</id>
      <timestamp>2012-03-09T10:22:41Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>Panda's &quot;direct&quot; package has nothing to do with &quot;DirectX&quot;</comment>
      <text xml:space="preserve" bytes="4220">&lt;b&gt;'Pursue'&lt;/b&gt; is a behavior where an AICharacter moves in the direction of a target NodePath until it reaches that entity, performing a change in direction of motion according to the entity's motion.

{{#ev:youtube|QdcbN3FLYVs}}


-----

In PandAI, 'Pursue' is defined as :
&lt;code python&gt;
aiBehaviors.pursue(NodePath target, float priority)
&lt;/code&gt;

&lt;b&gt;priority&lt;/b&gt; is by default set to 1.0 and is used when using two or more steering behaviors on an AICharacter.

-----

The velocity at which the AICharacter pursues is determined when you first create your AICharacter object using the AICharacter constructor.

* Note : Pursue's direction is recalculated every frame to handle any change in the target's position.

&lt;b&gt;The actual code working in Panda3D :&lt;/b&gt;

&lt;code python&gt;
import direct.directbase.DirectStart
from panda3d.core import *
from direct.showbase.DirectObject import DirectObject
from direct.task import Task
from direct.actor.Actor import Actor
#for Pandai
from panda3d.ai import *
#for Onscreen GUI
from direct.gui.OnscreenText import OnscreenText

# Globals
speed = 0.75

# Function to put instructions on the screen.
font = loader.loadFont(&quot;cmss12&quot;)
def addInstructions(pos, msg):
    return OnscreenText(text=msg, style=1, fg=(1,1,1,1), font = font,
                        pos=(-1.3, pos), align=TextNode.ALeft, scale = .05)

class World(DirectObject):

    def __init__(self):
        base.disableMouse()
        base.cam.setPosHpr(0,0,55,0,-90,0)
        
        self.loadModels()
        self.setAI()
        self.setMovement()

    def loadModels(self):
        # Seeker
        ralphStartPos = Vec3(-10, 0, 0)
        self.pursuer = Actor(&quot;models/ralph&quot;,
                                 {&quot;run&quot;:&quot;models/ralph-run&quot;})
        self.pursuer.reparentTo(render)
        self.pursuer.setScale(0.5)
        self.pursuer.setPos(ralphStartPos)
        # Target
        self.target = loader.loadModel(&quot;models/arrow&quot;)
        self.target.setColor(1,0,0)
        self.target.setPos(5,0,0)
        self.target.setScale(1)
        self.target.reparentTo(render)
      
    def setAI(self):
        #Creating AI World
        self.AIworld = AIWorld(render)
 
        self.AIchar = AICharacter(&quot;pursuer&quot;,self.pursuer, 100, 0.05, 5)
        self.AIworld.addAiChar(self.AIchar)
        self.AIbehaviors = self.AIchar.getAiBehaviors()
        
        self.AIbehaviors.pursue(self.target)
        self.pursuer.loop(&quot;run&quot;)

        #AI World update        
        taskMgr.add(self.AIUpdate,&quot;AIUpdate&quot;)
        
    #to update the AIWorld    
    def AIUpdate(self,task):
        self.AIworld.update()            
        return Task.cont

    #All the movement functions for the Target
    def setMovement(self):
        self.keyMap = {&quot;left&quot;:0, &quot;right&quot;:0, &quot;up&quot;:0, &quot;down&quot;:0}
        self.accept(&quot;arrow_left&quot;, self.setKey, [&quot;left&quot;,1])
        self.accept(&quot;arrow_right&quot;, self.setKey, [&quot;right&quot;,1])
        self.accept(&quot;arrow_up&quot;, self.setKey, [&quot;up&quot;,1])
        self.accept(&quot;arrow_down&quot;, self.setKey, [&quot;down&quot;,1])
        self.accept(&quot;arrow_left-up&quot;, self.setKey, [&quot;left&quot;,0])
        self.accept(&quot;arrow_right-up&quot;, self.setKey, [&quot;right&quot;,0])
        self.accept(&quot;arrow_up-up&quot;, self.setKey, [&quot;up&quot;,0])
        self.accept(&quot;arrow_down-up&quot;, self.setKey, [&quot;down&quot;,0])
        #movement task
        taskMgr.add(self.Mover,&quot;Mover&quot;)
        
        addInstructions(0.9, &quot;Use the Arrow keys to move the Red Target&quot;)

    def setKey(self, key, value):
        self.keyMap[key] = value
            
    def Mover(self,task):
        startPos = self.target.getPos()
        if (self.keyMap[&quot;left&quot;]!=0):
                self.target.setPos(startPos + Point3(-speed,0,0))
        if (self.keyMap[&quot;right&quot;]!=0):
                self.target.setPos(startPos + Point3(speed,0,0))
        if (self.keyMap[&quot;up&quot;]!=0):
                self.target.setPos(startPos + Point3(0,speed,0))
        if (self.keyMap[&quot;down&quot;]!=0):
                self.target.setPos(startPos + Point3(0,-speed,0))
                        
        return Task.cont
 
w = World()
run()

&lt;/code&gt;

&lt;b&gt;To get the full working demo, please visit :&lt;/b&gt;

https://sites.google.com/site/etcpandai/documentation/steering-behaviors/pursue/PandAIPursueExample.zip?attredirects=0&amp;d=1</text>
    </revision>
  </page>
  <page>
    <title>Pusher Example</title>
    <ns>0</ns>
    <id>1012</id>
      <sha1>cppygcpnxi2fyylfy0r4fxubd1owgtf</sha1>
    <revision>
      <id>7676</id>
      <timestamp>2012-03-08T20:18:26Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>new import system</comment>
      <text xml:space="preserve" bytes="2295">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

[python]
&lt;p&gt;Here is a short example that shows two small spheres using a &lt;code&gt;CollisionHandlerPusher&lt;/code&gt;:&lt;/p&gt;
&lt;code python&gt;
from direct.showbase.ShowBase import ShowBase
from panda3d.core import CollisionTraverser, CollisionHandlerPusher
from panda3d.core import CollisionNode, CollisionSphere
from panda3d.core import Point3

# Initialize the scene.
ShowBase()

# Initialize the collision traverser.
base.cTrav = CollisionTraverser()

# Initialize the Pusher collision handler.
pusher = CollisionHandlerPusher()

# Load a model.
smiley = loader.loadModel('smiley')
# Reparent the model to the camera so we can move it.
smiley.reparentTo(camera)
# Set the initial position of the model in the scene.
smiley.setPos(0, 25.5, 0.5)

# Create a collision node for this object.
cNode = CollisionNode('smiley')
# Attach a collision sphere solid to the collision node.
cNode.addSolid(CollisionSphere(0, 0, 0, 1.1))
# Attach the collision node to the object's model.
smileyC = smiley.attachNewNode(cNode)
# Set the object's collision node to render as visible.
smileyC.show()

# Load another model.
frowney = loader.loadModel('frowney')
# Reparent the model to render.
frowney.reparentTo(render)
# Set the position of the model in the scene.
frowney.setPos(5, 25, 0)

# Create a collsion node for this object.
cNode = CollisionNode('frowney')
# Attach a collision sphere solid to the collision node.
cNode.addSolid(CollisionSphere(0, 0, 0, 1.1))
# Attach the collision node to the object's model.
frowneyC = frowney.attachNewNode(cNode)
# Set the object's collision node to render as visible.
frowneyC.show()

# Add the Pusher collision handler to the collision traverser.
base.cTrav.addCollider(frowneyC, pusher)
# Add the 'frowney' collision node to the Pusher collision handler.
pusher.addCollider(frowneyC, frowney, base.drive.node())

# Have the 'smiley' sphere moving to help show what is happening.
frowney.posInterval(5, Point3(5, 25, 0), startPos=Point3(-5, 25, 0), fluid=1).loop()

# Run the scene. Move around with the mouse to see how the moving sphere changes 
# course to avoid the one attached to the camera.
run()
&lt;/code&gt;
[/python]

[cxx]
&lt;h2&gt;Incomplete Section&lt;/h2&gt;

&lt;p&gt;Note: this section is incomplete. It will be updated soon.&lt;/p&gt;
[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Putting your new geometry in the scene graph</title>
    <ns>0</ns>
    <id>1772</id>
      <sha1>6utfjp8z1sd7log42k36n6oe6rp5c64</sha1>
    <revision>
      <id>6326</id>
      <timestamp>2009-11-06T16:12:09Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>reverted change from Andre_Mikulec, the code is useful but totally in the wrong place</comment>
      <text xml:space="preserve" bytes="2051">Finally, now that you have a [[GeomVertexData]] and one or more
[[GeomPrimitive]] objects, you can create a [[Geom|&lt;b&gt;Geom&lt;/b&gt;]] object and a [[GeomNode|&lt;b&gt;GeomNode&lt;/b&gt;]] to
put the new geometry in the scene graph, so that it will be rendered.

[python]&lt;code python&gt;
geom = Geom(vdata)
geom.addPrimitive(prim)

node = GeomNode('gnode')
node.addGeom(geom)

nodePath = render.attachNewNode(node)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
PT(Geom) geom;
geom = new Geom(vdata);
geom-&gt;add_primitive(prim);

PT(GeomNode) node;
node = new GeomNode(&quot;gnode&quot;);
node-&gt;add_geom(geom);

NodePath nodePath = window-&gt;get_render().attach_new_node(node);
&lt;/code&gt;[/cxx]


The Geom constructor requires a pointer to the GeomVertexData object
you will be using.  There is only one GeomVertexData associated with
any particular Geom.  You can reset the Geom to use a different
GeomVertexData later, if you like, by calling geom.setVertexData().

The GeomNode constructor requires a name, which is the name of the
node and will be visible in the scene graph.  It can be any name you
like that means something to you.

In the above example, we have created only one Geom, and added only
one GeomPrimitive to the Geom.  This is the most common case when you
are creating geometry at runtime, although in fact a GeomNode may
include multiple Geoms, and each Geom may include multiple
GeomPrimitives.  (However, all of the primitives added to a Geom must
have the same fundamental primitive type: triangles, lines, or points.
You can add GeomTriangles and GeomTristrips to the same Geom, or you
can add GeomLines and GeomLinestrips, but if you have GeomTriangles
and GeomLinestrips, you must use two different Geoms.)

It is important that the range of vertex index numbers used by your
GeomPrimitives is consistent with the number of vertices in your
GeomVertexData (for instance, if you have 100 vertices in your
GeomVertexData, your GeomPrimitives must only reference vertices
numbered 0 through 99).  If this is not the case, you will get an
exception when you call addPrimitive().</text>
    </revision>
  </page>
  <page>
    <title>Pview</title>
    <ns>0</ns>
    <id>2316</id>
    <redirect title="Previewing 3D Models in Pview" />
      <sha1>t26m97xsrf0w4zn2gdf4w7xghwvrffz</sha1>
    <revision>
      <id>5726</id>
      <timestamp>2009-03-24T13:03:05Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[Previewing 3D Models in Pview]]</comment>
      <text xml:space="preserve" bytes="43">#REDIRECT [[Previewing 3D Models in Pview]]</text>
    </revision>
  </page>
  <page>
    <title>Python Editors</title>
    <ns>0</ns>
    <id>1013</id>
      <sha1>5i3cjnfclk73ddetred7iip8771bja7</sha1>
    <revision>
      <id>7500</id>
      <timestamp>2011-12-24T13:40:23Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>added Geany to the list of editors</comment>
      <text xml:space="preserve" bytes="3771">&lt;p&gt;
Using a well featured python editor or editor with python support will greatly
ease the process of writing python scripts.

Here are some of the features that you could look for when choosing an editor. Free editors don't usually have them all. There are quite a few capable editors out there though. In addition to all the features listed below, it should in general be a good and easy to use text editor.
&lt;ul&gt;
&lt;li&gt;Syntax highlighting&lt;/li&gt;
&lt;li&gt;Smart indentation&lt;/li&gt;
&lt;li&gt;Auto-completion of text&lt;/li&gt;
&lt;li&gt;Call tips&lt;/li&gt;
&lt;li&gt;Tree view function/class selection&lt;/li&gt;
&lt;li&gt;Integrated shell windows&lt;/li&gt;
&lt;li&gt;Inbuilt debugger support&lt;/li&gt;
&lt;li&gt;Code folding support&lt;/li&gt;
&lt;li&gt;Customibility and extensibility&lt;/li&gt;
&lt;li&gt;Multi-platform support&lt;/li&gt;
&lt;li&gt;Unicode support&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;

&lt;p&gt;
The python install itself comes with a very capable editor called IDLE, short for &lt;b&gt;I&lt;/b&gt;ntegrated &lt;b&gt;D&lt;/b&gt;eve&lt;b&gt;l&lt;/b&gt;opment &lt;b&gt;E&lt;/b&gt;nvironment. One of the features it has that the ones listed above do not is that it has an &lt;i&gt;enhanced&lt;/i&gt; integrated shell. More information about IDLE can be found [http://www.python.org/idle/doc/idlemain.html here].
&lt;/p&gt;

&lt;p&gt;
Below is a list of a few free text editors. There is a comprehensive list of editors at [http://www.python.org/moin/PythonEditors http://www.python.org/moin/PythonEditors]. Some of the information about the editors doesn't seem to be upto date at this listing. Try them yourself to find your favourite one.

&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;[http://pype.sourceforge.net/ PyPE]&lt;/td&gt;&lt;td&gt;Syntax highlighting, auto-completion, smart indentation, calltips, tree view function/class selection, integrated shell, drag&amp;drop, macros, customizable keyboard shortcuts, and more. Works on Windows and X. Written in python!&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;[http://www.gnu.org/software/emacs/emacs.html Emacs]&lt;/td&gt;&lt;td&gt;Very powerful text editor, multiplatform, python support. Smart indentation, auto-completion, syntax highlighting, extensible. &lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;[http://www.vim.org/ Vim]&lt;/td&gt;&lt;td&gt;Very powerful text editor, multiplatform, python support. Smart indentation, syntax highlighting, Scriptable in python.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;[http://www.python.org/moin/ConText ConText]&lt;/td&gt;&lt;td&gt;Windows based free text editor with python syntax highlighting, and indentation support.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;[http://www.stani.be/python/spe/blog/ SPE]&lt;/td&gt;&lt;td&gt;Syntax highlighting, smart indentation, auto-completion, call tips, class explorer, integrated shell, debugger, code folding, syntax coloring, UML viewer, syntax highlighting, source index, sticky notes, drag&amp;drop, context help, and much more. Runs on Windows, Linux and Mac OS X. Also links to Blender. GUI is extensible with wxGlade. GPL'ed and written in Python.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;[http://pydev.sourceforge.net/ PyDev]&lt;/td&gt;&lt;td&gt;PyDev is a plugin that enables users to use Eclipse for Python and Jython development -- making Eclipse a first class Python IDE -- It comes with many goodies such as code completion, syntax highlighting, syntax analysis, refactor, &lt;b&gt;debugging&lt;/b&gt; and many others.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;[http://www.activestate.com/Products/komodo_ide/komodo_edit.mhtml  Komodo Edit]&lt;/td&gt;&lt;td&gt;Komodo Edit, based on the award-winning Komodo IDE, offers sophisticated support for all major scripting languages, including in-depth autocomplete and calltips, multi-language file support, syntax coloring and syntax checking, Vi emulation, Emacs key bindings.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;[http://geany.org/  Geany]&lt;/td&gt;&lt;td&gt;Geany is a text editor using the GTK2 toolkit with basic features of an integrated development environment. It was developed to provide a small and fast IDE, which has only a few dependencies from other packages. It supports many filetypes and has some nice features.&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;
&lt;/p&gt;</text>
    </revision>
  </page>
  <page>
    <title>Rapidly-Moving Objects</title>
    <ns>0</ns>
    <id>1256</id>
      <sha1>rtlidwi40m7bbyspo7h2r44v6p0mbrt</sha1>
    <revision>
      <id>7675</id>
      <timestamp>2012-03-08T20:16:44Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="5167">Panda3D's collision system works by testing the current state of the
world every frame for a possible intersection.  If your objects are
moving so quickly that they might pass completely through another
object in the space of one frame, however, that collision might never
be detected.

To avoid this problem, the Panda3D scene graph supports an advanced
feature: it can record the &lt;i&gt;previous frame's position&lt;/i&gt; of each
moving object for the benefit of the CollisionTraverser.  The
CollisionTraverser can then take advantage of this information when it
is testing for collisions.  If it sees that a moving object was on one
side of an object last frame, and on the opposite side this frame, it
can trigger the collision detection even though the two objects might
not currently be intersecting.

There are a few things you need to do to activate this mode.

1. First, you must tell the CollisionTraverser that you intend to use
this mode; by default, it ignores the previous position information.
To activate this mode, call:

&lt;code python&gt;
base.cTrav.setRespectPrevTransform(True)
&lt;/code&gt;

You only need to make this call once, at the beginning of your
application (or whenever you create the CollisionTraverser).  That
switches the CollisionTraverser into the new mode.  If you create any
additional CollisionTraversers, you should make the call for them as
well.

2. Ensure that &lt;code&gt;base.resetPrevTransform(render)&lt;/code&gt; is called
every frame.  Actually, this is already done for you automatically by
ShowBase.py, so normally you don't need to do anything for this step.

The &lt;code&gt;resetPrevTransform()&lt;/code&gt; call should be made once per
frame (at the very beginning of the frame) for every different scene
graph in your application that involves collisions.  It ensures that
the current frame's position is copied to the previous frame's
position, before beginning the processing for that frame.  Note that
if you have multiple CollisionTraversers handling the same scene
graph, you only need to (and only should) call this function once, but
if you have two or more disconnected scene graphs, you will need to
call it for each scene graph.

If you don't understand the above paragraph, then you aren't using disconnected scene graphs, and you shouldn't worry about it.

3. Whenever you move an object from one point to another in your scene
(except when you put it into your scene the first time), instead of
using:

&lt;code python&gt;
object.setPos(newPos)
&lt;/code&gt;

You should use:

&lt;code python&gt;
object.setFluidPos(newPos)
&lt;/code&gt;

In general, &lt;code&gt;setPos()&lt;/code&gt; means &quot;put the object here,
directly&quot; and &lt;code&gt;setFluidPos()&lt;/code&gt; means &quot;slide the object here,
testing for collisions along the way&quot;.  It is important to make a
clear distinction between these two calls, and make the appropriate call
for each situation.

If you are moving an object with a [[Lerp Intervals|LerpInterval]],
and you want collisions to be active (and fluid) during the lerp, you
should pass the keyword parameter &lt;code&gt;fluid = 1&lt;/code&gt; to the
LerpInterval constructor.  It is rare to expect collisions to be
active while an object is moving under direct control of the
application, however.

&lt;h2&gt;Visualizing the previous transform&lt;/h2&gt;

When you are using the setFluidPos() call, and you have called
&lt;code&gt;show()&lt;/code&gt; on your CollisionNode to make it visible, you will
see the CollisionNode itself each frame, plus a ghosted representation
of where it was the previous frame.  This can help you visually see
that the previous-transform mechanism is working.  (It does not
guarantee that the &lt;code&gt;setRespectPrevTransform()&lt;/code&gt; call has
been made on your CollisionTraverser, however.)

&lt;h2&gt;Caveats&lt;/h2&gt;

At the present, the CollisionTraverser only uses the previous
transform information when it is testing a CollisionSphere into a
CollisionPolygon--that is, when the &quot;from&quot; object is a
CollisionSphere, and the &quot;into&quot; object is a CollisionPolygon (or a
wall of CollisionPolygons).  Other kinds of collision solids currently
do not consider the previous transform.  (However, the other collision
solids are generally thicker than a CollisionPolygon, so it is less
likely that a moving object will pass all the way through them in one
frame--so it is not quite as bad as it seems.)

Enabling the previous transform mode helps reduce slipping through
walls considerably.  However, it's not perfect; no collision system
is.  If your object is moving tremendously fast, or just happens to
get lucky and slip through a tiny crack between adjacent polygons, it
may still get through without detecting a collision.  Any good
application will be engineered so that the occasional collision slip
does not cause any real harm.

The CollisionHandlerFloor is especially bad about allowing objects to
slip through floors, in spite of the previous transform state,
especially when you avatar is walking up a sloping path.  This is just
because of the way the CollisionHandlerFloor works.  If you are having
problems with the CollisionHandlerFloor, consider reducing the slope
of your floors, increasing the height of the ray above the ground,
and/or reducing the speed of your avatar.</text>
    </revision>
  </page>
  <page>
    <title>Reading existing geometry data</title>
    <ns>0</ns>
    <id>1773</id>
      <sha1>nr7qe0ollah8lpeufywdr7choqqebkw</sha1>
    <revision>
      <id>8031</id>
      <timestamp>2013-05-30T07:35:38Z</timestamp>
      <contributor>
        <username>Pataua101</username>
        <id>665</id>
      </contributor>
      <text xml:space="preserve" bytes="7765">You can fairly easily extract and examine or operate on the vertices
for an existing model, although you should be aware that the
&lt;em&gt;order&lt;/em&gt; in which the vertices appear in a model is undefined.
There is no correlation between the order in which vertices are listed
in an egg file, and the order in which they will appear in the
resulting loaded model.  Panda may rearrange the vertices, or even add
or remove vertices, as needed to optimize the model for rendering
performance.  Even from one session to the next, the vertices might
come out in a different order.

This does make certain kinds of vertex operations difficult; if you
plan to write code that expects to encounter the vertices of a model
in a particular order, we recommend you build up those vertices
yourself using a [[More about GeomVertexReader, GeomVertexWriter, and GeomVertexRewriter|GeomVertexWriter]] (as described in [[Creating and filling a GeomVertexData]]), so that you have explicit control over the vertex order.

However, if you have no need to operate on the vertices in any
particular order, or if you just want to casually browse the vertices
in a model, feel free to use the following instructions to read the
data.

When you load a model, you have a handle to the root node of
the model, which is usually a &lt;b&gt;ModelRoot&lt;/b&gt; node.  The geometry itself
will be stored in a series of [[GeomNode|&lt;b&gt;GeomNodes&lt;/b&gt;]], which will be children of the
root node.  In order to examine the vertex data, you must visit the
GeomNodes in the model.  One way to do this is to walk through all the
GeomNodes like this:

[python]&lt;code python&gt;
geomNodeCollection = model.findAllMatches('**/+GeomNode')
for nodePath in geomNodeCollection.asList():
  geomNode = nodePath.node()
  processGeomNode(geomNode)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
NodePathCollection geomNodeCollection = model.find_all_matches(&quot;**/+GeomNode&quot;);
    for(int i =0;i&lt;geomNodeCollection.get_num_paths();i++){
        PT(GeomNode) g = DCAST(GeomNode,geomNodeCollection.get_path(i).node());
        processGeomNode(g);
    }
&lt;/code&gt;[/cxx]

Once you have a particular GeomNode, you must walk through the list of
[[Geom|&lt;b&gt;Geoms&lt;/b&gt;]] stored on that node.  Each Geom also has an associated
RenderState, which controls the visible appearance of that Geom
(e.g. texture, backfacing, etc.).

[python]&lt;code python&gt;
def processGeomNode(geomNode):
  for i in range(geomNode.getNumGeoms()):
    geom = geomNode.getGeom(i)
    state = geomNode.getGeomState(i)
    print geom
    print state
    processGeom(geom)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
void processGeomNode(GeomNode *geomnode)
{
     for(int j=0;j&lt;geomnode.get_num_geoms();j++){
         const PT(Geom) geom = geomnode.get_geom(j);
         geom-&gt;write(nout);//outputs basic info on the geom
         geomnode.get_geom_state(j)-&gt;write(nout);//basic renderstate info
         processGeom(geom);
     }
}
&lt;/code&gt;[/cxx]

Note that geomNode.getGeom() is only appropriate if you will be
reading, but not modifying, the data.  If you intend to modify the
geom data in any way (including any nested data like vertices or
primitives), you should use geomNode.modifyGeom() instead.

Each Geom has an associated [[GeomVertexData|&lt;b&gt;GeomVertexData&lt;/b&gt;]], and one or more
[[GeomPrimitive|&lt;b&gt;GeomPrimitives&lt;/b&gt;]].  Some GeomVertexData objects may be shared by more
than one Geom, especially if you have used flattenStrong() to optimize
a model.

[python]&lt;code python&gt;
def processGeom(geom):
  vdata = geom.getVertexData()
  print vdata
  processVertexData(vdata)
  for i in range(geom.getNumPrimitives()):
    prim = geom.getPrimitive(i)
    print prim
    processPrimitive(prim, vdata)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
void processGeom(Geom *geom)
{
    const PT(GeomVertexData) vdata = geom-&gt;get_vertex_data();
    vdata-&gt;write(nout);
    processVertexData(vdata);
    for(int i=0;i&lt;geom.get_num_primitives();i++){
     const PT(GeomPrimitive) prim = geom-&gt;get_primitive(i);
     prim-&gt;write(nout,0);
     processPrimitive(prim, vdata);
    }
}
&lt;/code&gt;[/cxx]

As above, get_vertex_data() is only appropriate if you will only be
reading, but not modifying, the vertex data.  Similarly,
getPrimitive() is appropriate only if you will not be modifying the
primitive index array.  If you intend to modify either one, use
modifyVertexData() or modifyPrimitive(), respectively.

You can use the [[More about GeomVertexReader, GeomVertexWriter, and GeomVertexRewriter|&lt;b&gt;GeomVertexReader&lt;/b&gt;]] class to examine the vertex data.
You should create a GeomVertexReader for each column of the data you
intend to read.  It is up to you to ensure that a given column exists
in the vertex data before you attempt to read it (you can use
vdata.hasColumn() to test this).

[python]&lt;code python&gt;
def processVertexData(vdata):
  vertex = GeomVertexReader(vdata, 'vertex')
  texcoord = GeomVertexReader(vdata, 'texcoord')
  while not vertex.isAtEnd():
    v = vertex.getData3f()
    t = texcoord.getData2f()
    print &quot;v = %s, t = %s&quot; % (repr(v), repr(t))
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
void processVertexData(const GeomVertexData *vdata)
{
    GeomVertexReader vertex = GeomVertexReader(vdata,&quot;vertex&quot;);
    GeomVertexReader texcoord = GeomVertexReader(vdata,&quot;texcoord&quot;);
    while(!vertex.is_at_end()){
        LVector3f v = vertex.get_data3f();
	LVector3f t = texcoord.get_data2f();
        nout &lt;&lt; &quot;V = &quot; &lt;&lt; v &lt;&lt; &quot;T = &quot; &lt;&lt; t &lt;&lt; endl;
    }
}
&lt;/code&gt;[/cxx]

Each GeomPrimitive may be any of a handful of different classes,
according to the primitive type it is; but all GeomPrimitive classes
have the same common interface to walk through the list of vertices
referenced by the primitives stored within the class.

You can use the setRow() method of GeomVertexReader to set the reader
to a particular vertex.  This affects the next call to getData().  In
this way, you can extract the vertex data for the vertices in the
order that the primitive references them (instead of in order from the
beginning to the end of the vertex table, as above).

[python]&lt;code python&gt;
def processPrimitive(prim, vdata):
  vertex = GeomVertexReader(vdata, 'vertex')

  prim = prim.decompose()

  for p in range(prim.getNumPrimitives()):
    s = prim.getPrimitiveStart(p)
    e = prim.getPrimitiveEnd(p)
    for i in range(s, e):
      vi = prim.getVertex(i)
      vertex.setRow(vi)
      v = vertex.getData3f()
      print &quot;prim %s has vertex %s: %s&quot; % (p, vi, repr(v))
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
void processPrimitive(const GeomPrimitive *prim,const GeomVertexData *vdata)
{
    GeomVertexReader vertex = GeomVertexReader(vdata,&quot;vertex&quot;);
   //Note: There should be prim = prim-&gt;decompose(); here,it wouldnt work
   //for me but i use the cvs panda and that could have been broken at this time.
    for(int k =0;k&lt;prim-&gt;get_num_primitives();k++){
	int s = prim-&gt;get_primitive_start(k);
	int e = prim-&gt;get_primitive_end(k);
	for(int i = s;i&lt;e;i++){
	    int vi = prim-&gt;get_vertex(b);
	    vertex.set_row(vi);
	    LVector3f v = vertex.get_data3f();
	    nout &lt;&lt; &quot;prim &quot; &lt;&lt; k &lt;&lt; &quot; has vertex &quot; &lt;&lt; vi &lt;&lt;&quot;: &quot; &lt;&lt; v &lt;&lt; endl;
        }
    } 
}
&lt;/code&gt;[/cxx]

You may find the call to prim.decompose() useful (as shown in the
above example).  This call automatically decomposes higher-order
primitive types, like GeomTristrips and GeomTrifans, into the
equivalent component primitive types, like GeomTriangles; but when called on a GeomTriangles, it returns the GeomTriangles object unchanged.  Similarly,
GeomLinestrips will be decomposed into GeomLines.  This way you can
write code that doesn't have to know anything about GeomTristrips and
GeomTrifans, which are fairly complex; it can assume it will only get
the much simpler GeomTriangles (or, in the case of lines or points,
GeomLines and GeomPoints, respectively).</text>
    </revision>
  </page>
  <page>
    <title>Reading the HTML tokens</title>
    <ns>0</ns>
    <id>2424</id>
      <sha1>2fyuy0s2vw35azd5fyd1lbnglaf10o4</sha1>
    <revision>
      <id>6289</id>
      <timestamp>2009-10-25T21:16:28Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="1138">As described in [[Advanced object tags]], you can write Python code to respond to any arbitrary tokens given in the &lt;object&gt; element.  The AppRunner provides several interfaces for this:

* base.appRunner.tokens

This is a the raw token data, as a list of (token, value) tuples.  Each token in the &lt;object&gt; element, or in a &lt;param&gt; element within the &lt;object&gt; element, will appear here, in the order they appear on the web page.  You can traverse this list if you have a token that supports multiple values.  However, for most token values, which only define one value each, it's probably easier to use one of the following:

* base.appRunner.getToken()
* base.appRunner.getTokenInt()
* base.appRunner.getTokenFloat()
* base.appRunner.getTokenBool()

These define a simple accessor to query a value defined for a particular token.  They all return None if the token is not defined.  The first form, getToken(), is the simplest, and returns the string value exactly as it appears on the web page.  getTokenInt(), getTokenFloat(), and getTokenBool() automatically coerce this value into an integer, floating-point number, and boolean value.</text>
    </revision>
  </page>
  <page>
    <title>Reference Counted</title>
    <ns>0</ns>
    <id>2164</id>
    <redirect title="Reference Counting" />
      <sha1>b1x7eucw2o9rea5z60blfo3sybol6z4</sha1>
    <revision>
      <id>4627</id>
      <timestamp>2007-12-08T17:43:04Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>Redirecting to [[Reference Counting]]</comment>
      <text xml:space="preserve" bytes="32">#REDIRECT [[Reference Counting]]</text>
    </revision>
  </page>
  <page>
    <title>Reference Counting</title>
    <ns>0</ns>
    <id>2166</id>
      <sha1>6tzgk9yjwohhqd8cfnl8b2qkubj2irp</sha1>
    <revision>
      <id>60305</id>
      <timestamp>2014-12-26T13:20:15Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>/* Smart Pointers */</comment>
      <text xml:space="preserve" bytes="6185">== Reference Counts ==
To manage the lifetime of objects, Panda3D has a reference counting system for many objects.  This means that for every object that uses this mechanism, a reference count is kept which counts the number of references exist to that object.  Every time a new reference is made (eg. assigned to a new variable), the reference count is increased.  When the reference count reaches zero, the object is deleted.

This is similar to Python's reference counting system, and in fact, the two systems interact when Panda3D is used with Python.  However, since an object's lifetime may persist beyond the lifetime of an object in Python, Python's own reference counting system alone is not sufficient.

The class that manages the reference count is ReferenceCount.  To see if a class is reference counted, check if it inherits from ReferenceCount.  To implement a new class that is reference counted, inherit it from either ReferenceCount or TypedReferenceCount (if use of the typing system is desired), or another class that in itself inherits from ReferenceCount.

== Managing Reference Counts ==
There are several ways that the reference count can be manipulated in C++ code.  To get the number of references to an object, use the &lt;code&gt;get_ref_count()&lt;/code&gt; method.

=== Smart Pointers ===
To correctly track references in C++ code, Panda3D needs to know whenever a new reference to the class is created.  Therefore, Panda3D defines a template class &lt;code&gt;PointerTo&amp;lt;T&amp;gt;&lt;/code&gt; which is just like the ordinary pointer &lt;code&gt;T*&lt;/code&gt;, except that the reference count is incremented when it is created or assigned, and decremented when it goes out of scope.  There is a convenience macro &lt;code&gt;PT(T)&lt;/code&gt; to save typing.

There is also a macro &lt;code&gt;ConstPointerTo&amp;lt;T&amp;gt;&lt;/code&gt;, shortened to &lt;code&gt;CPT(T)&lt;/code&gt;, which manages a pointer to a const object.  This is similar to &lt;code&gt;const T*&lt;/code&gt; in C++; the pointer can still be reassigned, but the object may not be modified.

This is a usage example:
&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;PT(TextNode) node = new TextNode(&quot;title&quot;);

node-&gt;set_text(&quot;I am a reference counted TextNode!&quot;);
&lt;/syntaxhighlight&gt;

A &lt;code&gt;PointerTo&lt;/code&gt; is functionally equivalent to a regular pointer, and it can cast implicitly to the appropriate pointer type.  You can use &lt;code&gt;ptr.p()&lt;/code&gt; to explicitly retrieve the underlying plain pointer.

=== When they aren't necessary ===
Although it is safest to use &lt;code&gt;PointerTo&lt;/code&gt; to refer to an object in all cases, in some cases it is not strictly necessary and may be more efficient not to.

This can only be done, however, when you are '''absolutely sure''' that the reference count cannot decrease to zero during the time you might be using that reference.  In particular, a getter or setter of a class storing a &lt;code&gt;PointerTo&lt;/code&gt; need not take or return a &lt;code&gt;PointerTo&lt;/code&gt; since the class object itself already holds a reference count.

The following code example highlights a case where it is not necessary:
&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;PT(TextNode) node;
node = new TextNode(&quot;title&quot;);

use_text_node(node);

void use_text_node(TextNode *node) {
  node-&gt;do_something();
}
&lt;/syntaxhighlight&gt;

One crucial example where the return value of a function has to be a &lt;code&gt;PointerTo&lt;/code&gt; is where the function may return a new instance of the object:
&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
PT(TextNode) make_text_node() {
  return new TextNode(&quot;title&quot;);
}

PT(TextNode) node = make_text_node();
&lt;/syntaxhighlight&gt;

== Managing Reference Count ==
Although it is recommended to use &lt;code&gt;PointerTo&lt;/code&gt; for all references, it is possible to manage the reference count manually using the &lt;code&gt;ref()&lt;/code&gt; and &lt;code&gt;unref()&lt;/code&gt; methods.

This can not always work as an alternative, though, since an object returned from a function that returns a &lt;code&gt;PointerTo&lt;/code&gt; may be destructed before you get a chance to call &lt;code&gt;ref()&lt;/code&gt; to save it!  This is why it's recommended to always use &lt;code&gt;PointerTo&lt;/code&gt; except in very rare, low-level cases.

Important to note, however, is that the &lt;code&gt;unref()&lt;/code&gt; method should ''not'' be used if it may cause the reference count to reach zero.  This is because a member function cannot destruct the object it is called on.  Instead, you should use the &lt;code&gt;unref_delete()&lt;/code&gt; macro to decrease the reference count unless you are absolutely sure that it will not reach zero.

== Weak Pointer ==
A weak pointer stores a reference to an object without incrementing its reference count.  In this respect it is just like a regular C++ pointer, except that weak pointers have extra advantages: they can know when the underlying object has been destructed.

Weak pointers are implemented by &lt;code&gt;WeakPointerTo&amp;lt;T&amp;gt;&lt;/code&gt; and &lt;code&gt;WeakConstPointerTo&amp;lt;T&amp;gt;&lt;/code&gt;, abbreviated to &lt;code&gt;WPT(T)&lt;/code&gt; and &lt;code&gt;WCPT(T)&lt;/code&gt;, respectively.  They work just like regular pointers, but be careful not to dereference it if it may have already been deleted!  To see if it has been deleted, call &lt;code&gt;ptr.was_deleted()&lt;/code&gt;.

== Circular References ==
When designing your class hierarchy, you should be particularly wary of circular references.  This happens when object A stores a reference to object B, but object B also stores a reference to object A.  Since each object will always retain a reference to the other object, the reference count will never reach zero and memory leaks may ensue.

One way to solve this problem is to store a regular, non-reference counted pointer to object A in object B, and let object A unset the reference to itself in its destructor.  This is not a general solution, however, and the most optimal solution depends on the specific situation.

== Stack Allocation ==
In some rare cases, it is desirable to create a temporary instance of the object on the stack.  To achieve this, it is necessary to call &lt;code&gt;local_object()&lt;/code&gt; on the object directly after allocation:
&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
Texture tex;
tex.local_object();
&lt;/syntaxhighlight&gt;
However, this should only be used for very temporary objects, since reference counted objects are not meant to be passed by value.</text>
    </revision>
  </page>
  <page>
    <title>Reference counted</title>
    <ns>0</ns>
    <id>2163</id>
    <redirect title="Reference Counting" />
      <sha1>b1x7eucw2o9rea5z60blfo3sybol6z4</sha1>
    <revision>
      <id>4626</id>
      <timestamp>2007-12-08T17:42:48Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>Redirecting to [[Reference Counting]]</comment>
      <text xml:space="preserve" bytes="32">#REDIRECT [[Reference Counting]]</text>
    </revision>
  </page>
  <page>
    <title>Reference counting</title>
    <ns>0</ns>
    <id>2165</id>
    <redirect title="Reference Counting" />
      <sha1>b1x7eucw2o9rea5z60blfo3sybol6z4</sha1>
    <revision>
      <id>4628</id>
      <timestamp>2007-12-08T17:43:21Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>Redirecting to [[Reference Counting]]</comment>
      <text xml:space="preserve" bytes="32">#REDIRECT [[Reference Counting]]</text>
    </revision>
  </page>
  <page>
    <title>Referencing packages</title>
    <ns>0</ns>
    <id>2393</id>
      <sha1>euyxhme9khdus59hi1wd1fd33isyf3z</sha1>
    <revision>
      <id>6642</id>
      <timestamp>2010-02-07T19:07:16Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <text xml:space="preserve" bytes="1892">When the Panda3D plugin system runs your p3d file, it must first
download the correct version of Panda3D, as well as any auxiliary
packages your p3d file requires in order to run.  Generally, the
auxiliary packages represent parts of the Panda3D system that are not
required by all p3d files, and so have been separated to minimize
unnecessary download.

The current set of auxiliary packages provided by the Panda3D team
are:

* fmod - The FMod audio system, a closed-source library that is cost-free only for non-commercial use.

* openal - The OpenAL audio system, an audio library that is free in both senses of the word, but does not work well on all platforms.

* audio - Including this package implicitly includes either fmod or openal, whichever works best on the current platform.  This is a good choice to enable audio for non-GPL, non-commercial applications.

* egg - The egg loader.  Include this package if you wish to load egg files or use the egg library at runtime.  Since packp3d automatically converts egg files to bam files, most applications don't need to include this package.

* vision - The Panda3D vision libraries, containing webcam, computer vision and augmented reality support.

* ode - The ODE physics engine.

* physx - The PhysX physics engine.  Only functional on 32-bits Linux and Windows.

* wx - The wxPython GUI system.

* tk - The Tk GUI system.

* ai - The PandAI libraries.

* morepy - A collection of the default Python modules.  You may need to mark this as dependency if you find default Python modules missing when running your game.

There are also other packages for Python libraries, such as httplib2, numpy, pil, pycurl, pygame, pyopengl, sqlite, tk and twisted.  More packages can be added if there is need.

To include any of the above packages in your p3d file, use the &quot;-r&quot;
parameter to packp3d, e.g. &quot;packp3d -o myapp.p3d -r audio -r ode&quot;.</text>
    </revision>
  </page>
  <page>
    <title>Removing Custom Class Instances</title>
    <ns>0</ns>
    <id>2659</id>
      <sha1>h9rcuibidgkcwjimcr915pol9lvvdzc</sha1>
    <revision>
      <id>7575</id>
      <timestamp>2012-01-29T12:32:47Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code highlight</comment>
      <text xml:space="preserve" bytes="5266">The following text was taken from the Panda3D 1.6 Game Engine Beginner's Guide available from Packt Publishing with the author's permission. The text refers to a &quot;custom class&quot;, which is a python class that is not part of the Panda3D SDK. Here is an example of a custom class:

&lt;code python&gt;
class MyClass:
  def __init__(self):
    myVar1 = 10
    myVar2 = 20
  def myMethod(self):
    return(self.myVar1, self.myVar2)
&lt;/code&gt;

From Panda3D 1.6 Game Engine Beginner's Guide:

Python will automatically garbage collect a custom class instance when all the references to that instance are removed. In theory, this makes garbage collection as simple as cleaning up those references, but because there are so many different places and reasons for these references garbage collection can quickly grow complicated. Following these steps will help to ensure that a custom class instance is properly garbage collected.

1. Call &lt;code&gt;removeNode()&lt;/code&gt; on all NodePaths in the scene graph – The first step is to clear out the NodePaths that the custom class has added to the scene graph. If this step isn’t accomplished, it won’t necessarily prevent the custom class instance from being garbage collected, but it could. Even if the custom class instance is still garbage collected the scene graph itself will retain references to the NodePaths that haven’t been cleared out and they will remain in the scene graph. There is one exception to this rule: when a parent NodePath has removeNode called on it that ultimately result in the removal of its child NodePaths, so long as nothing else retains a reference to them. However, relying on this behavior is an easy way to make mistakes so it’s better to manually remove all of the NodePaths a custom class adds to the scene graph.

2. Call &lt;code&gt;delete()&lt;/code&gt; on all Actors – Just calling &lt;code&gt;removeNode()&lt;/code&gt; on an Actor isn’t enough. Calling &lt;code&gt;delete()&lt;/code&gt; will remove ties to animations, exposed joints, and so on to ensure that all the extra components of the Actor are removed from memory as well.

3. Set all Intervals, Sequences, and Parallels equal to None – It’s very common for Intervals, Sequences, and Parallels to retain references to something in the class and prevent the class instance from being cleaned up. To be safe, it’s best to remove the references to these Intervals so that they get cleaned up themselves and any references they have to the class are removed.

4. Detach all 3D sounds connected to class NodePaths – 3D sounds won’t actually retain references to the custom class, but if the NodePaths they are attached to are removed with &lt;code&gt;removeNode()&lt;/code&gt; and the sounds aren’t detached, they’ll generate an error and crash the program when they try to access the removed NodePaths. Play it safe and detach the sounds.

5. End all tasks running in the class – The task manager will retain a reference to the class instance so long as the class instance has a task running, so set up all of the tasks in the custom class to end themselves with return task.done. This is the most reliable way to stop them and clear the reference to the custom class in the task manager.

6. If the custom class inherits from DirectObject, call &lt;code&gt;self.ignoreAll()&lt;/code&gt; – Panda3D’s message system will also retain a reference to the custom class if it is set up to receive messages. To be on the safe side, every class that inherits from DirectObject and will be deleted during run time should call &lt;code&gt;self.ignoreAll()&lt;/code&gt; to tell the message system that the class is no longer listening to messages. That will remove the reference.

7. Remove all direct references to the custom class instance – Naturally, the custom class instance won’t get cleaned up if something is referencing it directly, either through a circular self reference, or because it was created as a “child” of another class and that other class has a reference to it stored as a variable. All of these references need to be removed. This also includes references to the custom class instance placed in PythonTags.

The &lt;code&gt;__del__&lt;/code&gt; method is a good way to test if a custom class is being garbage collected. The &lt;code&gt;__del__&lt;/code&gt; method is similar to the &lt;code&gt;__init__&lt;/code&gt; method in that we don’t call it ourselves; it gets called when something happens. &lt;code&gt;__init__&lt;/code&gt; is called when a new instance of the class is created; &lt;code&gt;__del__&lt;/code&gt; is called when an instance of the class is garbage collected. It’s a pretty common thought to want to put some important clean up steps in the &lt;code&gt;__del__&lt;/code&gt; method itself, but this isn’t wise. In fact, it’s best not to have a &lt;code&gt;__del__&lt;/code&gt; method in any of our classes in the final product because the &lt;code&gt;__del__&lt;/code&gt; method can actually hinder proper garbage collection. A better usage is to put a simple print statement in the &lt;code&gt;__del__&lt;/code&gt; method that will serve as a notifier that Python has garbage collected the custom class instance. For example:
&lt;code python&gt;
def __del__(self):
  print(&quot;Instance of Custom Class Alpha Removed&quot;)
&lt;/code&gt;
Once we've confirmed that our custom class is being garbage collected properly, we can remove the &lt;code&gt;__del__&lt;/code&gt; method.</text>
    </revision>
  </page>
  <page>
    <title>Render-to-Texture and Image Postprocessing</title>
    <ns>0</ns>
    <id>2182</id>
      <sha1>q6l6of1zvvztnvlav129qp06zy3wenr</sha1>
    <revision>
      <id>4704</id>
      <timestamp>2008-02-28T01:17:49Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="2597">
&lt;h2&gt;Render-to-Texture Basics&lt;/h2&gt;

Conceptually, you can think of render-to-texture as being like
rendering a scene into a hidden window, and then copying the contents of the
window into a texture.  Such hidden
windows are not actually called windows, they're called &quot;buffers.&quot;  
Furthermore, the data is usually not copied into the texture, it's
usually transferred into the texture using a more efficient mechanism.
Details aside, though, if you think of it as rendering into a hidden window
and then copying into a texture, you have a pretty accurate idea of what
render-to-texture does.

Render-to-texture is particularly useful when you'd like to apply a &quot;filter&quot;
to your scene.  If you've ever used Photoshop, you know what a filter is:
Photoshop has lots of interesting filters that do blurring, texturizing,
edge detection, and more.  The first step in implementing a filter is to
render the entire scene into a texture.  Then, the texture is applied to
a full-screen quad and displayed in a window.  So far, it looks the same
as if you simply rendered the scene into the window.  However, by applying
a shader to the full-screen quad, you can implement your filter.

There are several other interesting uses for render-to-texture: water
reflections, environment mapping, creating virtual televisions, shadow
mapping... the list is quite long.

&lt;h2&gt;The Low-Level API and the High-Level Utilities&lt;/h2&gt;

Panda3D contains a very low-level API for creating offscreen buffers,
creating render-target textures, and the like.  This low-level API is 
extremely flexible: it gives you a great deal of control over 
what kinds of buffers you create, over what gets rendered into them,
over how the data gets transferred to a texture, and so forth.  The
advantage of using the low-level API is that you can control everything.
The disadvantage is that you have to control everything, and there's
a lot of stuff to control.

Panda3D also provides a number of utilities that make it convenient
to use render-to-texture for certain specific applications.  For
example, there is a utility that helps set up common image filters.
There is another that helps set up cube-map
environment maps.  The downside of these utilities is that each one
performs a fairly specific function, and if there isn't one for your
particular application, you'll need to resort to the lower-level API.

In the following sections, we document the high-level utilities first,
because these are what most people are going to use.  If none of the
utilities does what you need, then the last subsection explains the
low-level API.</text>
    </revision>
  </page>
  <page>
    <title>RenderEffects</title>
    <ns>0</ns>
    <id>2265</id>
    <redirect title="Render Effects" />
      <sha1>rzo5jwo0kkj6mksz6nveg5tx1465n3g</sha1>
    <revision>
      <id>5451</id>
      <timestamp>2008-09-03T18:14:42Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[Render Effects]]</comment>
      <text xml:space="preserve" bytes="28">#REDIRECT [[Render Effects]]</text>
    </revision>
  </page>
  <page>
    <title>Render Attributes</title>
    <ns>0</ns>
    <id>1014</id>
      <sha1>nho9eklq7nreolnaipdl16zf87k3vjn</sha1>
    <revision>
      <id>6214</id>
      <timestamp>2009-10-03T11:42:39Z</timestamp>
      <contributor>
        <username>Gogg</username>
        <id>389</id>
      </contributor>
      <text xml:space="preserve" bytes="1704">&lt;h2&gt;Render Attributes Basics&lt;/h2&gt;

After loading a model, you can alter its appearance by altering its &lt;i&gt;attributes&lt;/i&gt;.  For example, you can apply a &lt;i&gt;color&lt;/i&gt; to the model,
you can illuminate it with &lt;i&gt;lights&lt;/i&gt;, you can cause it to be
obscured by &lt;i&gt;fog&lt;/i&gt;, you can make it partially &lt;i&gt;transparent&lt;/i&gt;, and
so forth.  All of these are called render attributes.

Collectively, all the attributes of an object are called the object's
&lt;i&gt;render state&lt;/i&gt;, or sometimes just the object's &lt;i&gt;state.&lt;/i&gt;

&lt;h2&gt;Propagation of Attributes&lt;/h2&gt;

Attributes can be stored on any node of the scene graph; setting an attribute on a node automatically applies it to that node as well as to all of the children of the node (unless an override is in effect, but that's a more advanced topic).

It is possible to create these attributes and assign them to a node directly:

[python]&lt;code python&gt;
nodePath.node().setAttrib(attributeObject)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
node_path.node()-&gt;set_attrib(attributeObject);
&lt;/code&gt;[/cxx]

But in many cases, especially with the most commonly-modified attributes, you don't need to create the attributes directly as there is a convenience function on NodePath (e.g. &lt;code&gt;[func]nodePath[-&gt;]setFog()[/func]&lt;/code&gt;) that manages the creation of the attributes for you; there will also be a corresponding clear function on NodePath to remove the attribute (&lt;code&gt;[func]nodePath[-&gt;]clearFog()[/func]&lt;/code&gt;).

&lt;h2&gt;Render Attribute Priorities&lt;/h2&gt;

Every attribute has a &lt;i&gt;priority&lt;/i&gt;.  By default, that priority is zero.
That priority value affects the inheritance of attributes.

&lt;h2&gt;Incomplete Section&lt;/h2&gt;

Note: this section is incomplete.  It will be updated soon.</text>
    </revision>
  </page>
  <page>
    <title>Render Effects</title>
    <ns>0</ns>
    <id>1015</id>
      <sha1>5iewa080pxoh81o4s82neh4srewvehv</sha1>
    <revision>
      <id>7434</id>
      <timestamp>2011-12-08T15:45:39Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>typo</comment>
      <text xml:space="preserve" bytes="3010">&lt;p&gt;There are a number of special render effects that may be set on scene graph nodes to change the way they render.  This includes BillboardEffect, Compass Effect, DecalEffect, PolylightEffect, and ShowBoundsEffect.&lt;/p&gt;
&lt;h2&gt;List of All Render Effects:&lt;/h2&gt;
&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[Billboard Effects|BillboardEffect]]&lt;/b&gt;: Dicates that geometry at this node should automatically rotate to face the camera, or any other arbitrary node.
&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;CharacterJointEffect&lt;/b&gt;: The effect binds the node back to the character, so that querying the relative transform of the affected node will automatically force the indicated character to be updated first.
&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;PolylightEffect&lt;/b&gt;: A PolylightEffect can be used on a node to define a LightGroup for that node. A LightGroup contains PolylightNodes which are essentially nodes that add color to the polygons of a model based on distance. PolylightNode is a cheap way to get lighting effects specially for night scenes
&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;[[Compass Effects|CompassEffect]]&lt;/b&gt;: In its purest form, a CompassEffect is used to keep the node's rotation fixed relative to the top of the scene graph, despite other transforms that may exist above the node. Hence the name: the node behaves like a magnetic compass, always pointing in the same direction.
&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;ShowBoundsEffect&lt;/b&gt;: Applied to a GeomNode to cause a visible bounding volume to be drawn for this node. This is generally used only during development to help identify bounding volume issues.
&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;DecalEffect&lt;/b&gt;: Applied to a GeomNode to indicate that the children of this GeomNode are coplanar and should be drawn as decals (eliminating Z-fighting).
&lt;br&gt;&lt;br&gt;&lt;li&gt;&lt;b&gt;TexProjectorEffect &lt;/b&gt;: This effect automatically applies a computed texture matrix to the specified texture stage, according to the relative position of two specified nodes.


&lt;p&gt;RenderEffect represents render properties that must be applied as soon as they are encountered in the scene graph, rather than propagating down to the leaves.  This is different from RenderAttrib, which represents properties like color and texture that don't do anything until they propagate down to a GeomNode.  &lt;/p&gt;
&lt;p&gt;You should not attempt to create or modify a RenderEffect directly; instead, use the make() method of the appropriate kind of effect you want.  This
will allocate and return a new RenderEffect of the appropriate type, and it may share pointers if possible.  Do not modify the new RenderEffect if you wish to change its properties; instead, create a new one.&lt;/p&gt;
&lt;p&gt;Once you have created a render Effect, you need to decide what it should affect. If you have an effect that should affect everything in the scene the NodePath in the next line of code is &quot;render&quot;. If you only want it to affect specific objects, choose the appropriate place in the scene graph. &lt;/p&gt;

[python]&lt;code python&gt;
nodePath.node().setEffect(&lt;Render Effect&gt;)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
nodePath.node()-&gt;set_effect(&lt;Render Effect&gt;);
&lt;/code&gt;[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Render to Texture</title>
    <ns>0</ns>
    <id>2183</id>
    <redirect title="Low-Level Render to Texture" />
      <sha1>mdfoz9ojgffnmxspuzjttqedtkk27wo</sha1>
    <revision>
      <id>4708</id>
      <timestamp>2008-02-28T01:24:11Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <comment>[[Render to Texture]] moved to [[Low-Level Render to Texture]]</comment>
      <text xml:space="preserve" bytes="41">#REDIRECT [[Low-Level Render to Texture]]</text>
    </revision>
  </page>
  <page>
    <title>Render to Texture and Render to Multiple Windows</title>
    <ns>0</ns>
    <id>1705</id>
    <redirect title="Render to Texture" />
      <sha1>5okm3au5w8jt2vda9m460qatlu6fhvz</sha1>
    <revision>
      <id>3112</id>
      <timestamp>2005-12-07T18:54:48Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <comment>Render to Texture and Render to Multiple Windows moved to Render to Texture: I found D Rose's article on Graphics Engine, Graphics Pipe, etc.  I think that &quot;render to multiple windows&quot; fits better in there, somewhere.</comment>
      <text xml:space="preserve" bytes="31">#redirect [[Render to Texture]]</text>
    </revision>
  </page>
  <page>
    <title>Repositioning DirectGUI Elements on Window</title>
    <ns>0</ns>
    <id>2684</id>
    <redirect title="Positioning DirectGUI Elements on Window" />
      <sha1>cogmoffm6ke7yc8as2r7wxnduuydrmz</sha1>
    <revision>
      <id>7812</id>
      <timestamp>2012-07-07T19:14:34Z</timestamp>
      <contributor>
        <username>Sakurazaki</username>
        <id>576</id>
      </contributor>
      <comment>[[Repositioning DirectGUI Elements on Window]] moved to [[Positioning DirectGUI Elements on Window]]</comment>
      <text xml:space="preserve" bytes="54">#REDIRECT [[Positioning DirectGUI Elements on Window]]</text>
    </revision>
  </page>
  <page>
    <title>Repositioning DirectGUI Elements on Window Resize</title>
    <ns>0</ns>
    <id>2683</id>
    <redirect title="Repositioning DirectGUI Elements on Window" />
      <sha1>7nxeft2z74e8uaqugmce6na8lvmjjci</sha1>
    <revision>
      <id>7794</id>
      <timestamp>2012-07-07T13:33:35Z</timestamp>
      <contributor>
        <username>Sakurazaki</username>
        <id>576</id>
      </contributor>
      <comment>[[Repositioning DirectGUI Elements on Window Resize]] moved to [[Repositioning DirectGUI Elements on Window]]: General especification instead of focusing on a problem</comment>
      <text xml:space="preserve" bytes="56">#REDIRECT [[Repositioning DirectGUI Elements on Window]]</text>
    </revision>
  </page>
  <page>
    <title>Repositioning Text on Window Resize</title>
    <ns>0</ns>
    <id>2681</id>
      <sha1>n0v7cbde3z8smrd9v72wgrh7tpzxl04</sha1>
    <revision>
      <id>7783</id>
      <timestamp>2012-07-07T13:00:43Z</timestamp>
      <contributor>
        <username>Sakurazaki</username>
        <id>576</id>
      </contributor>
      <text xml:space="preserve" bytes="1769">Having an [[OnscreenText]] in window 4:3 aspect ratio has no problem since render2d works from (-1, 0 , -1) to (1, 0, 1), but when the window resizes to 16:9 ratio, you might have some troubles repositioning the text to the corners, for example.

Thats why [[Scene Graph Manipulations|aspect2d]] brings some variables that might be handy for you in these ocassions, in wich you want to have a text wrapped in a corner when the window resizes, from 4:3 to 16:9 or viceversa.

It's called a2d* and it must be called as &lt;code&gt;base.a2d*&lt;/code&gt;. The * stands for all the relative positions of your window:

&lt;ul&gt;
&lt;li&gt;Top
&lt;li&gt;Bottom
&lt;li&gt;Left
&lt;li&gt;Right
&lt;li&gt;TopLeft
&lt;li&gt;TopRight
&lt;li&gt;BottomLeft
&lt;li&gt;BottomRight
&lt;/ul&gt;

&lt;code python&gt;

myText.setPos(base.a2dBottomLeft, 0, base.a2dTopRight)
&lt;/code&gt;

This is a good way to rename the (-1, 0, 1) but, if you try this on a real [[OnScreenText]] you will see that it wont resize along the window.

For this, we must reparent our text to a2d* like this:

&lt;code python&gt;
myText.reparentTo(base.a2dBottomLeft)
&lt;/code&gt;

This will make your text wrap always into your corner, even if the ratio of the window changes from 4:3 to 16:9.

On reparenting, using the &lt;code&gt;pos = (0, 0)&lt;/code&gt; on the constructor of the [[OnscreenText]], if will be applied taking the origin as the a2d* you chose. If you chose &lt;code&gt;base.a2dBottomLeft&lt;/code&gt; your origin will be the bottom left corner of your screen.

Here you have a sample code so you can try yourself:

&lt;code python&gt;

mytext_text = &quot;My Text&quot;

mytext = OnscreenText(text = mytext_text, pos = (+0.2, +0.05), scale = 0.05, fg=(0,0,0,1), mayChange=1)
mytext.reparentTo(base.a2dBottomLeft)
&lt;/code&gt;

base.a2d* works perfectly for every DirectGUI component, so don't forget to try out with any of them.</text>
    </revision>
  </page>
  <page>
    <title>RigidBodyCombiner</title>
    <ns>0</ns>
    <id>2309</id>
    <redirect title="The Rigid Body Combiner" />
      <sha1>ivlb4om0uf1rstz7b3n2zmfj59cvufu</sha1>
    <revision>
      <id>5661</id>
      <timestamp>2008-12-30T11:23:00Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[The Rigid Body Combiner]]</comment>
      <text xml:space="preserve" bytes="37">#REDIRECT [[The Rigid Body Combiner]]</text>
    </revision>
  </page>
  <page>
    <title>Running Panda3D under the CXX Debugger</title>
    <ns>0</ns>
    <id>1075</id>
      <sha1>o6l0cdnwqfct2h52a9fo6sibrb2m51i</sha1>
    <revision>
      <id>6631</id>
      <timestamp>2010-02-07T04:45:42Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <minor/>
      <comment>[[Running Panda under the CXX Debugger]] moved to [[Running Panda3D under the CXX Debugger]]: Panda3D is the name of the engine; not Panda.</comment>
      <text xml:space="preserve" bytes="3139">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

These instructions show how to compile and run panda from inside the Microsoft Visual Studio debugger.

&lt;h2&gt;Before you Begin&lt;/h2&gt;

The first step is to download the panda source code and compile it.  The instructions can be found in the section [[Building Panda from Source]].  Be sure to compile with the Optimize setting of 1, otherwise, Visual Studio will not be able to debug properly.  Once you have compiled panda, start up visual studio, and ask it to create a new project:

&lt;br&gt;&lt;p align=&quot;center&quot;&gt;[[Image:debugpanda1.jpg]]&lt;/p&gt;&lt;br&gt;

There are four pieces of information you need to enter into the new project dialog:

* Tell it to make a &quot;C++ project&quot;
* Tell it to use a &quot;Makefile&quot;
* Tell it the name of the project, &quot;debugpanda&quot;
* Tell it where the panda source tree is (ie, &quot;c:\panda3d-b&quot;)

&lt;br&gt;&lt;p align=&quot;center&quot;&gt;[[Image:debugpanda2.jpg]]&lt;/p&gt;&lt;br&gt;

Click ok, and confirm.  You have now created the project, and the project is open for editing.  You now need to access the &quot;solution explorer:&quot;

&lt;br&gt;&lt;p align=&quot;center&quot;&gt;[[Image:debugpanda3.jpg]]&lt;/p&gt;&lt;br&gt;

Normally, you can see the solution explorer in the upper-right corner of visual studio.  It should show your project name (debugpanda).  The word &quot;debugpanda&quot; needs to be highlighted - if it is not, click on it:

&lt;br&gt;&lt;p align=&quot;center&quot;&gt;[[Image:debugpanda4.jpg]]&lt;/p&gt;&lt;br&gt;

Now that your project is selected, you can edit its project properties:

&lt;br&gt;&lt;p align=&quot;center&quot;&gt;[[Image:debugpanda5.jpg]]&lt;/p&gt;&lt;br&gt;

The project property dialog initially looks like this.  It contains three subpanels, the &quot;General&quot; panel, the &quot;Debugging&quot; panel, and the &quot;NMake&quot; subpanel.  You can see these three subheadings in the left pane:

&lt;br&gt;&lt;p align=&quot;center&quot;&gt;[[Image:debugpanda6.jpg]]&lt;/p&gt;&lt;br&gt;

There is nothing to fill in on the general panel, so switch to the debugging panel.  You need to fill in the command name, the command arguments, and the working directory.  For now, we will ask it to debug the Actors/Robots sample program.  Since visual studio puts the project file in a subdirectory, the paths need to be preceded by &quot;..&quot; to get to the root of the panda source tree: 

&lt;br&gt;&lt;p align=&quot;center&quot;&gt;[[Image:debugpanda7.jpg]]&lt;/p&gt;&lt;br&gt;

Finally, switch to the &quot;NMake&quot; panel.  Here, you can tell it what the command is to recompile panda.  I use a bat file &quot;mkp.bat&quot; to compile panda.  Since the project file is in a subdirectory, the command needs to be preceded by &quot;cd ..&quot; in order to get back to the root of the panda source tree:

&lt;br&gt;&lt;p align=&quot;center&quot;&gt;[[Image:debugpanda8.jpg]]&lt;/p&gt;&lt;br&gt;

Visual studio now knows how to run panda, and how to compile it.  You can run your program (in this case, the &quot;Actors/Robots&quot; tutorial) by clicking on the Debug menu:

&lt;br&gt;&lt;p align=&quot;center&quot;&gt;[[Image:debugpanda9.jpg]]&lt;/p&gt;&lt;br&gt;

You can rebuild panda at any time by clicking on the &quot;Build&quot; menu:

&lt;br&gt;&lt;p align=&quot;center&quot;&gt;[[Image:debugpanda10.jpg]]&lt;/p&gt;&lt;br&gt;

Now that you are running in the debugger, you can open any panda source file and set a breakpoint, or examine data.  Of course, it may be advantageous to learn how to use the python debugger as well as the C++ debugger.</text>
    </revision>
  </page>
  <page>
    <title>Running Panda under the CXX Debugger</title>
    <ns>0</ns>
    <id>2470</id>
    <redirect title="Running Panda3D under the CXX Debugger" />
      <sha1>ibxkr4tzrhnyi3ksctrfrc2qv1nw4nt</sha1>
    <revision>
      <id>6632</id>
      <timestamp>2010-02-07T04:45:42Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>[[Running Panda under the CXX Debugger]] moved to [[Running Panda3D under the CXX Debugger]]: Panda3D is the name of the engine; not Panda.</comment>
      <text xml:space="preserve" bytes="52">#REDIRECT [[Running Panda3D under the CXX Debugger]]</text>
    </revision>
  </page>
  <page>
    <title>Running p3d files</title>
    <ns>0</ns>
    <id>2394</id>
      <sha1>h3agvy01ozzri2a34fz5r13o674wy7v</sha1>
    <revision>
      <id>6663</id>
      <timestamp>2010-02-09T09:50:51Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <text xml:space="preserve" bytes="947">Once you have built a p3d file, you may run it immediately with the
panda3d program:

&lt;code bash&gt;
panda3d myapp.p3d
&lt;/code&gt;

Remember, you may need to add panda3d to your PATH first. On Windows,
this is installed into c:\Program Files\Panda3D by default. If you are
running on Linux or Mac, or running Cygwin on Windows, you can omit
&quot;panda3d&quot; and simply run your p3d file directly as its own command, if it has executable permissions.

You may also double-click the p3d file's icon on your desktop, or in
the Explorer or Finder browser, which automatically invokes panda3d.

You may now choose to distribute this p3d file directly to your
friends.  If they have installed the Panda3D plugin, they can also run
it by double-clicking on its icon.  This is an easy, no-nonsense way to
distribute your application, and saves you from having to mess around
with embedding your p3d file into a web page, or packaging it as a
self-contained application.</text>
    </revision>
  </page>
  <page>
    <title>Running your Program</title>
    <ns>0</ns>
    <id>2295</id>
      <sha1>eougtu7r2rv7r4lnzejwsvlcfqmw3x6</sha1>
    <revision>
      <id>6194</id>
      <timestamp>2009-09-29T10:52:27Z</timestamp>
      <contributor>
        <username>Gogg</username>
        <id>389</id>
      </contributor>
      <text xml:space="preserve" bytes="2217">[cxx]&lt;h2&gt;Running your freshly built program&lt;/h2&gt;

This section is mostly intended for the Python version of the manual. If you are a C++ user, your program should run without problems from your IDE or just starting it up from your operating system. If the program doesn't run and it produces an error message about missing libraries check that your PATH environment variable contains the directory of the Panda runtime. For more information review the &lt;b&gt;Installing Panda&lt;/b&gt; section that applies to your OS.

[/cxx]
[python]
&lt;h2&gt;Using Command Prompt to Run your Program&lt;/h2&gt;

You can run your script by using your computer’s ‘Command Prompt’. You access this by clicking ‘Start &gt; All Programs &gt; Accessories &gt; Command Prompt’, or by going to 'Start &gt; Run' and typing 'cmd'. When it opens, it should look something like this: 

[[Image:pic086uq.jpg]]

At the moment it’s pointing to its default directory, which in my case is ‘Documents and Settings’ (it doesn’t matter if yours is different). We need to change the directory to the one where we saved our script. To do this, we type cd. This stands for ‘change directory’. So type the following text behind the &gt; symbol.

&lt;code&gt;
cd C:\Panda3D-1.6.2\mystuff\
&lt;/code&gt;

Instead of version 1.6.2, you should type the version number of Panda that you have downloaded and installed.  Please note that this folder name is case sensitive and must match exactly (other than the version number, of course).  Then press the ‘Enter’ key on your keyboard. You should now have the following on the Command Prompt: 

[[Image:pic093tn.jpg]]

This means that it’s now pointing to the right directory. To run your script, and start Panda3D, type the following text behind the &gt; symbol: 

&lt;code&gt;
ppython myscript.py
&lt;/code&gt;

[[Image:pic108ge.jpg]]

Press the ‘Enter’ key on your keyboard. This will run the special version of Python that is distributed with Panda3D. If all is well, Panda3D will start and you should see the main rendering window appear. 

[[Image:EmptyPandaWindow.jpg]]

This is a empty program, it won't do anything.  The next step is to
add additional commands to the program, as described in one of the following
tutorials.
[/python]</text>
    </revision>
  </page>
  <page>
    <title>SPE</title>
    <ns>0</ns>
    <id>1784</id>
      <sha1>ix23m5s9ze90208onucqi867rvl6fvr</sha1>
    <revision>
      <id>7716</id>
      <timestamp>2012-03-09T10:51:41Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="2402">&lt;h2&gt;Installing SPE for use with Panda3D&lt;/h2&gt; Since Panda 1.3.0 the windows installer has the option to add panda's python to the registry. If you don't register or if you use an earlier version of panda, SPE cannot detect panda modules. Without them, features like autocomplete, the built-in console, debugger etc. do not work for Panda3D scripts. To correct this, SPE must first be integrated properly with python.

Integrate it manually in this order:

&lt;b&gt;1. download and install [http://www.panda3d.org/download.php Panda3D]&lt;/b&gt;

This installs python also. There should now be a directory &quot;\Panda3D-x.x.x&quot; where the x's are the version number.

&lt;b&gt;2. download and install [http://www.python.org/ python]&lt;/b&gt;

This installs the standard python interpreter required by the other installers. There should now be a directory &quot;\Pythonxx&quot; (again, x's are the version number) 

This directory can be deleted after step 5 if you wish. (not before!)

&lt;b&gt;3. download and install [http://www.wxpython.org/ wxpython]&lt;/b&gt;

SPE requires wxpython.
This installs in &quot;\Pythonxx\Lib\site-packages&quot;

&lt;b&gt;4. download and install [http://www.stani.be/python/spe/blog/ SPE]&lt;/b&gt;

This autodetects the standart python install, and also installs in &quot;\Pythonxx\Lib\site-packages&quot;

&lt;b&gt;5. Manually copy the new files and folders in &quot;\Pythonxx\Lib\site-packages&quot; to &quot;\Panda3D-x.x.x\python\lib\site-packages&quot;&lt;/b&gt;

When SPE is run from the new location using python it should have access to all the panda3D modules.

&lt;b&gt;6. Write a script for convenience&lt;/b&gt;

e.g. in Windows create a new shortcut with target: 
&lt;table class=&quot;code&quot;&gt;&lt;tr&gt;&lt;td&gt;
&quot;C:\Panda3D-x.x.x\python\python.exe&quot; &quot;C:\Panda3D-x.x.x\python\lib\site-packages\_spe\SPE.py&quot;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

This is just as easy in Linux using a shell script.

&lt;h2&gt;Importing DirectStart&lt;/h2&gt;
SPE may need to or require you to import DirectStart for its PyDoc generation and calltips. By default this also pops up the main window. This can get annoying, but fortunately opening the window can be easily deferred by either adding the line &lt;code&gt;window-type none&lt;/code&gt; to your Config.prc file or by adding the line
&lt;code python&gt;
loadPrcFileData(&quot;&quot;, &quot;window-type none&quot;)
&lt;/code&gt;
to your script before you import DirectStart:
&lt;code python&gt;
import direct.directbase.DirectStart
&lt;/code&gt;
You may open the window later with this line:
&lt;code python&gt;
base.openMainWindow(type = 'onscreen')
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>SSL hosting</title>
    <ns>0</ns>
    <id>2414</id>
      <sha1>8ba98i1a0mdkhpxmgi3k1ptyqggz58p</sha1>
    <revision>
      <id>6272</id>
      <timestamp>2009-10-21T00:01:17Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="2028">
As stated previously, the Panda3D plugin system first downloads the contents.xml from the root of your host URL, and uses this file to validate all of the other files that must be downloaded for a particular package.  This ensures that the files downloaded are precisely the same files that you uploaded--as long as that initial contents.xml file is downloaded correctly.

It is theoretically possible, through DNS spoofing, for a hacker to substitute a compromised contents.xml file that allows compromised packages to be inadvertently downloaded to a user's machine.  Though this is unlikely, this can be protected against by hosting the contents.xml file on a secure domain, with an https address.  The https protocol protects against DNS spoofing by ensuring that only the named host is actually contacted.

Using this feature is completely optional, but it does provide a bit more security against hackers.  By convention, if you specify your host URL with an https address, like this:

&lt;code python&gt;
packager.setHost('https://myhost.com/myrootdir/')
&lt;/code&gt;

then Panda3D will understand that the contents.xml file should be downloaded via the https protocol.  However, the remaining files will be downloaded via ordinary http protocol, from the same address, e.g. http://myhost/myrootdir/ .  This avoids the overhead of https on every download, and also allows downloading from mirror hosts to distribute the download burden.  If your cleartext http address it not the same as the https address, you can specify the specific address with the downloadUrl parameter, e.g.:

&lt;code python&gt;
packager.setHost('https://myhost.com/myrootdir/', 
                 downloadUrl = 'http://myhost.com:8080/myrootdir/')
&lt;/code&gt;

The first URL is the host URL, and is the address from which contents.xml will be downloaded, and is also the URL that should be specified when downloading the package later.  The second URL is the &quot;download URL&quot;, and is the address from which all of the other data, after contents.xml, will be downloaded.</text>
    </revision>
  </page>
  <page>
    <title>Sample Cube Map</title>
    <ns>0</ns>
    <id>1225</id>
      <sha1>1gkmeaig2kjeucb5qcj17mxb5vumwsl</sha1>
    <revision>
      <id>2504</id>
      <timestamp>2005-12-06T20:23:25Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="971">The following sample code loads up an environment, puts the camera in
the center of it, and generates the six faces of a cube map from the
point of view of the camera:

&lt;table class=&quot;code&quot;&gt;&lt;tr&gt;&lt;td&gt;&lt;pre&gt;
scene = loader.loadModel('bvw-f2004--streetscene/street-scene.egg')
scene.reparentTo(render)
scene.setZ(-2)
base.saveCubeMap('streetscene_cube_#.jpg', size = 256)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

These are the six faces generated:

Right:

[[Image:Streetscene cube 0.jpg]]

Left:

[[Image:Streetscene cube 1.jpg]]

Front:

[[Image:Streetscene cube 2.jpg]]

Back:

[[Image:Streetscene cube 3.jpg]]

Top:

[[Image:Streetscene cube 4.jpg]]

Bottom:

[[Image:Streetscene cube 5.jpg]]

And when they are assembled into a cube map, it looks like this:

[[Image:Streetscene cube.jpg|The six faces as a cube]]

Or, when we apply that cube map to a sphere, you can see there are
absolutely no seams between the edges:

[[Image:Streetscene sphere.jpg|The cube map applied to a sphere]]</text>
    </revision>
  </page>
  <page>
    <title>Sample Programs</title>
    <ns>0</ns>
    <id>2315</id>
    <redirect title="Sample Programs in the Distribution" />
      <sha1>2xh40wj0zz3a610ifj92bftgy3vh320</sha1>
    <revision>
      <id>5708</id>
      <timestamp>2009-03-04T18:17:37Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>Redirecting to [[Sample Programs in the Distribution]]</comment>
      <text xml:space="preserve" bytes="49">#REDIRECT [[Sample Programs in the Distribution]]</text>
    </revision>
  </page>
  <page>
    <title>Sample Programs: Asteroids</title>
    <ns>0</ns>
    <id>2103</id>
      <sha1>7g8c82tjz8oiz2gl4cvwf42dayyg31p</sha1>
    <revision>
      <id>7473</id>
      <timestamp>2011-12-24T13:03:06Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>Windows in uppercase, linux in lowecase :(</comment>
      <text xml:space="preserve" bytes="1063">&lt;b&gt;The Asteroids Sample Program&lt;/b&gt;

To run a sample program, you need to install Panda3D.  If you're a Windows user, you'll find the sample programs in your start menu.  If you're a Linux user, you'll find the sample programs in /usr/share/panda3d.

&lt;b&gt;Screenshots&lt;/b&gt;

[[Image:Screenshot-Sample-Programs-Asteroids.jpg]]

&lt;b&gt;Explanation&lt;/b&gt;

This sample program shows how to use Tasks.  Tasks are functions that run during every frame of the program. Panda3D runs a number of tasks during any program, but additional tasks may be added.  For this tutorial, tasks will be used to update the ship, asteriod and bullet positions, in addition to checking for collisions.  To do this, all the data you need to know is how much time has passed and the velocity of each object.

NOTE: Adding lots of processor intensive tasks will have an adverse affect on the framerate/performance of your program.

For more information on tasks, please consult the [[Tasks]] section of the manual.

&lt;b&gt;Back to the List of Sample Programs:&lt;/b&gt;

[[Sample Programs in the Distribution]]</text>
    </revision>
  </page>
  <page>
    <title>Sample Programs: Ball in Maze</title>
    <ns>0</ns>
    <id>2104</id>
      <sha1>rycj33rcfaub1mr6ah4p3si1vefcf2d</sha1>
    <revision>
      <id>7474</id>
      <timestamp>2011-12-24T13:03:32Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="1027">&lt;b&gt;The Ball-in-Maze Sample Program&lt;/b&gt;

To run a sample program, you need to install Panda3D. If you're a Windows user, you'll find the sample programs in your start menu. If you're a Linux user, you'll find the sample programs in /usr/share/panda3d.

&lt;b&gt;Screenshots&lt;/b&gt;

[[Image:Screenshot-Sample-Programs-Ball-in-Maze.jpg]]

&lt;b&gt;Explanation&lt;/b&gt;

This tutorial will demonstrate how collision detection works in panda and provide a simple implementation of its use. Collisions are used extensively in modern games for a variety of purposes. At the most basic level, collision detection allows for two objects to bump into each other and react. This can be used to keep the objects from passing through each other but is not limited to that purpose. In this tutorial, collision detection be used to simulate the game of Labyrinth and will keep the ball within the bounds of the board. It will also be used to detect if the ball is over a hole.

&lt;b&gt;Back to the List of Sample Programs:&lt;/b&gt;

[[Sample Programs in the Distribution]]</text>
    </revision>
  </page>
  <page>
    <title>Sample Programs: Boxing Robots</title>
    <ns>0</ns>
    <id>2105</id>
      <sha1>6tle0tugw37cuic14l4ext7vbnss3b2</sha1>
    <revision>
      <id>7475</id>
      <timestamp>2011-12-24T13:03:58Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="1178">&lt;b&gt;The Boxing Robots Sample Program&lt;/b&gt;

To run a sample program, you need to install Panda3D. If you're a Windows user, you'll find the sample programs in your start menu. If you're a Linux user, you'll find the sample programs in /usr/share/panda3d.

&lt;b&gt;Screenshots&lt;/b&gt;

[[Image:Screenshot-Sample-Programs-Boxing-Robots.jpg]]

&lt;b&gt;Explanation&lt;/b&gt;

This tutorial will show how to play animations on models aka &quot;actors&quot;. We will base this world on a the popular game of &quot;Rock 'em Sock 'em Robots&quot;.

Actors are specific models that come with some pre-generated animations. These animations are either available in the same egg file as the model or they are available as their own egg files. Only actors may play these animations, and actors also come with their own set of functions to use. Actors behave almost identically to models but use a different load command called Actor.Actor(). For more information on actors, please consult the Panda3D online manual.

The image above shows the tutorial in action. Use the A,S,K,L keys to make the robots punch and thus triggering their animations. 

&lt;b&gt;Back to the List of Sample Programs:&lt;/b&gt;

[[Sample Programs in the Distribution]]</text>
    </revision>
  </page>
  <page>
    <title>Sample Programs: Carousel</title>
    <ns>0</ns>
    <id>2106</id>
      <sha1>s133scfytmrz4ggzj9yo6fpyrsg4tdi</sha1>
    <revision>
      <id>7476</id>
      <timestamp>2011-12-24T13:04:32Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="1332">&lt;b&gt;The Carousel Sample Program&lt;/b&gt;

To run a sample program, you need to install Panda3D. If you're a Windows user, you'll find the sample programs in your start menu. If you're a Linux user, you'll find the sample programs in /usr/share/panda3d.

&lt;b&gt;Screenshots&lt;/b&gt;

[[Image:Screenshot-Sample-Programs-Carousel.jpg]]

&lt;b&gt;Explanation&lt;/b&gt;

This sample progam demonstrates some uses for intervals in panda to move objects in your panda world.

Intervals are built in Panda3D functions that will let you change an attribute over time. In this tutorial, the position and texture attributes of various objects will be altered over time to give life to a carousel. The most common intervals for doing simple movement of objects are the posInterval and hprInterval. These intervals will change the position/orientation of an object (or node) over a given time and given displacement/rotation, respectively. Another interval we will look at is the LerpFunc interval. LerpFunc will call a function and give it a linearly interpolated value range over a specified time range. This is how we will oscilate pandas via a sin wave and alternate textures over time. For more information on intervals, please refer to the intervals section of the online manual.


&lt;b&gt;Back to the List of Sample Programs:&lt;/b&gt;

[[Sample Programs in the Distribution]]</text>
    </revision>
  </page>
  <page>
    <title>Sample Programs: Cartoon Shader</title>
    <ns>0</ns>
    <id>2107</id>
      <sha1>f1bkdtsz3te7v5ah1xsu9xn8j2bjfsl</sha1>
    <revision>
      <id>7477</id>
      <timestamp>2011-12-24T13:04:56Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="1692">&lt;b&gt;The Cartoon Shader Sample Program&lt;/b&gt;

To run a sample program, you need to install Panda3D. If you're a Windows user, you'll find the sample programs in your start menu. If you're a Linux user, you'll find the sample programs in /usr/share/panda3d.

&lt;b&gt;Screenshots&lt;/b&gt;

[[Image:Screenshot-Sample-Programs-Cartoon-Shader.jpg]]

&lt;b&gt;Explanation&lt;/b&gt;

This tutorial will show how to make a cartoon shader. It requires three separate shaders. On video cards that do not support shaders, the results will not be interesting.

Every frame, the scene is rendered into the main window using a &quot;lighting shader.&quot; The lighting shader calculates lighting pretty much the same way OpenGL always does, but it adds a threshold function, so that the line between light and dark is a clear, discrete line.

Every frame, the scene is also rendered into an offscreen buffer using a shader that stores the surface normals into the buffer. Every frame, the contents of this buffer are copied to a texture. The result is a &quot;surface normals texture.&quot; The lower-right corner of the screen contains a small quad showing the contents of the &quot;surface normals texture.&quot;

The surface normals texture is applied to the main window using a fullscreen quad. A shader that detects edges is run on this quad. Wherever there is a discontinuity in the normals, the shader outputs black. Otherwise, it outputs a transparent pixel. This creates the lines around the model.

The model itself isn't even textured - it's vertex colored. Untextured models often look great in cartoon-shaded worlds.

The image below shows the tutorial in action.

&lt;b&gt;Back to the List of Sample Programs:&lt;/b&gt;

[[Sample Programs in the Distribution]]</text>
    </revision>
  </page>
  <page>
    <title>Sample Programs: Chessboard</title>
    <ns>0</ns>
    <id>2108</id>
      <sha1>l13gctjznm4prxdgsc6omkpi5kkm6wg</sha1>
    <revision>
      <id>7478</id>
      <timestamp>2011-12-24T13:06:06Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="1170">&lt;b&gt;The Chessboard Sample Program&lt;/b&gt;

To run a sample program, you need to install Panda3D. If you're a Windows user, you'll find the sample programs in your start menu. If you're a Linux user, you'll find the sample programs in /usr/share/panda3d.

&lt;b&gt;Screenshots&lt;/b&gt;

[[Image:Screenshot-Sample-Programs-Chessboard.jpg]]

&lt;b&gt;Explanation&lt;/b&gt;

This sample program demonstrates how to use the mouse cursor interactively in your panda world. It is sometimes desirable to be able to interact with objects in a 3D scene via a mouse cursor. There are many solutions to this problem and this tutorial will cover a popular method. The method used in this tutorial will use collision detection to determine which objects the mouse cursor is hovering over. By using collision rays and shooting them from the lens (camera) with respect to the current position of the mouse cursor, we can hit objects that are being covered by the cursor.

Note that there's a much faster way to achieve this, using the Plane class. However, this sample demonstrates how it can be done using the Collision system.

&lt;b&gt;Back to the List of Sample Programs:&lt;/b&gt;

[[Sample Programs in the Distribution]]</text>
    </revision>
  </page>
  <page>
    <title>Sample Programs: Disco Lights</title>
    <ns>0</ns>
    <id>2109</id>
      <sha1>0qxqkj5rt0fchldy335cb2ei2yg9ryi</sha1>
    <revision>
      <id>7479</id>
      <timestamp>2011-12-24T13:06:31Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="1064">&lt;b&gt;The Disco Lights Sample Program&lt;/b&gt;

To run a sample program, you need to install Panda3D. If you're a Windows user, you'll find the sample programs in your start menu. If you're a Linux user, you'll find the sample programs in /usr/share/panda3d.

&lt;b&gt;Screenshots&lt;/b&gt;

[[Image:Screenshot-Sample-Programs-Disco-Lights.jpg]]

&lt;b&gt;Explanation&lt;/b&gt;

This sample program demonstrates lighting in panda. Lighting in panda can add a lot of depth into a scene. In panda, you can create point, directional, ambient and spot lights(for a detailed description of these lights, see the manual link below). Note that lights in panda will not cast shadows. They can create a dark and light side of an object but they cannot cast shadows from one object to another or onto the same object. Panda lights also act on object vertices only. The more polygons an object has, the more detailed the lighting will be on it. For more information on lighting, please consult the Panda3D online manual. 

&lt;b&gt;Back to the List of Sample Programs:&lt;/b&gt;

[[Sample Programs in the Distribution]]</text>
    </revision>
  </page>
  <page>
    <title>Sample Programs: Distortion</title>
    <ns>0</ns>
    <id>2686</id>
      <sha1>7vjxhyqo7p5dr7k6cvxfqnu5m5sh2pr</sha1>
    <revision>
      <id>7850</id>
      <timestamp>2012-10-22T09:02:14Z</timestamp>
      <contributor>
        <username>Teedee</username>
        <id>449</id>
      </contributor>
      <text xml:space="preserve" bytes="517">&lt;b&gt;The Distortion Sample Program&lt;/b&gt;

To run a sample program, you need to install Panda3D. If you're a Windows user, you'll find the sample programs in your start menu. If you're a Linux user, you'll find the sample programs in /usr/share/panda3d.

&lt;b&gt;Screenshots&lt;/b&gt;

[[Image:Screenshot-Sample-Programs-Distortion.jpg]]

&lt;b&gt;Explanation&lt;/b&gt;

Creates an interesting shader effect where the entire screen is rendered into a texture.

&lt;b&gt;Back to the List of Sample Programs:&lt;/b&gt;

[[Sample Programs in the Distribution]]</text>
    </revision>
  </page>
  <page>
    <title>Sample Programs: Fireflies</title>
    <ns>0</ns>
    <id>2110</id>
      <sha1>fq7kj60c47p1gbm61p2e0rxv450e6y3</sha1>
    <revision>
      <id>7480</id>
      <timestamp>2011-12-24T13:07:32Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>typos</comment>
      <text xml:space="preserve" bytes="6698">&lt;b&gt;The Fireflies Sample Program&lt;/b&gt;

To run a sample program, you need to install Panda3D. If you're a Windows user, you'll find the sample programs in your start menu. If you're a Linux user, you'll find the sample programs in /usr/share/panda3d.

&lt;b&gt;Screenshots&lt;/b&gt;

[[Image:Screenshot-Sample-Programs-Fireflies.jpg]]

&lt;b&gt;Explanation&lt;/b&gt;

A nature scene with 500 fireflies: how do you do a high-polygon scene with 500 lights, without a total performance collapse?

This sample program shows how to do Deferred Shading in Panda. You can have hundreds of lights, and all the lights affect all the models automatically. This is not expensive: the cost is only proportional to the number of actual lit pixels times the number of times each pixel is lit. That's why fireflies make a perfect demonstration --- you could never have 500 lights in a high-polygon scene without deferred shading. But perhaps even more important is the elegance of a rendering algorithm that automatically connects lights to the appropriate objects without the need for LightAttribs.

To understand how deferred shading works, first consider how ordinary shading works in plain OpenGL. In most fairly simple cases, the lighting equation boils down to:

final = diffuse color * dot(light vector, surface normal) * attenuation(surface position, light position and orientation)

Where the attenuation function depends on the type of light. So anyhow, this equation has four inputs:

1. The diffuse color.
2. The surface normal.
3. The surface position.
4. The light parameters.

The idea behind deferred shading is that during the rendering process, you don't compute the final color. Instead, you store the values listed above in the framebuffer itself. Of course, you need a &quot;fat framebuffer&quot; to store all that data. In an image postprocessing step you scan the framebuffer and compute the final color.

Of course, that's a lot of data to store in the framebuffer. The first optimization is not to store the light parameters. It is not necessary to store light parameters because the light parameters don't vary from pixel to pixel --- they're constants.

Our second optimization involves surface position. Surface position can be inferred by calculating backward from the depth buffer. Each pixel on the screen represents a ray from the camera into the scene, and the depth value in the pixel indicates a distance along the ray. Because of this, it is not actually necessary to store surface position explicitly - it is only necessary to store depth values. Of course, OpenGL does that for free.

So the framebuffer now needs to store surface normal, diffuse color, and depth value (to infer surface position). In practice, most ordinary framebuffers can only store color and depth - they don't have any place to store a third value. So we need to use a special offscreen buffer with an &quot;auxiliary&quot; bitplane. The auxiliary bitplane stores the surface normal.

So then, there's the final postprocessing pass. This involves combining the diffuse color texture, the surface normal texture, the depth texture, and the light parameters into a final rendered output. The light parameters are passed into the postprocessing shader as constants, not as textures.

If there are a lot of lights, things get interesting. You use one postprocessing pass per light. Each pass only needs to scan those framebuffer pixels that are actually in range of the light in question. To traverse only the pixels that are affected by the light, just render the illuminated area's convex bounding volume.

The shader to store the diffuse color and surface normal is trivial. But the final postprocessing shader is a little complicated. What makes it tricky is that it needs to regenerate the original surface position from the screen position and depth value. The math for that deserves some explanation.

We need to take a clip-space coordinate and depth-buffer value (ClipX,ClipY,ClipZ,ClipW) and unproject it back to a view-space (ViewX,ViewY,ViewZ) coordinate. Lighting is then done in view-space.

Okay, so here's the math. Panda uses the projection matrix to transform view-space into clip-space. But in practice, the projection matrix for a perspective camera always contains four nonzero constants, and they're always in the same place:

&lt;pre class=&quot;codeblock&quot;&gt;
A	0	0	0
0	0	B	1
0	C	0	0
0	0	D	0
&lt;/pre&gt;

The result is that the panda projection matrix boils down to these simple equations:

&lt;pre class=&quot;codeblock&quot;&gt;
clipx = viewx * A
clipy = viewz * C
clipz = viewy * B + D
clipw = viewy
&lt;/pre&gt;

Look out, there has been a coordinate system change! In the scene graph, Z corresponds to &quot;up&quot;, but in clip-space, Z is the depth value (and X,Y address a pixel).

After panda calculates clip-space coordinates, it divides by W. Finally, it rescales the depth-value:

&lt;pre class=&quot;codeblock&quot;&gt;
screenx = clipx / clipw
screeny = clipy / clipw
screenz = clipz / clipw
depth = screenz * 0.5 + 0.5
&lt;/pre&gt;


So now we have some equations defining (clipx,clipy,clipz,clipw) in terms of (viewx,viewy,viewz), and (screenx,screeny,screenz) in terms of (clipx,clipy,clipz,clipw). It's basic algebra to solve these equations for (viewx, viewy, viewz) in terms of (screenx, screeny, screenz). Here, I have shown all my algebraic steps:

&lt;pre class=&quot;codeblock&quot;&gt;
depth = screenz * 0.5 + 0.5
depth = (clipz / clipw) * 0.5 + 0.5
depth = ((viewy * B + D) / viewy) * 0.5 + 0.5
depth - 0.5 = ((viewy * B + D) / viewy) * 0.5
(2*depth - 1.0) = ((viewy * B + D) / viewy)
(2*depth - 1.0) * viewy = viewy * B + D
(2*depth - 1.0) * viewy + viewy * -B = D
(2*depth - 1.0 - B) * viewy = D
viewy = 0.5D / (depth - 0.5 - 0.5B)

screenx = clipx / clipw
screenx = (viewx * A) / viewy
screenx * viewy = viewx * A
screenx * (0.5D / (depth - 0.5 - 0.5B)) = viewx * A
(screenx * 0.5D) / (depth - 0.5 - 0.5B) = viewx * A
(screenx * 0.5D/A) / (depth - 0.5 - 0.5B) = viewx
viewx = (screenx * 0.5D/A) / (depth - 0.5 - 0.5B)

screeny = clipy / clipw
screeny = (viewz * C) / viewy
screeny * viewy = viewz * C
screeny * (0.5D / (depth - 0.5 - 0.5B)) = viewz * C
(screeny * 0.5D) / (depth - 0.5 - 0.5B) = viewz * C
(screeny * 0.5D/C) / (depth - 0.5 - 0.5B) = viewz
viewz = (screeny * 0.5D/C) / (depth - 0.5 - 0.5B)
&lt;/pre&gt;

To save our vertex and pixel shaders a little work, we can precompute these constants:

&lt;pre class=&quot;codeblock&quot;&gt;
projx = 0.5D/A
projy = 0.5D
projz = 0.5D/C
projw = -0.5-0.5B
&lt;/pre&gt;

So, here are the equations in their final form:

&lt;pre class=&quot;codeblock&quot;&gt;
viewx = (screenx * projx) / (depth + projw)
viewy = (1 * projy) / (depth + projw)
viewz = (screeny * projz) / (depth + projw) 
&lt;/pre&gt;

&lt;b&gt;Back to the List of Sample Programs:&lt;/b&gt;

[[Sample Programs in the Distribution]]</text>
    </revision>
  </page>
  <page>
    <title>Sample Programs: Fractal Plants</title>
    <ns>0</ns>
    <id>2111</id>
      <sha1>td4xa3d2cseu1yaswkvoa0q3sas1g43</sha1>
    <revision>
      <id>4520</id>
      <timestamp>2007-09-01T20:33:14Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="621">&lt;b&gt;The Fractal Plants Sample Program&lt;/b&gt;

To run a sample program, you need to install Panda3D. If you're a Windows user, you'll find the sample programs in your start menu. If you're a linux user, you'll find the sample programs in /usr/share/panda3d.

&lt;b&gt;Screenshots&lt;/b&gt;

[[Image:Screenshot-Sample-Programs-Fractal-Plants.jpg]]

&lt;b&gt;Explanation&lt;/b&gt;

This sample program isn't so much about fractals as it is about synthesizing a 3D model.  Ie, this program does not include any 3D models on disk - it generates the trees procedurally.

&lt;b&gt;Back to the List of Sample Programs:&lt;/b&gt;

[[Sample Programs in the Distribution]]</text>
    </revision>
  </page>
  <page>
    <title>Sample Programs: Glow Filter</title>
    <ns>0</ns>
    <id>2112</id>
      <sha1>ll0k4r30i5cctq5x98ltdc0d8lwp1xu</sha1>
    <revision>
      <id>7481</id>
      <timestamp>2011-12-24T13:08:16Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="2560">&lt;b&gt;The Glow Filter Sample Program&lt;/b&gt;

To run a sample program, you need to install Panda3D. If you're a Windows user, you'll find the sample programs in your start menu. If you're a Linux user, you'll find the sample programs in /usr/share/panda3d.

&lt;b&gt;Screenshots&lt;/b&gt;

[[Image:Screenshot-Sample-Programs-Glow-Filter.jpg]]

&lt;b&gt;Explanation of the 'Basic' Version&lt;/b&gt;

There are two versions of this program: Basic and Advanced.  The Basic version
relies on Panda3D's automatic shader generation mechanisms and Panda3D's built in catalog of image-postprocessing filters.  In other words, in the Basic
version, Panda3D is doing all the hard work for us.  In the Advanced version,
we have written our own shaders and are doing our own image postprocessing.

So what the basic version demonstrates is really just how to turn on
the shader generation, how to turn on a 'light ramp' (the essence of 
cartoon shading), and how to turn on a built-in image postprocessing filter.

&lt;b&gt;Explanation of the 'Advanced' Version&lt;/b&gt;

The advanced version shows how to use Cg shaders to implement a &quot;glow&quot; postprocessing filter. The demo will only work on video cards that support shaders.

If you examine the texture for this model in photoshop, you'll see that it has an alpha channel. I'm not using the alpha channel to represent transparency. Instead, the alpha channel is a &quot;glow map.&quot; Where the alpha is 1, the model glows, in places where the alpha is zero, it does not glow.

The scene is rendered to the main window in the normal way. It is also rendered to an offscreen buffer using a special shader that pays attention to the glow map (in the alpha channel). Wherever the glow map is 1, it renders the model's normal color. Wherever the glow map is 0, it renders black. This offscreen buffer is called the &quot;glow buffer&quot;.

The contents of the glow buffer are then rendered into another offscreen buffer, the &quot;blur x&quot; buffer, using a shader that does a one-dimensional horizontal blur. The contents of the &quot;blur x&quot; buffer are then rendered into a third offscreen buffer, the &quot;blur y&quot; buffer, using a shader that does a one-dimensional vertical blur. Taken together, the two one-dimensional blurs add up to a two-dimensional blur. The result is that the glowing lines that were rendered into the glow buffer are smeared outward, forming little halos.

In a final step, the blurred texture is applied to the main window using additive blending - ie, the halos are added to the scene. 

&lt;b&gt;Back to the List of Sample Programs:&lt;/b&gt;

[[Sample Programs in the Distribution]]</text>
    </revision>
  </page>
  <page>
    <title>Sample Programs: Infinite Tunnel</title>
    <ns>0</ns>
    <id>2113</id>
      <sha1>m7cjat9tn91dcbpx389muy2j9z2tjya</sha1>
    <revision>
      <id>7482</id>
      <timestamp>2011-12-24T13:08:45Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>typo</comment>
      <text xml:space="preserve" bytes="1140">&lt;b&gt;The Infinite Tunnel Sample Program&lt;/b&gt;

To run a sample program, you need to install Panda3D. If you're a Windows user, you'll find the sample programs in your start menu. If you're a Linux user, you'll find the sample programs in /usr/share/panda3d.

&lt;b&gt;Screenshots&lt;/b&gt;

[[Image:Screenshot-Sample-Programs-Infinite-Tunnel.jpg]]

&lt;b&gt;Explanation&lt;/b&gt;

This tutorial will cover fog and how it can be used to make a finite length tunnel seem endless by hiding its endpoint in darkness. Fog in panda works be coloring objects based on their distance from the camera. Fog is not a 3D volume object like real world fog. With the right settings, Fog in panda can mimic the appearance of real world fog.

The way fog in Panda works is by coloring the models in the world. Fog cannot exist without any objects in the scene. The parts of the object which are furthest from the camera will get gradually colored by the color specified for the fog. If this color blends in with the background, it will appear as it the object is being occluded by a 'cloud' of fog.

&lt;b&gt;Back to the List of Sample Programs:&lt;/b&gt;

[[Sample Programs in the Distribution]]</text>
    </revision>
  </page>
  <page>
    <title>Sample Programs: Looking and Gripping</title>
    <ns>0</ns>
    <id>2114</id>
      <sha1>rgo6dfy9v802g322nn9uhdmx5vqpmeh</sha1>
    <revision>
      <id>7483</id>
      <timestamp>2011-12-24T13:10:08Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>typo</comment>
      <text xml:space="preserve" bytes="1927">&lt;b&gt;The Looking and Gripping Sample Program&lt;/b&gt;

To run a sample program, you need to install Panda3D. If you're a Windows user, you'll find the sample programs in your start menu. If you're a Linux user, you'll find the sample programs in /usr/share/panda3d.

&lt;b&gt;Screenshots&lt;/b&gt;

[[Image:Screenshot-Sample-Programs-Looking-and-Gripping.jpg]]

&lt;b&gt;Explanation&lt;/b&gt;

This tutorial will cover how you can manipulate actor joints in Panda. Joints are essentially bones used by a 3D package (Maya, 3D Studio, XSI, etc) to deform a character. The model is bound to these joints and moving these joints will cause the model to deform. For example, rotating the shoulder joint will move the arms, rotating the leg joints will bend the legs. In Panda, these joints are normally not accessible. However, by controlling them with controlJoint, you can manipulate the orientation of that joint in Panda independent of its preloaded animations. You could even use a model without premade animations and manipulate the joints manually in Panda.

Specifically in this tutorial, we will take control of the neck joint of a humanoid character and rotate that joint to always face the mouse cursor. This will in turn make the head of the character &quot;look&quot; at the mouse cursor. We will also expose the hand joint using exposeJoint and use its positional data to &quot;attach&quot; objects that the character can hold. By using exposeJoint, the object will stay in the character's hand even if the hand is moving through an animation.

NOTE: Models with joints will differ greatly from each other depending on how they were made and who made them. You may find that a certain model's joints are not oriented logically or practically. Also beware that joints may have limits on how far they can twist. Going beyond a joints limits may cause strange and unwanted deformations.

&lt;b&gt;Back to the List of Sample Programs:&lt;/b&gt;

[[Sample Programs in the Distribution]]</text>
    </revision>
  </page>
  <page>
    <title>Sample Programs: Media Player</title>
    <ns>0</ns>
    <id>2115</id>
      <sha1>7v8q5pzhhctgeg6zpvlxsyxbtnk1jb3</sha1>
    <revision>
      <id>7484</id>
      <timestamp>2011-12-24T13:10:25Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="689">&lt;b&gt;The Media Player Sample Program&lt;/b&gt;

To run a sample program, you need to install Panda3D. If you're a Windows user, you'll find the sample programs in your start menu. If you're a Linux user, you'll find the sample programs in /usr/share/panda3d.

&lt;b&gt;Screenshots&lt;/b&gt;

[[Image:Screenshot-Sample-Programs-Media-Player.jpg]]

&lt;b&gt;Explanation&lt;/b&gt;

This sample program shows how to play a movie in panda.  This is particularly
useful for cut-scenes, but movies can also be used as animated textures on
the surfaces of objects.  This sample shows both video and audio, and how
to synchronize them properly.

&lt;b&gt;Back to the List of Sample Programs:&lt;/b&gt;

[[Sample Programs in the Distribution]]</text>
    </revision>
  </page>
  <page>
    <title>Sample Programs: Motion Trails</title>
    <ns>0</ns>
    <id>2116</id>
      <sha1>fhd54wobc7gnlnc6zba20p65z6f3kqm</sha1>
    <revision>
      <id>7485</id>
      <timestamp>2011-12-24T13:10:43Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="1456">&lt;b&gt;The Motion Trails Sample Program&lt;/b&gt;

To run a sample program, you need to install Panda3D. If you're a Windows user, you'll find the sample programs in your start menu. If you're a Linux user, you'll find the sample programs in /usr/share/panda3d.

&lt;b&gt;Screenshots&lt;/b&gt;

[[Image:Screenshot-Sample-Programs-Motion-Trails.jpg]]

&lt;b&gt;Explanation&lt;/b&gt;

This tutorial shows how to create motion trails in panda. The basic process is this: after rendering the scene, you copy the scene into a texture. You apply that texture to a full-screen quad. You integrate that quad into the rendering of the next frame. That creates a feedback loop.

The basic steps are: create a texture that will hold the contents of the main window. Tell the main window to copy is output into this texture using setupRenderTexture. Obtain a full-screen quad containing this texture using getTextureCard. Position this quad in the scene.

You can get a lot of different effects by simply moving the quad a little bit. By putting it behind the actor, the actor is fully visible, and surrounded by trails. By putting it in front of the actor, the trails overlap the actor. By rotating the quad slightly, you get a whirlpool. By offsetting it or scaling it, you can cause the trails to move away from the actor. You can colorize it, adjust its transparency, and otherwise tweak it in a number of ways. 

&lt;b&gt;Back to the List of Sample Programs:&lt;/b&gt;

[[Sample Programs in the Distribution]]</text>
    </revision>
  </page>
  <page>
    <title>Sample Programs: Mouse Modes</title>
    <ns>0</ns>
    <id>51887</id>
      <sha1>26i0i58wzfd165nhf8yqm2kslo6jkcc</sha1>
    <revision>
      <id>60490</id>
      <timestamp>2015-05-07T22:56:12Z</timestamp>
      <contributor>
        <username>Eswartz</username>
        <id>22863</id>
      </contributor>
      <text xml:space="preserve" bytes="2115">&lt;b&gt;The Mouse Modes Sample Program&lt;/b&gt;

To run a sample program, you need to install Panda3D.  If you're a Windows user, you'll find the sample programs in your start menu.  If you're a Linux user, you'll find the sample programs in /usr/share/panda3d.

&lt;!-- 
&lt;b&gt;Screenshots&lt;/b&gt;

[[Image:Screenshot-Sample-Programs-Mouse-Modes.jpg]]
--&gt;

&lt;b&gt;Explanation&lt;/b&gt;

This sample program shows usage of different mouse modes, which control how the mouse cursor interacts with a Panda3D window.  

For the purposes of first-person games with &quot;mouselook,&quot; it's important to use a mode other the default (&quot;absolute&quot;), because in that mode, the mouse cursor may easily leave the window, and your game will stop receiving mouse events.  

To maintain a consistent stream of pointer events no matter how much the user moves the mouse, the &quot;relative&quot; mode and &quot;confined&quot; mode (new in 1.9.1) will keep the pointer inside the window.  

These latter two modes may not be available on all platforms, though, so the sample demonstrates how to account for switching modes and provide a consistent sense of control no matter which mode is in use.

&lt;b&gt;Usage&lt;/b&gt;

In the sample, a pretty cube lies near the center of the window, which you may rotate by moving the mouse. 

You may select between three possible mouse modes with the '0', '1', or '2' keys to see how the block moves depending on the mouse movement.  Note the center status line will tell which mode actually got applied.

The 'c' key toggles automatic re-centering of the mouse cursor, which is a strategy to avoid allowing the cursor to leave the window.  This is on by default, so any one of the three modes will generally provide a smooth mouse experience, but with rapid enough movements, the mouse can leave the window in &quot;absolute&quot; mode.

Finally, the 's' key toggles the visibility of the mouse cursor.

The [[Mouse Support]] section of the manual covers the mouse modes, detecting whether a mouse mode is supported, and a strategy for re-centering the mouse, as used by this sample.

&lt;b&gt;Back to the List of Sample Programs:&lt;/b&gt;

[[Sample Programs in the Distribution]]</text>
    </revision>
  </page>
  <page>
    <title>Sample Programs: Music Box</title>
    <ns>0</ns>
    <id>2117</id>
      <sha1>oi94km13kvouxo3aq9dee8f7w5wtn8k</sha1>
    <revision>
      <id>7486</id>
      <timestamp>2011-12-24T13:11:00Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="559">&lt;b&gt;The Music Box Sample Program&lt;/b&gt;

To run a sample program, you need to install Panda3D. If you're a Windows user, you'll find the sample programs in your start menu. If you're a Linux user, you'll find the sample programs in /usr/share/panda3d.

&lt;b&gt;Screenshots&lt;/b&gt;

[[Image:Screenshot-Sample-Programs-Music-Box.jpg]]

&lt;b&gt;Explanation&lt;/b&gt;

Music Box is a simple program that allows you to play sounds.  It demonstrates playing sounds, and creating GUI buttons and sliders.

&lt;b&gt;Back to the List of Sample Programs:&lt;/b&gt;

[[Sample Programs in the Distribution]]</text>
    </revision>
  </page>
  <page>
    <title>Sample Programs: Normal Mapping</title>
    <ns>0</ns>
    <id>2118</id>
      <sha1>q4ao39jidz59ef2jwr2xg0frgh9zoxf</sha1>
    <revision>
      <id>7487</id>
      <timestamp>2011-12-24T13:11:22Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="3825">&lt;b&gt;The Normal Mapping Sample Program&lt;/b&gt;

To run a sample program, you need to install Panda3D. If you're a Windows user, you'll find the sample programs in your start menu. If you're a Linux user, you'll find the sample programs in /usr/share/panda3d.

&lt;b&gt;Screenshots&lt;/b&gt;

[[Image:Screenshot-Sample-Programs-Normal-Mapping.jpg]]

&lt;b&gt;Explanation&lt;/b&gt;

Note: this explanation corresponds to Panda3D version 1.5.0.  It does not match the older version of Panda3D, version 1.4.2.  

Normal Mapping is a technique to make textured surfaces appear more &quot;lifelike&quot; by having them respond to changing lights and viewing angles. As the light moves around, it reflects off of simulated &quot;bumps&quot; on the surface (the bumps are not real, the polygons are flat, but they look real because of how they reflect the light).

&lt;b&gt;Panda's built-in Normal Mapping Capabilities&lt;/b&gt;

Normally, to use fancy rendering techniques like normal mapping, you would have to write special GPU code called &quot;shaders.&quot;  However, in Panda3D version 1.5.0, panda gained the ability to synthesize many shaders for you.  What that means is that you can use many modern rendering techniques (including normal mapping) without having to know shader programming at all.

Look in the &lt;code&gt;models&lt;/code&gt; subdirectory for a model called &quot;abstractroom&quot;.  It was created in Maya, and a normal map was applied in Maya.  The maya exporter was used to convert this into panda's model file format, &lt;code&gt;abstractroom.egg.&lt;/code&gt;  During the conversion process, the maya exporter noticed the normal map and included information about it in the egg file: if you examine the egg file with a text editor, you will see the references in there.  You can view the model using panda's model viewer:

&lt;table class=&quot;code&quot;&gt;&lt;tr&gt;&lt;td&gt;
pview abstractroom.egg
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

After pview loads, press 'c' to center the model, 'l' to turn on lighting, and 'p' to turn on per-pixel lighting.  Presto, you will see the effects of normal mapping.

If you are doing this in a program, the steps are basically the same: load a model which already has normal maps, set up some lights, and turn on per-pixel lighting.  The sample program &lt;code&gt;Tut-Normal-Mapping-Basic&lt;/code&gt; shows this process.

&lt;b&gt;Doing it the Hard Way&lt;/b&gt;

The problem with panda's shader synthesis capabilities is that they can only synthesize the shaders that people usually need.  If what you need is esoteric, you'll have to write your own shader.

There are two difficulties associated with writing your own shader.  The first is that you need to know shader programming.  Teaching shader programming is beyond the scope of this tutorial.  Panda uses the Cg shader language, which you can learn elsewhere.  Furthermore, normal mapping shaders are more complex than most.  The mathematics involved in normal mapping are quite complex, which puts writing a normal mapping shader even further outside the scope of this tutorial.

The second problem with writing your own shader is that shaders must be hardwired to a very limited set of circumstances.  The shader included with this sample program is hardwired for models with a single diffuse texture and a single normal map.  It is hardwired for absence of vertex colors.  It implements one white point light and one white ambient light.  Changing any of these parameters would require a different shader.

This is not because the shader was written lazily.  It is because shaders are by nature specialized to a specific combination of model attributes.  This makes it rather awkward to write a substantial program that uses manually-written shaders.  This is a big part of the reason that panda now supports shader synthesis - the shader generator can handle almost any kind of model.

&lt;b&gt;Back to the List of Sample Programs:&lt;/b&gt;

[[Sample Programs in the Distribution]]</text>
    </revision>
  </page>
  <page>
    <title>Sample Programs: Particles</title>
    <ns>0</ns>
    <id>2119</id>
      <sha1>kfger4juprk3k2to4qws0ywyrd2pr2e</sha1>
    <revision>
      <id>7488</id>
      <timestamp>2011-12-24T13:12:38Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>typos</comment>
      <text xml:space="preserve" bytes="2475">&lt;b&gt;The Particles Sample Program&lt;/b&gt;

To run a sample program, you need to install Panda3D. If you're a Windows user, you'll find the sample programs in your start menu. If you're a Linux user, you'll find the sample programs in /usr/share/panda3d.

&lt;b&gt;Screenshots&lt;/b&gt;

[[Image:Screenshot-Sample-Programs-Particles.jpg]]

&lt;b&gt;Explanation&lt;/b&gt;

In this tutorial, you will learn how to create particle effects in Panda3d. Particle effects are systems simulated by the movement of many small objects, or particles. They are commonly used to simulate phenomenon like explosions, sparks, fire, smoke, and steam to name a few. Particle effect systems are very complicated. It's not likely that you would be able to create any good systems just by reading a list of available parameters. You need to be able to see and manipulate the systems to really get results. Fortunately, there is a tool built into Panda for visualizing particle effects. particlePanelLoader.py contains the code needed to run the Particle Panel. Run it, and you should see a black screen with a default particle effect, and a second window listing the parameters for that effect.

There are too many parameters in the Particle Panel to go over them all, however, the main sections are:

* System: Details on how many particles are allowed and how often they are created.
* Factory: Sets the properties of particles when they are created.
* Emitter: Sets an area that particles can be created in and their initial velocities.
* Renderer: How the particles will be drawn on screen (Hint: Most good particle effects are sprites with a small texture at very low alpha (around .1) heavily blending between each other.).
* Forces: Sets forces that can be used to move existing particles.

Play around with the panel for a while, and create something you like. You can then save the settings to a file with the extension ptf. You can also load that ptf later and continue to modify it. Some sample ptfs are included for inspiration. The Panel does need some improvements because it is somewhat buggy. It can crash, especially when dragged around, and forgets some settings when they are saved out to a ptf. It forgets to include the extension of the texture for a SpriteRenderer, so you need to open the file by hand and correct the loader.loadTexture command or it will not load. It also forgets to record the axis masks on forces.

&lt;b&gt;Back to the List of Sample Programs:&lt;/b&gt;

[[Sample Programs in the Distribution]]</text>
    </revision>
  </page>
  <page>
    <title>Sample Programs: Procedural Cube</title>
    <ns>0</ns>
    <id>2120</id>
      <sha1>8i8g3v78huecsl1iubgihd7zsc5vp1y</sha1>
    <revision>
      <id>7489</id>
      <timestamp>2011-12-24T13:12:56Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="600">&lt;b&gt;The Procedural Cube Sample Program&lt;/b&gt;

To run a sample program, you need to install Panda3D. If you're a Windows user, you'll find the sample programs in your start menu. If you're a Linux user, you'll find the sample programs in /usr/share/panda3d.

&lt;b&gt;Screenshots&lt;/b&gt;

[[Image:Screenshot-Sample-Programs-Procedural-Cube.jpg]]

&lt;b&gt;Explanation&lt;/b&gt;

This program synthesizes a 3D model of a cube.  If you need to see in the minimum number of lines of code how to synthesize a model, this is the sample you want.

&lt;b&gt;Back to the List of Sample Programs:&lt;/b&gt;

[[Sample Programs in the Distribution]]</text>
    </revision>
  </page>
  <page>
    <title>Sample Programs: Roaming Ralph</title>
    <ns>0</ns>
    <id>2121</id>
      <sha1>2t1rdewxbo2hckolp1jy173id8tvmka</sha1>
    <revision>
      <id>7490</id>
      <timestamp>2011-12-24T13:14:14Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="1118">&lt;b&gt;The Roaming Ralph Sample Program&lt;/b&gt;

To run a sample program, you need to install Panda3D. If you're a Windows user, you'll find the sample programs in your start menu. If you're a Linux user, you'll find the sample programs in /usr/share/panda3d.

&lt;b&gt;Screenshots&lt;/b&gt;

[[Image:Screenshot-Sample-Programs-Roaming-Ralph.jpg]]

&lt;b&gt;Explanation&lt;/b&gt;

This tutorial shows a character walking on uneven terrain. He rises and falls with the contours of the terrain, stops when he runs into a tree or a rock, and won't walk off the edge. The camera follows him, also moving intelligently over the terrain, and you have some control over the camera angle. The character's body animates sensibly according to his motion.

Much of this is implemented using collision rays to detect the height of the terrain and the presence of obstacles. 

&lt;i&gt;Caution: this program uses an extremely inefficient method for detecting the height of the terrain.  There is a much better way to do it, but we have not had time to correct the sample program.&lt;/i&gt;

&lt;b&gt;Back to the List of Sample Programs:&lt;/b&gt;

[[Sample Programs in the Distribution]]</text>
    </revision>
  </page>
  <page>
    <title>Sample Programs: Shadows</title>
    <ns>0</ns>
    <id>2122</id>
      <sha1>fc6syzflc2jz3iws3ak45wltrn5os1o</sha1>
    <revision>
      <id>7491</id>
      <timestamp>2011-12-24T13:14:36Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="520">&lt;b&gt;The Shadows Sample Program&lt;/b&gt;

To run a sample program, you need to install Panda3D. If you're a Windows user, you'll find the sample programs in your start menu. If you're a Linux user, you'll find the sample programs in /usr/share/panda3d.

&lt;b&gt;Screenshots&lt;/b&gt;

[[Image:Screenshot-Sample-Programs-Shadows.jpg]]

&lt;b&gt;Explanation&lt;/b&gt;

This program shows how to use shadow maps in Panda3D.  This is a technique for
dynamic shadowing.

&lt;b&gt;Back to the List of Sample Programs:&lt;/b&gt;

[[Sample Programs in the Distribution]]</text>
    </revision>
  </page>
  <page>
    <title>Sample Programs: Solar System</title>
    <ns>0</ns>
    <id>2123</id>
      <sha1>fk4zlbqn6q678qydwjyfyzkvegh6gps</sha1>
    <revision>
      <id>7492</id>
      <timestamp>2011-12-24T13:15:01Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="927">&lt;b&gt;The Solar System Sample Program&lt;/b&gt;

To run a sample program, you need to install Panda3D. If you're a Windows user, you'll find the sample programs in your start menu. If you're a Linux user, you'll find the sample programs in /usr/share/panda3d.

&lt;b&gt;Screenshots&lt;/b&gt;

[[Image:Screenshot-Sample-Programs-Solar-System.jpg]]

&lt;b&gt;Explanation&lt;/b&gt;

This sample program shows planets orbiting around the sun, and a moon orbiting one of the planets.  If you just stare at the moon, you'll realize that its motion is a spiral:

[[Image:Spirograph.gif]]

The motion of the moon is only simple if you think about it in relative terms: the moon is moving in a circle &lt;i&gt;relative&lt;/i&gt; to the planet, and the planet is moving in a circle &lt;i&gt;relative&lt;/i&gt; to the sun.

This panda program shows how to implement relative movement and relative positioning.

&lt;b&gt;Back to the List of Sample Programs:&lt;/b&gt;

[[Sample Programs in the Distribution]]</text>
    </revision>
  </page>
  <page>
    <title>Sample Programs: Teapot on TV</title>
    <ns>0</ns>
    <id>2124</id>
      <sha1>nznal9ialgjhprow4opjuy55hp9gxnw</sha1>
    <revision>
      <id>7493</id>
      <timestamp>2011-12-24T13:15:18Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="625">&lt;b&gt;The Teapot on TV Sample Program&lt;/b&gt;

To run a sample program, you need to install Panda3D. If you're a Windows user, you'll find the sample programs in your start menu. If you're a Linux user, you'll find the sample programs in /usr/share/panda3d.

&lt;b&gt;Screenshots&lt;/b&gt;

[[Image:Screenshot-Sample-Programs-Teapot-on-TV.jpg]]

&lt;b&gt;Explanation&lt;/b&gt;

In this tutorial, a spinning teapot is rendered into a texture.  Then, the texture (which contains a picture of a teapot) is applied to the face of an animated TV-headed character, who dances.

&lt;b&gt;Back to the List of Sample Programs:&lt;/b&gt;

[[Sample Programs in the Distribution]]</text>
    </revision>
  </page>
  <page>
    <title>Sample Programs: Texture Swapping</title>
    <ns>0</ns>
    <id>2125</id>
      <sha1>9i5oy6c9wv9rwlfsbdvez820k4uohvt</sha1>
    <revision>
      <id>7494</id>
      <timestamp>2011-12-24T13:15:36Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <text xml:space="preserve" bytes="1604">&lt;b&gt;The Texture Swapping Sample Program&lt;/b&gt;

To run a sample program, you need to install Panda3D. If you're a Windows user, you'll find the sample programs in your start menu. If you're a Linux user, you'll find the sample programs in /usr/share/panda3d.

&lt;b&gt;Screenshots&lt;/b&gt;

[[Image:Screenshot-Sample-Programs-Texture-Swapping.jpg]]

&lt;b&gt;Explanation&lt;/b&gt;

This tutorial will show how to use a sequence of textures on an object to achieve a specific effect. Popular uses of this technique are:

* Animated sprites
* Moving shadows

The basic principle of this tutorial is that even though a model file contains a reference to a texture file, the actual texture applied to a model can be changed in panda. Textures are just image files and they can be loaded in panda via loader.loadTexture. Each model loaded into Panda has a texture attribute that can be changed. Not only can this feature be used to change the texture on a model from one to another but it can also be used play an animated sequence on the model by using a sequence of textures and swapping them at regular intervals.

This tutorial will also demonstrate the billboard function which orients an object to always face the the camera. This is useful for 2D sprites in a 3D world.

Above is a screenshot of the tutorial running with two animated sprites. One is a flying duck and the other is an explosion. Only the explosion has the billboard effect applied to it. As the camera moves, the explosion will turn to face the camera while the duck will not.

&lt;b&gt;Back to the List of Sample Programs:&lt;/b&gt;

[[Sample Programs in the Distribution]]</text>
    </revision>
  </page>
  <page>
    <title>Sample Programs in the Distribution</title>
    <ns>0</ns>
    <id>2102</id>
      <sha1>4409kuy2ijkwgd3oea975v1qsmzfodv</sha1>
    <revision>
      <id>7851</id>
      <timestamp>2012-10-22T09:02:41Z</timestamp>
      <contributor>
        <username>Teedee</username>
        <id>449</id>
      </contributor>
      <text xml:space="preserve" bytes="4125">&lt;p&gt;The Panda3D Distribution includes quite a few sample programs.  The following is a list of what's included, and which features of the engine each sample demonstrates. If you are just learning Panda3D, take a look at the ones marked as &quot;Beginner&quot; difficulty.&lt;/p&gt;

&lt;p&gt;To run a sample program, you need to install Panda3D. If you're a Windows user, you'll find the sample programs in your Start Menu. If you're a Linux user, you'll find the sample programs in /usr/share/panda3d. On Mac OS X, you'll find them in /Developer/Examples/Panda3D/.&lt;/p&gt;

&lt;table border=0 cellspacing=0 cellpadding=0&gt;
&lt;tr&gt;&lt;td&gt;
[[Sample Programs: Asteroids]]

* Difficulty: Advanced
* Creating tasks (routines that get called every frame)
* Using 2D graphics
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;
[[Sample Programs: Ball in Maze]]

* Difficulty: Intermediate
* Using the collision detector
* Reading the mouse
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;
[[Sample Programs: Boxing Robots]]

* Difficulty: Intermediate
* Loading animated actors and playing animations
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;
[[Sample Programs: Carousel]]

* Difficulty: Beginner
* Relative positioning
* Intervals (automatic movement)
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;
[[Sample Programs: Cartoon Shader]]

* Difficulty: Intermediate (or Advanced)
* Enables per-pixel lighting
* Explicit Shaders
* Image Postprocessing
* Render-to-Texture
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;
[[Sample Programs: Chessboard]]

* Difficulty: Intermediate
* Selecting an object with the mouse
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;
[[Sample Programs: Disco Lights]]

* Difficulty: Intermediate
* Using vertex lighting
* Enables per-pixel lighting
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;
[[Sample Programs: Distortion]]

* Difficulty: Advanced
* Creates an interesting shader effect where the entire screen is rendered into a texture.
&lt;/td&gt;&lt;/tr&gt; 

&lt;tr&gt;&lt;td&gt;
[[Sample Programs: Fireflies]]

* Difficulty: Very Advanced
* Deferred shading - a complex shader-based algorithm
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;
[[Sample Programs: Fractal Plants]]

* Difficulty: Very Advanced
* Creates a 3D model without loading it from disk
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;
[[Sample Programs: Glow Filter]]

* Difficulty: Intermediate (or Advanced)
* Enabling per-pixel lighting
* Explicit Shaders
* Image Postprocessing
* Render-to-Texture
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;
[[Sample Programs: Infinite Tunnel]]

* Difficulty: Intermediate
* Using fog to hide artifacts in the distance
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;
[[Sample Programs: Looking and Gripping]]

* Difficulty: Intermediate
* Controlling a character's head procedurally
* Causing a character to grip an object
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;
[[Sample Programs: Media Player]]

* Difficulty: Beginner
* Loading a texture from an AVI file
* Loading a sound from an AVI file
* Synchronizing audio and video
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;
[[Sample Programs: Motion Trails]]

* Difficulty: Advanced
* Captures contents of screen and reuses it later.
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;
[[Sample Programs: Music Box]]

* Difficulty: Intermediate
* Playing sounds
* GUI buttons and sliders
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;
[[Sample Programs: Normal Mapping]]

* Difficulty: Intermediate (or Advanced)
* Enables per-pixel lighting
* Explicit Shaders
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;
[[Sample Programs: Particles]]

* Difficulty: Advanced
* Demonstrates the particle system
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;
[[Sample Programs: Procedural Cube]]

* Difficulty: Advanced
* Creates a 3D model without loading it
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;
[[Sample Programs: Roaming Ralph]]

* Difficulty: Advanced
* A character walks around a terrain
* Uses collision system to detect height of terrain
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;
[[Sample Programs: Shadows]]

* Difficulty: Advanced
* Explicit Shaders
* Dynamic Shadows: shadow mapping
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;
[[Sample Programs: Solar System]]

* Difficulty: Beginner Tutorial
* Tutorial structure shows development steps
* Shows how objects can move relative to other objects
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;
[[Sample Programs: Teapot on TV]]

* Difficulty: Intermediate
* Render-to-texture
* Places rendered texture on model in scene
&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;
[[Sample Programs: Texture Swapping]]

* Difficulty: Intermediate
* Swaps textures on models to create interesting effects
&lt;/td&gt;&lt;/tr&gt; 

&lt;/table&gt;</text>
    </revision>
  </page>
  <page>
    <title>Sandbox</title>
    <ns>0</ns>
    <id>2330</id>
      <sha1>6ulnh73yqoc16dz2ol6vjkfylyzr884</sha1>
    <revision>
      <id>7068</id>
      <timestamp>2011-01-26T11:38:47Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <text xml:space="preserve" bytes="97">Hello.
[python]Hello Python user![/python]
[cxx]hello C++ user![/cxx]
{{#ev:youtube|l8dr4XSQkQc}}</text>
    </revision>
  </page>
  <page>
    <title>Scene Editor Lectures</title>
    <ns>0</ns>
    <id>1016</id>
      <sha1>8nbyrkekxyu1hx6mdcnbupsb9mlr6xh</sha1>
    <revision>
      <id>7720</id>
      <timestamp>2012-03-09T10:58:11Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>oops, wrong page</comment>
      <text xml:space="preserve" bytes="1214">The Scene Editor was developed at the Entertainment Technology Center (Carnegie Mellon University). It is meant to be a level editing or layout tool.

Below are some video tutorials which explain how to use the Scene Editor. All tutorials were recorded by Shalin Shodhan in May of 2004.

&lt;ul&gt;
	&lt;li&gt;[http://panda3d.org/videolectures/scene/1_Introduction.avi Introduction] (48 mb)
	&lt;li&gt;[http://panda3d.org/videolectures/scene/2_Camera_Control_And_Object_Manipulation.avi Camera Control and Object Manipulation] (18mb)
	&lt;li&gt;[http://panda3d.org/videolectures/scene/3_Animation_Loading.avi Animation Loading] (8 mb)
	&lt;li&gt;[http://panda3d.org/videolectures/scene/4_Lighting.avi Lighting] (11 mb)
	&lt;li&gt;[http://panda3d.org/videolectures/scene/5_Animation_Blending.avi Animation Blending] (26 mb)
	&lt;li&gt;[http://panda3d.org/videolectures/scene/6_Motion_Paths.avi Motion Paths] (24 mb)
	&lt;li&gt;[http://panda3d.org/videolectures/scene/7_Particles.avi Particles] (38 mb)
	&lt;li&gt;[http://panda3d.org/videolectures/scene/8_Collision.avi Collision] (34 mb)
	&lt;li&gt;[http://panda3d.org/videolectures/scene/9_Misc1.avi Miscellaneous Part I] (20 mb)
	&lt;li&gt;[http://panda3d.org/videolectures/scene/10_Misc2.avi Miscellaneous Part II] (16 mb)
&lt;/ul&gt;</text>
    </revision>
  </page>
  <page>
    <title>Scene Graph</title>
    <ns>0</ns>
    <id>2193</id>
    <redirect title="The Scene Graph" />
      <sha1>2bzfp3zmf61rwkbz0docndz38qi1vyl</sha1>
    <revision>
      <id>4824</id>
      <timestamp>2008-03-12T14:42:59Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>redirected</comment>
      <text xml:space="preserve" bytes="29">#REDIRECT [[The Scene Graph]]</text>
    </revision>
  </page>
  <page>
    <title>Scene Graph Manipulations</title>
    <ns>0</ns>
    <id>943</id>
      <sha1>67x4yarb19gp9wtxfypfpn1ts923t2a</sha1>
    <revision>
      <id>7853</id>
      <timestamp>2012-11-04T15:34:03Z</timestamp>
      <contributor>
        <username>Nemesis13</username>
        <id>394</id>
      </contributor>
      <text xml:space="preserve" bytes="6173">&lt;h2&gt;The default scene graphs&lt;/h2&gt;

By default, there are two different scene graphs created automatically when you start up Panda3D.  These graphs are referred to by their top nodes: &lt;b&gt;render&lt;/b&gt; and &lt;b&gt;render2d&lt;/b&gt;.

You use render most often; this is the top of the ordinary 3-D scene.  In order to put an object in the world, you will need to parent it to render (or to some node that is in turn parented to render).  

You will use render2d to render 2-D GUI elements, such as text or buttons, that you want to display onscreen; for instance, a heads-up display.  Anything parented to render2d will be rendered on top of the 3-D scene, as if it were painted on the screen glass.

The coordinate system of render2d is set up to match that of the mouse inputs: the lower-left corner of the screen is (-1, 0, -1), and the upper-right corner is (1, 0, 1).  Since this is a square coordinate system, but the screen is usually non-square, objects parented directly to render2d may appear squashed.  For this reason, Panda3D also defines a child of render2d, called &lt;b&gt;aspect2d&lt;/b&gt;, which has a scale applied to it to correct the non-square aspect ratio of render2d.  Most often, you will parent GUI elements to aspect2d rather than render2d.

Specifically, the coordinate system of aspect2d is by default scaled such that x ranges over [-ratio,ratio], and y ranges over [-1,1] where ratio is screen_size_x/screen_size_y (in the normal case of a window wider than it is tall).

As of Panda3D version 1.7.0, there is another child of render2d, called &lt;b&gt;pixel2d&lt;/b&gt;.  This is scaled in such a way that one Panda unit represents one pixel in the window.  The origin, (0, 0, 0) is in the upperleft corner of the window. The lower right corner has x and z values equal to the width and -height of the window respectively. As Panda3D uses a Z-Up Right coordinate system, the Y coordinate in the window will actually be the inverted Z coordinate in Panda.
This node is especially helpful when you want to do pixel-perfect positioning and scaling.

Finally, you may see references to one other top-level node called &lt;b&gt;hidden&lt;/b&gt;.  This is simply an ordinary node that has no rendering properties set up for it, so that things parented to hidden will not be rendered.  Older Panda3D code needed to use hidden to remove a node from the render scene graph.  However, this is no longer necessary, and its use is not recommended for new programs; the best way to remove a node from render is to call nodePath.detach[python]N[/python][cxx]_n[/cxx]ode().

&lt;h2&gt;Loading models&lt;/h2&gt;

You can load up a model with a filename path, in the [[Panda Filename Syntax]], to the model's egg or bam file.  In many examples, the filename extension is omitted; in this case, Panda will look for a file with either the .egg or .bam extension.

[python]&lt;code python&gt;
myNodePath = loader.loadModel(&quot;path/to/models/myModel.egg&quot;)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
NodePath myNodePath =
  window-&gt;load_model(framework.get_models(),&quot;path/to/models/myModel.egg&quot;);
&lt;/code&gt;[/cxx]

The first time you call &lt;code&gt;loadModel()&lt;/code&gt; for a particular model, that model is read and saved in a table in memory; on each subsequent call, the model is simply copied from the table, instead of reading the file.

The above call is appropriate for loading static models; for animated models, see [[Loading Actors and Animations]].

&lt;h2&gt;Reparenting nodes and models&lt;/h2&gt;

One of the most fundamental scene graph manipulations is changing a node's parent.  You need to do this at least once after you load a model, to put it under render for viewing:

[python]&lt;code python&gt;
myModel.reparentTo(render)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
myModel.reparent_to(window-&gt;get_render());
&lt;/code&gt;[/cxx]

And to remove it again:

[python]&lt;code python&gt;
myModel.detachNode()
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
myModel.detach_node();
&lt;/code&gt;[/cxx]

To completely remove a NodePath from the scene graph and memory call remove[python]N[/python][cxx]_n[/cxx]ode, this has the effect of emptying the node and releasing the memory taken up by the node. Use it only when you have no further use for the node:

[python]&lt;code python&gt;
myModel.removeNode()
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
myModel.remove_node();
&lt;/code&gt;[/cxx]

As you become more comfortable with scene graph operations, you may find yourself taking more and more advantage of a deeply nested scene graph, and you may start to parent your models to other nodes than just render.  Sometimes it is convenient to create an empty node for this purpose, for instance, to group several models together:

[python]&lt;code python&gt;
dummyNode = render.attachNewNode(&quot;Dummy Node Name&quot;)
myModel.reparentTo(dummyNode)
myOtherModel.reparentTo(dummyNode)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
NodePath dummyNode = window-&gt;get_render().attach_new_node(&quot;Dummy Node Name&quot;);
myModel.reparent_to(dummyNode);
myOtherModel.reparent_to(dummyNode);
&lt;/code&gt;[/cxx]

Since a node inherits its position information from its parent node, when you reparent a node in the scene graph you might inadvertently change its position in the world.  If you need to avoid this, you can use a special variant on reparentTo():

[python]&lt;code python&gt;
myModel.wrtReparentTo(newParent)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
myModel.wrt_reparent_to(newParent);
&lt;/code&gt;[/cxx]

The &quot;wrt&quot; prefix stands for &quot;with respect to&quot;.  This special method works like [func]reparent_to()[/func], except that it automatically recomputes the local transform on myModel to compensate for the change in transform under the new parent, so that the node ends up in the same position relative to the world.

Note that the computation required to perform wrtReparentTo() is a floating-point matrix computation and is therefore inherently imprecise.  This means that if you use wrtReparentTo() repeatedly, thousands of times on the same node, it may eventually accumulate enough numerical inaccuracies to introduce a slight scale on the object (for instance, a scale of 1, 1, 0.99999); if left unchecked, this scale could eventually become noticeable.

Beginners tend to overuse this method; you should not use wrtReparentTo() unless there is a real reason to use it.</text>
    </revision>
  </page>
  <page>
    <title>Searching the Scene Graph</title>
    <ns>0</ns>
    <id>1017</id>
      <sha1>e734fba7pqtrcabinew9xyok2hz4ka4</sha1>
    <revision>
      <id>7361</id>
      <timestamp>2011-10-25T18:59:11Z</timestamp>
      <contributor>
        <username>GrizzLyCRO</username>
        <id>420</id>
      </contributor>
      <comment>Added recursive search by tag example</comment>
      <text xml:space="preserve" bytes="5204">It is often useful to get a handle to a particular node deep within the scene graph, especially to get a sub-part of a model that was loaded from a single file.  There are a number of methods dedicated to finding entrenched nodes and returning the NodePaths.

First, and most useful, is the ls() command:

[python]&lt;code python&gt;
myNodePath.ls()
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
myNodePath.ls();
&lt;/code&gt;[/cxx]

This simply lists all of the children of the indicated NodePath, along with all of their children, and so on until the entire subgraph is printed out.  It also lists the transforms and [[Render Attributes]] that are on each node.  This is an especially useful command for when you're running interactively with Python; it's a good way to check that the scene graph is what you think it should be.

The two methods &lt;code&gt;find()&lt;/code&gt; and &lt;code&gt;[func]findAllMatches[/func]()&lt;/code&gt;
will return a &lt;code&gt;NodePath&lt;/code&gt; and a &lt;code&gt;NodePathCollection&lt;/code&gt; respectively. These methods require a path string as an argument. Searches can based on name or type. In its simplest form this path consists of a series of node names separated by slashes, like a directory pathname. When creating the string each component may optionally consist of one of the following special names, instead of a node name.

&lt;table&gt;
&lt;tr&gt;&lt;td width=80&gt;*&lt;/td&gt;&lt;td&gt;Matches exactly one node of any name&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;**&lt;/td&gt;&lt;td&gt;Matches any sequence of zero or more nodes&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;+typename&lt;/td&gt;&lt;td&gt;Matches any node that is or derives from the given type&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;-typename&lt;/td&gt;&lt;td&gt;Matches any node that is the given type exactly&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;=tag&lt;/td&gt;&lt;td&gt;Matches any node that has the indicated tag&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;=tag=value&lt;/td&gt;&lt;td&gt;Matches any node whose tag matches the indicated value&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

Standard filename globbing characters, such as *, ?, and [a-z] are also usable. Also the @@ special character before a node name indicates that this particular node is a stashed node. Normally, stashed nodes are not returned. @@*, by extension, means any stashed node.

The argument may also be followed with control flags. To use a control flag, add a semicolon after the argument, followed by at least one of the special flags with no extra spaces or punctuation.

&lt;table&gt;
&lt;tr&gt;&lt;td width=50&gt;-h&lt;/td&gt;&lt;td&gt;Do not return hidden nodes&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;+h&lt;/td&gt;&lt;td&gt;Return hidden nodes&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;-s&lt;/td&gt;&lt;td&gt;Do not return stashed nodes unless explicitly referenced with @@&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;+s&lt;/td&gt;&lt;td&gt;Return stashed nodes even without any explicit @@ characters&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;-i&lt;/td&gt;&lt;td&gt;Node name comparisons are not case insensitive: case must match exactly&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;+i&lt;/td&gt;&lt;td&gt;Node name comparisons are case insensitive: case is not important. This affects matches against the node name only; node type and tag strings are always case sensitive&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

The default flags are +h-s-i.

The &lt;code&gt;find()&lt;/code&gt; method searches for a single node that matches the path string given. If there are multiple matches, the method returns the shortest match. If it finds no match, it will return an empty NodePath. On the other hand, &lt;code&gt;[func]findAllMatches[/func]()&lt;/code&gt; will return all NodePaths found, shortest first.

[python]&lt;code python&gt;
myNodePath.find(&quot;&lt;Path&gt;&quot;)
myNodePath.findAllMatches(&quot;&lt;Path&gt;&quot;)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
myNodePath.find(&quot;&lt;Path&gt;&quot;);
myNodePath.find_all_matches(&quot;&lt;Path&gt;&quot;);
&lt;/code&gt;[/cxx]

Some examples:

[python]&lt;code python&gt;
myNodePath.find(&quot;house/door&quot;)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
myNodePath.find(&quot;house/door&quot;);
&lt;/code&gt;[/cxx]

This will look for a node named &quot;door&quot;, which is a child of a node named &quot;house&quot;, which is a child of the starting path.

[python]&lt;code python&gt;
myNodePath.find(&quot;**/red*&quot;)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
myNodePath.find(&quot;**/red*&quot;);
&lt;/code&gt;[/cxx]

This will look for any node anywhere in the tree (below the starting path) with a name that begins with &quot;red&quot;. More documentation about matching patterns can be found at the [http://www.panda3d.org/apiref.php?page=NodePath NodePath API reference page].

[python]&lt;code python&gt;
shipNP.findAllMatches(&quot;**/=type=weaponMount&quot;)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
shipNP.findAllMatches(&quot;**/=type=weaponMount&quot;);
&lt;/code&gt;[/cxx]

This will search myNodePath recursively using tag/value. Tag name is &quot;type&quot; and tag value is &quot;weaponMount&quot;. All matches found will be returned.

In addition there are also the methods &lt;code&gt;[func]getParent[/func]()&lt;/code&gt; and &lt;code&gt;[func]getChildren[/func]()&lt;/code&gt;. &lt;code&gt;[func]getParent[/func]()&lt;/code&gt; returns the NodePath of the parent node. &lt;code&gt;[func]getChildren[/func]()&lt;/code&gt; returns the children of the current node as a NodePathCollection[python] (which can be treated like a list, in Panda3D version 1.6.0 and above)[/python].

[python]&lt;code python&gt;
for child in myNodePath.getChildren():
  print child
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
NodePathCollection children = myNodePath.get_children();
for (int i = 0; i &lt; children.size(); ++i) {
  std::cout &lt;&lt; children[i] &lt;&lt; &quot;\n&quot;;
}
&lt;/code&gt;[/cxx]

For more information and a complete list of NodePath 
functions please see the [http://panda3d.org/apiref.php?page=NodePath API reference].</text>
    </revision>
  </page>
  <page>
    <title>Seek</title>
    <ns>0</ns>
    <id>2582</id>
      <sha1>cxne2op5qvanv98doswy7c4sbq1gkjd</sha1>
    <revision>
      <id>7694</id>
      <timestamp>2012-03-09T10:17:30Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <comment>import DirectStart for &quot;directx stuff&quot;, seriously guys?</comment>
      <text xml:space="preserve" bytes="2618">&lt;b&gt;'Seek'&lt;/b&gt; is a behavior where an AICharacter moves in the direction of a target NodePath or position until it reaches that entity.

&lt;b&gt;Video of this behavior in Panda3D :&lt;/b&gt;

{{#ev:youtube|-UMeYgZLa8Q}}

-----

&lt;b&gt;In PandAI, seek is defined as :&lt;/b&gt;
&lt;code python&gt;
aiBehaviors.seek(NodePath target, float priority)
aiBehaviors.seek(Vec3 position, float priority)
&lt;/code&gt;

&lt;b&gt;priority&lt;/b&gt; is by default set to 1.0 and is used when using two or more steering behaviors on an AICharacter.

-----

The velocity at which the AICharacter seeks is determined when you first create your AICharacter object using the AICharacter constructor.

* Note : Seek's direction is calculated only during the first instance of the call and so is more efficient than pursue, if all you want is an object to go to a point.

-----

&lt;b&gt;Here is a full program written implementing 'seek' using PandAI :&lt;/b&gt;

&lt;code python&gt;
import direct.directbase.DirectStart
from panda3d.core import *
from direct.showbase.DirectObject import DirectObject
from direct.task import Task
from direct.actor.Actor import Actor
#for Pandai
from panda3d.ai import *

class World(DirectObject):

    def __init__(self):
        base.disableMouse()
        base.cam.setPosHpr(0,0,55,0,-90,0)
        
        self.loadModels()
        self.setAI()
       
    def loadModels(self):
        # Seeker
        ralphStartPos = Vec3(-10, 0, 0)
        self.seeker = Actor(&quot;models/ralph&quot;,
                                 {&quot;run&quot;:&quot;models/ralph-run&quot;})
        self.seeker.reparentTo(render)
        self.seeker.setScale(0.5)
        self.seeker.setPos(ralphStartPos)
        # Target
        self.target = loader.loadModel(&quot;models/arrow&quot;)
        self.target.setColor(1,0,0)
        self.target.setPos(5,0,0)
        self.target.setScale(1)
        self.target.reparentTo(render)
      
    def setAI(self):
        #Creating AI World
        self.AIworld = AIWorld(render)
 
        self.AIchar = AICharacter(&quot;seeker&quot;,self.seeker, 100, 0.05, 5)
        self.AIworld.addAiChar(self.AIchar)
        self.AIbehaviors = self.AIchar.getAiBehaviors()
        
        self.AIbehaviors.seek(self.target)
        self.seeker.loop(&quot;run&quot;)

        #AI World update        
        taskMgr.add(self.AIUpdate,&quot;AIUpdate&quot;)
        
    #to update the AIWorld    
    def AIUpdate(self,task):
        self.AIworld.update()            
        return Task.cont
 
w = World()
run()

&lt;/code&gt;

-----

* &lt;b&gt;Note: To get the full working demo for this, please visit :&lt;/b&gt;

https://sites.google.com/site/etcpandai/documentation/steering-behaviors/seek/PandAISeekExample.zip?attredirects=0&amp;d=1</text>
    </revision>
  </page>
  <page>
    <title>Self-signed certificates</title>
    <ns>0</ns>
    <id>2400</id>
      <sha1>ih7oi625urhmdop5h3zsoywgh4t3bjm</sha1>
    <revision>
      <id>6241</id>
      <timestamp>2009-10-17T15:35:26Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="1216">The self-signed certificate is the simplest kind of certificate to
acquire, since it doesn't require working with any certificate
agencies.  You can generate a self-signed certificate on your own, and
you can use it to sign your p3d files.

A self-signed certificate is not as good as an authenticated
certificate, though, because there's no one to certify that you really
are who you claim to be.  The user has to take your word for it.  If
you use a self-signed certificate to sign your p3d file, the user will
be presented with a warning, and will have to go through an additional
step to approve your certificate.  We recommend you use a self-signed
certificate only for internal development, but get a normal
authenticated certificate when you're ready to make your app available
to the public.

You can use the openssl command to generate a self-signed certificate.
You probably already have openssl installed if you're running on Linux
or Mac; if you're on Windows, you can find it on the internet easily.

A sample command sequence to generate a self-signed certificate
follows:

&lt;code bash&gt;
openssl genrsa 1024 &gt; mycert.pem
openssl req -new -x509 -nodes -sha1 -days 365 -key mycert.pem &gt;&gt; mycert.pem
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>Sequences and Parallels</title>
    <ns>0</ns>
    <id>1018</id>
      <sha1>n3ds2ql4kx7u92j15hia97lvo4p4s2z</sha1>
    <revision>
      <id>5970</id>
      <timestamp>2009-07-12T21:24:15Z</timestamp>
      <contributor>
        <username>Chroipahtz</username>
        <id>297</id>
      </contributor>
      <comment>Formatting</comment>
      <text xml:space="preserve" bytes="2264">You will need to have this include statement to use Sequences and Parallels.

&lt;code python&gt;
from direct.interval.IntervalGlobal import *
&lt;/code&gt;

Sequences and Parallels can control when intervals are played. Sequences play intervals one after the other, effectively a “do in order” command. Parallels are a “do together,” playing all intervals at the same time. Both have simple formats, and every kind of interval may be used.

&lt;code python&gt;
mySequence = Sequence(myInterval1,…,myIntervaln, name=&quot;Sequence Name&quot;)
myParallel = Parallel(myInterval1,…,myIntervaln, name=&quot;Parallel Name&quot;)
&lt;/code&gt;

To add to sequences or parallels after creating them, use the &lt;code&gt;append&lt;/code&gt; method.

&lt;code python&gt;
mySequence.append(myInterval)
myParallel.append(myInterval)
&lt;/code&gt;

Sequences and Parallels may also be combined for even greater control. Also, there is a wait interval that can add a delay to Sequences. While it can be defined beforehand, it does not have to be.

&lt;code python&gt;
delay = Wait(2.5)
pandaWalkSeq = 
    Sequence(
        Parallel(pandaWalk, pandaWalkAnim), 
        delay,
        Parallel(pandaWalkBack, pandaWalkAnim), 
        Wait(1.0), 
        Func(myFunction, arg1)
    )
&lt;/code&gt;

In the above example, a wait interval is generated. After that, a Sequence is made that uses a Parallel, the defined wait interval, another Parallel, and a wait interval, and a call to the function function myFunction is generated in the Sequence. Such Sequences can get very long very quick, so it may be prudent to define the internal Parallels and Sequences before creating the master Sequence.

One can do very powerful things with Sequences and Parallels.  Examine this Sequence: 

&lt;code python&gt;
s = OnscreenImage('wav_is_playing.png')
s.reparentTo(aspect2d)
s.setTransparency(1)
fadeIn = s.colorScaleInterval(3, Vec4(1,1,1,1), Vec4(1,1,1,0))
fadeOut = s.colorScaleInterval(3, Vec4(1,1,1,0))
sound = loader.loadSfx('sound.wav')

Sequence(
         fadeIn,
         SoundInterval(sound),
         fadeOut
        ).start()

run()
&lt;/code&gt;

It fades an image in, plays a sound, waits till sounds stops and then fades the image out. Doing this conventional way would require a class to store state, a task to check timings, and produce messy code.</text>
    </revision>
  </page>
  <page>
    <title>Setting Up to Handle Events</title>
    <ns>0</ns>
    <id>1263</id>
    <redirect title="Event Handlers" />
      <sha1>4rd1g2nz18ontn7y49u97x8z640wrm3</sha1>
    <revision>
      <id>2542</id>
      <timestamp>2005-11-01T19:09:07Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <comment>Setting Up to Handle Events moved to Event Handlers</comment>
      <text xml:space="preserve" bytes="29">#REDIRECT [[Event Handlers]]
</text>
    </revision>
  </page>
  <page>
    <title>Shader Basics</title>
    <ns>0</ns>
    <id>1056</id>
      <sha1>7f1kaswujt9mj2c4q13erk97t56ql8g</sha1>
    <revision>
      <id>60539</id>
      <timestamp>2015-07-31T10:32:34Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>/* Using Shaders in Panda3D */</comment>
      <text xml:space="preserve" bytes="12371">== Overview of Shaders ==

As of version 1.7.0, Panda3D supports two shading languages: '''Cg''' and '''GLSL'''. Section assumes that you have a working knowledge of a shader language.  If not, it would be wise to read about Cg or GLSL before trying to understand how they fit into Panda3D.

Though Panda3D has used only Cg in the past, it is recommended that you create new shaders in GLSL unless you want to target DirectX as well, since the NVIDIA Cg toolkit is no longer being maintained.

There are various types of shaders, each capable of describing a different stage in the rendering process.  In the most simple case, a model simply has a ''vertex shader'', which describes how each vertex is processed, and a ''fragment shader'' (also called a ''pixel shader'' in DirectX parlance), describing how the color of each visible pixel on the model is determined.  A shader pipeline can be composed of one or more of the following types of shaders:

; Vertex shader
: The first stage of the pipeline.  It is run for each vertex on the model geometry, and is responsible for preparing the vertex data, usually by transforming the original vertex position to on-screen X, Y coordinates.
; Tessellation control (hull) shader
: Optional.  When tessellation is used, this specifies how to subdivide the tessellation patch.  GLSL only.
; Tessellation evaluation (domain) shader
: Optional.  When tessellation is used, this determines the position of the tessellated vertices.  GLSL only.
; Geometry shader
: Optional.  This is run for each ''input primitive'' (usually a triangle), and determines how the geometry is formed from the input vertices.  It may also create additional geometry.
; Fragment (pixel) shaders
: This is the last stage of the pipeline before the pixel is blended into the framebuffer, and usually the most useful one.  It determines the color of each pixel of the rendered geometry, and therefore performs tasks such as lighting and texturing.

You will often only find a vertex and fragment shader, since geometry and tessellation shaders are relatively new features that are useful only in more specific cases.

== Cg Shaders ==
=== Overview of Cg Shaders ===
A Cg shader must contain procedures named &lt;code&gt;vshader()&lt;/code&gt; and &lt;code&gt;fshader()&lt;/code&gt;; the vertex shader and fragment shader respectively. If a geometry shader is used, then it must also contain a procedure named &lt;code&gt;gshader()&lt;/code&gt;.

=== Single-File Cg Shaders ===
&lt;p&gt;To write a Cg shader in a single file, you must create a shader program that looks much like the one shown below. This example preserves position but switches the red and green channels of everything it is applied to:&lt;/p&gt;

&lt;syntaxhighlight lang=&quot;glsl&quot;&gt;//Cg

void vshader(float4 vtx_position : POSITION,
             float4 vtx_color: COLOR,
             out float4 l_position : POSITION,
             out float4 l_color0 : COLOR0,
             uniform float4x4 mat_modelproj)
{
  l_position = mul(mat_modelproj, vtx_position);
  l_color0 = vtx_color;
}

void fshader(float4 l_color0 : COLOR0,
             out float4 o_color : COLOR)
{
  o_color = float4(l_color0[1],l_color0[0], l_color0[2],l_color0[3]);
}
&lt;/syntaxhighlight&gt;

=== Multi-File Cg Shaders ===
Cg shaders can be divided into several files as well; one for the vertex shader, another for the fragment shader, and a third for the geometry shader. The procedure names are still required to be &lt;code&gt;vshader()&lt;/code&gt;, &lt;code&gt;fshader()&lt;/code&gt; and &lt;code&gt;gshader()&lt;/code&gt; in their respective shader files.

== GLSL Shaders ==
=== Overview of GLSL Shaders ===
To write a GLSL shader, you must write your vertex, pixel and geometry shaders separately, since GLSL requires the names of the entry point to all be &lt;code&gt;main()&lt;/code&gt;.

=== GLSL Example ===
This example applies the first texture of the model using the first texture coordinate set, but switches the red and blue channels around.

This is the vertex shader, named myshader.vert:
&lt;syntaxhighlight lang=&quot;glsl&quot;&gt;#version 130

// Uniform inputs
uniform mat4 p3d_ModelViewProjectionMatrix;

// Vertex inputs
in vec4 p3d_Vertex;
in vec2 p3d_MultiTexCoord0;

// Output to fragment shader
out vec2 texcoord;

void main() {
  gl_Position = p3d_ModelViewProjectionMatrix * p3d_Vertex;
  texcoord = p3d_MultiTexCoord0;
}
&lt;/syntaxhighlight&gt;

This is the fragment shader, named myshader.frag:
&lt;syntaxhighlight lang=&quot;glsl&quot;&gt;#version 130

uniform sampler2D p3d_Texture0;

// Input from vertex shader
in vec2 texcoord;

void main() {
  vec4 color = texture(p3d_Texture0, texcoord);
  gl_FragColor = color.bgra;
}
&lt;/syntaxhighlight&gt;

== Using Shaders in Panda3D ==
Shaders in Panda3D use the &lt;code&gt;Shader&lt;/code&gt; class. When a shader is loaded, an object of this class is returned. This is then applied to a node using the &lt;code&gt;set_shader&lt;/code&gt; method of the &lt;code&gt;NodePath&lt;/code&gt; class.

=== Loading a Cg Shader ===
&lt;p&gt;Loading a single-file Cg shader is done with the &lt;code&gt;Shader[::]load()&lt;/code&gt; procedure. The first parameter is the path to the shader file, and the second is the shader language, which in this case is &lt;code&gt;Shader.SL_Cg&lt;/code&gt;. The following is an example of using this procedure:&lt;/p&gt;

[python]
&lt;syntaxhighlight lang=&quot;python&quot;&gt;
from panda3d.core import Shader

myShader = Shader.load(&quot;myshader.sha&quot;, Shader.SL_Cg)
&lt;/syntaxhighlight&gt;
[/python]
[cxx]
&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
#include &quot;shader.h&quot;

PT(Shader) myShader = Shader::load(&quot;myshader.sha&quot;, Shader.SL_Cg);
&lt;/syntaxhighlight&gt;
[/cxx]

&lt;p&gt;Loading a multi-file Cg shader requires a different set of parameters for the &lt;code&gt;load()&lt;/code&gt; function; the first being the shader language, and the second, third and fourth being paths to the vertex, fragment and geometry shaders respectively.  Here is an example:&lt;/p&gt;

[python]
&lt;syntaxhighlight lang=&quot;python&quot;&gt;
myShader = Shader.load(Shader.SL_Cg, vertex=&quot;myvertexshader.sha&quot;, fragment=&quot;myfragmentshader.sha&quot;, geometry=&quot;mygeometryshader.sha&quot;)
&lt;/syntaxhighlight&gt;
[/python]
[cxx]
&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
PT(Shader) myShader = Shader::load(Shader.SL_Cg, &quot;myvertexshader.sha&quot;, &quot;myfragmentshader.sha&quot;, &quot;mygeometryshader.sha&quot;);
&lt;/syntaxhighlight&gt;
[/cxx]

=== Loading a GLSL Shader ===
In the following code sample, a GLSL shader is loaded:

[python]
&lt;syntaxhighlight lang=&quot;python&quot;&gt;
myShader = Shader.load(Shader.SL_GLSL, vertex=&quot;myshader.vert&quot;, fragment=&quot;myshader.frag&quot;, geometry=&quot;myshader.geom&quot;)
&lt;/syntaxhighlight&gt;
[/python]
[cxx]
&lt;syntaxhighlight lang=&quot;python&quot;&gt;
PT(Shader) myShader = Shader::load(Shader.SL_GLSL, &quot;myvertexshader.vert&quot;, &quot;myfragmentshader.frag&quot;, &quot;mygeometryshader.geom&quot;);
&lt;/syntaxhighlight&gt;
[/cxx]

=== Applying a Shader ===
Shaders can be applied to any &lt;code&gt;NodePath&lt;/code&gt; with the &lt;code&gt;set_shader()&lt;/code&gt; method.  Here is an example that applies a loaded shader to a model:

[python]
&lt;syntaxhighlight lang=&quot;python&quot;&gt;
myModel.set_shader(myShader)
&lt;/syntaxhighlight&gt;
[/python]
[cxx]
&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
myModel.set_shader(myShader);
&lt;/syntaxhighlight&gt;
[/cxx]

The call to &lt;code&gt;set_shader()&lt;/code&gt; causes the &lt;code&gt;NodePath&lt;/code&gt; to be rendered with the shader passed to it as a parameter. Shaders propagate down the scene graph, like any other render attribute; the node and everything beneath it will use the shader.

&lt;!-- NOTE: The following still needs renovating. --&gt;

== Fetching Data from the Panda3D Runtime ==

Each shader program contains a parameter list.  Panda3D scans the parameter list and interprets each parameter name as a request to extract data from the panda runtime.  For example, if the shader contains a parameter declaration &lt;code&gt;float3 vtx_position : POSITION&lt;/code&gt;, Panda3D will interpret that as a request for the vertex position, and it will satisfy the request. Panda3D will only allow parameter declarations that it recognizes and understands.

Panda3D will generate an error if the parameter qualifiers do not match what Panda3D is expecting.  For example, if you declare the parameter &lt;code&gt;float3 vtx_position&lt;/code&gt;, then Panda3D will be happy. If, on the other hand, you were to declare &lt;code&gt;uniform sampler2D vtx_position&lt;/code&gt;, then Panda3D would generate two separate errors: Panda3D knows that vtx_position is supposed to be a float-vector, not a texture, that it is supposed to be varying, not uniform.

Again, all parameter names must be recognized.  There is a [[List of Possible Shader Inputs|list of possible Cg shader inputs]] that shows all the valid parameter names and the data that Panda3D will supply.

== Supplying data to the Shader Manually ==

Most of the data that the shader could want can be fetched from Panda3D at runtime by using the appropriate parameter names. However, it is sometimes necessary to supply some user-provided data to the shader. For this, you need &lt;code&gt;set_shader_input()&lt;/code&gt;. Here is an example:

[python]&lt;syntaxhighlight lang=&quot;python&quot;&gt;
myModel.set_shader_input(&quot;tint&quot;, (1.0, 0.5, 0.5, 1.0));
&lt;/syntaxhighlight&gt;
[/python][cxx]
&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
myModel.set_shader_input(&quot;tint&quot;, LVector4f(1.0, 0.5, 0.5, 1.0));
&lt;/syntaxhighlight&gt;[/cxx]

The method &lt;code&gt;set_shader_input()&lt;/code&gt; stores data that can be accessed by the shader.  It is possible to store data of type &lt;code&gt;Texture&lt;/code&gt;, &lt;code&gt;NodePath&lt;/code&gt;, and any vector object.

The data that you store using &lt;code&gt;set_shader_input()&lt;/code&gt; isn't necessarily used by the shader. Instead, the values are stored in the node, but unless the shader explicitly asks for them, they will sit unused.  So the example above simply stores the vector, but it is up to the shader whether or not it is interested in a data item labeled &quot;tint&quot;.

To fetch data that was supplied using &lt;code&gt;set_shader_input()&lt;/code&gt;, the shader must use the appropriate parameter name. See the [[List of Possible Shader Inputs|list of possible Cg shader inputs]], many of which refer to the data that was stored using &lt;code&gt;set_shader_input()&lt;/code&gt;.

Shader Inputs propagate down the scene graph, and accumulate as they go. For example, if you store &lt;code&gt;set_shader_input(&quot;x&quot;, 1)&lt;/code&gt; on a node, and &lt;code&gt;set_shader_input(&quot;y&quot;, 2)&lt;/code&gt; on its child, then the child will contain both values. If you store &lt;code&gt;set_shader_input(&quot;z&quot;, 1)&lt;/code&gt; on a node, and &lt;code&gt;set_shader_input(&quot;z&quot;, 2)&lt;/code&gt; on its child, then the latter will override the former. The method &lt;code&gt;set_shader_input()&lt;/code&gt; accepts a third parameter, priority, which defaults to zero. If you store &lt;code&gt;set_shader_input(&quot;w&quot;, 1, priority=1000)&lt;/code&gt; on a node, and &lt;code&gt;set_shader_input(&quot;w&quot;, 2, priority=500)&lt;/code&gt; on the child, then the child will contain (&quot;w&quot;==1), because the priority 1000 overrides the priority 500.

== Shader Render Attributes ==

The functions &lt;code&gt;nodePath.set_shader()&lt;/code&gt; and &lt;code&gt;nodePath.set_shader_input()&lt;/code&gt; are used to apply a shader to a node in the scene graph. Internally, these functions manipulate a render attribute of class &lt;code&gt;ShaderAttrib&lt;/code&gt; on the node.

In rare occasions, it is necessary to manipulate &lt;code&gt;ShaderAttrib&lt;/code&gt; objects explicitly.[python] As an example, the code below shows how to create a &lt;code&gt;ShaderAttrib&lt;/code&gt; and apply it to a camera:

&lt;syntaxhighlight lang=&quot;python&quot;&gt;
myShaderAttrib = ShaderAttrib.make()
myShaderAttrib = myShaderAttrib.setShader(Shader.load(&quot;myshader.sha&quot;))
myShaderAttrib = myShaderAttrib.setShaderInput(&quot;tint&quot;, Vec4(1.0, 0.5, 0.5, 1.0))
base.cam.node().setInitialState(render.getState().addAttrib(myShaderAttrib))
&lt;/syntaxhighlight&gt;
[/python]
Be careful: attribs are immutable objects. So when you apply a function like &lt;code&gt;set_shader()&lt;/code&gt; or &lt;code&gt;set_shader_input()&lt;/code&gt; to a &lt;code&gt;ShaderAttrib&lt;/code&gt;, you aren't modifying the attrib. Instead, these functions work by returning a new attrib (which contains the modified data).

== Deferred Shader Compilation ==

When you create a Cg shader object, it compiles the shader, checking for syntax errors.  But it does not check whether or not your video card is powerful enough to handle the shader.  This only happens later on, when you try to render something with the shader.  In the case of GLSL shaders, all of this will only happen when the shader is first used to render something.

In the unusual event that your computer contains multiple video cards, the shader may be compiled more than once. It is possible that the compilation could succeed for one video card, and fail for the other.</text>
    </revision>
  </page>
  <page>
    <title>Shader generator</title>
    <ns>0</ns>
    <id>2364</id>
    <redirect title="The Shader Generator" />
      <sha1>i8y0oiqqflrdvxcfgixt15ksmkj3383</sha1>
    <revision>
      <id>5935</id>
      <timestamp>2009-07-11T13:56:48Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[The Shader Generator]]</comment>
      <text xml:space="preserve" bytes="34">#REDIRECT [[The Shader Generator]]</text>
    </revision>
  </page>
  <page>
    <title>Shaders</title>
    <ns>0</ns>
    <id>1059</id>
      <sha1>11uft35as8gm1x3t0eoeb8efq360dlf</sha1>
    <revision>
      <id>6121</id>
      <timestamp>2009-09-25T17:51:34Z</timestamp>
      <contributor>
        <username>MikeC</username>
        <id>281</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="2884">&lt;b&gt;What are Shaders?&lt;/b&gt;

Once upon a time, each 3D video card had a fixed list of things that it could do.  At first, the feature lists were short: the cards could draw polygons, do some basic texturing, a little alpha blending, and that was it.  As time went on, the list of features increased and increased: offscreen buffers, multisampling, hardware transform and lighting, and so forth.  Every time somebody thought of some new rendering trick they wanted to try, they had to design a new video card with the new ability.  People are creative, so soon, the list of known features exceeded 350 - this is not an exaggeration, see the OpenGL extension registry!  Each of these features corresponded to each of the hundreds of rendering tricks that people had thought of so far.  Yet, people kept designing new video card features, because their creativity for inventing new rendering tricks had not nearly been exhausted.

Eventually, somebody realized that video cards needed to be more like computers.  When you want your computer to have a new capability, you don't design a new computer.  You install a new piece of software.  Adding software gives a computer new capabilities.  If you could download new software to your video card, they reasoned, you wouldn't need design a new video card every time you thought of a new rendering trick.  You could upgrade the new feature right into the card, right when you needed it.  

And so, shaders were invented. Shaders are software for video cards. Shaders look just like computer programs, but they're executed by the video card, not the computer.  If a video card supports shaders, it can be upgraded to support almost any desired behavior.  Pretty much, the only thing that limits a shader-based video card is its speed.

&lt;b&gt;Automatic use of Shaders&lt;/b&gt;

As of version 1.5.0, Panda has several advanced rendering techniques such as per-pixel lighting, normal mapping, gloss mapping, glow mapping, HDR, bloom, and cartoon inking.  In order to make these work, Panda is quietly uploading shaders to your video card.  You don't need to write shaders to use these features, or even know much about shaders.  You just turn these features on.  To learn how to turn these features on, read about these features in their own sections of the manual. 

&lt;b&gt;Writing your own Shaders&lt;/b&gt;

If what you want to do is one of the things that Panda already supports automatically, such as per-pixel lighting, normal mapping, gloss mapping, glow mapping, HDR, bloom, or cartoon inking, you don't need to write any shaders.  Just let Panda handle it.

But if you want to do anything else --- for instance, if you wanted to do painterly rendering, or water reflections, or lens flare, or ... well, your imagination's the limit --- in that case, you need to write your own shaders.  The following sections will tell you about how to do that in Panda3D.</text>
    </revision>
  </page>
  <page>
    <title>Shaders and Coordinate Spaces</title>
    <ns>0</ns>
    <id>1720</id>
      <sha1>lp8iy0zu2navyngwelz6atydkya8571</sha1>
    <revision>
      <id>60494</id>
      <timestamp>2015-05-11T16:20:24Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <text xml:space="preserve" bytes="6586">&lt;b&gt;The Major Coordinate Spaces&lt;/b&gt;

When writing complex shaders, it is often necessary to do a lot of
coordinate system conversion.  In order to get this right, it is
important to be aware of all the different coordinate spaces that
panda uses.  You must know what &quot;space&quot; the coordinate is in.  Here
is a list of the major coordinate spaces:

&lt;i&gt;Model Space:&lt;/i&gt; If a coordinate is in model space, then it is relative
to the center of the model currently being rendered. The vertex arrays
are in model space, therefore, if you access the vertex position using
vtx_position, you have a coordinate in model space.  Model space is
z-up right-handed.

&lt;i&gt;World Space:&lt;/i&gt; If a coordinate is in world space, then it is relative
to the scene's origin. World space is z-up right-handed.

&lt;i&gt;View Space:&lt;/i&gt; If a coordinate is in view space, then it is relative
to the camera.  View space is z-up right-handed.

&lt;i&gt;API View Space:&lt;/i&gt; This coordinate space is identical to view
space, except that the axes may be flipped to match the natural
orientation of the rendering API. In the case of OpenGL, API view
space is y-up right-handed.  In the case of DirectX, API view space is
y-up left-handed.

&lt;i&gt;Clip Space:&lt;/i&gt; Panda's clip space is a coordinate system in
which (X/W, Y/W) maps to a screen pixel, and (Z/W) maps to a
depth-buffer value.  All values in this space range over [-1,1].

&lt;i&gt;API Clip Space:&lt;/i&gt; This coordinate space is identical to clip
space, except that the axes may be flipped to match the natural
orientation of the rendering API, and the numeric ranges may be
rescaled to match the needs of the rendering API. In the case of
OpenGL, the (Z/W) values range from [-1, 1].  In the case of
DirectX, the (Z/W) values range from [0,1].

In OpenGL, &quot;clip space&quot; and &quot;API clip space&quot; are equivalent.

&lt;b&gt;Supplying Translation Matrices to a Shader&lt;/b&gt;

You can use a shader parameter named &quot;trans_x_to_y&quot; to automatically
obtain a matrix that converts any coordinate system to any other.
The words x and y can be &quot;model,&quot; &quot;world,&quot; &quot;view,&quot; &quot;apiview,&quot;
&quot;clip,&quot; or &quot;apiclip.&quot; Using this notation, you can build
up almost any transform matrix that you might need.
Here is a short list of popular matrices that can be
recreated using this syntax.  Of course, this isn't even close to
exhaustive: there are seven keywords, so there are 7x7 possible matrices,
of which 7 are the identity matrix.

&lt;table width=&quot;100%&quot;&gt;
&lt;tr&gt;&lt;td&gt;Desired Matrix&lt;/td&gt;&lt;td&gt;Syntax&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;The Modelview Matrix&lt;/td&gt;       &lt;td&gt;trans_model_to_apiview&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;The Projection Matrix&lt;/td&gt;      &lt;td&gt;trans_apiview_to_apiclip&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;the DirectX world matrix&lt;/td&gt;   &lt;td&gt;trans_model_to_world&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;the DirectX view matrix&lt;/td&gt;    &lt;td&gt;trans_world_to_apiview&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;gsg.getCameraTransform()&lt;/td&gt;   &lt;td&gt;trans_view_to_world&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;gsg.getWorldTransform()&lt;/td&gt;    &lt;td&gt;trans_world_to_view&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;gsg.getExternalTransform()&lt;/td&gt; &lt;td&gt;trans_model_to_view&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;gsg.getInternalTransform()&lt;/td&gt; &lt;td&gt;trans_model_to_apiview&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;gsg.getCsTransform()&lt;/td&gt;       &lt;td&gt;trans_view_to_apiview&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;gsg.getInvCsTransform()&lt;/td&gt;    &lt;td&gt;trans_apiview_to_view&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&lt;b&gt;A note about GLSL inputs&lt;/b&gt;

The p3d_ModelViewMatrix and p3d_ProjectionMatrix by default transform to and from &quot;apiview&quot; space, in order to match the behavior of the equivalent gl_-prefixed inputs from earlier GLSL versions.  Panda3D traditionally uses a right-handed Y-up coordinate space for all OpenGL operations because some OpenGL fixed-function features rely on this space in order to produce the correct results.

However, if you develop a largely shader-based application and/or don't really use features like fixed-function sphere mapping, you may choose to disable this conversion to Y-up space.  This will define &quot;apiview&quot; space to be equivalent to &quot;view&quot; space, which simplifies many things, and will reduce overhead due to unnecessary coordinate space conversion.

This is possible in Panda3D 1.9.1 and above, by putting &lt;code&gt;gl-coordinate-system default&lt;/code&gt; in your Config.prc file.

&lt;b&gt;Recommendation: Don't use API View Space or API Clip Space&lt;/b&gt;

The coordinate systems &quot;API View Space&quot; and &quot;API Clip Space&quot; are not
very useful.  The fact that their behavior changes from one rendering
API to the next makes them extremely hard to work with.  Of course,
you have to use the composed modelview/projection matrix to transform
your vertices, and in doing so, you are implicitly using these spaces.
But aside from that, it is strongly recommended that you not use
these spaces for anything else.

&lt;b&gt;Model_of_x, View_of_x, Clip_of_x&lt;/b&gt;

When you use the word &quot;model&quot; in a trans directive, you implicitly
mean &quot;the model currently being rendered.&quot;  But you can make any 
nodepath accessible to the shader subsystem using &lt;code&gt;[func]setShaderInput[/func]&lt;/code&gt;:

[python]&lt;code python&gt;
myhouse = loader.loadModel(&quot;myhouse&quot;)
render.setShaderInput(&quot;myhouse&quot;, myhouse)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
NodePath myhouse = window-&gt;load_model(framework.get_models(), &quot;myhouse&quot;);
window-&gt;get_render().set_shader_input(&quot;myhouse&quot;, myhouse);
&lt;/code&gt;[/cxx]

Then, in the shader, you can convert coordinates to or from the
model-space of this particular nodepath:

&lt;code cg&gt;
uniform float4x4 trans_world_to_model_of_myhouse
&lt;/code&gt;

or, use the syntactic shorthand:

&lt;code cg&gt;
uniform float4x4 trans_world_to_myhouse
&lt;/code&gt;

Likewise, you can create a camera and pass it into the shader
subsystem.  This is particularly useful when doing shadow mapping:

[python]&lt;code python&gt;
render.setShaderInput(&quot;shadowcam&quot;, shadowcam)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
render.set_shader_input(&quot;shadowcam&quot;, shadowcam);
&lt;/code&gt;[/cxx]

Now you can transform vertices into the clip-space of the given
camera using this notation:

&lt;code cg&gt;
uniform float4x4 trans_model_to_clip_of_shadowcam
&lt;/code&gt;

If you transform your model's vertices from model space into the
clip space of a shadow camera, the resulting
(X/W,Y/W) values can be used as texture coordinates to projectively
texture the shadow map onto the scene (after rescaling them), and
the (Z/W) value can be compared to the value stored in the depth
map (again, after rescaling it).

Panda does support the notation &quot;trans_x_to_apiclip_of_y&quot;, but again,
our recommendation is not to use it.

You can transform a vertex to the view space of an alternate camera,
using &quot;view of x.&quot;  In fact, this is exactly identical to &quot;model of
x,&quot; but it's probably good form to use &quot;view of x&quot; when x is a camera.</text>
    </revision>
  </page>
  <page>
    <title>ShowBase</title>
    <ns>0</ns>
    <id>2259</id>
      <sha1>7h90rh45c13rvmi35fw2vfoj1kx5hu5</sha1>
    <revision>
      <id>60324</id>
      <timestamp>2014-12-30T14:02:54Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="2365">[python]
== Overview ==
&lt;p&gt;If you are already up to speed with Python, the following code may look like a black box:&lt;/p&gt;

&lt;code lang=&quot;python&quot;&gt;
from direct.showbase.ShowBase import ShowBase

base = ShowBase()
base.run()
&lt;/code&gt;

The class [http://www.panda3d.org/reference/python/classshowbase_1_1ShowBase_1_1ShowBase.php ShowBase] inherits from DirectObject. Under Linux, the relevant file can be found in:

&lt;code&gt;/usr/share/panda3d/direct/showbase/&lt;/code&gt;

On Windows, the code is (by default) located in:

&lt;code&gt;C:\Panda3D-1.X.X\direct\showbase&lt;/code&gt;

An important item created meanwhile is a base task manager as &lt;code&gt;taskMgr&lt;/code&gt;. The function &lt;code&gt;run()&lt;/code&gt; is in fact a single call to launch this task manager. 

== Global Variables with __builtin__ ==
Some key variables used in all Panda3D scripts are actually attributes of the ShowBase instance. Here is the relevant code making these attribute global in scope:

&lt;code lang=&quot;python&quot;&gt;
__builtin__.base = self
__builtin__.render2d = self.render2d
__builtin__.aspect2d = self.aspect2d
__builtin__.pixel2d = self.pixel2d
__builtin__.render = self.render
__builtin__.hidden = self.hidden
__builtin__.camera = self.camera
__builtin__.loader = self.loader
__builtin__.taskMgr = self.taskMgr
__builtin__.jobMgr = self.jobMgr
__builtin__.eventMgr = self.eventMgr
__builtin__.messenger = self.messenger
__builtin__.bboard = self.bboard
__builtin__.run = self.run
__builtin__.ostream = Notify.out()
__builtin__.directNotify = directNotify
__builtin__.giveNotify = giveNotify
__builtin__.globalClock = globalClock
__builtin__.vfs = vfs
__builtin__.cpMgr = ConfigPageManager.getGlobalPtr()
__builtin__.cvMgr = ConfigVariableManager.getGlobalPtr()
__builtin__.pandaSystem = PandaSystem.getGlobalPtr()
__builtin__.wantUberdog = base.config.GetBool('want-uberdog', 1)
&lt;/code&gt;

This is where the commonly used objects &lt;code&gt;base&lt;/code&gt;, &lt;code&gt;render&lt;/code&gt;, &lt;code&gt;render2d&lt;/code&gt;, &lt;code&gt;camera&lt;/code&gt;, &lt;code&gt;messenger&lt;/code&gt;, and &lt;code&gt;taskMgr&lt;/code&gt; are created. There are more such variables added to &lt;code&gt;__builtin__&lt;/code&gt;. Consult the code if you want to find them all. 

Note that this way of exposing these attributes make them available globally even though these will not be returned by a call to the built-in function &lt;code&gt;dir()&lt;/code&gt;.
[/python]
[cxx]
&lt;p&gt;This section does not apply to C++.&lt;/p&gt;
[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Signing your p3d files</title>
    <ns>0</ns>
    <id>2403</id>
      <sha1>ot1h9pe2gxkgdp8wx7ti5qskyywo80j</sha1>
    <revision>
      <id>6668</id>
      <timestamp>2010-02-09T09:56:49Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <text xml:space="preserve" bytes="1310">Once you have a certificate, you can use it to sign any of your p3d
files.  Be sure the certificate is in pem format; use the openssl
command to convert it to pem format first if you need to.

The easiest way to sign a p3d file is to specify the -S parameter to
packp3d at the time you generate it:

&lt;code bash&gt;
packp3d -S mycert.pem -o myapp.p3d -d c:/myapp
&lt;/code&gt;

The above is the appropriate command to use if your public key and
private key are combined in the same file.  If they are separate, you
can specify both files with &quot;-S mypublic.pem,,myprivate.pem&quot;.  (Note
the double comma; it is necessary.)  If you also have a certificate
chain file, then you should specify all three files: &quot;-S
mypublic.pem,mychain.pem,myprivate.pem&quot;.

It is also possible to sign a p3d file after it has been generated,
with the multify command:

&lt;code bash&gt;
multify -S mycert.pem -uvf myapp.p3d
multify -S mycert.pem,mychain.pem,myprivate.pem -uvf myapp.p3d
&lt;/code&gt;

You can add multiple signatures to a p3d file.  If the user has
already approved any of the certificates used to sign a p3d file, then
that p3d file will be considered automatically approved.  If the user
has approved none of the certificates, then the first one (and only
the first one) used to sign the file will be presented to the user for
approval.</text>
    </revision>
  </page>
  <page>
    <title>Simple Environment Mapping</title>
    <ns>0</ns>
    <id>1201</id>
      <sha1>8s5veqx1hu2imeo2x17bm3qfqub4i13</sha1>
    <revision>
      <id>7639</id>
      <timestamp>2012-03-08T18:05:28Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="6247">There is a classic technique in real-time computer graphics for making
objects appear shiny or reflective.  It's called &lt;b&gt;environment
mapping&lt;/b&gt; or sometimes &lt;b&gt;reflection mapping&lt;/b&gt; or, in this case,
&lt;b&gt;sphere mapping&lt;/b&gt;.

Environment mapping is not ray tracing.  But it's a cheesy way to get
a similar effect.  The idea for both of them is that, mathematically,
it's easy to calculate the direction from which a ray of light must
have been coming before it bounced off a particular point of a shiny
object and entered your eye.  If the renderer were using ray tracing,
it would follow this ray, for each point on your shiny object,
backwards from your eye, and determine what object in the environment
the ray came from; and that's what you'd see in the reflection.

Ray tracing is still too computation-intensive to be done in real
time.  But a reflection vector is easy to calculate per-vertex, and if
we could turn a reflection vector into a (u, v) texture coordinate
pair, the graphics hardware is particularly good at looking up the
color in a texture image that corresponds to that (u, v) pair.  So all
we need is an image that shows the objects in our environment.

In &lt;b&gt;sphere mapping&lt;/b&gt;, the 3-D reflection vector is turned into a
2-D texture coordinate pair by mathematically applying a spherical
distortion.  This means the environment map should be a view of the
world as seen through a 360-degree fisheye lens, or as reflected in a
shiny ball like a holiday ornament.  You can see why it is called
sphere mapping.

[[Image:Streetscene env.jpg|bvw-f2004--streetscene as a sphere map]]

Panda3D can generate sphere maps for you.  The above sphere map was
generated with the following code:

&lt;code python&gt;
scene = loader.loadModel('bvw-f2004--streetscene/street-scene.egg')
scene.reparentTo(render)
scene.setZ(-2)
base.saveSphereMap('streetscene_env.jpg', size = 256)
&lt;/code&gt; 

The idea is simply to put the camera in the middle of your
environment, approximately where your shiny object would be.  Then
just call &lt;code&gt;base.saveSphereMap()&lt;/code&gt;, and a suitable sphere map image
will be generated and written to disk for you.  Note that this feature is new as of Panda3D 1.1.

Now you can apply the environment map to just about any object you
like.  For instance, the teapot:

&lt;code python&gt;
tex = loader.loadTexture('streetscene_env.jpg')
teapot.setTexGen(TextureStage.getDefault(), TexGenAttrib.MEyeSphereMap)
teapot.setTexture(tex)
&lt;/code&gt; 

[[Image:Chrome teapot.jpg|The teapot with sphere map]]

In this example, you can see that the key to sphere mapping in Panda
is to set the [[Automatic Texture Coordinates|TexGen mode]] to
MEyeSphereMap.  This mode computes a spherical (u, v) texture
coordinate pair based on the reflection vector for each vertex of the
teapot.  In order for this to work, your model must have normals
defined for all its vertices (the teapot has good normals).

Shiny teapots are one thing, but it would be nice to make something
like, say, a car look shiny.  We could just do exactly the same thing
as above, but our car has a texture map already.  If we just replace
the texture map with the environment map we'll end up with a chrome
car:

&lt;code python&gt;
car = loader.loadModel('bvw-f2004--carnsx/carnsx.egg')
tex = loader.loadTexture('streetscene_env.jpg')
car.setTexGen(TextureStage.getDefault(), TexGenAttrib.MEyeSphereMap)
car.setTexture(tex, 1)
&lt;/code&gt; 

[[Image:Chrome car.jpg|The car with sphere map]]

That looks pretty silly.  So we'd really prefer to use [[Multitexture Introduction|multitexture]]
to apply both the car's regular texture, and layer a little bit of
shine on top of that.  We'll use [[Texture Blend Modes|Add mode]] to
add the environment map to the existing color, which is appropriate
for a shiny highlight on an object.

In order to use Add mode without oversaturating the colors, we need to
darken the environment map substantially.  We could use any image
processing program to do this; for this example, we'll use Panda3D's
&lt;code&gt;image-trans&lt;/code&gt; utility:

&lt;pre class=&quot;codeblock&quot;&gt;
image-trans -cscale 0.2 -o streetscene_env_dark.jpg streetscene_env.jpg
&lt;/pre&gt; 

So the new map looks like this:

[[Image:Streetscene env dark.jpg|The darkened environment map]]

While we're fixing things up, let's move the wheels to a different
node, so we can assign the shine just to the metal and glass body of
the car:

&lt;code python&gt;
car = loader.loadModel('bvw-f2004--carnsx/carnsx.egg')
body = car.find('**/body')
body.findAllMatches('**/FL_wheel*').reparentTo(car)
&lt;/code&gt; 

And now the shine is applied like this:

&lt;code python&gt;
tex = loader.loadTexture('streetscene_env_dark.jpg')
ts = TextureStage('env')
ts.setMode(TextureStage.MAdd)
body.setTexGen(ts, TexGenAttrib.MEyeSphereMap)
body.setTexture(ts, tex)
&lt;/code&gt; 

[[Image:Shiny car.jpg|The car with color and shine together]]

Note that the shiny highlights are now quite subtle, but still
compelling, especially when you see the car move.

The sphere map technique isn't perfect.  The biggest problem with it
is that you have to prepare it ahead of time, which means you have to
know exactly what will be reflected in your shiny objects--it's
impossible for an object to reflect a dynamic object (for instance, an
adjacent car).

Another problem is that the point-of-view is baked into the sphere
map, so that if the camera were to swing around to view the car from
the other side, the things you could see in the reflection would still
be the objects behind the camera on this side.

Both of these problems can be solved by [[Cube Maps|cube mapping]],
which is a more advanced technique for, among other things,
applying environment maps.  However, cube maps aren't always ideal;
very often, the venerable sphere map really is the best choice.

It is rare that an application presents a closeup view of a smooth,
round mirrored object in which you can see reflections clearly, like
the teapot example above; usually, reflections are just a subtle
glinting on the surface, like the car.  In these cases the sphere map
is ideal, since it is not so important exactly &lt;i&gt;what&lt;/i&gt; the
reflections are, but simply that there &lt;i&gt;are&lt;/i&gt; reflections.  And
the sphere map is the easiest and fastest way to render reflections.</text>
    </revision>
  </page>
  <page>
    <title>Simple FSM Usage</title>
    <ns>0</ns>
    <id>1714</id>
      <sha1>j3c84z3v9t0bqpvox6h7ygtlgvbe3v5</sha1>
    <revision>
      <id>7320</id>
      <timestamp>2011-09-13T16:47:59Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="5700">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

[python]
&lt;p&gt;A Panda3D FSM is implemented by defining a new Python class which inherits from the class direct.fsm.FSM.FSM (normally imported as simply FSM), and defining the appropriate enter and exit methods on the class.&lt;/p&gt;

&lt;p&gt;FSM states are represented by name strings, which should not
contain spaces or punctuation marks; by Panda3D convention, state
names should begin with a capital letter.  An FSM is always in exactly
one state a time; the name of the current state in stored in
&lt;code&gt;fsm.state&lt;/code&gt;.  When it transitions from one state to
another, it first calls &lt;code&gt;exitOldState()&lt;/code&gt;, and then it calls
&lt;code&gt;enterNewState()&lt;/code&gt;, where OldState is the name of the
previous state, and NewState is the name of the state it is entering.
While it is making this transition, the FSM is not technically in
either state, and &lt;code&gt;fsm.state&lt;/code&gt; will be None--but you can
find both old and new state names in &lt;code&gt;fsm.oldState&lt;/code&gt; and
&lt;code&gt;fsm.newState&lt;/code&gt;, respectively.&lt;/p&gt;

&lt;p&gt;To define a possible state for an FSM, you only need to define an
&lt;code&gt;enterStateName()&lt;/code&gt; and/or &lt;code&gt;exitStateName()&lt;/code&gt;
method on your class, where StateName is the name of the state you
would like to define.  The &lt;code&gt;enterStateName()&lt;/code&gt; method should
perform all the necessary action for entering your new state, and the
corresponding &lt;code&gt;exitStateName()&lt;/code&gt; method should generally
undo everything that was done in &lt;code&gt;enterStateName()&lt;/code&gt;, so
that the world is returned to a neutral state.&lt;/p&gt;

&lt;p&gt;An FSM starts and finishes in the state named &quot;Off&quot;.  When the FSM
is created, it is already in &quot;Off&quot;; and when you destroy it (by
calling &lt;code&gt;fsm.cleanup()&lt;/code&gt;), it automatically transitions back
to &quot;Off&quot;.&lt;/p&gt;

&lt;p&gt;To request an FSM to transition explicitly to a new state, use the
call &lt;code&gt;fsm.request('StateName')&lt;/code&gt;, where StateName is the
state you would like it to transition to.&lt;/p&gt;

== Arguments to enterStateName methods ==

&lt;p&gt;Normally, both &lt;code&gt;enterStateName()&lt;/code&gt; and
&lt;code&gt;exitStateName()&lt;/code&gt; take no arguments (other than self).
However, if your FSM requires some information before it can
transition to a particular state, you can define any arguments you
like to the enterStateName method for that state; these arguments
should be passed in to the &lt;code&gt;request()&lt;/code&gt; call, following the
state name.&lt;/p&gt;

&lt;code python&gt;
from direct.fsm.FSM import FSM

class AvatarFSM(FSM):

    def enterWalk(self, speed, doorMask):
        avatar.setPlayRate(speed, 'walk')
        avatar.loop('walk')
        footstepsSound.play()
        enableDoorCollisions(doorMask)
        
    def exitWalk(self):
        avatar.stop()
        footstepsSound.stop()
        disableDoorCollisions()

myfsm = AvatarFSM('myAvatar')
myfsm.request('Walk', 1.0, BitMask32.bit(2))
&lt;/code&gt;

&lt;p&gt;Note that the exitStateName method must always take no arguments.&lt;/p&gt;

== Allowed and disallowed state transitions ==

&lt;p&gt;By default, every state transition request is allowed: the call
&lt;code&gt;fsm.request('StateName')&lt;/code&gt; will always succeed, and the the
FSM will be left in the new state.  You may wish to make your FSM more
robust by disallowing certain transitions that you don't want to
happen.&lt;/p&gt;

&lt;p&gt;For instance, consider the example FSM described previously, which
had the following state diagram:&lt;/p&gt;

&lt;center&gt;&lt;table style=&quot;border-collapse: separate; border-spacing: 1pt 0pt&quot;&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;big&gt;&amp;#8599;&lt;/big&gt;&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding: 5pt&quot;&gt;
Walk2Swim
&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;big&gt;&amp;#8600;&lt;/big&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding: 5pt&quot;&gt;
Walk
&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding: 5pt&quot;&gt;
Swim
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;big&gt;&amp;rarr;&lt;/big&gt;&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding: 5pt&quot;&gt;
Drowning
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;big&gt;&amp;#8598;&lt;/big&gt;&lt;/td&gt;
&lt;td style=&quot;border: 1px solid black; background: #c1beea; padding: 5pt&quot;&gt;
Swim2Walk
&lt;/td&gt;
&lt;td style=&quot;text-align: center&quot;&gt;&lt;big&gt;&amp;#8601;&lt;/big&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;

&lt;p&gt;In this diagram, the arrows represent legal transitions.  It is
legal to transition from 'Walk' to 'Walk2Swim', but not from 'Walk' to
'Swim2Walk'.  If you were to request the FSM to enter state
'Swim2Walk' while it is currently in state 'Walk', that's a bug; you
might prefer to have the FSM throw an exception, so you can find this
bug.&lt;/p&gt;

&lt;p&gt;To enforce this, you can store &lt;code&gt;self.defaultTransitions&lt;/code&gt;
in the FSM's &lt;code&gt;__init__()&lt;/code&gt; method.  This should be a map of
allowed transitions from each state.  That is, each key of the map is
a state name; for that key, the value is a list of allowed transitions
from the indicated state.  Any transition not listed in
defaultTransitions is considered invalid.  For example:&lt;/p&gt;

&lt;code python&gt;
class AvatarFSM(FSM):

    def __init__(self):
        FSM.__init__(self, 'myAvatar')
        self.defaultTransitions = {
            'Walk' : [ 'Walk2Swim' ],
            'Walk2Swim' : [ 'Swim' ],
            'Swim' : [ 'Swim2Walk', 'Drowning' ],
            'Swim2Walk' : [ 'Walk' ],
            'Drowning' : [ ],
            }
&lt;/code&gt;

&lt;p&gt;If you do not assign anything to &lt;code&gt;self.defaultTransitions()&lt;/code&gt;, then all
transitions are legal.  However, if you &lt;em&gt;do&lt;/em&gt; assign a map like
the above, then requesting a transition that is not listed in the map
will raise the exception &lt;code&gt;FSM.RequestDenied&lt;/code&gt;.&lt;/p&gt;
[/python]
[cxx]
&lt;p&gt;This section does not apply to C++ users.&lt;/p&gt;
[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Simple Texture Replacement</title>
    <ns>0</ns>
    <id>1020</id>
      <sha1>stbglrebxssj23lw41cj6vu951yhz65</sha1>
    <revision>
      <id>7634</id>
      <timestamp>2012-03-08T17:56:54Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="3798">Although usually you will load and display models that are already textured, you can also apply or replace a texture image on a model at runtime.  To do this, you must first get a handle to the texture, for instance by loading it directly:

&lt;code python&gt;
myTexture = loader.loadTexture(&quot;myTexture.png&quot;)
&lt;/code&gt;

The above loadTexture() call will search along the current model-path for the named image file (in this example, a file named &quot;myTexture.png&quot;).  If the texture is not found or cannot be read for some reason, None is returned.

Once you have a texture, you can apply it to a model with the &lt;code&gt;setTexture() &lt;/code&gt; call.  For instance, suppose you used the CardMaker class to generate a plain white card:

&lt;code python&gt;
cm = CardMaker('card')
card = render.attachNewNode(cm.generate())
&lt;/code&gt;

Then you can load up a texture and apply it to the card like this:

&lt;code python&gt;
tex = loader.loadTexture('maps/noise.rgb')
card.setTexture(tex)
&lt;/code&gt;

(Note that it is not necessary to use the override parameter to the setTexture() call--that is, you do not need to do card.setTexture(tex, 1)--because in this case, the card does not already have any other texture applied to it, so your texture will be visible even without the override.)

In order for this to work, the model you apply it to must already have &lt;b&gt;texture coordinates&lt;/b&gt; defined (see [[Simple Texturing]]).  As it happens, the CardMaker generates texture coordinates by default when it generates a card, so no problem there.

You can also use &lt;code&gt;setTexture()&lt;/code&gt; to replace the texture on an already-textured model.  In this case, you must specify a second parameter to setTexture, which is the same optional Panda override parameter you can specify on any kind of Panda state change.  Normally, you simply pass 1 as the second parameter to setTexture().  Without this override, the texture that is assigned directly at the Geom level will have precedence over the state change you make at the model node, and the texture change won't be made.

For instance, to change the appearance of smiley:

&lt;code python&gt;
smiley = loader.loadModel('smiley.egg')
smiley.reparentTo(render)
tex = loader.loadTexture('maps/noise.rgb')
smiley.setTexture(tex, 1)
&lt;/code&gt;

[[Image:Texture smiley noise.png|Smiley with noise.egg applied]]

Often, you want to replace the texture on just one piece of a model, rather than setting the texture on every element.  To do this, you simply get a NodePath handle to the piece or pieces of the model that you want to change, as described in the section [[Manipulating a Piece of a Model]], and make the &lt;code&gt;setTexture()&lt;/code&gt; call on those NodePaths.

For instance, this car model has multiple textures available in different colors:

[[Image:Car red.png|Description]]

For the most part, this car was painted with one big texture image, which looks like this:

[[Image:Carnsx.png|Description]]

But we also have a blue version of the same texture image:

[[Image:Carnsx blue.png|Description]]

Although it is tempting to use setTexture() to assign the blue texture to the whole car, that would also assign the blue texture to the car's tires, which need to use a different texture map.  So instead, we apply the blue texture just to the pieces that we want to change:

&lt;code python&gt;
car = loader.loadModel('bvw-f2004--carnsx/carnsx.egg')
blue = loader.loadTexture('bvw-f2004--carnsx/carnsx-blue.png')
car.find('**/body/body').setTexture(blue, 1)
car.find('**/body/polySurface1').setTexture(blue, 1)
car.find('**/body/polySurface2').setTexture(blue, 1)
&lt;/code&gt;

And the result is this:

[[Image:Car with blue.png|Description]]

If you are interested in changing the image of a texture during program execution, say to adjust some of its pixels, see [[Creating New Textures from Scratch]].</text>
    </revision>
  </page>
  <page>
    <title>Simple Texturing</title>
    <ns>0</ns>
    <id>1171</id>
      <sha1>s08rxmvpr169gbfef3i981t2hod1617</sha1>
    <revision>
      <id>6445</id>
      <timestamp>2009-12-26T23:41:36Z</timestamp>
      <contributor>
        <username>Gogg</username>
        <id>389</id>
      </contributor>
      <text xml:space="preserve" bytes="2835">A &lt;b&gt;texture map&lt;/b&gt; or &lt;b&gt;texture image&lt;/b&gt; is a two-dimensional image file, like a JPEG or a Windows BMP file, that is used to apply color to a 3-D model.  It is called a &quot;texture&quot; because one of the earliest uses of this technique was to apply an interesting texture to walls and floors that would otherwise be one flat, plastic-looking color.  Nowadays texturing is so common in 3-D applications that it is often the only thing used to apply color to models--without texture maps, many models would simply be white.

There are a vast array of rendering effects that can be achieved with different variants on texturing.  Before you can learn about them, it is important to understand the basics of texturing first.

In simple texturing--by far the most common form--you can think of the texture map as a layer of paint that is applied to the model.  In order for the graphics hardware to know in what direction the paint should be applied, the model must have been created with &lt;b&gt;texture coordinates&lt;/b&gt;--a special (u, v) coordinate pair that is associated with each vertex of your model.  Each vertex's (u, v) texture coordinates place the vertex at a particular point within the texture map, in the same way that the vertex's (x, y, z) coordinates place the vertex at a particular point in 3-D space.

These texture coordinates are sometimes called &lt;b&gt;uv's&lt;/b&gt; because of the (u, v) name of the coordinate pair.  Almost any modeling package that you might use to create a model can create texture coordinates at the same time, and many do it without even asking.

By convention, every texture map is assigned a (u, v) coordinate range such that the u coordinate ranges from 0 to 1 from left to right, and the v coordinate ranges from 0 to 1 from bottom to top.  This means that the bottom-left corner of the texture is at coordinate (0, 0), and the top-right corner is at (1, 1).  For instance, take a look at some typical texture maps:

[[Image:Texture uvs.png|The assignment of (u, v) values to texture images]]

It is the (u, v) texture coordinates that you assign to the vertices that determine how the texture map will be applied to your model.  When each triangle of your model is drawn, it is drawn with the colors from your texture map that fall within the same triangle of vertices in (u, v) texture map space.  For instance, the sample smiley.egg model that ships with Panda has its vertices defined such that the &lt;i&gt;u&lt;/i&gt; coordinate increases from 0 to 1 around its diameter, and the &lt;i&gt;v&lt;/i&gt; coordinate increases from 0 at the bottom to 1 at the top.  This causes the texture image to be wrapped horizontally around the sphere:

[[Image:Texture smiley.png|The assignment of (u, v) values to vertices]]

Note that the (u, v) range for a texture image is always the same, 0 to 1, regardless of the size of the texture.</text>
    </revision>
  </page>
  <page>
    <title>Simulating the Physics World</title>
    <ns>0</ns>
    <id>2286</id>
      <sha1>94suaf2we7mmvryw36o4641biza4r8t</sha1>
    <revision>
      <id>7686</id>
      <timestamp>2012-03-09T09:48:44Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>new import system</comment>
      <text xml:space="preserve" bytes="5480">&lt;h2&gt;Simulating the physics scene&lt;/h2&gt;
Now, we've only had some theory so far, but haven't seen any simulation yet. To simulate, we will need to keep calling the &lt;code&gt;[func]quickStep[/func](stepSize)&lt;/code&gt; function on the OdeWorld instance. stepSize is how much time should be simulated in one step. To get the most stable simulation, it is recommended that the stepSize be kept constant.

The problem with using the delta time of a task to step the simulation is that the time between tasks might not be consistent. To get around this, a deltaTime accumulator is used to figure out how many steps must be taken. When a step is performed, the world is iterated a few times, you can specify how much times the world is being iterated by calling the &lt;code&gt;[func]setQuickStepNumIterations[/func](num)&lt;/code&gt; function on the OdeWorld instance.

Here's a small example showing a simple simulation showing an iron ball falling from a ridge:
[python]
&lt;code python&gt;from direct.directbase import DirectStart
from panda3d.ode import OdeWorld, OdeBody, OdeMass
from panda3d.core import Quat

# Load the cube where the ball will fall from
cube = loader.loadModel(&quot;box.egg&quot;)
cube.reparentTo(render)
cube.setColor(0.2, 0, 0.7)
cube.setScale(20)

# Load the smiley model which will act as our iron ball
sphere = loader.loadModel(&quot;smiley.egg&quot;)
sphere.reparentTo(render)
sphere.setPos(10, 1, 21)
sphere.setColor(0.7, 0.4, 0.4)

# Setup our physics world and the body
world = OdeWorld()
world.setGravity(0, 0, -9.81)
body = OdeBody(world)
M = OdeMass()
M.setSphere(7874, 1.0)
body.setMass(M)
body.setPosition(sphere.getPos(render))
body.setQuaternion(sphere.getQuat(render))

# Set the camera position
base.disableMouse()
base.camera.setPos(80, -20, 40)
base.camera.lookAt(0, 0, 10)

# Create an accumulator to track the time since the sim
# has been running
deltaTimeAccumulator = 0.0
# This stepSize makes the simulation run at 90 frames per second
stepSize = 1.0 / 90.0

# The task for our simulation
def simulationTask(task):
  global deltaTimeAccumulator
  # Set the force on the body to push it off the ridge
  body.setForce(0, min(task.time**4 * 500000 - 500000, 0), 0)
  # Add the deltaTime for the task to the accumulator
  deltaTimeAccumulator += globalClock.getDt()
  while deltaTimeAccumulator &gt; stepSize:
    # Remove a stepSize from the accumulator until
    # the accumulated time is less than the stepsize
    deltaTimeAccumulator -= stepSize
    # Step the simulation
    world.quickStep(stepSize)
  # set the new positions
  sphere.setPosQuat(render, body.getPosition(), Quat(body.getQuaternion()))
  return task.cont

taskMgr.doMethodLater(1.0, simulationTask, &quot;Physics Simulation&quot;)

run()&lt;/code&gt;
[/python]
[cxx]
&lt;code cxx&gt;// To keep the C++ samples short, we assume a running Panda
// environment, with a &quot;framework&quot;, &quot;window&quot;, &quot;camera&quot; and &quot;taskMgr&quot; variables
// in the global scope. Likewise, only the includes relevant to this chapter
// are shown. Check the beginning of the manual for a tutorial on making a
// full Panda3D C++ app.
// Sample entry point: simulation()

#include &quot;odeWorld.h&quot;
#include &quot;odeBody.h&quot;
#include &quot;odeMass.h&quot;

OdeBody *body;
OdeWorld world;
NodePath sphere;
PT(ClockObject) globalClock = ClockObject::get_global_clock();

// Create an accumulator to track the time since the sim
// has been running
float deltaTimeAccumulator = 0.0f;

// This stepSize makes the simulation run at 90 frames per second
float stepSize = 1.0f / 90.0f;

AsyncTask::DoneStatus simulationTask (GenericAsyncTask* task, void* data);

void simulation(){
  // Load the cube where the ball will fall from
  NodePath cube window-&gt;load_model(framework.get_models(), &quot;models/box&quot;);
  cube.reparent_to(window-&gt;get_render());
  cube.set_scale(0.25, 0.25, 0.25);
  cube.set_pos(0, 0, 0);

  // Load the smiley model which will act as our iron ball
  sphere = window-&gt;load_model(framework.get_models(), &quot;models/smiley&quot;);
  sphere.reparent_to(window-&gt;get_render());
  sphere.set_scale(0.25, 0.25, 0.25);
  sphere.set_pos(0, 0, 1);

  // Setup our physics world and the body
  world.set_gravity(0, 0, -9.81);
  body = new OdeBody(world);
  OdeMass M = OdeMass();
  M.set_sphere(7874, 1.0);
  body-&gt;set_mass(M);
  body-&gt;set_position(sphere.get_pos(window-&gt;get_render()));
  body-&gt;set_quaternion(sphere.get_quat(window-&gt;get_render()));

  // Set the camera position
  camera.set_pos (80, -20, 40);
  camera.look_at (0, 0, 0);

  PT(GenericAsyncTask) simulationTaskObject =
    new GenericAsyncTask(&quot;startup task&quot;, &amp;simulationTask, (void*) NULL);
  simulationTaskObject-&gt;set_delay(2);
  taskMgr-&gt;add(simulationTaskObject);
}

// The task for our simulation
AsyncTask::DoneStatus simulationTask (GenericAsyncTask* task, void* data) {
  // Set the force on the body to push it off the ridge
  body-&gt;set_force(0, min(pow(task-&gt;get_elapsed_time(),4) * 500000 - 500000, 0), 0);
  // Add the deltaTime for the task to the accumulator
  deltaTimeAccumulator += globalClock-&gt;get_dt();
  while (deltaTimeAccumulator &gt; stepSize ) {
    // Remove a stepSize from the accumulator until
    // the accumulated time is less than the stepsize
    deltaTimeAccumulator -= stepSize;
    // Step the simulation
    world.quick_step(stepSize);
  }
  // set the new positions
  sphere.set_pos_quat(window-&gt;get_render(),
    body-&gt;get_position(), body-&gt;get_quaternion());
  return AsyncTask::DS_cont;
}

&lt;/code&gt;
[/cxx]

&lt;h2&gt;Incomplete Section&lt;/h2&gt;

Note: this section is incomplete.  It will be updated soon.</text>
    </revision>
  </page>
  <page>
    <title>Sound</title>
    <ns>0</ns>
    <id>1021</id>
      <sha1>qyyqww91tecumq490bq7ft9v6qq82qx</sha1>
    <revision>
      <id>60530</id>
      <timestamp>2015-07-22T20:44:45Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>update openal note</comment>
      <text xml:space="preserve" bytes="2321">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

== Sound System Options ==
&lt;p&gt;To play audio in your game, Panda3D can offer you the following three choices of audio libraries:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;[http://connect.creativelabs.com/openal/default.aspx OpenAL]&lt;/b&gt; is a well-known and popular open-source audio library.  Panda3D uses the [http://openal-soft.org/ OpenAL Soft] implementation.&lt;/li&gt;
&lt;br /&gt;
&lt;li&gt;&lt;b&gt;[http://www.fmod.org/ FMOD]&lt;/b&gt; is a powerful proprietary cross-platform sound engine that supports various types of sound files - MP3, WAV, AIFF, MIDI, MOD, WMA, and OGG Vorbis. However, its license restricts you from using it for commercial purposes unless you actually purchase a special license. Non-commercial use of FMOD is free of charge. (For more information on this, visit the [http://www.fmod.org/index.php/sales FMOD Licenses] page.)&lt;/li&gt;
&lt;br /&gt;
&lt;li&gt;&lt;b&gt;[http://www.radgametools.com/miles.htm Miles]&lt;/b&gt; is a sound system that is not included in the downloadable binaries of Panda3D. In order to use this you will need to purchase Miles and compile Panda3D from scratch using the ppremake system.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If these choices are not enough for you, then you can try other sound libraries.&lt;/p&gt;
== Setting the Sound System ==
&lt;p&gt;To configure Panda3D to use a specific sound system, you will need to change your [[Configuring Panda|Config.prc]] configuration. You should look up the variable &lt;code&gt;audio-library-name&lt;/code&gt; and change the value to one of &lt;code&gt;p3openal_audio&lt;/code&gt;, &lt;code&gt;p3fmod_audio&lt;/code&gt;, or &lt;code&gt;miles_audio&lt;/code&gt;. (The names of the libraries may differ with the way Panda3D was built.)&lt;/p&gt;

== Extra Notes ==
&lt;p&gt;If you don't want to use one or both of the libraries shipped by default with the SDK, then you can remove the associated library files after installation or compile Panda3D from source with the appropriate settings to keep them out of the build.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Note for users of Panda3D 1.5.4 and under:&lt;/b&gt; If you are using FMOD and a 64-bit operating system, you might run into a strange assertion error or even a crash if the memory address of the sound exceeds 4 billion. This is because of an issue in FMOD. To avoid being affected by this issue, you must make sure your memory usage doesn't exceed 4 GiB (which is not likely, and even impossible on 32-bit systems).&lt;/p&gt;</text>
    </revision>
  </page>
  <page>
    <title>Sound Intervals</title>
    <ns>0</ns>
    <id>1022</id>
      <sha1>3rl3t2w7s8w989gp9udwa04d9vsz6v7</sha1>
    <revision>
      <id>5965</id>
      <timestamp>2009-07-12T21:08:36Z</timestamp>
      <contributor>
        <username>Chroipahtz</username>
        <id>297</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="694">See [[Loading and Playing Sounds and Music]] for basic information on how to load and play sounds.

Sound intervals play sounds from inside an interval. Like actor intervals, sound intervals have a loop parameter and the ability to be paused. Sound intervals also have volume and start time parameters.

&lt;code python&gt;
mySound = loader.loadSfx(&quot;mySound.wav&quot;)

myInterval = SoundInterval(
    mySound,
    loop = 0 or 1,
    duration = myDuration,
    volume = myVolume,
    startTime = myStartTime
)
&lt;/code&gt;

The looping provided by the sound interval is not clean. There will be a pause between loops of roughly a tenth of a second.  See [[Manipulating Sounds]] for a better way to loop sounds.</text>
    </revision>
  </page>
  <page>
    <title>Source Codes</title>
    <ns>0</ns>
    <id>2596</id>
      <sha1>kzyxyi4apm2ztpkrurgm17o0389sacj</sha1>
    <revision>
      <id>7472</id>
      <timestamp>2011-12-24T12:47:07Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="930">
PandAI is open source and in fact is meant as a learning tool for users wanting to learn AI too.

This means that the entire source for PandAI, which was written in C++ and the mesh generators for path finding is available here :



&lt;b&gt;Source Codes :&lt;/b&gt;


1. &lt;b&gt;Pandai_v1.0_src.zip&lt;/b&gt; - This is the entire source code of PandAI + Doxygen documentation. (Open Source)

https://sites.google.com/site/etcpandai/download/Pandai_v1.0_src.zip?attredirects=0&amp;d=1


2. &lt;b&gt;meshgen_v1.0_src.zip&lt;/b&gt; - This is the entire source code of the mesh generator for Maya and Max (Open Source)

https://sites.google.com/site/etcpandai/download/meshgen_v1.0_src.zip?attredirects=0&amp;d=1


3. &lt;b&gt;BlenderMeshGen.zip&lt;/b&gt; - This is the python source code for the Blender mesh generator + few samples (Open Source)

https://sites.google.com/site/etcpandai/download/BlenderMeshGen.zip?attredirects=0&amp;d=1

Note that newer versions of Panda include PandaAI.</text>
    </revision>
  </page>
  <page>
    <title>Splash image tags</title>
    <ns>0</ns>
    <id>2477</id>
    <redirect title="Splash window tags" />
      <sha1>nau4g5d492e5kyxtgpe646jmtpn3m35</sha1>
    <revision>
      <id>6711</id>
      <timestamp>2010-03-04T19:19:53Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>[[Splash image tags]] moved to [[Splash window tags]]</comment>
      <text xml:space="preserve" bytes="32">#REDIRECT [[Splash window tags]]</text>
    </revision>
  </page>
  <page>
    <title>Splash window tags</title>
    <ns>0</ns>
    <id>2419</id>
      <sha1>ii61x5l4wj9tff61108r5qeu23iayoo</sha1>
    <revision>
      <id>7314</id>
      <timestamp>2011-09-01T04:59:30Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="2423">The following table lists the custom P3D tokens that you may specify within the &lt;object&gt; element, as described in [[Advanced object tags]].  You can use these settings to customize the look of the app's embedded frame whenever the Panda3D window is not being displayed, e.g. before or after launch.

{| border=&quot;1&quot;
! Token !! Meaning 
|-
| splash_img || The URL of an image to display in the plugin space, anytime before Panda starts running (unless a more specific image, below, overrides)
|-
| download_img || The image to display while the p3d file and its required packages are being downloaded
|-
| unauth_img || The image to display when the app is unrecognized, and is waiting for the user to click the red &quot;authorize&quot; button
|-
| ready_img || The image to display when the app is ready to run, and waiting for the user to click the green &quot;play&quot; button
|-
| failed_img || The image to display when the app cannot launch for some reason (e.g. bad URL)
|-
| launch_img || The image to display while the app is launching: the time after the user has clicked &quot;play&quot; and before it actually opens its Panda3D window
|-
| active_img || The image to display while the app is running (but the app has taken its window out of the frame)
|-
| noplugin_img || This is available only if you use the [[Embedding_with_RunPanda3D|RunPanda3D.js]] method of embedding your p3d file.  In this case, this specifies the image to display if the plugin is not installed or cannot be run for some reason.
|-
| noplugin_href || As above, this is available only if you use the RunPanda3D.js method of embedding your p3d file, and it specifies the URL that the user should be taken to if he or she clicks on the embed region when the plugin is not installed.  A good choice, for instance, is http://www.panda3d.org/download.php?runtime .
|-
| auth_ready&lt;br&gt;auth_rollover&lt;br&gt;auth_click || The three images that define the normally red &quot;authorize&quot; button
|-
| play_ready&lt;br&gt;play_rollover&lt;br&gt;play_click || The three images that define the normally green &quot;play&quot; button
|-
| fgcolor || The text color of the text that may appear in the window
|-
| bgcolor || The background color of the window before the app has launched
|-
| barcolor || The fill color of the loading bar that is shown before the app launches
|}

Note that all of the image URL's above must refer to either a PNG or a JPEG image.  Other image types are not supported by the plugin.</text>
    </revision>
  </page>
  <page>
    <title>Standard packages</title>
    <ns>0</ns>
    <id>2406</id>
      <sha1>qfeagy1zv476qu7vtm97yt6l8y8rqv2</sha1>
    <revision>
      <id>6669</id>
      <timestamp>2010-02-09T09:59:54Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <text xml:space="preserve" bytes="1942">There are a number of packages hosted at the standard Panda3D host URL, http://runtime.panda3d.org : panda3d, fmod, openal, audio, egg, ode, wx, tk and more - visit the link for a full list (every subdirectory represents a package).

Each of these has a package version string that is updated with each new major.minor.0 release of Panda, for instance, the 1.7.x series of Panda3D is hosted with the package version &quot;cmu_1_7&quot;.  As the 1.7.1 and later bugfix releases are made, they are made in-place under the same version string, so that p3d files that reference the package version &quot;cmu_1_7&quot; will automatically download the bugfix release version.  However, when the 1.8.0 release is made, it will be made under the version &quot;cmu_1_8&quot;, and the &quot;cmu_1_7&quot; branch will remain unchanged thereafter, so that p3d files that reference that version can continue to use it without being affected by possible changes in the 1.8.x series.

When you reference a package by name with the -r parameter, the default is to reference one of the standard packages offered by the same host URL that built packp3d.p3d itself.  If you wish to reference a different package on another host, or a different version of a particular package, you can specify the full package with &quot;-r name,version,hostURL&quot;.

The &quot;panda3d&quot; package is special.  This is the package that includes the core part of the Panda3D code, the code necessary to open a graphics window and begin rendering.  It is not optional.  Every p3d file must reference some package called &quot;panda3d&quot;, though it can be with any version string, and any host URL.  (You can even build and host your own package named &quot;panda3d&quot; if your application requires a custom build of Panda3D for some reason, though we don't recommend doing this unless there is a good reason to.)  The panda3d package must contain the executable program p3dpython, which is used to start the p3d application running in a child process.</text>
    </revision>
  </page>
  <page>
    <title>Start Guide For The Absolute Beginner</title>
    <ns>0</ns>
    <id>2190</id>
    <redirect title="How to use a Python Editor" />
      <sha1>pmb5znrn1fg2quid0s2nmmkwoo8hdp2</sha1>
    <revision>
      <id>4784</id>
      <timestamp>2008-03-07T10:39:50Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <comment>[[Start Guide For The Absolute Beginner]] moved to [[How to use a Python Editor]]: Name was meaningless, did not describe what the page taught.</comment>
      <text xml:space="preserve" bytes="40">#REDIRECT [[How to use a Python Editor]]</text>
    </revision>
  </page>
  <page>
    <title>Started Guide For The Absolute Beginner</title>
    <ns>0</ns>
    <id>1745</id>
    <redirect title="Start Guide For The Absolute Beginner" />
      <sha1>8y9ie9s56gz82eqpzfej20ejdtvuceo</sha1>
    <revision>
      <id>3346</id>
      <timestamp>2006-05-08T10:21:46Z</timestamp>
      <contributor>
        <username>Martin</username>
        <id>31</id>
      </contributor>
      <comment>Started Guide For The Absolute Beginner moved to Start Guide For The Absolute Beginner: sorry a mistake with the title</comment>
      <text xml:space="preserve" bytes="51">#redirect [[Start Guide For The Absolute Beginner]]</text>
    </revision>
  </page>
  <page>
    <title>Starting Panda3D</title>
    <ns>0</ns>
    <id>935</id>
      <sha1>orvwyv7h8zw57uddfm0y0hmwxie53ye</sha1>
    <revision>
      <id>60474</id>
      <timestamp>2015-03-15T12:28:28Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>instructions for replacing deprecated DirectStart</comment>
      <text xml:space="preserve" bytes="4207">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;
 
[python]
== Creating a New Panda3D Application ==
=== [[ShowBase]] ===
To start Panda3D, create a text file and save it with the .py extension. PYPE, SPE and IDLE are Python-specific text-editors, but any text editor will work. Enter the following text into your Python file:

&lt;syntaxhighlight lang=&quot;python&quot;&gt;
from direct.showbase.ShowBase import ShowBase

class MyApp(ShowBase):

    def __init__(self):
        ShowBase.__init__(self)

app = MyApp()
app.run()

&lt;/syntaxhighlight&gt;

&lt;p&gt;Here we made our main class inherit from &lt;code&gt;ShowBase&lt;/code&gt;. The ShowBase class loads most of the other Panda3D modules, and causes the 3D window to appear. The &lt;code&gt;run()&lt;/code&gt; procedure in ShowBase contains the Panda3D main loop. It renders a frame, handles the background tasks, and then repeats. It does not normally return, so it needs to be called only once and must be the last line in your script. In this particular example, there will be nothing to render, so you should expect a window containing an empty grey area.&lt;/p&gt;

=== DirectStart ===
&lt;code&gt;DirectStart&lt;/code&gt; is a shortcut that instantiates ShowBase automatically on import. This may be useful for quick prototyping at the expense of clean code layout. The following example demonstrates its use:

&lt;syntaxhighlight lang=&quot;python&quot;&gt;
import direct.directbase.DirectStart

run()
&lt;/syntaxhighlight&gt;

The import line automatically constructs an instance of ShowBase, which starts the engine and creates an empty window. Because ShowBase uses Python's &lt;code&gt;__builtin__&lt;/code&gt;, its functions are allowed to be called without storing the instance in a variable. For the sake of cleanliness, the rest of this tutorial shall use the ShowBase subclass.

DirectStart is deprecated starting with Panda3D 1.9.0.  In order to upgrade old code, you can simply replace the DirectStart import with the following:
&lt;syntaxhighlight lang=&quot;python&quot;&gt;
from direct.showbase.ShowBase import ShowBase
base = ShowBase()
&lt;/syntaxhighlight&gt;

== Running the Program ==
To run your program on Windows or Mac, enter the following in a terminal (command prompt):

&lt;syntaxhighlight lang=&quot;bash&quot;&gt;
ppython filename.py
&lt;/syntaxhighlight&gt;

To run it on GNU/Linux, enter the following in a terminal:

&lt;syntaxhighlight lang=&quot;bash&quot;&gt;
python filename.py
&lt;/syntaxhighlight&gt;

If Panda3D has been installed properly, a grey window titled ''Panda'' appears. There is nothing we can do with this window, but that will change shortly.
[/python]
[cxx]
== Creating a New Panda3D Application ==
To start Panda3D, create a text file and save it with a .cxx extension. Any text editor will work. Enter the following text into your C++ file:

&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
#include &quot;pandaFramework.h&quot;
#include &quot;pandaSystem.h&quot;

int main(int argc, char *argv[]) {
    //open a new window framework
  PandaFramework framework;
  framework.open_framework(argc, argv);
    //set the window title to My Panda3D Window
  framework.set_window_title(&quot;My Panda3D Window&quot;);
    //open the window
  WindowFramework *window = framework.open_window();

  //here is room for your own code

    //do the main loop, equal to run() in python
  framework.main_loop();
    //close the window framework
  framework.close_framework();
  return (0);
}
&lt;/syntaxhighlight&gt;
For information about the Window Framework to open a window, click [[The Window Framework|here]].

&lt;code&gt;pandaFramework.h&lt;/code&gt; and &lt;code&gt;pandaSystem.h&lt;/code&gt; load most of the Panda3D modules. The ''main_loop()'' subroutine contains the Panda3D main loop. It renders a frame, handles the background tasks, and then repeats.  It does not normally return, so it needs to be called only once and must be the last line in your script. In this particular example, there will be nothing to render, so you should expect a window containing an empty grey area.

== Running the Program ==
The steps required to build and run your program were already explained on [[Getting Started with your Development Environment]].

If Panda3D has been installed properly, a gray window titled ''My Panda3D Window'' will appear when you run your program. There is nothing we can do with this window, but that will change shortly.
[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Starting Panda3D (CXX)</title>
    <ns>0</ns>
    <id>2077</id>
      <sha1>fndrec7uowc9rd3coukzzt6c6rbt8gn</sha1>
    <revision>
      <id>4983</id>
      <timestamp>2008-03-14T21:45:05Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="1635">To start Panda3D, create a text file and save it with a .cxx extension. [http://www.pspad.com PSPad] is a good text-editor with C++ highlighting, but any text editor will work. Enter the following text into your C++ file:

&lt;pre class=&quot;codeblock&quot;&gt;
#include &quot;pandaFramework.h&quot;
#include &quot;pandaSystem.h&quot;

PandaFramework framework;

int main(int argc, char *argv[]) {
    //open a new window framework
  framework.open_framework(argc, argv);
    //set the window title to My Panda3D Window
  framework.set_window_title(&quot;My Panda3D Window&quot;);
    //open the window
  WindowFramework *window = framework.open_window();

  //here is room for your own code

    //do the main loop, equal to run() in python
  framework.main_loop();
    //close the window framework
  framework.close_framework();
  return (0);
}
&lt;/pre&gt;
For information about the Window Framework to open a window, click [[The Window Framework|here]].

&lt;i&gt;pandaFramework.h&lt;/i&gt; and &lt;i&gt;pandaSystem.h&lt;/i&gt; load most of the Panda3D modules. The &lt;i&gt;main_loop()&lt;/i&gt; subroutine contains the Panda3D
main loop. It renders a frame, handles the background tasks, and
then repeats.  It does not normally return, so it only needs to be called once and must be the last line in your script. In this particular example,
there will be nothing to render, so you should expect a window
containing an empty grey area.

To run your program, follow the compile steps explained on [[How to build a CXX Panda3D game|this page]].

If Panda3D has been installed properly, a gray window titled &lt;i&gt;My Panda3D Window&lt;/i&gt; will appear.
There is nothing we can do with this window, but that will change shortly.</text>
    </revision>
  </page>
  <page>
    <title>Static Obstacles</title>
    <ns>0</ns>
    <id>2593</id>
      <sha1>pqa5ybrvqw0xaaqn8wpf67cotomordb</sha1>
    <revision>
      <id>7707</id>
      <timestamp>2012-03-09T10:31:15Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="7037">&lt;b&gt;STATIC OBSTACLES :&lt;/b&gt;


{{#ev:youtube|mn2kX0C8XdM}}


-----


In PandAI, use it via :

&lt;code python&gt;
addStaticObstacle(NodePath obstacle);
&lt;/code&gt;


-----


&lt;b&gt;The code for this tutorial :&lt;/b&gt;

&lt;code python&gt;
# This tutorial provides an example of creating a character
# and having it walk around using PandAI
# pathfinding with static obstacle avoidance

import direct.directbase.DirectStart
from panda3d.core import *
from direct.showbase.DirectObject import DirectObject
#for intervals
from direct.interval.IntervalGlobal import *
#for FSM
from direct.fsm import FSM
from direct.fsm import State
#for tasks
from direct.task import Task
#for Actors
from direct.actor.Actor import Actor
#for math
import math
#for system commands
import random, sys, os, math
#for directGUI
from direct.gui.DirectGui import *
from direct.gui.OnscreenText import OnscreenText

#for Pandai
from panda3d.ai import *

#************************GLOBAL**********************************************
speed = 0.75

# Figure out what directory this program is in.
MYDIR=os.path.abspath(sys.path[0])
MYDIR=Filename.fromOsSpecific(MYDIR).getFullpath()

font = loader.loadFont(&quot;cmss12&quot;)

# Function to put instructions on the screen.
def addInstructions(pos, msg):
    return OnscreenText(text=msg, style=1, fg=(1,1,1,1), font = font,
                        pos=(-1.3, pos), align=TextNode.ALeft, scale = .05)

# Function to put title on the screen.
def addTitle(text):
    return OnscreenText(text=text, style=1, fg=(1,1,1,1), font = font,
                        pos=(1.3,-0.95), align=TextNode.ARight, scale = .07)

class World(DirectObject):

    def __init__(self):
        
        self.keyMap = {&quot;left&quot;:0, &quot;right&quot;:0, &quot;up&quot;:0, &quot;down&quot;:0}
        
        self.title = addTitle(&quot;Pandai Tutorial: Adding Dynamic Obstacles&quot;)
        self.inst1 = addInstructions(0.95, &quot;[ESC]: Quit&quot;)
        self.inst2 = addInstructions(0.90, &quot;[Enter]: Start Pathfinding&quot;)
        self.inst21 = addInstructions(0.85, &quot;[Arrow Keys]: Move Arrow&quot;)
        self.inst3 = addInstructions(0.80, &quot;[1]: Small box&quot;)
        self.inst4 = addInstructions(0.75, &quot;[2]: Big box&quot;)
        self.inst5 = addInstructions(0.70, &quot;[Space]: Place box&quot;)
        
        #base.disableMouse()
        base.cam.setPosHpr(0,-210,135,0,327,0)
        self.box = 0
        self.pointer_move = False
        
        self.loadModels()
        self.setAI()
       
    def loadModels(self):

        self.environ1 = loader.loadModel(&quot;models/skydome&quot;)      
        self.environ1.reparentTo(render)
        self.environ1.setPos(0,0,0)
        self.environ1.setScale(1)
        
        self.environ2 = loader.loadModel(&quot;models/skydome&quot;)      
        self.environ2.reparentTo(render)
        self.environ2.setP(180)
        self.environ2.setH(270)
        self.environ2.setScale(1)

        self.environ = loader.loadModel(&quot;models/groundPlane&quot;)      
        self.environ.reparentTo(render)
        self.environ.setPos(0,0,0)
               
        # Create the main character, Ralph

        #ralphStartPos = self.environ.find(&quot;**/start_point&quot;).getPos()
        ralphStartPos = Vec3(-51,-64,0)
        self.ralph = Actor(&quot;models/ralph&quot;,
                                 {&quot;run&quot;:&quot;models/ralph-run&quot;,
                                  &quot;walk&quot;:&quot;models/ralph-walk&quot;})
        self.ralph.reparentTo(render)
        self.ralph.setScale(2)
        self.ralph.setPos(ralphStartPos)
        
        self.pointer = loader.loadModel(&quot;models/arrow&quot;)
        self.pointer.setColor(1,0,0)
        self.pointer.setPos(60,-60,0)
        self.pointer.setScale(3)
        self.pointer.reparentTo(render)
      
    def setAI(self):
        #Creating AI World
        self.AIworld = AIWorld(render)
        
        self.accept(&quot;enter&quot;, self.setMove)
        self.accept(&quot;1&quot;, self.addBlock)
        self.accept(&quot;2&quot;, self.addBigBlock)
        self.accept(&quot;space&quot;, self.addStaticObstacle)
        
        #movement
        self.accept(&quot;arrow_left&quot;, self.setKey, [&quot;left&quot;,1])
        self.accept(&quot;arrow_right&quot;, self.setKey, [&quot;right&quot;,1])
        self.accept(&quot;arrow_up&quot;, self.setKey, [&quot;up&quot;,1])
        self.accept(&quot;arrow_down&quot;, self.setKey, [&quot;down&quot;,1])
        self.accept(&quot;arrow_left-up&quot;, self.setKey, [&quot;left&quot;,0])
        self.accept(&quot;arrow_right-up&quot;, self.setKey, [&quot;right&quot;,0])
        self.accept(&quot;arrow_up-up&quot;, self.setKey, [&quot;up&quot;,0])
        self.accept(&quot;arrow_down-up&quot;, self.setKey, [&quot;down&quot;,0])
        
        self.AIchar = AICharacter(&quot;ralph&quot;,self.ralph, 60, 0.05, 15)
        self.AIworld.addAiChar(self.AIchar)
        self.AIbehaviors = self.AIchar.getAiBehaviors()
        
        self.AIbehaviors.initPathFind(&quot;models/navmesh.csv&quot;)
        
        #AI World update        
        taskMgr.add(self.AIUpdate,&quot;AIUpdate&quot;)
        
        #movement task
        taskMgr.add(self.Mover,&quot;Mover&quot;)
        
        self.dirnlight1 = DirectionalLight(&quot;dirn_light1&quot;)
        self.dirnlight1.setColor(Vec4(1.0,1.0,1.0,1.0))
        self.dirnlightnode1 = render.attachNewNode(self.dirnlight1)
        self.dirnlightnode1.setHpr(0,317,0)
        render.setLight(self.dirnlightnode1)
        
    def setMove(self):
        self.AIbehaviors.pathFindTo(self.pointer)
        self.ralph.loop(&quot;run&quot;)
    
    def addBlock(self):
        self.pointer_move = True
        self.box = loader.loadModel(&quot;models/box&quot;)
        self.box.setPos(0,-60,0)
        self.box.setScale(1)
        self.box.reparentTo(render)
        
    def addBigBlock(self):
        self.pointer_move = True
        self.box = loader.loadModel(&quot;models/box&quot;)
        self.box.setPos(0,-60,0)
        self.box.setScale(2)
        self.box.setColor(1,1,0)
        self.box.reparentTo(render)
    
    def addStaticObstacle(self):
        if(self.box!=0):
            self.AIbehaviors.addStaticObstacle(self.box)
            self.box = 0
            self.pointer_move = False
            
    #to update the AIWorld    
    def AIUpdate(self,task):
        self.AIworld.update()
        #if(self.AIbehaviors.behaviorStatus(&quot;pathfollow&quot;) == &quot;done&quot;):
            #self.ralph.stop(&quot;run&quot;)
            #self.ralph.pose(&quot;walk&quot;, 0)
            
        return Task.cont
    
    def setKey(self, key, value):
        self.keyMap[key] = value
        
    def Mover(self,task):
        startPos = self.pointer.getPos()
        if (self.keyMap[&quot;left&quot;]!=0):
            self.pointer.setPos(startPos + Point3(-speed,0,0))
        if (self.keyMap[&quot;right&quot;]!=0):
            self.pointer.setPos(startPos + Point3(speed,0,0))
        if (self.keyMap[&quot;up&quot;]!=0):
            self.pointer.setPos(startPos + Point3(0,speed,0))
        if (self.keyMap[&quot;down&quot;]!=0):
            self.pointer.setPos(startPos + Point3(0,-speed,0))
            
        if(self.pointer_move == True and self.box != 0):
            self.box.setPos(self.pointer.getPos())
                
        return Task.cont


w = World()
run()

&lt;/code&gt;


-----


&lt;b&gt;The full working demo can be downloaded at :&lt;/b&gt;

https://sites.google.com/site/etcpandai/documentation/pathfinding/StaticObstacleDemo.zip?attredirects=0&amp;d=1</text>
    </revision>
  </page>
  <page>
    <title>Steering Behaviors</title>
    <ns>0</ns>
    <id>2581</id>
      <sha1>7h3vbbxib4fvqt4lsuw4glk1mvxoehw</sha1>
    <revision>
      <id>7059</id>
      <timestamp>2011-01-26T07:02:22Z</timestamp>
      <contributor>
        <username>NNair</username>
        <id>515</id>
      </contributor>
      <text xml:space="preserve" bytes="3147">These AI behaviors control the basic motion of NPC objects in a game and make it look realistic. 

PandAI is inbuilt with handling the functionality of the seven following basic steering behaviors :

&lt;b&gt;
Seek

Flee

Pursue

Evade

Arrival

Wander

Flock

Obstacle Avoidance

Path Follow
&lt;/b&gt;

Before you start exploring these various behaviors, let me give you a brief introduction on how it is setup and what you need to begin :

All the Steering Behaviors are part of the Behavior class of any AI Character. Hence, to use them you need to get a reference to it via &lt;b&gt;'getAiBehaviors()'&lt;/b&gt; function of the AICharacter class.

Once you get this reference, you can use it to call any steering behavior. 

&lt;code python&gt;
    
    //For example:

     aiBehaviors = aiCharacter.getAiBehaviors();  
     aiBehaviors.seek(targetNodePath);

&lt;/code&gt;

* Once you have read this page, you can proceed to explore the individual pages for each AI Behavior for details and even an example demo for each one working.

-----


&lt;b&gt;PRIORITIES :&lt;/b&gt;

Every steering behavior can also take a second parameter which is priority. This ranges from 0 to 1 and it defines the behaviors intensity when combined with other behaviors. 

&lt;code python&gt;

    //For example: 
    
    aiBehaviors.seek(targetNodePath_1, 0.5);
    aiBehaviors.flee(targetNodePath_2, 0.5);

&lt;/code&gt;

&lt;b&gt;This will cause the AICharacter's resultant force to be an equal balance of seeking 'targetNodePath_1' and fleeing 'targetNodePath_2' .&lt;/b&gt;


-----

&lt;b&gt;HELPER FUNCTIONS : &lt;/b&gt;

(For beginners -&gt; Come back to these when you need this functionality)


&lt;b&gt;For the AIWorld class:&lt;/b&gt;
&lt;code python&gt;
void addAiChar(AICharacter aiChar);

void removeAiChar(string name);

void addFlock(Flock *flock);

void flockOff(int ID);

void flockOn(int ID);

Flock getFlock(int ID);
&lt;/code&gt;

&lt;b&gt;For the AICharacter class:&lt;/b&gt;
&lt;code python&gt;
double getMass();

void setMass(double m);

LVecBase3f getVelocity();

double getMaxForce();

void setMaxForce(double max_force);

NodePath getNodePath();

void setNodePath(NodePath np);
&lt;/code&gt;
 
&lt;b&gt;For the AIBehaviors class:&lt;/b&gt;
&lt;code python&gt;
aiBehaviors.behaviorStatus(string AIName)
&lt;/code&gt;
This function returns the status of an AI Behavior whether it is active, paused, done or disabled. Returns  -1 if an invalid string is passed.

*Note for pathfinding status, use pathfollow as the string name, since pathfinding is a subset of pathfollow.

 
&lt;b&gt;To remove any AI after their call has been instantiated.&lt;/b&gt;
&lt;code python&gt;
void removeAi(string &quot;AIName&quot;);
&lt;/code&gt;
*Note for pathfinding removal, use pathfollow as the string name, since pathfinding is a subset of pathfollow.

 
&lt;b&gt;To pause or resume any AI after their call has been instantiated.&lt;/b&gt;
&lt;code python&gt;
void pauseAi(string &quot;AIName&quot;);

void resumeAi(string &quot;AIName&quot;);
&lt;/code&gt;
where AIName refers to:

&quot;all&quot; - removes all the Ai's

&quot;seek&quot; - removes seek

&quot;flee&quot; - removes flee

&quot;pursue&quot; - removes arrival

&quot;evade&quot; - removes pursuit

&quot;arrival&quot; - removes evade

&quot;wander&quot; - removes wander

&quot;flock&quot; - removes flock

&quot;obstacle_avoidance&quot; - removes obstacle_avoidance

&quot;pathfollow&quot; - removes pathfollow


-----</text>
    </revision>
  </page>
  <page>
    <title>Stencil Test/Write Attribute</title>
    <ns>0</ns>
    <id>2098</id>
      <sha1>p9e57itdjcd3kwgluo6i0xlggytrf7i</sha1>
    <revision>
      <id>7632</id>
      <timestamp>2012-03-08T17:49:32Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>new import system and python code tags</comment>
      <text xml:space="preserve" bytes="5363">&lt;p&gt;The StencilAttrib is used for testing and writing to the stencil buffer.  Note that both of these actions can be performed simultaneously with a single StencilAttrib.&lt;/p&gt;

&lt;p&gt;The stencil buffer is an ancillary graphics buffer, in addition to the more well-known color and depth buffers.  It provides a per-pixel mask for the rendering pipeline which can be exploited to selectively render objects or parts of objects.  Typical applications of the stencil buffer include binary masking, shadowing and planar reflections.&lt;/p&gt;

&lt;p&gt;Usually, using the stencil buffer involves creating some objects which are not rendered into the color buffer.  Their contribution to the rendered scene is to provide an invisible boundary that can be used to turn color buffer rendering on and off for other objects in the scene.  Think of it as a cardboard cut-out through which the world is viewed.&lt;/p&gt;

&lt;p&gt;During a stencil comparison, the StencilAttrib's reference value is compared against the value stored in the stencil buffer.  The order matters here.  For example, consider comparison function StencilAttrib.SCFGreaterThan with reference value r=1.  A pixel passes the stencil test if r &gt; S&lt;sub&gt;p&lt;/sub&gt;, where S&lt;sub&gt;p&lt;/sub&gt; is the value in the stencil buffer at pixel &lt;i&gt;p&lt;/i&gt;.  Objects contributing values to the stencil buffer that will be read by other StencilAttributes' comparison functions must be rendered first, or unexpected results will occur.  See [[How to Control Render Order]].&lt;/p&gt;

&lt;p&gt;The stencil buffer is disabled by default.  In order to use StencilAttribs, you must add the following line to your config.prc file:&lt;/p&gt;

&lt;pre class=&quot;codeblock&quot;&gt;
framebuffer-stencil #t
&lt;/pre&gt;

&lt;p&gt;StencilAttribs are defined exclusively by their constructor functions, so let's examine one to understand what each part does.  The following code creates an attribute which tells an object to render only if the stencil buffer is exactly 1, and does not itself modify the stencil buffer.&lt;/p&gt;

&lt;code python&gt;
stencilReader =
  StencilAttrib.make(1,StencilAttrib.SCFEqual,StencilAttrib.SOKeep,
                       StencilAttrib.SOKeep,StencilAttrib.SOKeep,1,1,0)
&lt;/code&gt;

&lt;p&gt;The first parameter is a boolean.  If this parameter is zero, the StencilAttrib is not processed.  Next is the comparison function this attribute uses, in this case Equal.  The next three parameters determine what happens to the stencil buffer depending on the result of the comparison.  We'll get to these in a minute.  The three Keep values tell this attribute never to modify the values in the buffer.  Next is the reference value for the comparison function.  Before the reference value is passed to the comparison function, however, it is bitwise ANDed with a mask.  In our case, we're interested in reading but not in writing the stencil buffer, so we pass 1 and 0 for the read and write masks, respectively.  These masks are the last two parameters for the StencilAttrib.&lt;/p&gt;

&lt;p&gt;Next, we'll look at a stencil attribute that writes the stencil buffer.  Presumably, these two functions will work in tandem to create an effect.&lt;/p&gt;

&lt;code python&gt;
constantOneStencil =
  StencilAttrib.make(1,StencilAttrib.SCFAlways,StencilAttrib.SOZero,
                       StencilAttrib.SOReplace,StencilAttrib.SOReplace,1,0,1)
&lt;/code&gt;

&lt;p&gt;Again we start by enabling the attribute.  The comparison function here is Always, meaning that the test passes no matter the parameters.  Next is the operation to perform on the stencil buffer if the test fails (which in this case will never happen) -- we set the stencil buffer value to zero.  The next parameter determines what should happen if the stencil function passes, but the depth test fails, and finally, what should happen if both the stencil and depth tests pass.  In our case we want to set the value of the stencil buffer whether we pass the depth test or not, so both are set to Replace.  The reference value to set in the stencil buffer is 1.  We're writing regardless of what's in the buffer already, so we'll set the read and write masks to 0 and 1, respectively.&lt;/p&gt;

&lt;p&gt;Now we can add these attributes to nodes in the scene to exploit the effect. Here is the entire script.&lt;/p&gt;

&lt;code python&gt;
from panda3d.core import *

# Do this before the next import:
loadPrcFileData(&quot;&quot;, &quot;framebuffer-stencil #t&quot;)

import direct.directbase.DirectStart

constantOneStencil = StencilAttrib.make(1,StencilAttrib.SCFAlways,
StencilAttrib.SOZero,StencilAttrib.SOReplace,
StencilAttrib.SOReplace,1,0,1)
 
stencilReader = StencilAttrib.make(1,StencilAttrib.SCFEqual,
StencilAttrib.SOKeep, StencilAttrib.SOKeep,
StencilAttrib.SOKeep,1,1,0) 

cm = CardMaker(&quot;cardmaker&quot;)
cm.setFrame(-.5,.5,-.5,.5)

# To rotate the card to face the camera, we create
# it and then parent it to the camera.
viewingSquare = render.attachNewNode(cm.generate())
viewingSquare.reparentTo(base.camera)
viewingSquare.setPos(0, 5, 0) 

viewingSquare.node().setAttrib(constantOneStencil)
viewingSquare.node().setAttrib(ColorWriteAttrib.make(0))
viewingSquare.setBin('background',0)
viewingSquare.setDepthWrite(0)

view = loader.loadModel(&quot;panda&quot;)
view.reparentTo(render)
view.setScale(3)
view.setY(150)
view.node().setAttrib(stencilReader)

run()
&lt;/code&gt;

&lt;p&gt;You can get a little more insight into stencils in this thread on the forums: http://www.panda3d.org/phpbb2/viewtopic.php?p=48451#48451&lt;/p&gt;</text>
    </revision>
  </page>
  <page>
    <title>Stereo/Multiview Textures</title>
    <ns>0</ns>
    <id>2626</id>
      <sha1>oo5kd0moyqd2xg1ubp4pt0mhxhpx9ta</sha1>
    <revision>
      <id>7222</id>
      <timestamp>2011-08-08T22:48:49Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="3339">Any Panda texture, including a cube map or video texture, can also be loaded as a &lt;em&gt;multiview&lt;/em&gt; texture.  This means that there are multiple different images, or views, stored within the texture object.

This feature is new as of Panda3D version 1.8.

The most common use for a multiview texture is to implement a &lt;em&gt;stereo&lt;/em&gt; texture, or a texture with two views: one for each of the left and the right eyes.  For instance, you would do this to project a 3-D movie onto a screen in your virtual space.

In its default configuration, whenever Panda renders to a 3-D stereo window (see [[Stereo Display Regions]]), any multiview textures are automatically treated as stereo textures.  View 0 is presented to the left eye, and view 1 is presented to the right eye.  Additional views beyond view 1 are not used.

A multiview texture is loaded as a series of independent texture images (similar to the way a cube map or 3-D texture is loaded).  Each image is numbered, and first image (or left image) is image number 0.  The right image is image number 1.  If there are additional views, they are numbered consecutively from there.  All of the images in the series must have the same filename, except for the image sequence number.

To load a multiview texture, use:

[python]&lt;code python&gt;
tex = loader.loadTexture('filename_#.png', multiview = True)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
LoaderOptions options;
options.set_texture_flags(LoaderOptions::TF_multiview);
PT(Texture) tex = TexturePool::load_texture(&quot;filename_#.png&quot;, 0, false, options);
&lt;/code&gt;[/cxx]

where the hash mark in the filename is replaced with the digit (or digits) that correspond to the image sequence number.  For instance, the above example would load image files named filename_0.png and filename_1.png.

You can also load cube maps in the same way.  A cube map consists of six independently loaded texture images numbered 0 through 5, which define the six faces of a cube.  With a stereo cube map, there are twelve texture images numbered 0 through 11.  The first six images define the six faces of the cube in the left view, and the next six images define the six faces of the cube in the right view.

[python]&lt;code python&gt;
tex = loader.loadCubeMap('cubemap_##.png', multiview = True)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
LoaderOptions options;
options.set_texture_flags(LoaderOptions::TF_multiview);
PT(Texture) tex = TexturePool::load_texture(&quot;cubemap_##.png&quot;, 0, false, options);
&lt;/code&gt;[/cxx]

Finally, 3-D textures work this way as well.  (Note that here by 3-D texture we mean one that contains height, width, and depth; this is not to be confused with a stereo texture, which contains a left and a right view.  It is possible to have a stereo 3-D texture, which contains a left and a right view that both contain height, width, and depth.)  When loading a multiview 3-D texture, you must specify the number of views explicitly, because Panda won't be able to figure that out based on the number of images files alone.

[python]&lt;code python&gt;
tex = loader.load3DTexture('tex3d_#.png', multiview = True, numViews = 2)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
LoaderOptions options;
options.set_texture_flags(LoaderOptions::TF_multiview);
options.set_texture_num_views(2);
PT(Texture) tex = TexturePool::load_3d_texture(&quot;tex3d_#.png&quot;, 0, false, options);
&lt;/code&gt;[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Stereo Display Regions</title>
    <ns>0</ns>
    <id>2624</id>
      <sha1>evfbyi7aw7uh2atn9ri10z840vijdxi</sha1>
    <revision>
      <id>60269</id>
      <timestamp>2014-08-20T20:57:39Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>notes about 1.9.0 changes to stereo</comment>
      <text xml:space="preserve" bytes="7060">A StereoDisplayRegion is a special kind of DisplayRegion that contains two views internally: one view for the left eye, and a different view for the right eye.  If you have a special 3-D display device, then Panda can use it to deliver each view to the appropriate eye.

Alternatively, you can also simply create the two required views independently, one DisplayRegion for the left eye, and a separate DisplayRegion for the right eye.  However, creating a single StereoDisplayRegion for both eyes at the same time is often more convenient.

When you call &lt;code&gt;window[-&gt;][func]make_display_region[/func]()&lt;/code&gt;, it will implicitly return a StereoDisplayRegion instead of a regular DisplayRegion if your window or buffer indicates that it supports stereo output (that is, if window.isStereo() returns true).  There are four ways that you can have a graphics output that supports stereo output:

(1) You have a special 3-D display device and the drivers to support it, and you put &lt;code&gt;framebuffer-stereo 1&lt;/code&gt; in your Config.prc file.  This tells Panda to activate the OpenGL interfaces to enable the 3-D hardware.

(2) You put &lt;code&gt;red-blue-stereo 1&lt;/code&gt; in your Config.prc file.  This tells Panda to render the two different eyes in two different colors, so that the traditional red-blue (or red-cyan) glasses, for instance for 3-D comic books, can be used to view the scene in 3-D.  Color is distorted, so it is best if your scene relies on unsaturated color palettes.  Shades of gray work particularly well.

(3) You put &lt;code&gt;side-by-side-stereo 1&lt;/code&gt; in your Config.prc file.  This is similar to red-blue-stereo, above, but the two views are rendered side-by-side in the same window.  This is useful for developing stereo applications, so you can see each view easily; it may also be useful for environments such as head-mounted displays where the output spans two different displays, and each display represents a different eye.

(4) As of Panda3D 1.9.0, you may create a stereo off-screen buffer without special hardware support, assuming the card supports using multiple render targets (most modern cards do), by setting the stereo flag in the &lt;code&gt;FrameBufferProperties&lt;/code&gt; object.  Panda3D will automatically designate one of the draw buffers to contain the stereo view for the other eye.  When binding a texture to the color attachment for render-to-texture, Panda3D will automatically initialize it as a [[Stereo/Multiview Textures|multiview texture]] containing both left and right views.  This is only supported in OpenGL as of writing.

==Using a StereoDisplayRegion==

A StereoDisplayRegion actually consists of two ordinary DisplayRegions, created automatically.  If you need to, you can access them individually with &lt;code&gt;sdr[-&gt;][func]get_left_eye[/func]()&lt;/code&gt; or &lt;code&gt;sdr[-&gt;][func]get_right_eye[/func]()&lt;/code&gt;.

Both the left and the right eye DisplayRegions actually share the same Camera object.  The thing that makes the view different for the left and the right eyes is the stereo channel setting, which you can set via &lt;code&gt;dr[-&gt;][func]set_stereo_channel[/func]()&lt;/code&gt;.  (You can change this setting on any DisplayRegion you like; it doesn't have to be a special StereoDisplayRegion.  The only thing that a StereoDisplayRegion does is it  manages the internal left and right DisplayRegions automatically, but there's no reason you need to use a StereoDisplayRegion if you want to manage them yourself.)

You can set a DisplayRegion's stereo channel to one of &lt;code&gt;[cxx]Lens::SC_left[/cxx][python]Lens.SCLeft[/python]&lt;/code&gt;, &lt;code&gt;[cxx]Lens::SC_right[/cxx][python]Lens.SCRight[/python]&lt;/code&gt;, or &lt;code&gt;[cxx]Lens::SC_mono[/cxx][python]Lens.SCMono[/python]&lt;/code&gt;.  The default for a non-stereo DisplayRegion is &lt;code&gt;[cxx]Lens::SC_mono[/cxx][python]Lens.SCMono[/python]&lt;/code&gt;, which means the normal view from the center of the camera.  If you set it to either left or right, then the point of view is slid automatically to the left or right, respectively, according to the stereo lens parameters.

Setting the stereo channel to left or right also resets the texture view offset associated with the DisplayRegion: the default tex view offset is 0 for the left eye, and 1 for the right eye.  This allows dual-view stereo textures to render properly in the DisplayRegion, so that the left view is visible in the left eye and the right view in the right eye.  See [[Stereo/Multiview Textures]] for more about this feature.

The lens parameters can be controlled via &lt;code&gt;lens[-&gt;][func]set_interocular_distance[/func]()&lt;/code&gt; and &lt;code&gt;lens[-&gt;][func]set_convergence_distance[/func]()&lt;/code&gt;, or by the equivalent Config.prc settings &lt;code&gt;default-iod&lt;/code&gt; and &lt;code&gt;default-converge&lt;/code&gt;.  Refer to the following illustration:

[[Image:Stereo lens parameters.jpg|Stereo Lens Parameters]]

In this image, the camera indicated with &quot;C&quot; is the center view, the normal view from the center of the camera view in the case of &lt;code&gt;[cxx]Lens::SC_mono[/cxx][python]Lens.SCMono[/python]&lt;/code&gt;.  &quot;L&quot; and &quot;R&quot; represent the left and right points of view for the same camera, which will be used in the case of &lt;code&gt;[cxx]Lens::SC_left[/cxx][python]Lens.SCLeft[/python]&lt;/code&gt; or &lt;code&gt;[cxx]Lens::SC_right[/cxx][python]Lens.SCRight[/python]&lt;/code&gt;.  The distance between these two eyes, line &quot;a&quot; on the image, is the interocular distance, which should be in the same units as the scene you are viewing.

The gray lines on the image represent the direction the camera appears to be facing into the scene.  Both the left and the right eyes converge together at one point, which is the convergence distance.  This distance is represented by line &quot;b&quot; on the image.  Generally, the objects that are this distance away will appear to be in the screen plane.  Objects that are closer than the convergence distance will appear to float in front of the screen, while objects that are further than the convergence distance will appear to be inside the screen.

Note that the default stereo frustums that Panda creates are off-axis frustums, not toe-in frustums.  That is, both the left and the right eyes are still pointing in the precise same direction as the center camera, but the frustum is distorted a bit to make objects converge approximately at the requested distance.  This is generally regarded as producing a superior stereo effect over the more naive toe-in approach, in which the left and right eyes are simply tilted towards each other to provide the required convergence.

If you require a different stereo frustum--for instance, if you wish to use toe-in stereo, or some other kind of stereo frustum of your choosing--you may simply set each DisplayRegion to use its own camera (instead of both sharing the same camera), and assign the particular frustum you wish to each eye.

'''Note:''' Prior to Panda3D 1.9.0, the convergence was being calculated incorrectly.  It has since been corrected.  To restore the legacy behavior you can set the &lt;code&gt;stereo-lens-old-convergence&lt;/code&gt; variable to &lt;code&gt;true&lt;/code&gt;.</text>
    </revision>
  </page>
  <page>
    <title>Subclassing</title>
    <ns>0</ns>
    <id>2321</id>
      <sha1>tu9p611wczfmlkzwij2auf1fxazyz6s</sha1>
    <revision>
      <id>7692</id>
      <timestamp>2012-03-09T10:12:05Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>new import system</comment>
      <text xml:space="preserve" bytes="6943">===Introduction===
Both Python and C++, being object-oriented programming languages, take advantage of the concept known as &quot;Inheritance&quot;, to allow for a class to subclass one or more other classes. This allows for the creation of a sub-class (or descendent class) that is said to &quot;inherit&quot; all the attributes of the super class (or ancestor class), usually with the purpose of expanding upon them. 

Subclassing pure-python classes from python or C++ classes from C++ is fairly straightforward and there's plenty of literature on the subject. The wikipedia article on [http://en.wikipedia.org/wiki/Inheritance_(computer_science) inheritance] is a good starting point before proceeding to the language-specific documentation. 

Special care however must be taken when creating a Python class that subclasses from a C++ class, as there are limitations to it.

===The Theory===
The C++ classes do not exactly exist in the Python namespace. They can't; they're C++ objects, not Python objects. Instead, for each C++ class that must be available through Python, a wrapper class that has the same name as the C++ class and all of the same methods has been created. When you call one of the methods on the Python wrapper, it turns around and calls the underlying C++ method of the same name. Thus, it looks like you're actually dealing directly with the C++ object, even though you're really dealing with a Python object.

When you inherit from a C++ class, you are actually inheriting from the Python wrapper class. You can't actually inherit from the C++ class itself, since you're writing a Python class, not a C++ class.

This means that whenever you create an instance of your new inherited class, you're creating an instance of the C++ class, the Python wrapper, and your Python inherited class. But then if you pass a pointer of your instance to some C++ method, all it receives is a pointer to the C++ class. 

In the context of Panda, if you create an instance of a new &quot;node&quot; class and store it in the scene graph, you are really only storing the underlying C++ object in the scene graph--the Python part of the object gets left behind. This makes sense, because the C++ structures can only store pointers to C++ objects, not Python objects.

So, when you pull the node out of the scene graph later, it creates a new Python wrapper around it and returns that new wrapper. Now all you have is the original C++ node--it's not your new node class any more, it's just the Python wrapper to the C++ class.

===The Practice===
With most C++ classes the only way forward is to create a new C++ subclass and the related Python wrapper around it. However, there is a work-around for classes such as PandaNode and NodePath. Both these C++ classes have in fact been designed with functionality to store and retrieve python objects on them. Specifically, the methods '''setPythonTag()''', '''getPythonTag()''' and '''hasPythonTag()''' are available to respectively store, retrieve and check for the existence of a pointer to an arbitrary python object on these C++ objects.

This allows us to subclass from the Python wrapper class around the C++ object and store, on the C++ object, a pointer to the new sub class. 

Let's first see an example of what '''doesn't''' work:

&lt;code python&gt;
import direct.directbase.DirectStart
from panda3d.core import PandaNode

## Here we define the new class, subclassing PandaNode
## and adding a new variable to it.
class MyNewNode(PandaNode):
    def __init__(self, aName):
        PandaNode.__init__(self, aName)
        self.aVariable = &quot;A value&quot;

## Here we are creating a new node and we -think- 
## we are placing it in the scene graph:
myNewNode = MyNewNode(&quot;MyNewNode&quot;)
aNodePath = aspect2d.attachNewNode(myNewNode)

## Here we -attempt- to fetch the stored variable,
## but we'll get an error because aNodePath.node()
## returns a PandaNode, not myNewNode!
print(aNodePath.node().aVariable)
&lt;/code&gt;

The workaround is for an instance of the new node class to store itself on the PandaNode, as a Python tag:

&lt;code python&gt;
import direct.directbase.DirectStart
from panda3d.core import PandaNode

## Here we define the new class, subclassing PandaNode
## storing its own instance as a python tag and 
## initializing a new variable.
class MyNewNode(PandaNode):
    def __init__(self, aName):
        PandaNode.__init__(self, aName)
        PandaNode.setPythonTag(self, &quot;subclass&quot;, self)
        self.aVariable = &quot;A value&quot;

## Here we create a new node and we are aware we are
## placing its -PandaNode- in the scene graph.
myNewNode = MyNewNode(&quot;MyNewNode&quot;)
aNodePath = aspect2d.attachNewNode(myNewNode)

## Now, first we fetch the panda node:
thePandaNode = aNodePath.node() 

## then we fetch the instance of MyNewNode stored on it:
theInstanceOfMyNewNode = thePandaNode.getPythonTag(&quot;subclass&quot;)

## and finally we fetch the variable we were 
## interested in all along:
print(theInstanceOfMyNewNode.aVariable)
&lt;/code&gt;

===In the real world===
In a real-world scenario, while dealing with many nodes of arbitrary types, things get only marginally more difficult. Ultimately you'll want to access attributes that you know are present on nodes of one or more new subclasses. For this purpose, once you have a handle to the subclass instance, you can either test for the type you are expecting (safe but makes the application more static) or you can test for the presence of the attribute itself (less safe but creates potentially more dynamic, expandable application). 

For example:
&lt;code python&gt;
## here we setup the scene
aNodePath = render.attachNewNode(anInstanceOfMyNewSubclass)
aPandaNode = aNodePath.node()

## here we loop over all nodes under render,  
## to find the one we are interested in:
for child in render.getChildren()
    if child.hasPythonTag(&quot;subclass&quot;):
       theInstanceOfASubclass = child.getPythonTag(&quot;subclass&quot;)

       ## here we test for its type, which is safe
       ## but doesn't catch subclasses of the subclass
       ## or simply other objects that have the same
       ## interface and would work just as well:
       if type(theInstanceOfASubclass ) == type(MyNewSubclass):
           theInstanceOfASubclass.aVariable = &quot;a new value&quot;
           continue

       ## here instead we test for the presence of an
       ## attribute, which mean that all compatible  
       ## objects get modified:
       if hasattr(theInstanceOfASubclass, &quot;aVariable&quot;):
           theInstanceOfASubclass.aVariable = &quot;a new value&quot;
           continue
&lt;/code&gt;

===Conclusion===
In conclusion we might not be able to truly subclass a C++ class from Python, but we can certainly get very close to it. There is of course an overhead and these solutions should not be overused, resorting to pure C++ subclasses where performance is an issue. But where performance is not -as much- of an issue, you can probably get a lot of mileage following the examples provided above and expanding upon them.</text>
    </revision>
  </page>
  <page>
    <title>Table of features supported per graphic renderer</title>
    <ns>0</ns>
    <id>2429</id>
      <sha1>0to2mvt62v1ohfqbxnz2l7czp14dykv</sha1>
    <revision>
      <id>60482</id>
      <timestamp>2015-04-16T16:48:00Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>flesh out list more</comment>
      <text xml:space="preserve" bytes="1200">This is a table of features that are not supported by all of the available Panda3D graphics back-end plug-ins. For brevity, features supported by all of the renderers are omitted.

This is by no means a complete list.  The OpenGL renderer is by far the most complete back-end, and many features that it supports are not yet listed below.

{| border=&quot;1&quot;
!
! OpenGL
! Direct3D 9
! GLES, WebGL
! Tinydisplay
|-
! Rendering
| Hardware
| Hardware
| Hardware
| Software
|-
! Cg shaders
| Yes
| Yes
| No
| No
|-
! GLSL shaders
| Yes
| No
| Yes
| No
|-
! Geometry shaders
| Yes
| No
| No
| No
|-
! Shader generation
| Yes
| Partial
| No
| No
|-
! sRGB support
| Yes
| Yes
| No
| Yes
|-
! Depth textures
| Yes
| No&lt;sup&gt;1&lt;/sup&gt;
| Yes
| No
|-
! 3-D textures
| Yes
| Yes
| Yes
| No
|-
! Buffer textures
| Since 1.10
| No
| No
| No
|-
! Multisampling
| Yes
| Yes&lt;sup&gt;2&lt;/sup&gt;
| Yes
| No
|-
! Thick wireframe
| Yes
| No
| Yes
| No
|-
! Geometry instancing
| Yes
| No
| Since 1.9.1
| No
|}

&lt;sup&gt;1&lt;/sup&gt; You can achieve shadow mapping by using shaders instead of the depth buffer at a minimal performance cost.

&lt;sup&gt;2&lt;/sup&gt; Supported through the configuration setting &lt;code&gt;dx-multisample-antialiasing-level&lt;/code&gt;.</text>
    </revision>
  </page>
  <page>
    <title>Task Chains</title>
    <ns>0</ns>
    <id>2432</id>
      <sha1>3b96w0lk4hiidcre922damk87q5z0os</sha1>
    <revision>
      <id>6409</id>
      <timestamp>2009-12-16T20:05:49Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="6415">When you add tasks to the TaskManager, you are actually adding them to the default &lt;b&gt;Task Chain&lt;/b&gt;.  The TaskManager maintains one or more task chains; each chain is a list of tasks that are available to be executed.

You are free to create additional task chains as you see the need.  Normally, though, there is no reason to have more than the default task chain, unless you wish to take advantage of threaded tasks: each task chain has the option of being serviced by one or more sub-threads, which allows the tasks on that chain to run in parallel with (or at a lower priority than) the main tasks.

Note that threading is an advanced topic, and the use of threading inherently comes with risks.  In particular, it is easy to introduce race conditions or deadlocks in code that involves multiple threads.  You are responsible for protecting critical sections of your code from mutual access with proper use of synchronization primitives, such as provided by Panda's [python]direct.stdpy.threading module[/python][cxx]Mutex and ConditionVar classes[/cxx].  For the purposes of this discussion, we will assume that you are already familiar with the proper use of synchronization primitives in threading.

Note also that Panda may be compiled with a special threading mode (called &quot;simple threads&quot;) that is designed to be low overhead, but which is fundamentally incompatible with true threads as provided by the system library.  Thus, in any Panda application, you must always use Panda's synchronization primitives, and not the system-provided ones; and you must use Panda's thread primitives and not call into the system thread library directly, or you will risk a terrible crash.  [python]That is, you should use direct.stdpy.threading and not the standard threading module.[/python][cxx]That is, you should use Panda's Thread and Mutex classes, and not any system thread or mutex objects.[/cxx]  See [[Threading]] for more.

==Defining task chains==

To set up a new task chain, you simply call:
[cxx]
&lt;code cxx&gt;
AsyncTaskManager *task_mgr = AsyncTaskManager::get_global_ptr();
AsyncTaskChain *chain = task_mgr-&gt;make_task_chain(&quot;chain_name&quot;);
&lt;/code&gt;
Each task chain must have a unique name.  If you pass a name to make_task_chain() that has already been used, it will return the same pointer that was returned previously.

Once you have a task chain pointer, you may then set parameters on that instance to configure the chain according to your needs.

[/cxx]
[python]
&lt;code python&gt;
taskMgr.setupTaskChain('chain_name', numThreads = None, tickClock = None,
                       threadPriority = None, frameBudget = None,
                       frameSync = None, timeslicePriority = None)
&lt;/code&gt;
Task chains are identified by their unique name.  Repeated calls to setupTaskChain() with the same task chain name will reconfigure the same task chain.
[/python]

The task chain parameters are:

{| border=&quot;1&quot;
! Parameter !! Meaning 
|-
| [python]numThreads[/python][cxx]set_num_threads()[/cxx] || Specifies the number of threads that will service this task chain.  The default is zero, which means the task chain will be handled by the main thread.  If you set this to 1, then a single thread will be spawned to handle all of the tasks in the chain one at a time, in the normal order.  If you set this to some number higher than 1, then multiple threads will be spawned to handle the tasks on the chain.  In this case, some of the tasks may be run in parallel with each other, and task ordering is difficult to guarantee.
|-
| [python]tickClock[/python][cxx]set_tick_clock()[/cxx] || If this is true, then this task chain will be responsible for ticking the global clock each frame (and thereby incrementing the frame counter).  There should be just one task chain responsible for ticking the clock, and usually it is the default task chain.
|-
| [python]threadPriority[/python][cxx]set_thread_priority()[/cxx] || This specifies the priority level to assign to threads on this task chain.  It may be one of [func]TP_low[/func], [func]TP_normal[/func], TP[func]_high[/func], or TP[func]_urgent[/func].  This is passed to the underlying threading system to control the way the threads are scheduled.  It only has meaning for a threaded task chain, of course.
|-
| [python]frameBudget[/python][cxx]set_frame_budget()[/cxx] || This is the maximum amount of time (in seconds) to allow this task chain to run per frame.  Set it to -1 to mean no limit (the default).  It's not directly related to threadPriority.
|-
| [python]frameSync[/python][cxx]set_frame_sync()[/cxx] || Set this true to force the task chain to sync to the clock.  When this flag is false, the default, the task chain will finish all of its tasks and then immediately start from the first task again, regardless of the clock frame.  When it is true, the task chain will finish all of its tasks and then wait for the clock to tick to the next frame before resuming the first task.  This only makes sense for threaded tasks chains; non-threaded task chains are automatically synchronous.
|-
| [python]timeslicePriority[/python][cxx]set_timeslice_priority()[/cxx] || This is false in the default mode, in which each task runs exactly once each frame, round-robin style, regardless of the task's priority value.  Set it to true to change the meaning of priority so that certain tasks are run less often, in proportion to their time used and to their priority value. See [func]AsyncTaskManager[::]set_timeslice_priority()[/func] for more.
|}

==Using task chains==

[python]
You may add any tasks to the task chain of your choosing with the optional taskChain parameter to taskMgr.add() or taskMgr.doMethodLater().  This parameter should receive the name of the task chain to add the task to; this is the 'chain_name' you specified in the above call to taskMgr.setupTaskChain().  For example:

&lt;code python&gt;
taskMgr.add(self.myTaskFunc, 'myTaskName', taskChain = 'myChain')
&lt;/code&gt;
[/python]
[cxx]
You may add any tasks to the task chain of your choosing by using AsyncTask::set_task_chain().  This method should receive the string name of the task chain to add the task to; this is the &quot;chain_name&quot; you specified in the above call to task_mgr-&gt;make_task_chain().  For example:

&lt;code cxx&gt;
PT(AsyncTask) task = new GenericAsyncTask(&quot;myTaskName&quot;);
task-&gt;set_function(my_task_func);
task-&gt;set_task_chain(&quot;myChain&quot;);
task_mgr-&gt;add(task);
&lt;/code&gt;
[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Tasks</title>
    <ns>0</ns>
    <id>1023</id>
      <sha1>9cweoi6smgccfl13rsvei76cojfo76b</sha1>
    <revision>
      <id>7435</id>
      <timestamp>2011-12-08T19:48:46Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>typo</comment>
      <text xml:space="preserve" bytes="16419">Tasks are special functions that are called once each frame while your application executes.  They are similar in concept to threads. However, in Panda3D, tasks are not generally separate threads; instead, all tasks are run cooperatively, one at a time, within the main thread.  This design simplifies game programming considerably by removing the requirement to protect critical sections of code from mutual access.  (See Task Chains in the next section if you really want to use threading.)

When you start Panda3D by initializing ShowBase, a handful of tasks are created by default, but you are free to add as many additional tasks as you like.

&lt;h2&gt;The Task Function&lt;/h2&gt;

A task is defined with a function or class method; this function is the main entry point for the task and will be called once per frame while the task is running.  By default, the function receives one parameter, which is the task object; the task object carries information about the task itself, such as the amount of time that the task has been running.

Your task function should return when it has finished processing for the frame.  Because all tasks are run in the same thread, you must not spend too much time processing any one task function; the entire application will be locked up until the function returns.

The task function may return either [python]&lt;code&gt;Task.cont&lt;/code&gt;[/python][cxx]&lt;code&gt;AsyncTask::DS_cont&lt;/code&gt;[/cxx] to indicate that the task should be called again next frame, or [python]&lt;code&gt;Task.done&lt;/code&gt;[/python][cxx]&lt;code&gt;AsyncTask::DS_done&lt;/code&gt;[/cxx] to indicate that it should not be called again. [python]If it returns None (which is to say, it does not return anything), then the default behavior is to stop.[/python]

You can check how long your task has been running by checking [python]&lt;code&gt;task.time&lt;/code&gt;[/python][cxx]&lt;code&gt;task-&gt;get_elapsed_time()&lt;/code&gt;[/cxx] in your task function. You can also check how many times the task function has been run by using [python]&lt;code&gt;task.frame&lt;/code&gt;[/python][cxx]&lt;code&gt;task-&gt;get_elapsed_frames()&lt;/code&gt;[/cxx].

The below example imports the Task module and shows a function used as a task.

[python]&lt;code python&gt;
from direct.task import Task

# This task runs for two seconds, then prints done
def exampleTask(task):
  if task.time &lt; 2.0:
    return task.cont
  print 'Done'
  return task.done
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
#include &quot;asyncTaskManager.h&quot;

// This task runs for two seconds, then prints done
AsyncTask::DoneStatus example_task(GenericAsyncTask* task, void* data){
    if (task-&gt;get_elapsed_time() &lt; 2.0){
        return AsyncTask::DS_cont;
    }
    cout &lt;&lt; &quot;Done&quot; &lt;&lt; endl;
    return AsyncTask::DS_done;
}
&lt;/code&gt;[/cxx]

&lt;h2&gt;Task Return Values&lt;/h2&gt;

The value returned from a task affects how the task manager handles that task going forward.

&lt;center&gt;
&lt;table border=1 cellpadding=1 cellspacing=0&gt;
&lt;tr&gt;
&lt;th&gt;Variable&lt;/th&gt;
&lt;th align=&quot;left&quot;&gt;Purpose&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[python]&lt;code&gt;Task.done&lt;/code&gt;[/python][cxx]&lt;code&gt;AsyncTask::DS_done&lt;/code&gt;[/cxx]
&lt;td&gt;Specifies that a task is finished and removes it from the task manager.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[python]&lt;code&gt;Task.cont&lt;/code&gt;[/python][cxx]&lt;code&gt;AsyncTask::DS_cont&lt;/code&gt;[/cxx]&lt;/td&gt;
&lt;td&gt;Perform the task again next frame.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[python]&lt;code&gt;Task.again&lt;/code&gt;[/python][cxx]&lt;code&gt;AsyncTask::DS_again&lt;/code&gt;[/cxx]&lt;/td&gt;
&lt;td&gt;Perform the task again, using the same delay as initially specified.&lt;/td&gt;
&lt;/tr&gt;
[python]
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;None&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Same as done.&lt;/td&gt;
&lt;/tr&gt;
[/python]
&lt;/table&gt;&lt;/center&gt;

[cxx]
&lt;h2&gt;The Do-Later Task?&lt;/h2&gt;

If you have used Panda3D in Python maybe you are familiar with the Python function &lt;code&gt;taskMgr.doMethodLater()&lt;/code&gt;, which let's you schedule a task to be started after a certain delay. This isn't needed in C++, because you can set a delay on a task directly with &lt;code&gt;task-&gt;set_delay()&lt;/code&gt;. An example will be provided below in the task manager section.
[/cxx]
[python]
&lt;h2&gt;The Do-Later Task&lt;/h2&gt;

A useful special kind of task is the do-later: this is similar to a task, but rather than being called every frame it will be called only once, after a certain amount of time (in seconds) has elapsed.  You can, of course, implement a do-later task with a regular task that simply does nothing until a certain amount of time has elapsed (as in the above example), but using a do-later is a much more efficient way to achieve the same thing, especially if you will have many such tasks waiting around.

&lt;code python&gt;
taskMgr.doMethodLater(delayTime, myFunction, 'Task Name')
&lt;/code&gt;

In this example myFunction must accept a task variable.  If you wish to use a function that does not accept a task variable:

&lt;code python&gt;
taskMgr.doMethodLater(delayTime, myFunction, 'Task Name', extraArgs = [variables])
&lt;/code&gt;

Note: if you wish to call a function which takes no variables simply pass &lt;code&gt;extraArgs = []&lt;/code&gt;

Do-Later task's can be repeated from the task function by returning &lt;code&gt;task.again&lt;/code&gt;. You can also change the delay of the Do-Later task by changing &lt;code&gt;task.delayTime&lt;/code&gt;, but changing this will not have any effect on the task's actual delay time until the &lt;i&gt;next&lt;/i&gt; time it gets added to the do-later list, for instance by returning Task.again.

&lt;code python&gt;
# This task increments itself so that the delay between task executions 
# gradually increases over time. If you do not change task.delayTime
# the task will simply repeat itself every 2 seconds
def myFunction(task):
    print &quot;Delay:&quot;,task.delayTime
    print &quot;Frame:&quot;,task.frame
    task.delayTime += 1
    return task.again

myTask = taskMgr.doMethodLater(2, myFunction, 'tickTask')
&lt;/code&gt;

If you wish to change the delayTime outside of the task function itself, and have it make an immediate effect, you can remove and re-add the task by hand, for instance:
&lt;code python&gt;
taskMgr.remove(task)
task.delayTime += 1
taskMgr.add(task)
&lt;/code&gt;

Although there is a public member &lt;code&gt;task.wakeTime&lt;/code&gt; which stores the time at which the task should wake up, you should not attempt to modify this.  Doing so may appear to work in some simple cases, but will actually invalidate the Task Manager's internal priority queue, potentially causing other tasks to wake up later or sooner than they are supposed to.  (In Panda3D version 1.6 and later, changing this value is specifically disallowed.)
[/python]

&lt;h2&gt;The Task Object&lt;/h2&gt;

The &lt;code&gt;task&lt;/code&gt; object is passed into all Task Functions. There are several members accessible in the func object, [cxx]among[/cxx] these are:

&lt;center&gt;
&lt;table border=1 cellpadding=1 cellspacing=0&gt;
&lt;tr&gt;
&lt;th width=&quot;40%&quot;&gt;Member&lt;/th&gt;
&lt;th align=&quot;left&quot;&gt;Returns&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;task[-&gt;][python]time[/python][cxx]get_elapsed_time()[/cxx]&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;A float that indicates how long this task function has been running since the first execution of the function. The timer is running even when the task function is not being executed.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;task[-&gt;][python]frame[/python][cxx]get_elapsed_frames()[/cxx]&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;An integer that counts the number of elapsed frames since this function was added. Count may start from 0 or 1.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;task[-&gt;][python]id[/python][cxx]get_task_id()[/cxx]&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;An integer that gives the unique id assigned to this task by the Task Manager.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;task[-&gt;][python]name[/python][cxx]get_name()[/cxx]&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;The task name assigned to the task function.&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;

To remove the task and stop it from executing, call &lt;code&gt;task[-&gt;]remove()&lt;/code&gt;.

&lt;h2&gt;The Task Manager&lt;/h2&gt;

[python]All tasks are handled through the global Task Manager object, called &lt;code&gt;taskMgr&lt;/code&gt; in Panda3D.[/python][cxx]All tasks are handled through the Task Manager object. Here we assume that you have obtained a reference to it and stored it in a variable called &lt;code&gt;taskMgr&lt;/code&gt;, for example:

&lt;code cxx&gt;
PT(AsyncTaskManager) taskMgr = AsyncTaskManager::get_global_ptr();
&lt;/code&gt;

[/cxx] The Task Manager keeps a list of all currently-running tasks.[python]To add your task function to the task list, call &lt;code&gt;taskMgr.add()&lt;/code&gt; with your function and an arbitrary name for the task. &lt;code&gt;taskMgr.add()&lt;/code&gt; returns a Task which can be used to remove the task later on.[/python] [cxx]To add a task to the Task Manager, first create a task object by indicating your function and an arbitrary name, and then add it to the task list by calling &lt;code&gt;taskMgr-&gt;add()&lt;/code&gt; with a pointer to your task.[/cxx]

[python]&lt;code python&gt;
taskMgr.add(exampleTask, 'MyTaskName')
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
PT(GenericAsyncTask) task;
task = new GenericAsyncTask(&quot;MyTaskName&quot;, &amp;example_task, (void*) NULL);

taskMgr-&gt;add(task);
&lt;/code&gt;[/cxx]

You can add extra arguments to the call through the [python]extraArgs[/python][cxx]third[/cxx] parameter. [python]When you add extraArgs, the task parameter is no longer sent to your function by default. If you still want it, make sure to set appendTask to true. &lt;code&gt;appendTask=True&lt;/code&gt; makes the task the last argument sent to the function.

&lt;code python&gt;
taskMgr.add(exampleTask, 'MyTaskName', extraArgs=[a,b,c], appendTask=True)
&lt;/code&gt;
[/python]

Although normally each task is given a unique name, you may also create multiple different tasks with the same name.  This can be convenient for [python]removing many task functions at the same time[/python][cxx]locating many related task objects at the same time[/cxx].  Each task remains independent of the others, even if they have the same name; this means that a task function returning [python]&lt;code&gt;Task.done&lt;/code&gt;[/python][cxx]&lt;code&gt;AsyncTask::DS_done&lt;/code&gt;[/cxx] will not affect any other task functions.

[python]&lt;code python&gt;
taskMgr.add(taskFunc, 'Existing TaskName')
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
PT(GenericAsyncTask) task2;
task2 = new GenericAsyncTask(&quot;Existing TaskName&quot;, &amp;example_task, (void*) NULL);
&lt;/code&gt;[/cxx]

[python]
To remove the task and stop it from executing, call &lt;code&gt;taskMgr.remove()&lt;/code&gt;.  You can pass in either the name of the task, or the task object (which was returned by &lt;code&gt;taskMgr.add()&lt;/code&gt;, above).

&lt;code python&gt;
taskMgr.remove('MyTaskName')
&lt;/code&gt;
[/python]
[cxx]
To remove the task and stop it from executing, you can call &lt;code&gt;task-&gt;remove()&lt;/code&gt;.

&lt;code cxx&gt;
task-&gt;remove();
&lt;/code&gt;

A useful task method is &lt;code&gt;task-&gt;set_delay()&lt;/code&gt;; it causes your task to be called after a certain amount of time (in seconds). You can, of course, implement this kind of functionality with an underlayed task that simply does nothing until a certain amount of time has elapsed (as in the above example), but using this method is a much more efficient way to achieve the same thing, especially if you will have many such tasks waiting around. Note that you need to set the delay before you add the task to the Task Manager, otherwise the call won't have an effect.

&lt;code cxx&gt;
task-&gt;set_delay (60);
taskMgr-&gt;add(task);
&lt;/code&gt;


Similarly, if you wish to change the delay time of a task, you have to remove the task and re-add it by hand. For instance:

&lt;code cxx&gt;
task-&gt;remove();
task-&gt;set_delay(10);
taskMgr-&gt;add(task);
&lt;/code&gt;

You can also alter the delay of the task inside the task function, but you will have to return AsyncTask::DS_again afterwards so that it takes effect.

[/cxx]

[python]
You may add a cleanup function to the task function with the uponDeath parameter. Similar to task functions, the uponDeath function has a task object as a parameter.  The cleanup function is called whenever the task finishes, for instance by &lt;code&gt;return Task.done&lt;/code&gt;, or when it is explicitly removed via &lt;code&gt;taskMgr.remove()&lt;/code&gt;.

&lt;code python&gt;
taskMgr.add(exampleTask, 'TaskName', uponDeath=cleanupFunc)
&lt;/code&gt;
[/python]
[cxx]
You may add a cleanup function to the task with the &lt;code&gt;task-&gt;set_upon_death()&lt;/code&gt; function. Similar to task functions, this function receives a function pointer as a parameter.  The cleanup function is called whenever the task finishes, for instance by &lt;code&gt;return AsyncTask::DS_done;&lt;/code&gt;, or when it is explicitly removed via a &lt;code&gt;task-&gt;remove()&lt;/code&gt; call.

&lt;code cxx&gt;
task-&gt;set_upon_death(&amp;cleanupFunc);
&lt;/code&gt;
[/cxx]

To control order in which tasks are executed, you can use sort or priority argument. If you use only sort or only priority, tasks given lesser value will execute sooner.

[python]
&lt;code python&gt;
taskMgr.add(task2, &quot;second&quot;,sort=2)
taskMgr.add(task1, &quot;first&quot; ,sort=1)
&lt;/code&gt;
or
&lt;code python&gt;
taskMgr.add(task2, &quot;second&quot;,priority=2)
taskMgr.add(task1, &quot;first&quot; ,priority=1)
&lt;/code&gt;
In both cases, task1 given name &quot;first&quot; will be executed before task2 (&quot;second&quot;).
[/python]

If you use both sort and priority arguments, tasks with lower sort value will be executed first. However, if there are several tasks which have same sort value, but different priority value then that tasks are going to be executed in a way that ones with HIGHER priority value will be executed first.
[python]
To clarify it a bit, here is code sample, tasks are named in order in which they are executed.
&lt;code python&gt;
taskMgr.add(task1, &quot;first&quot;,  sort=1, priority=2)
taskMgr.add(task2, &quot;second&quot;,sort=1,priority=1)
taskMgr.add(task3, &quot;third&quot;,sort=2, priority=1)
taskMgr.add(task4, &quot;fourth&quot;,sort=3, priority=13)
taskMgr.add(task5, &quot;fifth&quot;,sort=3, priority=4)
&lt;/code&gt;
[/python]

To print the list of tasks currently running, [python]simply print out &lt;code&gt;taskMgr&lt;/code&gt;.[/python][cxx]simply call &lt;code&gt;taskMgr-&gt;write(cout);&lt;/code&gt;.[/cxx] Among your own tasks, you may see the following system tasks listed:

&lt;center&gt;&lt;table border=1 cellpadding=1 cellspacing=0&gt;
&lt;tr&gt;&lt;td&gt;dataloop&lt;/td&gt;&lt;td&gt;      Processes the keyboard and mouse inputs&lt;/td&gt;&lt;/tr&gt;
[python]&lt;tr&gt;&lt;td&gt;tkloop&lt;/td&gt;&lt;td&gt;      Processes Tk GUI events&lt;/td&gt;&lt;/tr&gt;[/python]
&lt;tr&gt;&lt;td&gt;event[python]Manager[/python]&lt;/td&gt;&lt;td&gt;      Processes events generated by C++ code, such as collision events&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;igloop&lt;/td&gt;&lt;td&gt;Draws the scene&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;

[python]
There also is graphical interface for managing tasks. This is very useful for having a look at the tasks while your application is running. 
&lt;code python&gt;
taskMgr.popupControls()
&lt;/code&gt;
[/python]

&lt;h2&gt; Task timing &lt;/h2&gt;

To see the specific timing information for each task when you print taskMgr, add the following line to your Config.prc file

&lt;code&gt;
task-timer-verbose #t
&lt;/code&gt;

(see [[The Configuration File]] for config syntax)

&lt;h2&gt;Examples&lt;/h2&gt;

[python]
&lt;b&gt;uponDeath&lt;/b&gt;

&lt;code python&gt;
taskAccumulator = 0

def cleanUp(task):
  global taskAccumulator
  print &quot;Task func has accumulated&quot;,taskAccumulator
  # Reset the accumulator
  taskAccumulator = 0

# A task that runs forever
def taskFunc(task):
  global taskAccumulator
  taskAccumulator += 1
  return task.cont

def taskStop(task):
  taskMgr.remove('Accumulator')

# Add the taskFunc function with an uponDeath argument
taskMgr.add(taskFunc, 'Accumulator', uponDeath=cleanUp)
# Stops the task 2 seconds later
taskMgr.doMethodLater(2, taskStop, 'Task Stop')
&lt;/code&gt;[/python]
[cxx]
&lt;b&gt;set_upon_death()&lt;/b&gt;

&lt;code cxx&gt;
int task_accumulator = 0;

void clean_up(GenericAsyncTask *task, bool clean_exit, void *user_data) {
    cout &lt;&lt; &quot;Task func has accumulated &quot; &lt;&lt; task_accumulator &lt;&lt; endl;
    //Reset the accumulator
    task_accumulator = 0;
}

// A task that runs forever
AsyncTask::DoneStatus task_func(GenericAsyncTask* task, void* data) {
    task_accumulator++;
    return AsyncTask::DS_cont;
}

AsyncTask::DoneStatus task_stop(GenericAsyncTask* task, void* data) {
    ((GenericAsyncTask*)data)-&gt;remove();
    return AsyncTask::DS_done;
}

// Note that we skip the initialization and finalization of
// the application for the sake of simplifying the example.
int main(int argc, char *argv[]) {

    /* Insert here your app initialization code */
    /* ... */

    PT(GenericAsyncTask) task, stopper_task;
    //Add the task_func function with an upon_death callback
    task = new GenericAsyncTask(&quot;Accumulator&quot;, &amp;task_func, (void*) NULL);
    task-&gt;set_upon_death (&amp;clean_up);
    taskMgr-&gt;add(task);
    //Adds another task to stop the main task 2 seconds later
    stopper_task = new GenericAsyncTask(&quot;Task stopper&quot;, &amp;task_stop, task);
    stopper_task-&gt;set_delay(2);
    taskMgr-&gt;add(stopper_task);

    /* Insert here your app finalization code */
    /* ... */

}

&lt;/code&gt;[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Tasks and Event Handling</title>
    <ns>0</ns>
    <id>977</id>
      <sha1>83naqhrw9rf0ghzxh2ezsivw3olxx3m</sha1>
    <revision>
      <id>35707</id>
      <timestamp>2013-10-30T07:09:26Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <text xml:space="preserve" bytes="320">Tasks are subroutines (functions) that you write that get called by Panda every frame or every specified amount of time. Event handlers are subroutines that you write that get called by Panda when certain special events occur. Together, these two mechanisms enable you to update your Panda world between rendering steps.</text>
    </revision>
  </page>
  <page>
    <title>Terrain</title>
    <ns>0</ns>
    <id>2229</id>
      <sha1>okqg0syauxxbimnn4gxq42zvexvy434</sha1>
    <revision>
      <id>5475</id>
      <timestamp>2008-09-27T07:16:58Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="2117">Panda3D also provides classes for terrain generation. Those classes take a height field image, and generate visible geometry from the provided height field.

If you work with very large terrains, the renderer may not be able to handle such a great amount of triangles. To solve that issue, Panda3D provides LOD (Level of Detail), this means that it will generate the terrain at high quality near the focal point (which is usually the camera), but will provide lower quality terrain - that is, less triangles - because those far away parts are not as much visible as the closer parts.

Panda3D provides two classes for terrain generation and LOD handling:
* The &lt;b&gt;[[HeightfieldTesselator]]&lt;/b&gt;. This class can take a grayscale height field image and generate a terrain. It uses a linear LOD system, and, of course, because when the camera moves away from the focal point, the terrain needs to be regenerated to 'focus' on the new focal point. On extremely large terrains, this might lead to complications, because regenerating the entire terrain takes time, and the player might experience some lag when it is regenerated. That is why this class is not very suitable for extremely large terrains.
* The &lt;b&gt;[[GeoMipTerrain]]&lt;/b&gt;, formerly known as &lt;b&gt;PGMM&lt;/b&gt;. This is a community-contributed terrain system and has been included since Panda3D 1.5.1. This algorithm takes a height field and also converts it into geometry, but it splits the terrain up in smaller chunks, so when the focal point changes, not all chunks have to be regenerated. This is to prevent lagging when the focal point moves. For smaller terrains, however, you might not need such extensive terrain calculations, and use the HeightfieldTesselator instead.
The GeoMipTerrain also provides a way to generate terrain bruteforce, that means without LOD and at full quality.

Various other terrain generators have been contributed by the community:
* [http://panda3d.org/phpbb2/viewtopic.php?t=2265 SoarX]
* [http://panda3d.org/phpbb2/viewtopic.php?t=1200 chombee's terrain renderer]
* [http://panda3d.org/phpbb2/viewtopic.php?t=4408 snaptotheterrain]</text>
    </revision>
  </page>
  <page>
    <title>TextNode</title>
    <ns>0</ns>
    <id>2096</id>
    <redirect title="Text Node" />
      <sha1>aismvwg4a9gsepheqrscu64tu35hlrk</sha1>
    <revision>
      <id>4265</id>
      <timestamp>2007-04-10T14:33:29Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>redirected</comment>
      <text xml:space="preserve" bytes="23">#REDIRECT [[Text Node]]</text>
    </revision>
  </page>
  <page>
    <title>Text Fonts</title>
    <ns>0</ns>
    <id>1109</id>
      <sha1>gow1b2wmwb0cjpnoc5aw6wyljo4ax2f</sha1>
    <revision>
      <id>7828</id>
      <timestamp>2012-07-12T15:22:17Z</timestamp>
      <contributor>
        <username>Dri</username>
        <id>577</id>
      </contributor>
      <text xml:space="preserve" bytes="6534">===Loading a Font===
Panda3D can render text using a variety of fonts.  If your version of Panda3D has been compiled with support for the FreeType library (the default distribution of Panda3D has been), then you can load any TTF file, or any other font file type that is supported by FreeType, directly:

[python]
&lt;code python&gt;
font = loader.loadFont('arial.ttf')
&lt;/code&gt;
[/python]

[cxx]
&lt;code cxx&gt;
PT(TextFont) font=FontPool::load_font(&quot;arial.ttf&quot;);
&lt;/code&gt;
[/cxx]



The named file is searched for along the model-path, just like a regular egg file.  You can also give the full path to the font file if you prefer (but remember to observe the [[Panda Filename Syntax]]).

It is also possible to pre-generate a font with the egg-mkfont command-line utility:

&lt;pre class=&quot;codeblock&quot;&gt;
egg-mkfont -o arial.egg arial.ttf
&lt;/pre&gt;

This will generate an egg file (arial.egg in the above example) and an associated texture file that can then be loaded as if it were a font:

[python]
&lt;code python&gt;
font = loader.loadFont('arial.egg')
&lt;/code&gt;
[/python]

[cxx]
&lt;code cxx&gt;
PT(TextFont) font=FontPool::load_font(&quot;arial.egg&quot;);
&lt;/code&gt;
[/cxx]

There are several options you can specify to the egg-mkfont utility; use &quot;egg-mkfont -h&quot; to give a list.

For example, to generate a font file with foo.png as the texture, instead of the default foo.rgb do the following:

&lt;pre class=&quot;codeblock&quot;&gt;
egg-mkfont -pp foo.png -o foo.egg foo.ttf
&lt;/pre&gt;

The advantages to pre-generating a font are (a) the resulting egg file can be used by a version of Panda that does not include support for FreeType, and (b) you can apply some painterly effects to the generated texture image using Photoshop or a similar program (note that you'll need to open the egg file in a text editor and change the &lt;Texture&gt; entry to replace &quot;alpha&quot; with &quot;rgba&quot;, otherwise the font will appear grayscale).  On the other hand, you have to decide ahead of time which characters you will want to use from the font; the default is the set of ASCII characters.

There are three default font files supplied with the default distribution of Panda3D in the models subdirectory; these are &quot;cmr12.egg&quot;, a Roman font, &quot;cmss12.egg&quot;, a Sans-Serif font, and &quot;cmtt12.egg&quot;, a Teletypewriter-style fixed-width font.  These three fonts were generated from free fonts provided with the Metafont utility (which is not a part of Panda3D).  There is also a default font image which is compiled into Panda if you do not load any other font.

=== Font Quality ===
Occasionally, i.e. when displaying large characters and irrespective of the font used, the default font quality won't be enough and the characters will show noticeable blurring, especially along curving edges. The way to overcome this is to set appropriately the ''pixels per unit'' value of the font object. This is done through the method [func]setPixelPerUnit[/func]() of the class [http://www.panda3d.org/reference/python/classpanda3d_1_1core_1_1DynamicTextFont.php DynamicTextFont], i.e.:

[python]
&lt;code python&gt;
font.setPixelsPerUnit(60)
&lt;/code&gt;
[/python]

[cxx]
&lt;code cxx&gt;
PT(TextFont) font=FontPool::load_font(&quot;arial.ttf&quot;);
PT(DynamicTextFont) dfont=DCAST(DynamicTextFont, font);
dfont-&gt;set_pixels_per_unit(60);
&lt;/code&gt;
[/cxx]


Notice that this method is only available with DynamicTextFont objects. These are the objects created when loading FreeType-compatible fonts such as TTF files. In these cases the font file is loaded into memory and characters are rasterized and mapped onto a polygon as the need arises. Changes to the font object (such as resetting the pixels per unit value) will regenerate the textures for all characters that have been generated so far, a small price to pay for the flexibility of a dynamic font. When a font is loaded from an egg file instead, the returned object is a [http://www.panda3d.org/reference/python/classpanda3d_1_1core_1_1.php StaticTextFont] that provides a much restricted functionality. Effectively these kind of egg files are &quot;frozen&quot; fonts: their characters have been permanently rendered into a texture and cannot be easily changed from inside your application. 

Panda3D defaults to 30 pixels per unit and this is sufficient for small to normal sized on screen text. Should you wish to use higher values and if you experience crashes (this issue should disappear with Panda3D 1.6.3), you might need to increase the page size, normally set to 256 pixels in height and width. To do so you can use the method '''[func]setPageSize[/func](width, height)''', i.e:

[python]
&lt;code python&gt;
font.setPageSize(512,512)
&lt;/code&gt;
[/python]

[cxx]
&lt;code cxx&gt;
dfont-&gt;set_page_size(512,512);
&lt;/code&gt;
[/cxx]

Beware however that this increases the size of the texture for each character, hence increasing memory consumption. I.e. all else being equal a page size of 256x256 (the default) will use a quarter of the memory used with a page size of 512x512 and 1/16th of the memory used by a page size of 1024x1024. 

===Alternative Render Modes===
Fonts loaded through the FreeType library (resulting in a DynamicTextFont object) are normally rasterized into textures and mapped onto polygons, due to the default Render Mode being set to '''[python]TextFont.RMTexture[/python][cxx]TextFont::RM_texture[/cxx]'''. The render mode however changed using the method '''[func]setRenderMode[/func]()''', to allow for radically different generated characters. For example, the following statement ensures that generated characters will be fully three-dimensional, thick, polygonal characters. 

[python]
&lt;code python&gt;
font.setRenderMode(TextFont.RMSolid)
&lt;/code&gt;
[/python]

[cxx]
&lt;code cxx&gt;
dfont-&gt;set_render_mode(TexFont::RM_solid);
&lt;/code&gt;
[/cxx]

[python]
Other available modes are TextFont.RMWireframe, generating characters as polylines, TextFont.RMPolygon, generating characters as flat polygonal objects, and TextFont.RMExtruded, generating characters as extruded polygonal surfaces.
[/python]

[cxx]
Other available modes are TextFont::RM_wireframe, generating characters as polylines, TextFont::RM_polygon, generating characters as flat polygonal objects, and TextFont::RM_extruded, generating characters as extruded polygonal surfaces.
[/cxx]

'''WARNING''': at the time of the writing and with very few exceptions, nearly all tested TTF fonts available on Vista were compatible with the RMTexture render mode. However, many of the same fonts would crash the application if set to a different render mode such as TextFont.RMSolid. (Bug Report [https://bugs.launchpad.net/panda3d/+bug/383251 #383251])</text>
    </revision>
  </page>
  <page>
    <title>Text Node</title>
    <ns>0</ns>
    <id>1110</id>
      <sha1>l7jzhi9549prbwi04ywfllyhske839c</sha1>
    <revision>
      <id>7651</id>
      <timestamp>2012-03-08T18:36:36Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="10234">The most fundamental way to render text in Panda3D is via the &lt;code&gt;TextNode&lt;/code&gt; interface.  This may be a little more work than the [[OnscreenText]] or [[DirectLabel]] objects, but it gives you a lot more control over the appearance of the text.

To use a TextNode, simply create one and call &lt;code&gt;setText()&lt;/code&gt; to set the actual text to display, and then parent the TextNode wherever you like (you can put it under [[Scene Graph Manipulations|aspect2d]] to make a 2-d onscreen text, or you can put it in the 3-d world for in-the-world text).  Note that if you parent the text to render2d or aspect2d, you will probably need to give it a fairly small scale, since the coordinate space of the whole screen in render2d is in the range (-1, 1).

[python]&lt;code python&gt;
text = TextNode('node name')
text.setText(&quot;Every day in every way I'm getting better and better.&quot;)
textNodePath = aspect2d.attachNewNode(text)
textNodePath.setScale(0.07)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
PT(TextNode) text;
text = new TextNode(&quot;node name&quot;);
text-&gt;set_text(&quot;Every day in every way I'm getting better and better.&quot;);
NodePath textNodePath = window-&gt;get_aspect_2d().attach_new_node(text);
textNodePath.set_scale(0.07);
&lt;/code&gt;[/cxx]

[[Image:Text plain.png|A simple TextNode example]]

Note that the TextNode constructor takes a string name, which is not related to the text that is to be displayed.  Also note that the default text color is white; we show it as black in these examples to make it easier to see on the white background.

There are a large number of properties that you can specify on the TextNode to control the appearance of your text.

&lt;h3&gt;Font&lt;/h3&gt;

[python]&lt;code python&gt;
cmr12 = loader.loadFont('cmr12.egg')
text.setFont(cmr12)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
PT(TextFont) cmr12=FontPool::load_font(&quot;cmss12.egg&quot;);
text-&gt;set_font(cmr12);
&lt;/code&gt;[/cxx]

[[Image:Text font.png|TextNode.setFont() example]]

You may use any font you like, including a TTF file; see [[Text Fonts]].

&lt;h3&gt;Small Caps&lt;/h3&gt;

&lt;code python&gt;
text.setSmallCaps(True)
&lt;/code&gt;

[python]&lt;code python&gt;
cmr12 = loader.loadFont('cmr12.egg')
text.setFont(cmr12)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
PT(TextFont) cmr12=FontPool::load_font(&quot;cmss12.egg&quot;);
text-&gt;set_font(cmr12);
&lt;/code&gt;[/cxx]

[[Image:Text smallcaps.png|TextNode.setSmallCaps() example]]

&lt;code&gt;setSmallCaps()&lt;/code&gt; accepts a boolean true or false value; set it true to enable small caps mode.  In this mode, instead of rendering lowercase letters, the TextNode renders capital letters that are a bit smaller than the true capital letters.  This is an especially useful feature if your font of choice doesn't happen to include lowercase letters. 

You can also specify the relative scale of the &quot;lowercase&quot; letters:

[python]&lt;code python&gt;
text.setSmallCapsScale(0.4)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
text-&gt;set_small_caps_scale(0.4);
&lt;/code&gt;[/cxx]

[[Image:Text smallcaps scale.png|TextNode.setSmallCapsScale() example]]

Where 1.0 is exactly the same size as the capital letters, and 0.5 is half the size.  The default is 0.8.

&lt;h3&gt;Slant&lt;/h3&gt;

[python]&lt;code python&gt;
text.setSlant(0.3)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
text-&gt;set_slant(0.3);
&lt;/code&gt;[/cxx]

[[Image:Text slant.png|TextNode.setSlant() example]]

Slant can be used to give an effect similar to italicizing.  The parameter value is 0.0 for no slant, or 1.0 for a 45-degree rightward slant.  Usually values in the range 0.2 to 0.3 give a pleasing effect.  You can also use a negative number to give a reverse slant.

[python]&lt;code python&gt;
text.setTextColor(1, 0.5, 0.5, 1)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
text-&gt;set_text_color(1, 0.5, 0.5, 1);
&lt;/code&gt;[/cxx]

[[Image:Text color.png|TextNode.setColor() example]]

The color is specified with its r, g, b, a components.  Note that if a is not 1, the text will be slightly transparent.

&lt;h3&gt;Shadow&lt;/h3&gt;

[python]&lt;code python&gt;
text.setShadow(0.05, 0.05)
text.setShadowColor(0, 0, 0, 1)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
text-&gt;set_shadow(0.05, 0.05);
text-&gt;set_shadow_color(0, 0, 0, 1);
&lt;/code&gt;[/cxx]

[[Image:Text shadow.png|TextNode.setShadow() example]]

A shadow is another copy of the text, drawn behind the original text and offset slightly to the right and down.  It can help make the text stand out from its background, especially when there is not a high contrast between the text color and the background color.  (The text color in this example is exactly the same pink color used in the example above, but note how much clearer it is with the shadow.)  The downside of a shadow is that it doubles the number of polygons required to render the text.

Setting a shadow requires two calls: &lt;code&gt;setShadow()&lt;/code&gt; accepts a pair of numbers indicating the distance to shift the shadow right and down, respectively, in screen units; these are usually very small numbers like 0.05.  &lt;code&gt;setShadowColor()&lt;/code&gt; accepts the r, g, b, a color of the shadow; the default is black.

&lt;h3&gt;Wordwrap&lt;/h3&gt;

By default, text will be formatted on one line, unless it includes newline characters.  Enabling wordwrap will automatically break the text into multiple lines if it doesn't fit within the specified width.

[python]&lt;code python&gt;
text.setWordwrap(15.0)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
text-&gt;set_wordwrap(15.0);
&lt;/code&gt;[/cxx]

[[Image:Text wordwrap.png|TextNode.setWordwrap() example]]

The parameter to &lt;code&gt;setWordwrap()&lt;/code&gt; should be the maximum width of each line, in screen units.

&lt;h3&gt;Alignment&lt;/h3&gt;

Text is left-aligned by default; that is, it starts at the position you specify with textNodePath.setPos() and goes out to the right from there.  If you have multiple lines of text, you may prefer to center the text or right-align it instead:

[python]&lt;code python&gt;
text.setAlign(TextNode.ACenter)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
text-&gt;set_align(TextNode::A_center);
&lt;/code&gt;[/cxx]

[[Image:Text align.png|TextNode.setAlign() example]]

The parameter to &lt;code&gt;setAlign()&lt;/code&gt; should be one of &lt;code&gt;TextNode.ALeft&lt;/code&gt;, &lt;code&gt;TextNode.ACenter&lt;/code&gt;, or &lt;code&gt;TextNode.ARight&lt;/code&gt;.  Note that changing the alignment of the text will shift its position relative to the starting point; that is, the text is aligned relative to the starting point.

You can also set the alignment to one of &lt;code&gt;TextNode.ABoxedLeft&lt;/code&gt;, &lt;code&gt;TextNode.ABoxedCenter&lt;/code&gt;, or &lt;code&gt;TextNode.ABoxedRight&lt;/code&gt;.  These are similar to the above, but they do not shift the text's position relative to the starting point; the text is aligned within the specified margin, which extends for wordwrap units to the right of the starting point.

&lt;h3&gt;Frame&lt;/h3&gt;

You can specify that a thin frame should be drawn around the entire text rectangle:

[python]&lt;code python&gt;
text.setFrameColor(0, 0, 1, 1)
text.setFrameAsMargin(0.2, 0.2, 0.1, 0.1)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
text-&gt;set_frame_color(0, 0, 1, 1);
text-&gt;set_frame_as_margin(0.2, 0.2, 0.1, 0.1);
&lt;/code&gt;[/cxx]


[[Image:Text frame.png|TextNode.setFrameAsMargin() example]]

As with the shadow, specifying a frame requires two calls; one to specify the color, and another to specify the dimensions of the frame.  The call &lt;code&gt;setFrameAsMargin()&lt;/code&gt; specifies four parameters, which represent the amount of space to insert between the edge of the text and the frame on the left, right, bottom, and top edges, respectively.  All four parameters can be 0.0 to tightly enclose the text (although some fonts render a little bit outside their reported boundaries).

&lt;h3&gt;Card&lt;/h3&gt;

Finally, you can draw a solid card behind the text rectangle:

[python]&lt;code python&gt;
text.setCardColor(1, 1, 0.5, 1)
text.setCardAsMargin(0, 0, 0, 0)
text.setCardDecal(True)
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
text-&gt;set_card_color(1, 1, 0.5, 1);
text-&gt;set_card_as_margin(0, 0, 0, 0);
text-&gt;set_card_decal(true);
&lt;/code&gt;[/cxx]


[[Image:Text card.png|TextNode.setCardAsMargin() example]]

This can also help to make the text easier to read when it is against a similar-colored background.  Often, you will want the card to be semitransparent, which you can achieve by specifying an alpha value of 0.2 or 0.3 to the &lt;code&gt;setCardColor()&lt;/code&gt; method.

The parameters to &lt;code&gt;setCardAsMargin()&lt;/code&gt; are the same as those for &lt;code&gt;setFrameAsMargin()&lt;/code&gt;, above: the distance to extend the card beyond the left, right, bottom, and top edges, respectively.  (In this example, we have both the card and the frame on at the same time, and you can see that the card exactly fits the text, while the frame extends a little bit beyond--showing the effects of the slightly different parameters passed to &lt;code&gt;setFrameAsMargin()&lt;/code&gt; and &lt;code&gt;setCardAsMargin()&lt;/code&gt; in this example.)

If the text is to be visible in the 3-d world (that is, parented to render instead of to render2d), then you may observe z-fighting, or flashing, between the text and the card.  To avoid this, call &lt;code&gt;text.setCardDecal(True)&lt;/code&gt;.  This is not necessary when the text will be parented under render2d or aspect2d, or when you will be controlling the binning of the text explicitly.

&lt;h2&gt; Picking a Text Node &lt;/h2&gt;
Strictly speaking, a TextNode has no geometry, so you can't pick it.

There are two possible workarounds.

(1) Create your own card to go behind the TextNode, using e.g. CardMaker. You should be able to say cardMaker.setFrame(textNode.getFrameActual()) to set the card to be the same dimensions as the text's frame. Then you will need to either offset the text a few inches in front of the card to prevent Z-fighting, or explicitly decal the text onto the card, with something like this:

&lt;code python&gt;
card = NodePath(cardMaker.generate())
tnp = card.attachNewNode(textNode)
card.setEffect(DecalEffect.make())
&lt;/code&gt;

(2) Instead of parenting the TextNode directly to the scene, parent the node returned by textNode.generate() instead. This will be a static node that contains the polygons that render the text. If the text changes in the future, it won't automatically update the geometry in this node; you will have to replace this node with the new result of textNode.generate(). But this node will be 100% pickable. In particular, if you have specified &lt;code&gt;textNode.setCardDecal(True)&lt;/code&gt;, then the first child of the node should be the card geometry.</text>
    </revision>
  </page>
  <page>
    <title>Text Rendering</title>
    <ns>0</ns>
    <id>2048</id>
    <redirect title="Text and Image Rendering" />
      <sha1>fs0f1z2yaeovdtcw16mbgc82sygqbkb</sha1>
    <revision>
      <id>3999</id>
      <timestamp>2006-12-24T16:02:11Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>[[Text Rendering]] moved to [[Text and Image Rendering]]</comment>
      <text xml:space="preserve" bytes="38">#REDIRECT [[Text and Image Rendering]]</text>
    </revision>
  </page>
  <page>
    <title>Text and Image Rendering</title>
    <ns>0</ns>
    <id>1124</id>
      <sha1>jytphxmaevunmvs79yb6fdnlht6cjyz</sha1>
    <revision>
      <id>5076</id>
      <timestamp>2008-03-14T23:58:24Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="1628">Panda includes support for easily rendering dynamic text onscreen or in the 3-d world.  It supports full use of the Unicode character set, so it can easily render international languages (including Asian languages, when used with an appropriate font).

There are three interfaces for creating text, depending on your requirements: the [[Text Node|TextNode]], which is the fundamental text-rendering class and serves as the implementation for the other two, [[OnscreenText]], a simple high-level wrapper around TextNode, [[OnscreenImage]], the same as [[OnscreenText]] but now for images, and [[DirectLabel]], which integrates with the rest of the [[DirectGUI]] system.

&lt;h2&gt;International character sets&lt;/h2&gt;

By default, Panda assumes the text strings you give it are formatted in the &lt;b&gt;iso8859&lt;/b&gt; character set, also called &lt;b&gt;latin-1&lt;/b&gt; on Linux.  This is a standard character set that uses one byte per character and supports most Western European languages, and is likely to be the character set you're using anyway.  If you have need for more characters than are supported by &lt;b&gt;iso8859&lt;/b&gt;, you must use a more advanced encoding system like &lt;b&gt;utf-8&lt;/b&gt; (which may use one, two, or three bytes per character).  To use utf-8, put the following in your Config.prc file:

&lt;pre class=&quot;codeblock&quot;&gt;
text-encoding utf8
&lt;/pre&gt;

And then make sure the strings you pass as text strings are encoded using the &quot;utf-8&quot; encoding method, for instance by saving your Python source files in &quot;utf-8&quot; (this can actually be tricky to do properly in Windows; we recommend you use a non-Microsoft editor such as Emacs or Eclipse to do this).</text>
    </revision>
  </page>
  <page>
    <title>Texture Blend Modes</title>
    <ns>0</ns>
    <id>2168</id>
    <redirect title="Texture Modes" />
      <sha1>ds5uxdfux5sd91qarjp26lrue6l3p9s</sha1>
    <revision>
      <id>4672</id>
      <timestamp>2008-02-24T06:32:04Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <comment>[[Texture Blend Modes]] moved to [[Texture Modes]]: Texture Modes used to be about blending, now there are modes that are not relevant to blending (ie, Normal Map, Gloss Map, etc.)</comment>
      <text xml:space="preserve" bytes="27">#REDIRECT [[Texture Modes]]</text>
    </revision>
  </page>
  <page>
    <title>Texture Combine Modes</title>
    <ns>0</ns>
    <id>1189</id>
      <sha1>oog56541fwc6lm3l57twy2nt2l3bkj4</sha1>
    <revision>
      <id>7636</id>
      <timestamp>2012-03-08T18:00:49Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="5085">{| style=&quot;width:95%; margin:0 auto; background:#FFFACD; border:1px solid orange; text-align:left;&quot;
| Some of the information in this page might not be correct.
&lt;br&gt;See the [[{{NAMESPACE}} talk:{{PAGENAME}}|Discussion page]] for more details.
|}

In addition to the several [[Texture Blend Modes]] described previously, there is a more advanced interface on TextureStage that allows for a larger vocabulary of texture blending options.

Although several of the following options (CMReplace, CMModulate, CMAdd) have obvious parallels with the simpler blend modes described previously, they are in fact more powerful, because with each of the following you may specify the particular source or sources to be used for the operation; you are not limited to simply applying the operation to the top texture and the texture below.

&lt;h2&gt;RGB modes&lt;/h2&gt;

The following specify the effect of the RGB (color) channels.  A separate set of methods, below, specifies the effect of the alpha channel.

&lt;code python&gt;
ts.setCombineRgb(TextureStage.CMReplace, source, operand)
&lt;/code&gt;

This mode is similar to &quot;replace mode&quot;.  Whatever color is specified by source and operand becomes the new color.

&lt;code python&gt;
ts.setCombineRgb(TextureStage.CMModulate, source0, operand0, source1, operand1)
&lt;/code&gt; 

This mode is similar to &quot;modulate mode&quot;.  The color from source0/operand0 is multiplied by the color from source1/operand1.

&lt;code python&gt;
ts.setCombineRgb(TextureStage.CMAdd, source0, operand0, source1, operand1)
&lt;/code&gt; 

This mode is similar to &quot;add mode&quot;.  The color from source0/operand0 is added to the color from source1/operand1, and the result is clamped to 1 (white).

&lt;code python&gt;
ts.setCombineRgb(TextureStage.CMAddSigned, source0, operand0, source1, operand1)
&lt;/code&gt; 

In this mode, the colors are added as signed numbers, and the result wraps.

&lt;code python&gt;
ts.setCombineRgb(TextureStage.CMSubtract, source0, operand0, source1, operand1)
&lt;/code&gt; 

In this mode, source1/operand1 is subtracted from source0/operand0.

&lt;code python&gt;
ts.setCombineRgb(TextureStage.CMInterpolate,
                 source0, operand0, source1, operand1, source2, operand2)
&lt;/code&gt; 

This is the only mode that uses three sources.  The value of source2/operand2 is used to select between source0/operand0 and source1/operand1.  When source2 is 0, source0 is selected, and when source2 is 1, source1 is selected.  When source2 is between 0 and 1, the color is smoothly blended between source0 and source1.

&lt;h2&gt;Alpha modes&lt;/h2&gt;

The following methods more-or-less duplicate the functionality of the above, but they control what happens to the alpha channel.  Thus, you have explicit control over whether an alpha cutout in the top texture should produce an alpha cutout in the resulting object.

&lt;code python&gt;
ts.setCombineAlpha(TextureStage.CMReplace, source, operand)
ts.setCombineAlpha(TextureStage.CMModulate, source0, operand0, source1, operand1)
ts.setCombineAlpha(TextureStage.CMAdd, source0, operand0, source1, operand1)
ts.setCombineAlpha(TextureStage.CMAddSigned, source0, operand0, source1, operand1)
ts.setCombineAlpha(TextureStage.CMSubtract, source0, operand0, source1, operand1)
ts.setCombineAlpha(TextureStage.CMInterpolate, source0, operand0, source1, operand1,
                   source2, operand2)
&lt;/code&gt; 

&lt;h2&gt;Source values&lt;/h2&gt;

This table lists the legal values for any of source, source0, source1, or source2, in the above calls.  This broadly gives you control over which two (or three) textures are used as inputs to the above combine modes.

&lt;table&gt;
&lt;tr&gt;&lt;td&gt;TextureStage.CSTexture&lt;/td&gt;&lt;td&gt;The current, or &quot;top&quot; texture image.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;TextureStage.CSConstant&lt;/td&gt;&lt;td&gt;A constant color, specified via TextureStage.setColor().&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;TextureStage.CSConstantColorScale&lt;/td&gt;&lt;td&gt;The same as CSConstant, but the color will be modified by NodePath.setColorScale().&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;TextureStage.CSPrimaryColor&lt;/td&gt;&lt;td&gt;The &quot;primary&quot; color of the object, before the first texture stage was applied, and including any lighting effects.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;TextureStage.CSPrevious&lt;/td&gt;&lt;td&gt;The result of the previous texture stage; i.e. the texture below.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;TextureStage.CSLastSavedResult&lt;/td&gt;&lt;td&gt;The result of any of the previous texture stages; specifically, the last stage for which TextureStage.setSavedResult(True) was called.&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&lt;h2&gt;Operands&lt;/h2&gt;

This table lists the legal values for any of operand, operand0, operand1, or operand2, in the above calls.  This fine-tunes the channel data that is used from each texture input.

&lt;table&gt;
&lt;tr&gt;&lt;td&gt;TextureStage.COSrcColor&lt;/td&gt;&lt;td&gt;Use the RGB color.  When used in a setCombineAlpha() call, RGB is automatically aggregated into grayscale.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;TextureStage.COOneMinusSrcColor&lt;/td&gt;&lt;td&gt;The complement of the RGB color.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;TextureStage.COSrcAlpha&lt;/td&gt;&lt;td&gt;Use the alpha value.  When used in a setCombineRgb() call, alpha is automatically expanded into uniform RGB.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;TextureStage.COOneMinusSrcAlpha&lt;/td&gt;&lt;td&gt;The complement of the alpha value.&lt;/td&gt;&lt;/tr&gt;</text>
    </revision>
  </page>
  <page>
    <title>Texture Compression</title>
    <ns>0</ns>
    <id>2262</id>
      <sha1>0hy5b7y0n2ka2kp76zf2f9n2smfzz23</sha1>
    <revision>
      <id>5444</id>
      <timestamp>2008-08-30T00:03:15Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="5521">You may be familiar with image file formats like JPEG, which can compress image data dramatically and make image files much smaller than they would be otherwise, in return for sacrificing a tiny bit of the original image quality.

JPEG compression only applies onto to the image size on disk, however.  Once you load a texture image into memory, whether it came from a JPEG, PNG, or TGA file, it always takes up the same amount of texture memory on your graphics card (based on the size of the texture).

There is a different option, however, for compressing texture images in-memory.  Most modern graphics cards can use a handful of run-time compression algorithms to render directly from a texture that has been compressed in-memory.  This is called DXT compression.  It's not really very much like JPEG compression internally, but you can think of it in the same way.  It does have some things in common: it reduces the size of the image dramatically (4 times or even 8 times smaller), and it sacrifices a tiny bit of image quality.

== Runtime texture compression ==

The easiest way to enable compressed texture images is to put the following in your Config.prc file:
&lt;pre class=&quot;codeblock&quot;&gt;
compressed-textures 1
&lt;/pre&gt;

This will ask your graphics driver to compress each texture as it loads.  This means it takes a tiny bit longer to load each texture, but the resulting texture will take up much less space in texture memory.

There's one important advantage to compressing the textures at runtime this way: the graphics driver will be able to compress all the textures using whatever texture compression algorithm it understands, DXT or otherwise.  Not all graphics cards support all compression algorithms, so using this option allows the driver to choose the best algorithm it supports.  If the graphics driver doesn't support any compression algorithms at all, it will simply load the textures uncompressed.  Either way, your application will still run and all of your textures will be visible.

== TXO file format ==

Panda has a native file format for storing texture images, called TXO (the abbreviation is for &quot;texture object&quot;).  This is similar to BAM files.  A TXO file contains all of the texture image data in a format very similar to Panda's internal representation, so it loads into memory very quickly.

More importantly, perhaps, TXO files can optionally store pre-compressed texture images.  You can use the command:
&lt;pre class=&quot;codeblock&quot;&gt;
egg2bam -txo -ctex model.egg -o model.bam
&lt;/pre&gt;
to convert your model to a BAM file, and all of its textures to TXO files, with the image data pre-compressed within the TXO file so that it will not need to be compressed at runtime later.  (You may need to specify &quot;pandagl&quot; instead of &quot;pandadx9&quot; as your rendering engine while you run the egg2bam command--at the time of this writing, there were issues with using Panda's DirectX driver in an offline mode like this.  However, the resulting TXO files will load on either OpenGL or DirectX at runtime.)

TXO files have the same drawbacks as BAM files: they are tied to a particular version of Panda, so you may need to regenerate them when you next upgrade your Panda version.

A bigger drawback to storing pre-compressed texture images this way is that your application might no longer run on all graphics cards.  Not all graphics cards support all kinds of DXT compression, and if you try to load a TXO file that a graphics card doesn't understand, it simply won't load.  Thus, pre-compressing all of your textures may make your application less portable.

== DDS file format ==

In addition to Panda's native TXO file format, there is a fairly standard format called DDS, which has some of the same properties of TXO.  Like TXO, you can store pre-compressed images in a DDS file.  The biggest advantage of the DDS file format is that there are already several tools available on the internet to generate DDS files, including GIMP and Photoshop plugins.  (Note, however, that loading DDS files is a new feature of Panda, and these files are not supported in Panda versions before 1.6.)

Generating your own DDS files has several advantages; chief among them is that you have complete control over the compression artifacts of your texture.  However, it has the same portability issues as storing pre-compressed texture images in TXO files: there is a possibility some graphics cards don't support the texture compression you have used, in which case it simply won't load.

== Texture cache ==

There is a compromise between dynamic compression and pre-compressed textures: you can ask Panda to compress textures on the fly, and then save the resulting compressed image to a TXO file on disk.  The next time you load that particular texture, it will load quickly from its TXO file.  Since the TXO file was generated by the user's graphics driver, it will presumably use a supported compression algorithm.

To enable this feature, simply insert the following lines in your Config.prc file:
&lt;pre class=&quot;codeblock&quot;&gt;
compressed-textures 1
model-cache-dir /c/temp/panda-cache
model-cache-compressed-textures 1
&lt;/pre&gt;
Where model-cache-dir specifies any folder on the disk (it will be created if it doesn't already exist).  Note that the model-cache-dir may already be specified; the default distribution of Panda specifies a model-cache to speed up loading bam files.

Like DDS file format, the model-cache-compressed-textures variable is a new feature in Panda, and isn't available in versions prior to 1.6.</text>
    </revision>
  </page>
  <page>
    <title>Texture Filter Types</title>
    <ns>0</ns>
    <id>1255</id>
      <sha1>1ernfout9nxwlvd8lf972fkx6nxpec6</sha1>
    <revision>
      <id>7633</id>
      <timestamp>2012-03-08T17:55:23Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="5199">It's rare that the pixels of a texture image match one-to-one with
actual screen pixels when a texture is visible onscreen.  Usually, it
is the case that either a single pixel of the texture is stretched
over multiple screen pixels (&lt;b&gt;texture magnification&lt;/b&gt;--the texture image is stretched bigger), or the
opposite, that multiple pixels of a texture contribute to the color of
a single screen pixel (&lt;b&gt;texture minification&lt;/b&gt;--the texture image is squished smaller).  Often, a single
polygon will have some texture pixels that need to be magnified, and
some pixels that need to be minified (the graphics card can handle
both cases on a single polygon).

You can control how the texture looks when it is magnified or minified
by setting its &lt;b&gt;filter type&lt;/b&gt;.

&lt;code python&gt;
texture.setMagfilter(filterType)
texture.setMinfilter(filterType)
&lt;/code&gt;

There is a separate filterType setting for magnification and for
minification.  For both magnification and minification, the filterType
may be one of:

&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;code&gt;Texture.FTNearest&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Sample the nearest pixel.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;code&gt;Texture.FTLinear&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Sample the four nearest
pixels, and linearly interpolate them.&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

For minification only, in addition to the above two choices, you can
also choose from:

&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;code&gt;Texture.FTNearestMipmapNearest&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Point sample the pixel from the nearest mipmap level.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;code&gt;Texture.FTLinearMipmapNearest&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Bilinear filter the pixel from the nearest mipmap level.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;code&gt;Texture.FTNearestMipmapLinear&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Point sample the pixel from two mipmap levels, and linearly blend.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;code&gt;Texture.FTLinearMipmapLinear&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Bilinearly filter the pixel from two mipmap levels, and linearly blend the results.  This is also called &lt;b&gt;trilinear filtering&lt;/b&gt;.&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

The default filter type for both magnification and minification is
&lt;code&gt;FTLinear&lt;/code&gt;.

Consider the visual effects of the various filter types on magnification and
minification of the following texture:

[[Image:fractal.jpg|A fractal image]]

&lt;h2&gt;FTNearest&lt;/h2&gt;

&lt;code python&gt;
texture.setMagfilter(Texture.FTNearest)
texture.setMinfilter(Texture.FTNearest)
&lt;/code&gt;

[[Image:Texture mag nearest.jpg|Magnification w/FTNearest]]
[[Image:Texture min nearest.jpg|Minification w/FTNearest]]

Usually, &lt;code&gt;FTNearest&lt;/code&gt; is used only to achieve a special
pixelly effect.

&lt;h2&gt;FTLinear&lt;/h2&gt;

&lt;code python&gt;
texture.setMagfilter(Texture.FTLinear)
texture.setMinfilter(Texture.FTLinear)
&lt;/code&gt;

[[Image:Texture mag linear.jpg|Magnification w/FTLinear]]
[[Image:Texture min linear 0.jpg|Minification w/FTLinear]]

&lt;code&gt;FTLinear&lt;/code&gt; is a good general-purpose choice, though it
isn't perfect.

&lt;h2&gt;Mipmaps&lt;/h2&gt;

Many graphics tutorials will go on for pages and pages about exactly
what mipmapping means and how it all works inside.  We'll spare you
those details here; but you should understand the following things
about mipmapping:

(1) It requires 33% more texture memory (per mipmapped texture), but
it renders quickly.

(2) It helps the texture look much smoother than filtering alone when
it is minified.

(3) Mipmapping doesn't have anything at all to do with magnification.

(4) It has a tendency to blur minified textures out a little too much,
especially when the texture is applied to a polygon that is very
nearly edge-on to the camera.

There are four different filter types that involve mipmapping, but you
almost always want to use just the last one,
&lt;code&gt;FTLinearMipmapLinear&lt;/code&gt;.  The other modes are for advanced
uses, and sometimes can be used to tweak the mipmap artifacts a bit
(especially to reduce point 4, above).  If you don't understand the description in the table above, it's not worth worrying about.

&lt;code python&gt;
texture.setMinfilter(Texture.FTLinearMipmapLinear)
&lt;/code&gt;

[[Image:Texture min mipmap 0.jpg|Minification w/FTLinearMipmapLinear]]

&lt;h2&gt;Anisotropic Filtering&lt;/h2&gt;

There is one final addition to the texture filtering equation: you can
enable anisotropic filtering on top of any of the above filter modes,
which enables a more expensive, slightly slower rendering mode that
generally produces superior effects.  In particular, anisotropic
filtering is usually better at handling texture minification than
mipmapping, and doesn't tend to blur out the texture so much.

To enable anisotropic filtering, you specify the degree:

&lt;code python&gt;
texture.setAnisotropicDegree(degree)
&lt;/code&gt;

The degree should be an integer number.  The default value is 1, which
indicates no anisotropic filtering; set it to a higher number to
indicate the amount of filtering you require.  Larger numbers are more
expensive but produce a better result, up to the capability of your
graphics card.  Many graphics cards don't support any degree other
than 2, which is usually sufficient anyway.

&lt;code python&gt;
texture.setAnisotropicDegree(2)
&lt;/code&gt;

[[Image:Texture mag aniso.jpg|Magnification w/anisotropic filtering]]
[[Image:Texture min aniso.jpg|Minification w/anisotropic filtering]]

Some older graphics cards cannot perform anisotropic filtering.</text>
    </revision>
  </page>
  <page>
    <title>Texture Management</title>
    <ns>0</ns>
    <id>2263</id>
      <sha1>gte5yyw8v00zjhnzf0b87h0khtnxj7j</sha1>
    <revision>
      <id>5445</id>
      <timestamp>2008-08-30T00:07:28Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="3824">Different graphics cards provide different amounts of texture memory.  If you're loading a lot of different textures, especially if they're large, you can easily consume all of your available texture memory.  In principle, this shouldn't cause problems, as long as you don't have all of your textures onscreen at once: both OpenGL and DirectX are supposed to automatically evict textures from graphics memory as needed.

In practice, it doesn't always work this cleanly.  In some integrated graphics cards, the &quot;graphics memory&quot; is actually your system memory, so the graphics driver never needs to evict textures--but if you load too many textures, there may not be enough memory left for your application.  Furthermore, some graphics drivers have major bugs that manifest as you start to approach the limit of your graphics memory, causing strange rendering artifacts or even crashes.

For these reasons, it may be useful to limit the amount of graphics memory your application uses.  Panda provides several tools to help with this.

== Automatically reducing textures ==

You can reduce textures automatically as they are loaded.  The easiest way to do this is to put a line like:
&lt;pre class=&quot;codeblock&quot;&gt;
texture-scale 0.5
&lt;/pre&gt;
in your Config.prc file.  The above example will scale all textures by a factor of 0.5 in each dimension (for an overall reduction to 1/4 of the total memory requirement).  If there are certain textures that should not be scaled, for instance GUI textures, you can exclude them with lines like:
&lt;pre class=&quot;codeblock&quot;&gt;
exclude-texture-scale digits_*.png
exclude-texture-scale gui*.jpg
&lt;/pre&gt;

== Enabling texture compression ==

Another possibility is to enable and use [[Texture Compression]], as described on the next page.  If supported by your graphics card, this will reduce texture memory requirements dramatically, to 1/4 or 1/8 of the original.  There is some reduction of quality, but not as much as the quality reduction you'd get from downscaling the textures by the equivalent amount.  It is also possible to enable texture compression in conjunction with texture scaling.

== Limiting graphics memory usage overall ==

Finally, it may be prudent to limit the amount of graphics memory that Panda attempts to use, with a line like:
&lt;pre class=&quot;codeblock&quot;&gt;
graphics-memory-limit 67108864
&lt;/pre&gt;
The above example imposes a limit of 64MB (64 * 1024 * 1024) on the graphics memory that Panda will attempt to use.  This can be a good idea to avoid allocating runaway textures on integrated graphics cards with no fixed texture limit, or to work around buggy graphics drivers that crash when you use too much.  Panda will automatically start to unload textures when the specified limit is exceeded, even if the graphics driver would allow allocating more.

Ideally, it would be great to query the amount of useful graphics memory provided by the card, and set this as the graphics-memory-limit; unfortunately, this is impractical for several reasons, including the reasons given above.  Typically, if you wish your application to work on a variety of hardware, you will need to come up with a handful of default settings and allow the user to select between them, according to his own knowledge of his hardware capabilities.

Note that graphics-memory-limit is a new feature of Panda, and is not available in versions before Panda3D 1.6.

== Monitoring memory usage ==

You can see how much graphics memory you are actually consuming with the [[Measuring_Performance_with_PStats|PStats]] tool.  Select the &quot;Graphics memory&quot; option.  This graph will show the amount of memory required for active (onscreen), and inactive (offscreen) textures.  It also includes memory required for vertex and index buffers, though these are typically much smaller than your texture memory requirements.</text>
    </revision>
  </page>
  <page>
    <title>Texture Management and Optimizations</title>
    <ns>0</ns>
    <id>2161</id>
      <sha1>phoiac9h4m842xq45sp7s6u21eteeq1</sha1>
    <revision>
      <id>5443</id>
      <timestamp>2008-08-29T04:46:03Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="0" />
    </revision>
  </page>
  <page>
    <title>Texture Modes</title>
    <ns>0</ns>
    <id>1188</id>
      <sha1>spio4v3sxiuur6m7bh927z3zhczemjp</sha1>
    <revision>
      <id>6529</id>
      <timestamp>2010-01-11T11:39:00Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>more parallax mapping</comment>
      <text xml:space="preserve" bytes="13615">There are several kinds of textures: color textures, normal maps, gloss maps, glow maps, and so forth.  To distinguish these, use the &lt;code&gt;TextureStage[::][func]setMode[/func]&lt;/code&gt; function. 

Futhermore, within the general category of color textures, there are several ways to combine the colors: Modulate, Decal, Blend, and so forth.  These, too, are controlled using the &lt;code&gt;TextureStage[::][func]setMode[/func]&lt;/code&gt; function.

&lt;h2&gt;The Basics&lt;/h2&gt;

Let's go back to the example of applying a texture to the smiley model.  In this case, we'll create a new TextureStage to apply the following texture image:

[[Image:Color pattern.png|Sample multitexture image]]

To this scene:

[[Image:Smiley multitex none.png|Smiley with no multitexture]]

Note that the circular white part of the sample image is actually not white at all, but an alpha cutout (you are seeing through the image to the white page background).  We have rendered smiley.egg against a colored background so you can see the effects of alpha in the various modes below; in some of them, the alpha is propagated through to the final color, so smiley is transparent in those parts of the image, but in other modes, the alpha is used for a different purpose, and smiley is not transparent there.

Note also that, for the purposes of illustration, we have only applied the sample texture image to a portion of the smiley model, rather than to the whole model.  (This was done by transforming the texture coordinates of this texture stage, which is covered in [[Texture Transforms|a later topic]].)

&lt;h2&gt;Modulate mode&lt;/h2&gt;

This is the default blend mode.  In this mode, the top texture color is multiplied by the bottom texture color to produce the result.  This means the resulting texture color will be darker (or at least, no brighter) than both of the original texture colors.

[python]&lt;code python&gt;
ts = TextureStage('ts')
ts.setMode(TextureStage.MModulate)
smiley.setTexture(ts, tex)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
PT(TextureStage) ts = new TextureStage(&quot;ts&quot;);
ts-&gt;set_mode(TextureStage::M_modulate);
smiley.set_texture(ts, tex);
&lt;/code&gt;[/cxx]

[[Image:Smiley multitex modulate.png|Modulate blend mode]]

Note that in this mode, an alpha cutout in the top texture produces an alpha cutout in the resulting image.

&lt;h2&gt;Add mode&lt;/h2&gt;

In this mode, the top texture color is added to the bottom texture color, and clamped to 1 (white).  This means the resulting texture color will be brighter (or at least, no darker) than both of the original texture colors.

[python]&lt;code python&gt;
ts = TextureStage('ts')
ts.setMode(TextureStage.MAdd)
smiley.setTexture(ts, tex)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
PT(TextureStage) ts = new TextureStage(&quot;ts&quot;);
ts-&gt;set_mode(TextureStage::M_add);
smiley.set_texture(ts, tex);
&lt;/code&gt;[/cxx]

[[Image:Smiley multitex add.png|Add blend mode]]

Note that in this mode, as in modulate mode, an alpha cutout in the top texture produces an alpha cutout in the resulting image.  Also note that, unless one or both of your source textures was rather dark, there is a tendency for the colors to get washed out at white where everything clamps to 1.

&lt;h2&gt;Replace mode&lt;/h2&gt;

In this mode the top texture completely replaces the bottom texture.  This mode is not often used.

[python]&lt;code python&gt;
ts = TextureStage('ts')
ts.setMode(TextureStage.MReplace)
smiley.setTexture(ts, tex)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
PT(TextureStage) ts = new TextureStage(&quot;ts&quot;);
ts-&gt;set_mode(TextureStage::M_replace);
smiley.set_texture(ts, tex);
&lt;/code&gt;[/cxx]

[[Image:Smiley multitex replace.png|Replace blend mode]]

Note that the alpha cutout is preserved, but the effects of lighting (which are considered part of the underlying texture) have been lost.

&lt;h2&gt;Decal mode&lt;/h2&gt;

In this mode the top texture completely replaces the bottom texture, but only where alpha = 1 in the top texture.  When alpha = 0, the bottom texture shows through, and there is a smooth blending for alpha values between 0 and 1.

[python]&lt;code python&gt;
ts = TextureStage('ts')
ts.setMode(TextureStage.MDecal)
smiley.setTexture(ts, tex)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
PT(TextureStage) ts = new TextureStage(&quot;ts&quot;);
ts-&gt;set_mode(TextureStage::M_decal);
smiley.set_texture(ts, tex);
&lt;/code&gt;[/cxx]

[[Image:Smiley multitex decal 1.png|Decal blend mode]]

Note that the alpha cutout is no longer preserved in this mode, because alpha is used to determine which texture should be visible.  Also note that the effects of lighting are lost for the decalled part of the texture.

Panda3D also provides a built-in decal capability, for rendering a small polygon coplanar with and embedded within a larger polygon, which is not related to the decal texture blend mode.

&lt;h2&gt;Blend mode&lt;/h2&gt;

Blend mode is similar to decal mode, except you can specify the color of the decal as a parameter at runtime.  You can vary the color and you don't have to have a different texture image prepared for each possible color.  However, the decal will always be monochromatic (it will be drawn in different shades of whatever color you specify).

Blend mode can only be used with a grayscale texture, and it does not use alpha.  Since the sample texture above is not a grayscale texture, we will use a different texture for this example:

[[Image:White a.png]]

This texture does not have an alpha channel; it is simply a grayscale image with a large white &quot;A&quot; on a field of black.  Blend mode will produce the original color where the image is black, and the color we specify with &lt;code&gt;TextureStage.setColor()&lt;/code&gt; where the image is white.  Where the image is shades of gray, there will be a smooth blending between the colors.

[python]&lt;code python&gt;
ts = TextureStage('ts')
ts.setMode(TextureStage.MBlend)
ts.setColor(Vec4(1, 0, 0, 1))
smiley.setTexture(ts, tex)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
PT(TextureStage) ts = new TextureStage(&quot;ts&quot;);
ts-&gt;set_mode(TextureStage::M_blend);
ts-&gt;set_color(LVector4f(1, 0, 0, 1));
smiley.set_texture(ts, tex);
&lt;/code&gt;[/cxx]

[[Image:Smiley multitex blend red.png|Blend mode, with a red image]]

And we can change the color of the decal at will, simply with:

[python]&lt;code python&gt;
ts.setColor(Vec4(0, 0, 1, 1))
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
ts-&gt;set_color(LVector4f(0, 0, 1, 1));
&lt;/code&gt;[/cxx]

[[Image:Smiley multitex blend blue.png|Blend mode, with a blue image]]

Note that, as with the decal example above, the lighting information is lost where the decal is applied.

&lt;h2&gt;Normal Map Mode&lt;/h2&gt;

Normal maps are maps that cause surfaces to appear to have raised and lowered areas.  They are also called &quot;bump maps.&quot;  Unlike most maps, normal maps do not affect the color of the model - they affect the lighting.  When light hits a normal-mapped model, the light creates highlights and shadows throughout those ridges and bumps.  If no lights are applied to the model, then there will be no shadows or highlights, and the normal map will be invisible.  Currently, Panda3D only allows one normal map per polygon, additional normal maps will be ignored.

[python]&lt;code python&gt;
ts = TextureStage('ts')
ts.setMode(TextureStage.MNormal)
smiley.setTexture(ts, tex)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
PT(TextureStage) ts = new TextureStage(&quot;ts&quot;);
ts-&gt;set_mode(TextureStage::M_normal);
smiley.set_texture(ts, tex);
&lt;/code&gt;[/cxx]

The creation of normal maps is a sufficiently complex process that it is beyond the scope of this manual.  However, there are many good tools out there like Z-Brush, Crazy Bump, and the like which create normal maps.

See also: [[Sample Programs: Normal Mapping]]

Normal maps are new to Panda3D as of version 1.5.0.  They only function when [[The Shader Generator|shader generation]] is enabled.

&lt;h2&gt;Height / Parallax Map Mode&lt;/h2&gt;

&lt;b&gt;This feature is new as of Panda3D 1.7.0.&lt;/b&gt;&lt;br /&gt;
As an addition to normal mapping, you can specify a grayscale height map to enable parallax mapping.  This technique offsets the UV coordinates based on the height value and eye normal vector, so the resulting surface will have more apparent depth.  Currently, Panda only supports one height map per polygon, additional height maps will be ignored.

[python]&lt;code python&gt;
ts = TextureStage('ts')
ts.setMode(TextureStage.MHeight)
smiley.setTexture(ts, tex)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
PT(TextureStage) ts = new TextureStage(&quot;ts&quot;);
ts-&gt;set_mode(TextureStage::M_height);
smiley.set_texture(ts, tex);
&lt;/code&gt;[/cxx]

Since parallax mapping doesn't look very good without normal mapping, they are often used both together.  As an optimization, most people prefer to store the height map into the alpha channel of the normal map.  If you are using such a packed normal/height map, you need to use the MNormalHeight mode in Panda:

[python]&lt;code python&gt;
# The second parameter to loadTexture will be stored in the texture's alpha channel.
tex = loader.loadTexture(&quot;normalmap.png&quot;, &quot;heightmap.png&quot;)

ts = TextureStage('ts')
ts.setMode(TextureStage.MNormalHeight)
smiley.setTexture(ts, tex)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
# The second parameter to load_texture will be stored in the texture's alpha channel.
PT(Texture) tex = TexturePool::load_texture(&quot;normalmap.png&quot;, &quot;heightmap.png&quot;);

PT(TextureStage) ts = new TextureStage(&quot;ts&quot;);
ts-&gt;set_mode(TextureStage::M_normal_height);
smiley.set_texture(ts, tex);
&lt;/code&gt;[/cxx]

By default, the parallax mapping algorithm will use 3 samples, and the effect will be scaled by 0.1. To change these parameters, use the following Config.prc lines:
&lt;code prc&gt;
parallax-mapping-samples 3
parallax-mapping-scale 0.1
&lt;/code&gt;
The amount of samples is how accurate the parallax mapping will be.  Lower values are cheaper, but the result will be less accurate.  The scale is the magnitude of the effect - with a lower value the effect decreases, with a higher value the surface will have more apparent depth (although the artifacts due to lack of occlusion will be more visible). Use a negative value to invert the effect (this has the same effect as inverting the heightmap).

&lt;h2&gt;Gloss Map Mode&lt;/h2&gt;

A gloss map is a black-and-white image indicating where the model is supposed to be shiny and where it is supposed to be dull.  Gloss maps do not affect the color of the model - they affect the degree to which the model reflects specular highlights.  So if no lights are applied to the model, and thus there are no specular highlights at all, then the gloss map will be invisible.

More precisely, the gloss map affects the material specular color of the model. If the model already has a material specular color, then it is multiplied by the value (0-1) in the gloss map.  In this way, the gloss map can effectively turn on or off the specularity on a per-pixel basis.  If the model does not already have a material specular color specified, then applying a gloss map causes the material specular color to range from off to bright white.

A gloss map must be an alpha-texture:

[python]&lt;code python&gt;
ts = TextureStage('ts')
ts.setMode(TextureStage.MGloss)
smiley.setTexture(ts, tex)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
PT(TextureStage) ts = new TextureStage(&quot;ts&quot;);
ts-&gt;set_mode(TextureStage::M_gloss);
smiley.set_texture(ts, tex);
&lt;/code&gt;[/cxx]

If you wish, you can pack a modulate-texture and a gloss-map into a single RGBA texture.  In that case, the RGB components are just regular color values that are modulated onto the model, and the A controls gloss:

[python]&lt;code python&gt;
ts = TextureStage('ts')
ts.setMode(TextureStage.MModulateGloss)
smiley.setTexture(ts, tex)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
PT(TextureStage) ts = new TextureStage(&quot;ts&quot;);
ts-&gt;set_mode(TextureStage::M_modulate_gloss);
smiley.set_texture(ts, tex);
&lt;/code&gt;[/cxx]

Currently, Panda3D only allows one gloss map per polygon, additional gloss maps will be ignored.

Gloss maps are new to Panda3D as of version 1.5.0.  They only function when [[The Shader Generator|shader generation]] is enabled.

&lt;h2&gt;Glow Map Mode&lt;/h2&gt;

A glow map is a black-and-white texture which indicates that a model should be glowing in certain areas.  More specifically, the contents of the glow map are added to the material emission.  This causes those parts of the model to be lit even when the lights are otherwise off.

In practice, though, things don't really look like they're glowing unless you apply a bloom filter to your scene.  Panda can be made to copy the contents of your glow map into the framebuffer alpha, from which it can be read by the bloom filter.  The bloom filter then really creates a dramatic glow effect.  All of this is documented in the chapter on the bloom filter.

A glow map must be an alpha-texture:

[python]&lt;code python&gt;
ts = TextureStage('ts')
ts.setMode(TextureStage.MGlow)
smiley.setTexture(ts, tex)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
PT(TextureStage) ts = new TextureStage(&quot;ts&quot;);
ts-&gt;set_mode(TextureStage::M_glow);
smiley.set_texture(ts, tex);
&lt;/code&gt;[/cxx]

If you wish, you can pack a modulate-texture and a glow-map into a single RGBA texture.  In that case, the RGB components are just regular color values that are modulated onto the model, and the A controls glow:

[python]&lt;code python&gt;
ts = TextureStage('ts')
ts.setMode(TextureStage.MModulateGlow)
smiley.setTexture(ts, tex)
&lt;/code&gt;[/python][cxx]&lt;code cxx&gt;
PT(TextureStage) ts = new TextureStage(&quot;ts&quot;);
ts-&gt;set_mode(TextureStage::M_modulate_glow);
smiley.set_texture(ts, tex);
&lt;/code&gt;[/cxx]

Currently, Panda3D only allows one glow map per polygon, additional glow maps will be ignored.

See also: [[Sample Programs: Glow Filter]]

Glow maps are new to Panda3D as of version 1.5.0.  They only function when [[The Shader Generator|shader generation]] is enabled.</text>
    </revision>
  </page>
  <page>
    <title>Texture Order</title>
    <ns>0</ns>
    <id>1190</id>
      <sha1>ijv79abuvw9xqt58qh42ktkwukccydw</sha1>
    <revision>
      <id>6176</id>
      <timestamp>2009-09-28T08:53:06Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="1573">When there are multiple textures in effect, depending on the [[Texture Blend Modes|Texture Blend Mode]] in use, it may be important to control the order in which the textures apply.  For instance, although Modulate mode and Add mode are order-independent, texture order makes a big difference to Decal mode, Replace mode, and Blend mode.

To specify the texture order, use &lt;code&gt;TextureStage[::][func]setSort[/func]()&lt;/code&gt; on one or more of your TextureStages.  If you do not specify a sort value, the default sort value is 0.  When the geometry is rendered, all of the textures are rendered in increasing order of sort value, such that the largest sort value is rendered on top.  Thus, if you want to use Decal mode, for instance, to apply a texture on top of a lower texture, it would be a good idea to use [func]setSort[/func]() to give a higher sort value to your decal texture.

Also, since some hardware might not be able to render all of the TextureStages that you have defined on a particular node, Panda provides a way for you to specify which texture(s) are the most important.  Use &lt;code&gt;TextureStage[::][func]setPriority[/func]()&lt;/code&gt; for this.

The priority value is only consulted when you have applied more TextureStages to a particular node than your current hardware can render.  In this case, Panda will select the n textures with the highest priority value (and then sort them in order by the [func]setSort[/func]() value).  Between two textures with the same priority, Panda will prefer the one with the lower sort value.  The default priority is 0.</text>
    </revision>
  </page>
  <page>
    <title>Texture Replacement</title>
    <ns>0</ns>
    <id>1024</id>
      <sha1>gpelc2w54en2rvbeeqsd1217tkptbsw</sha1>
    <revision>
      <id>2314</id>
      <timestamp>2005-04-16T21:43:47Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="1241">&lt;p&gt;
When an actor egg file is created, some optimization occurs and the model hierarchy is hidden from view. While normally this optimization is a good thing, if you want to change textures on a specific part of the model (for example, just a character's face) you will need access to this geometry hiearchy. This is where egg-optchar.exe is helpful again. Egg-optchar allows you to rename, duplicate character joints and perform other functions on a model with a skeleton.  See [[Actor Manipulations]] for more information.&lt;/p&gt;

&lt;p&gt;
To be able to make the geometry visible as a node in the resulting model, you can use the following option:

&lt;table class=&quot;code&quot;&gt;
  &lt;tr&gt;
    &lt;td&gt;-flag &lt;name of geometry part in original model&gt;=&lt;desired name of part in Panda3D&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

A specific example:

&lt;table class=&quot;code&quot;&gt;
  &lt;tr&gt;
    &lt;td&gt;egg-optchar -flag face=face char_model.egg&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;


&lt;p&gt;
&lt;b class = &quot;code&quot;&gt; &quot;-flag *=*&quot;&lt;/b&gt; will keep all geometry named as they were in the original model.
&lt;/p&gt;

Now to swap textures in Panda3D you just need to find that geomnode, in our case suppose it's &quot;face&quot;:
&lt;table class=&quot;code&quot;&gt;
  &lt;tr&gt;
    &lt;td&gt;actorName.actor.find(&quot;**/face&quot;).setTexture(newTexture,1)&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;


&lt;/p&gt;</text>
    </revision>
  </page>
  <page>
    <title>Texture Replacement on sub-parts of an Actor</title>
    <ns>0</ns>
    <id>1071</id>
      <sha1>6jl8o8ewf4yz5nvj7n4gdghdj27lw72</sha1>
    <revision>
      <id>2288</id>
      <timestamp>2005-04-30T00:27:39Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="1805">
Every model, when loaded, becomes a &lt;i&gt;modelnode&lt;/i&gt; in the scene graph.  Beneath the &lt;i&gt;modelnode&lt;/i&gt; are one or more &lt;i&gt;geomnodes&lt;/i&gt; containing the actual polygons.  To change the texture of a piece of a model, you need a pointer to the relevant geomnode.

In order to obtain such a pointer, you must first ensure that the relevant geometry is in a &lt;i&gt;geomnode&lt;/i&gt; of its own (and not merged with all the other geometry).  In other words, you must ensure that panda's optimization mechanisms do not cause the geometry to be merged with the geometry of the rest of the model. While normally this optimization is a good thing, if you want to change textures on a specific part of the model (for example, just a character's face) you will need this geometry to be separate.

This is where the utility program &lt;i&gt;egg-optchar&lt;/i&gt; is helpful. Among other things, egg-optchar allows you to label a section of a model for later manipulation.  Once you have labeled a piece of geometry, panda's optimization mechanisms will not fold it in to the rest of the model.

Your first step is to note the name of the object in your modeling program.  For example, suppose you want to control the texture of a model's head, and suppose (hypothetically) the head is labeled &quot;Sphere01&quot; in your modeling program.  Use egg-optchar to tell panda that &quot;Sphere01&quot; deserves to be kept separate and labeled:

egg-optchar -flag Sphere01=theHead myEggFile.egg

The &quot;-flag&quot; switch will ensure that panda does not rearrange the geometry at that node, folding it into the model as a whole.  It also assigns the geometry a meaningful name.

To swap textures on the head, you must search the scene graph for the necessary geomnode.  The relevant function is &lt;i&gt;node.find&lt;/i&gt;: 

myActor.actor.find(&quot;**/theHead&quot;).setTexture(newTexture,1)</text>
    </revision>
  </page>
  <page>
    <title>Texture Transforms</title>
    <ns>0</ns>
    <id>1191</id>
      <sha1>8961contusozte1csbtgp9q6gnm219c</sha1>
    <revision>
      <id>7421</id>
      <timestamp>2011-12-08T15:00:34Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="3543">It is possible to apply a matrix to transform the (u, v) texture
coordinates of a model before rendering.  In this way, you can adjust
the position, rotation, or scale of a texture, sliding the texture
around to suit your particular needs.

Use the following NodePath methods to do this:

&lt;code python&gt;
nodePath.setTexOffset(TextureStage, uOffset, vOffset)
nodePath.setTexScale(TextureStage, uScale, vScale)
nodePath.setTexRotate(TextureStage, degrees)
&lt;/code&gt;

If you don't have a particular TextureStage, use
&lt;code&gt;TextureStage.getDefault()&lt;/code&gt; as the first parameter.

Note that the operation in each case is applied to the (u, v) texture
coordinates, not to the texture; so it will have the opposite effect
on the texture.  For instance, the call &lt;code&gt;nodePath.setTexScale(ts,
2, 2)&lt;/code&gt; will effectively double the values of the texture
coordinates on the model, which doubles the space over which the texture is applied, and thus makes the texture appear half as large.

The above methods apply a 2-d transform to your texture
coordinates, which is appropriate, since texture coordinates are
usually two-dimensional.  However, sometimes you are working with [[3-D Textures|3-d texture coordinates]], and you really do want to apply a 3-d transform.  For those cases, there are the following methods:

&lt;code python&gt;
nodePath.setTexPos(TextureStage, uOffset, vOffset, wOffset)
nodePath.setTexScale(TextureStage, uScale, vScale, wScale)
nodePath.setTexHpr(TextureStage, h, p, r)
&lt;/code&gt;

And there is also one generic form:

&lt;code python&gt;
nodePath.setTexTransform(TextureStage, transform);
&lt;/code&gt;

This last method sets a generic
TransformState object.  This is the same kind of 4x4 transform matrix
object that you can get from a NodePath via e.g.,
&lt;code&gt;NodePath.getTransform()&lt;/code&gt;.  You can also construct a new TransformState
via a number of methods like &lt;code&gt;TransformState.makePos(VBase3(0, 1, 0))&lt;/code&gt;.  If you intend to apply a 2-d transform only, you should restrict yourself to methods like &lt;code&gt;TransformState.makePos2d(VBase2(0, 1))&lt;/code&gt;; using only 2-d operations may allow the graphics backend to use a slightly simpler calculation.

Note that the texture transform is associated with a particular
TextureStage; it is not a fixed property of the model or its texture
coordinates.  You can therefore apply a different texture transform to
each different TextureStage, so that if you have multiple textures in
effect on a particular node, they need not all be in the same place,
even if they all use the same texture coordinates.  For instance, this
technique was used to generate the sample images in the [[Texture Blend Modes]] section.  In fact, the following code was used to place this
sample texture (excerpted):

&lt;code python&gt;
smiley = loader.loadModel('smiley.egg')
ts = TextureStage('ts')
pattern = loader.loadTexture('color_pattern.png')
smiley.setTexture(ts, pattern)
smiley.setTexScale(ts, 8, 4)
smiley.setTexOffset(ts, -4, -2)
&lt;/code&gt;

and the resulting texture:

[[Image:Smiley multitex decal 1.png|Multitexture sample]]

In the above example, we have applied a scale of (8, 4) to reduce the
size of the decal image substantially, and then we specified an offset
of (-4, -2) to slide it around in the positive (u, v) direction to
smiley's face (since the (0, 0) coordinate happens to be on smiley's
backside).  However, these operations affect only the decal image; the
original smiley texture is unchanged from its normal position, even
though both textures are using the same texture coordinates.</text>
    </revision>
  </page>
  <page>
    <title>Texture Wrap Modes</title>
    <ns>0</ns>
    <id>1245</id>
      <sha1>tne2uwd1y3fjik55w416m08nyouzogk</sha1>
    <revision>
      <id>60215</id>
      <timestamp>2014-07-24T18:03:27Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>use proper syntaxhighlight tags</comment>
      <text xml:space="preserve" bytes="6862">As described earlier, the ''(u, v)'' texture coordinates that you assign to your vertices
are what determines how the texture fits on your geometry.  Often, you will use
texture coordinates that always fall within the range [0, 1], which is
the complete range of the pixels of your texture image.  However, it is
also legal to use texture coordinates that go outside this range; you can
have negative values, for instance, or numbers higher than 1.

So if the texture image is only defined over the range [0, 1], what does
the texture look like outside this range?  You can specify this with
the '''texture wrap mode'''.

[python]&lt;syntaxhighlight lang=&quot;python&quot;&gt;
texture.setWrapU(wrap_mode)
texture.setWrapV(wrap_mode)
&lt;/syntaxhighlight&gt;[/python]
[cxx]&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
texture-&gt;set_wrap_u(wrap_mode);
texture-&gt;set_wrap_w(wrap_mode);
&lt;/syntaxhighlight&gt;[/cxx]

The wrap_mode parameter is specified separately for the ''u'' and
''v'' directions (there is also a &lt;code&gt;[func]setWrapW[/func]()&lt;/code&gt; for
[[3-D Textures|3-D textures]], but that's an advanced topic).  The
wrapMode may be any of the following values:

{|
|&lt;code&gt;Texture[::]WM_repeat&lt;/code&gt;
|The texture image repeats to infinity.
|-
|&lt;code&gt;Texture[::]WM_clamp&lt;/code&gt;
|The last pixel of the texture image stretches out to infinity.
|-
|&lt;code&gt;Texture[::]WM_border_color&lt;/code&gt;
|The color specified by &lt;code&gt;texture[-&gt;][func]setBorderColor[/func]()&lt;/code&gt; is used to fill the space.
|-
|&lt;code&gt;Texture[::]WM_mirror&lt;/code&gt;
|The texture image flips back-and-forth to infinity.
|-
|&lt;code&gt;Texture[::]WM_mirror_once&lt;/code&gt;
|The texture image flips backwards, once, and then the &quot;border color&quot; is used.
|}

The default wrap mode is &lt;code&gt;WM_repeat&lt;/code&gt;.

Consider the following simple texture image:

[[Image:Small r.png|black_r.png]]

We will apply this texture in the center of a large polygon whose
texture coordinates range considerably farther than [0, 1] in both
directions.

== WM_repeat ==

[python]&lt;syntaxhighlight lang=&quot;python&quot;&gt;
texture.setWrapU(Texture.WM_repeat)
texture.setWrapV(Texture.WM_repeat)
&lt;/syntaxhighlight&gt;[/python]
[cxx]&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
texture-&gt;set_wrap_u(Texture::WM_repeat);
texture-&gt;set_wrap_v(Texture::WM_repeat);
&lt;/syntaxhighlight&gt;[/cxx]

[[Image:Texture repeat.png|WM_repeat]]

&lt;code&gt;WM_repeat&lt;/code&gt; mode is often used to tile a relatively small
texture over a large surface.

== WM_clamp ==

[python]&lt;syntaxhighlight lang=&quot;python&quot;&gt;
texture.setWrapU(Texture.WM_clamp)
texture.setWrapV(Texture.WM_clamp)
&lt;/syntaxhighlight&gt;[/python]
[cxx]&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
texture-&gt;set_wrap_u(Texture::WM_clamp);
texture-&gt;set_wrap_v(Texture::WM_clamp);
&lt;/syntaxhighlight&gt;[/cxx]

[[Image:Texture clamp.png|WM_clamp]]

&lt;code&gt;WM_clamp&lt;/code&gt; mode is rarely used on large polygons because, frankly, it looks terrible when the pixels stretch out to infinity like this; but this mode is usually the right choice when the texture exactly fills its polygon (see ''One caution about a common wrap error,'' below).

== WM_border_color ==

[python]&lt;syntaxhighlight lang=&quot;python&quot;&gt;
texture.setWrapU(Texture.WM_border_color)
texture.setWrapV(Texture.WM_border_color)
texture.setBorderColor(VBase4(0.4, 0.5, 1, 1))
&lt;/syntaxhighlight&gt;[/python]
[cxx]&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
texture-&gt;set_wrap_u(Texture::WM_border_color);
texture-&gt;set_wrap_v(Texture::WM_border_color);
texture-&gt;set_border_color(Colorf(0.4, 0.5, 1, 1));
&lt;/syntaxhighlight&gt;[/cxx]

[[Image:Texture border color blue.png|WM_border_color]]

The above blue color was chosen for illustration purposes; you can use
any color you like for the border color.  Normally, you would use the background
color of the texture as the border color, like this:

[python]&lt;syntaxhighlight lang=&quot;python&quot;&gt;
texture.setWrapU(Texture.WMBorderColor)
texture.setWrapV(Texture.WMBorderColor)
&lt;/syntaxhighlight&gt;[/python]
[cxx]&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
texture-&gt;set_wrap_u(Texture::WM_border_color);
texture-&gt;set_wrap_v(Texture::WM_border_color);
texture-&gt;set_border_color(Colorf(1, 1, 1, 1));
&lt;/syntaxhighlight&gt;[/cxx]

[[Image:Texture border color white.png|WMBorderColor]]

Some very old graphics drivers don't support
&lt;code&gt;WM_border_color&lt;/code&gt;.  In this case, Panda3D will fall back to
&lt;code&gt;WM_clamp&lt;/code&gt;, which will look similar as long as there is a
sufficient margin of background color around the edge of your texture (unlike our sample texture, which goes all the way out the edge).

== WM_mirror ==

[python]&lt;syntaxhighlight lang=&quot;python&quot;&gt;
texture.setWrapU(Texture.WM_mirror)
texture.setWrapV(Texture.WM_mirror)
&lt;/syntaxhighlight&gt;[/python]
[cxx]&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
texture-&gt;set_wrap_u(Texture::WM_mirror);
texture-&gt;set_wrap_v(Texture::WM_mirror);
&lt;/syntaxhighlight&gt;[/cxx]

[[Image:Texture mirror.png|WM_mirror]]

Many older graphics drivers do not support &lt;code&gt;WM_mirror&lt;/code&gt;.  In
this case, Panda3D will fall back to &lt;code&gt;WM_repeat&lt;/code&gt;.

== WM_mirror_once ==

[python]&lt;syntaxhighlight lang=&quot;python&quot;&gt;
texture.setWrapU(Texture.WM_mirror_once)
texture.setWrapV(Texture.WM_mirror_once)
texture.setBorderColor(VBase4(0.4, 0.5, 1, 1))
&lt;/syntaxhighlight&gt;[/python]
[cxx]&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
texture-&gt;set_wrap_u(Texture::WM_mirror_once);
texture-&gt;set_wrap_v(Texture::WM_mirror_once);
texture-&gt;set_border_color(Colorf(0.4, 0.5, 1, 1));
&lt;/syntaxhighlight&gt;[/cxx]

[[Image:Texture mirror once.png|WM_mirror_once]]

Few graphics drivers support &lt;code&gt;WM_mirror_once&lt;/code&gt;.  In this case,
Panda3D will fall back to &lt;code&gt;WM_border_color&lt;/code&gt;.

== Setting different wrap modes ==

It is possible to set different wrap modes in the ''u'' and
''v'' directions:

[python]&lt;syntaxhighlight lang=&quot;python&quot;&gt;
texture.setWrapU(Texture.WM_repeat)
texture.setWrapV(Texture.WM_clamp)
&lt;/syntaxhighlight&gt;[/python]
[cxx]&lt;syntaxhighlight lang=&quot;cpp&quot;&gt;
texture-&gt;set_wrap_u(Texture::WM_repeat);
texture-&gt;set_wrap_v(Texture::WM_clamp);
&lt;/syntaxhighlight&gt;[/cxx]

[[Image:Texture clamp repeat.png|WM_clamp and WM_repeat]]

== One caution about a common wrap mode error ==

When you apply a texture that is intended to exactly fill a
polygon--that is, the texture coordinates range from 0 to 1, but no
further--you should usually set its wrap mode to ''clamp''.  This
is because if you let it keep the default value of ''repeat'', the
color may bleed in from the opposite edge, producing a thin line along
the edge of your polygon, like this:

[[Image:Texture wrap error.png|A common wrap mode error]]

This is a particularly common error with a texture that is painted as
an alpha cutout, where there is an image with a fully transparent
background: you will often see an thin, barely-visible edge floating
along the top (for instance) of the polygon.  This edge is actually
the bottom edge of the texture bleeding onto the top, because the
designer specified &lt;code&gt;WM_repeat&lt;/code&gt; instead of
the correct mode, &lt;code&gt;WM_clamp&lt;/code&gt;.</text>
    </revision>
  </page>
  <page>
    <title>Texturing</title>
    <ns>0</ns>
    <id>1065</id>
      <sha1>tpm2rpra16j7qaq744q3jlu633gupge</sha1>
    <revision>
      <id>6459</id>
      <timestamp>2009-12-30T20:06:35Z</timestamp>
      <contributor>
        <username>Nemesis</username>
        <id>193</id>
      </contributor>
      <comment>fixed the confusion about relative and absolute paths</comment>
      <text xml:space="preserve" bytes="596">At its simplest, texturing merely consists of applying a texture in your modeling program. When you export the model, the path to the texture and some options for it like filtering or repeat-method (see next pages) are saved into the egg file.
The texture paths can be either relative (as seen from the egg file) or absolute (full path). See [[Loading Models]] for more info about Panda's Filename Syntax. In most cases the relative path makes more sense.

Panda can load JPG, PNG, TIF, and a number of other file formats.

More advanced texturing methods are described in the following sections.</text>
    </revision>
  </page>
  <page>
    <title>Texturing in CXX</title>
    <ns>0</ns>
    <id>2162</id>
      <sha1>at4u2akwi1e4xt9uam38gog0lvhxwpe</sha1>
    <revision>
      <id>7044</id>
      <timestamp>2011-01-18T16:08:43Z</timestamp>
      <contributor>
        <username>Treeform</username>
        <id>163</id>
      </contributor>
      <minor/>
      <comment>fixed a small C++ error</comment>
      <text xml:space="preserve" bytes="1353">[python]This page is related to C++ usage of Panda3D and not to Python usage. If you are a Python user, please skip this page. For C++ users, please toggle to the C++ version of this page.[/python]
[cxx]
== Texturing in C++ ==
Panda's C++ interface to texturing is basically the same as it's Python interface, That's why it is very recommended to read the entire section including the Python examples.

However, there are two major differences, which are explained in this page.


&lt;b&gt;1.&lt;/b&gt; C++ does not have a loader.loadTexture. You need to use the TexturePool to load textures. Please note that the Texture class is [[reference counted]].
&lt;code cxx&gt;include &quot;texturePool.h&quot;

PT(Texture) tex;
tex = TexturePool::load_texture(&quot;maps/noise.rgb&quot;);

NodePath smiley;
smiley = window-&gt;load_model(window-&gt;get_render(),&quot;smiley.egg&quot;);
smiley.set_texture(tex, 1);&lt;/code&gt;


&lt;b&gt;2.&lt;/b&gt; You don't directly need CardMaker to display your texture in a 2D or 3D scene. You can load it as if it were a model, and treat it like any other model.
&lt;code cxx&gt;NodePath noiseplane;
noiseplane = window-&gt;load_model(window-&gt;get_render(), &quot;maps/noise.rgb&quot;);&lt;/code&gt;
This short piece of code will result in a single polygon in the scene with the noise texture applied to it.
If you need it in the 2d scene, you can use get_aspect2d() or get_render2d() instead of get_render().[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>The 2D Display Region</title>
    <ns>0</ns>
    <id>2313</id>
      <sha1>12410bhqauqnwdh9aesfdsmdvvaf7gb</sha1>
    <revision>
      <id>7669</id>
      <timestamp>2012-03-08T20:02:58Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="3397">There is one more DisplayRegion that Panda normally creates automatically for the main window.  This is the 2-D DisplayRegion that renders the onscreen GUI or heads-up display.  It is simply another DisplayRegion that covers the entire screen, like the 3-D DisplayRegion it layers on top of, except that its camera has an [[Orthographic Lenses|Orthographic Lens]] instead of a normal [[Lens and Field of View|Perspective Lens]].

[[Image:DisplayRegion_gui.jpg]]

This is the DisplayRegion associated with render2d, and is normally used to render all of the gui elements and onscreen text items you may lay on top of the screen.

If you are creating a secondary window or buffer, and you would like to layer 2-D elements on top of the screen, you can do so by simply creating a 2-D scene similar to render2d.  Some sample code to do so is shown here:

&lt;code python&gt;
dr = win.makeDisplayRegion()
dr.setSort(20)

myCamera2d = NodePath(Camera('myCam2d'))
lens = OrthographicLens()
lens.setFilmSize(2, 2)
lens.setNearFar(-1000, 1000)
myCamera2d.node().setLens(lens)

myRender2d = NodePath('myRender2d')
myRender2d.setDepthTest(False)
myRender2d.setDepthWrite(False)
myCamera2d.reparentTo(myRender2d)
dr.setCamera(myCamera2d)
&lt;/code&gt;

The first group of commands creates a new DisplayRegion on the window and sets its sort value to 20, so that it will be drawn after the main DisplayRegion has been drawn.  This is important in order to layer text on top of the 3-D scene, of course.

The second group of commands creates a camera with an OrthographicLens.  The lens is created with a wide near/far clipping plane: -1000 to 1000.  This probably doesn't matter too much since we expect that everything we parent to this scene graph will have a Y value of 0 (which is easily between -1000 and 1000), but this allows us to accept a wide range of Y values.

The third group of commands sets up the myRender2d scene graph.  It is just an ordinary node, with a few properties set on it, and the 2-D camera we have just created attached to it.  We turn off the depth test and depth write properties because these are not important for a 2-D scene graph, and we don't want them to get in the way of our gui elements.

==DirectGui in your new window==

Note that if you wish to create any [[DirectGUI|DirectGui]] elements, like buttons or other clickable widgets, in the new 2-D scene graph, and interact with them, you have just a bit more set-up to do.  DirectGui has a special mechanism to connect it to the mouse pointer, which requires that all of its interactive objects be attached directly or indirectly to a PGTop node.  In the default main window, this PGTop node is aspect2d, a special node created both to compensate for the non-square aspect ratio of the window, and also to be the special PGTop node required by DirectGui.  If you are creating your own 2-D scene graph, you can create your own aspect2d node something like this:

&lt;code python&gt;
aspectRatio = base.getAspectRatio()
myAspect2d = myRender2d.attachNewNode(PGTop('myAspect2d'))
myAspect2d.setScale(1.0 / aspectRatio, 1.0, 1.0)
myAspect2d.node().setMouseWatcher(base.mouseWatcherNode)
&lt;/code&gt;

If this is for a different window than base.win, you will probably need to also create your own MouseWatcher, other than base.mouseWatcherNode, to manage the mouse associated with your new window.  See elsewhere for more information about this.</text>
    </revision>
  </page>
  <page>
    <title>The Canvas Class</title>
    <ns>0</ns>
    <id>2478</id>
      <sha1>025ezngd1izm0s92f3vtex0ys2mk0v5</sha1>
    <revision>
      <id>6738</id>
      <timestamp>2010-03-11T09:16:14Z</timestamp>
      <contributor>
        <username>Gogg</username>
        <id>389</id>
      </contributor>
      <text xml:space="preserve" bytes="4339">((This feature is not published yet, I'm just using this orphaned page to document as I code and to put my thoughts in order. Also, this will be usable from Python but I'll start writing everything in C++ until I'm happy with the API))

&lt;h2&gt;The Canvas class&lt;/h2&gt;

The Canvas facility in Panda3D allows you to create or manipulate 2D graphics procedurally. Unlike the PNMPainter class, it can draw directly on textures, giving a big performance boost if you need to draw on textures on a per-frame basis. Also, unlike the PNMPainter class, it is a fully featured 2D drawing library. The Canvas class supports:

* Drawing directly into panda RAM Textures. The texture must be uncompressed and be 32 bits per channel. By default, the Canvas class will create a texture for you with the correct format that you can later retrieve and use in Panda, though you can also supply your own.
* Drawing directly into a buffer of your choice by passing a pointer. This buffer is also assumed to be 32 bits.
* Writing to and loading from Texture objects.
* Writing to and loading from PNMImage objects.
* Writing to and loading from any file format supported by your Panda version.
* Drawing ellipses, rectangles and arbitrary polygons (close or open.)
* Drawing text.
* Gradient or solid-colored brushes.
* Variable thickness pens. (Dashed pens coming soon.)
* Blend operations: you can blend one Canvas object into another by a given opacity value and mask. Supported blend modes are: normal, darken, multiply, lighten, screen, difference, hue, saturation, color, luminosity.
* Adjustment filters: Hue, saturation, lightness, brightness, contrast, invert.
* Effect filters: 3x3 Blur.
* Subpixel precision anti-aliasing in both text and shapes (like modern commercial Operating Systems), as opposed to Freetype's simple anti-aliasing used by Panda on text nodes.
* All drawing operations have subpixel precision (floating number space), although you can also set and retrieve the color of individual pixels in integer space.
* Resize operations: resize (bicubic, bilinear or simple), crop.
* Channel operations: swap, copy.

Internally, it uses Freetype 2 for obtaining the outlines of text glyphs and the Antigrain 2.4 library for rasterization of shapes and text. For compatibility with Panda3D it uses internally the BGRA format, although due to the nature of color operations, this normally doesn't matter (although for some operations the alpha channel has special meaning, so it should still be the fourth channel).

&lt;h2&gt;Initializing a Canvas&lt;/h2&gt;

There are many ways to initialize the Canvas class depending on your needs.

The simplest way is just passing the width and height, Canvas will create a Texture object internally, you can later retrieve that texture and use it in Panda3D.

&lt;code cxx&gt;
Canvas * canvas = new Canvas(256,256);
PT(Texture) texture = canvas-&gt;get_texture();
&lt;/code&gt;

Note that you can draw on the canvas before or after retrieving the texture and the texture will be updated since both canvas and texture are using the same storage here.

You can also use the Canvas to draw on external storage, like for example an already existing Panda texture. In this case you just have to make sure that the texture is uncompressed. The texture must also be 32 bits, and an internal BGRA format is assumed, although you shouldn't have to worry about this as this is already the default format. In the following example we create the texture from scratch, but you could also load it from disk.

&lt;code cxx&gt;
PT(Texture) texture = new Texture();
texture-&gt;set_compression(Texture::CM_off);
// Don't pay attention to the fact the format here says rgb rather than bgr.
texture-&gt;setup_2d_texture(512, 512, Texture::T_unsigned_int_24_8, Texture::F_rgba8);

Canvas * canvas = new Canvas(texture-&gt;modify_ram_image(), 512, 512);
&lt;/code&gt;

You can also create a Canvas that uses internal storage but doesn't create a Texture object. This is useful is you just want to create temporary Canvas objects for use as a layer in blending operations, more on this later.

&lt;code cxx&gt;
// False here means: don't create a texture.
Canvas * canvas = new Canvas(256, 256, false);
&lt;/code&gt;

&lt;h2&gt;Loading from and writing to files &lt;/h2&gt;
&lt;h2&gt;Drawing shapes &lt;/h2&gt;
&lt;h2&gt;Drawing text &lt;/h2&gt;
&lt;h2&gt;Adjustments and other simple operations&lt;/h2&gt;
&lt;h2&gt;Blending operations&lt;/h2&gt;</text>
    </revision>
  </page>
  <page>
    <title>The Configuration File</title>
    <ns>0</ns>
    <id>1072</id>
      <sha1>0rvgj3tttm307fqjs02r7kzxjxslub4</sha1>
    <revision>
      <id>4124</id>
      <timestamp>2007-02-19T10:15:17Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>double page.</comment>
      <text xml:space="preserve" bytes="74">This section will explain about the configuration files that Panda3D uses.</text>
    </revision>
  </page>
  <page>
    <title>The Default Camera Driver</title>
    <ns>0</ns>
    <id>1025</id>
      <sha1>2fj9gev6h8swmkmttw8w84h1n65gnsg</sha1>
    <revision>
      <id>7645</id>
      <timestamp>2012-03-08T18:17:59Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="2453">By default, panda runs a task that enables you to move the camera using the mouse.  This task will conflict with any code you write to move the camera.  The task controls the camera by updating the camera's position every frame to where the mouse thinks it should be.  This means that any other code that directly controls the camera will not seem to work, because it will be fighting the mouse for control.

If you want to move the camera directly under show control, you must first disable the camera control task and then the camera will move as expected.

&lt;code python&gt;
base.disableMouse()
&lt;/code&gt;

The ShowBase class contains some handy methods to allow the user control over the camera. The &lt;code&gt;useDrive()&lt;/code&gt; command enables keyboard and mouse control. Both control systems move only on the x and y axes, so moving up and down along the z axis is impossible with these systems.

The keyboard system uses the arrow keys. Up moves the camera forward, and down move it back. The left and right arrows turn the camera.

The mouse system responds whenever any button is held. If the pointer is towards the top of the screen, the camera moves forward. If it is towards the bottom, the camera moves backwards. If it is on either side, the camera rotates to that direction. The speed the camera moves is determined by how far from the center the mouse pointer is. Additionally, there is another command that allows control based on trackball mice.

&lt;code python&gt;
base.useDrive()
base.useTrackball()
&lt;/code&gt;

ShowBase also provides the method &lt;code&gt;oobe()&lt;/code&gt; to give you to control of the basic camera node (base.cam) with the mouse/trackball while the code continues to move the camera node (base.camera).  This can be useful for debugging purposes.  The word stands for &quot;out-of-body experience&quot; and is handy for giving you a God's-eye view of your application at any point in development.  The method is a toggle; call it once to enable OOBE mode, and then again to disable it.

&lt;code python&gt;
base.oobe()
&lt;/code&gt;

&lt;code&gt;oobeCull()&lt;/code&gt; is a variant on &lt;code&gt;oobe()&lt;/code&gt;, and it works similarly, except that it still culls the scene as if the camera were still in its original position, while drawing the scene from the point of view of your camera's new position. So now you can view the scene from your &quot;out of body&quot; placement, and walk around, and you can see things popping in and out of view as your view frustum moves around the world.</text>
    </revision>
  </page>
  <page>
    <title>The Global Clock</title>
    <ns>0</ns>
    <id>1709</id>
      <sha1>6frxei0urph4rmfyfjnghmnw9l7g99k</sha1>
    <revision>
      <id>6880</id>
      <timestamp>2010-06-16T18:01:12Z</timestamp>
      <contributor>
        <username>Croxis</username>
        <id>430</id>
      </contributor>
      <minor/>
      <comment>Fixed to new api page</comment>
      <text xml:space="preserve" bytes="896">The global clock is an instance of the [http://www.panda3d.org/reference/python/class!panda3d.core.ClockObject ClockObject] class. [python]It gets imported into the global namespace when you load the DirectStart/Showbase modules.[/python][cxx]There's a single instance of it already initialized that you can access statically.[/cxx]

To get the time (in seconds) since the last frame was drawn:
[python]&lt;code python&gt;
dt = globalClock.getDt()
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
double dt = ClockObject::get_global_clock()-&gt;get_dt();
&lt;/code&gt;[/cxx]

Another useful function is the frame time (in seconds, since the program started):
[python]&lt;code python&gt;
frameTime = globalClock.getFrameTime()
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
double frame_time = ClockObject::get_global_clock()-&gt;get_frame_time();
&lt;/code&gt;[/cxx]

&lt;h2&gt;Incomplete Section&lt;/h2&gt;

Note: this section is incomplete.  It will be updated soon.</text>
    </revision>
  </page>
  <page>
    <title>The GraphicsOutput class</title>
    <ns>0</ns>
    <id>1151</id>
      <sha1>noz86m58c73yvsdsio7cla54uez51jn</sha1>
    <revision>
      <id>7728</id>
      <timestamp>2012-03-10T07:05:21Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="6903">Buffers and windows, encapsulated in the &lt;code&gt;GraphicsBuffer&lt;/code&gt; and &lt;code&gt;GraphicsWindow&lt;/code&gt; classes are almost interchangable in Panda. In fact most operations in the &lt;code&gt;GraphicsEngine&lt;/code&gt; class are defined on and return &lt;code&gt;GraphicsOutput&lt;/code&gt; objects, the class that both &lt;code&gt;GraphicsBuffer&lt;/code&gt; and &lt;code&gt;GraphicsWindow&lt;/code&gt; inherit from. Therefore, we will discuss the properties of &lt;code&gt;GraphicsOutput&lt;/code&gt; objects first.

The first very important note is that none of these classes are meant to be constructed directly, i.e.:
&lt;code python&gt;
myOutput=GraphicsOutput() 
myWindow=GraphicsWindow()
myBuffer=GraphicsBuffer()
&lt;/code&gt;
will not work. Refer to [[The Graphics Engine]] for how to create these objects. Furthermore, since &lt;code&gt;GraphicsOutput&lt;/code&gt; is an abstract class, &lt;code&gt;GraphicsWindow&lt;/code&gt; objects will be used in code examples. 

All &lt;code&gt;GraphicsOutput&lt;/code&gt; objects have &lt;code&gt;getGsg()&lt;/code&gt;, &lt;code&gt;getPipe()&lt;/code&gt;, and &lt;code&gt;getName()&lt;/code&gt; which return respectively their  [[The Graphics Engine|GraphicsStateGuardian]], [[The Graphics Pipe| GraphicsPipe]], and [[The Graphics Engine|name]]. You can also get the width and height using &lt;code&gt;getXSize()&lt;/code&gt; and &lt;code&gt;getYSize()&lt;/code&gt;.

&lt;code python&gt;
from panda3d.core import GraphicsWindow

#assume we already have a window setup and in myWindow
myWindowGsg=myWindow.getGsg()
myWindowPipe=myWindow.getPipe()
myWindowName=myWindow.getName()

myWindowWidth=myWindow.getXSize()
myWindowLength=myWindow.getYSize()
&lt;/code&gt;

You can also save a screenshot from any &lt;code&gt;GraphicsOutput&lt;/code&gt; by using &lt;code&gt;saveScreenShot(fileName)&lt;/code&gt;, where &lt;code&gt;fileName&lt;/code&gt; is the name of the picture(the format of the picture is specified by the extension of &lt;code&gt;filename&lt;/code&gt;). Returns &lt;code&gt;True&lt;/code&gt; upon succes and &lt;code&gt;False&lt;/code&gt; otherwise. The picture is saved in the directory of the script you are running.

&lt;code python&gt;
from panda3d.core import Filename
myWindow.saveScreenShot(Filename('hello.bmp'))
&lt;/code&gt;

This naturally flows into rendering into a texture. We'll start with copying a scene. If you want to get a texture that simply copies what's in its &lt;code&gt;GraphicsOutput&lt;/code&gt; object, you must first make a call to &lt;code&gt;setupCopyTexture()&lt;/code&gt;. You can then get the texture by using &lt;code&gt;getTexture()&lt;/code&gt;. You can now [[Simple Texture Replacement|apply the texture to a NodePath]] as you would a texture loaded from memory. Thanks to the magic of pointers, the texture automatically updates itself if the contents of its &lt;code&gt;GraphicsOutput&lt;/code&gt; change. If you do not want this behaviour you should use &lt;code&gt;detachTexture()&lt;/code&gt; when you no longer want the texture to be updated. However, since the first frame is always blank, the best way to use &lt;code&gt;detachTexture()&lt;/code&gt; is in a [[Tasks|do-later task]] or [[Event Handling|event]].

&lt;code python&gt;
myWindow.setupCopyTexture()
myTexture=myWindow.getTexture()

#assume myModel is already setup
myModel.setTexture(myTexture)

#and if you want to stop the texture from updating itself
def stopUpdating():
   global myWindow
   myWindow.detachTexture()
taskMgr.doMethodLater(1,stopUpdating,'stops updating')
&lt;/code&gt;

While this is helpful, you may want to render an entirely new scene into a &lt;code&gt;GraphicsOutput&lt;/code&gt; and then place it on screen (i.e. you have a televsion in your main scene and want to generate the show on the spot). The first thing you do is create a &lt;code&gt;GraphicsOutput&lt;/code&gt; to hold the scene. You do this by calling &lt;code&gt;makeTextureBuffer&lt;/code&gt;. It makes a &lt;code&gt;GraphicsOutput&lt;/code&gt; specifically for rendering a scene and then retrieving it by &lt;code&gt;getTexture()&lt;/code&gt;.
&lt;code python&gt;
makeTextureBuffer(name, xSize, ySize)
&lt;/code&gt;
The arguments &lt;code&gt;name&lt;/code&gt;, &lt;code&gt;xSize&lt;/code&gt;, and &lt;code&gt;ySize&lt;/code&gt; mean the same things they do for [[The Graphics Engine|makeWindow and makeBuffer]].

 You then have to create a new [[Camera Control|camera]] for the new scene, using   

&lt;code python&gt;
base.makeCamera(win, sort=0, scene=None,
  displayRegion=(0,1,0,1), aspectRatio=None, camName='cam')
&lt;/code&gt;

Here's a break down of what the parameters mean:
&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td VALIGN=&quot;top&quot;&gt;&lt;code&gt;win&lt;/code&gt;&lt;/td&gt;&lt;td&gt;The &lt;code&gt;GraphicsOutput&lt;/code&gt; object that you want to make the camera for&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td VALIGN=&quot;top&quot;&gt;&lt;code&gt;sort&lt;/code&gt;&lt;/td&gt;&lt;td&gt;The sort value of the camera. Decides the order in which &lt;code&gt;DisplayRegion&lt;/code&gt;s in the same window are drawn. See API for more information.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td VALIGN=&quot;top&quot;&gt;&lt;code&gt;scene&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Due to deprecation of other functions this parameter does not affect anything.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td VALIGN=&quot;top&quot;&gt;&lt;code&gt;displayRegion&lt;/code&gt;&lt;/td&gt;&lt;td&gt;The area of the new &lt;code&gt;GraphicsOutput&lt;/code&gt; that you want to cover in the form (left start point, right end point, bottom start point, top end point). (0,0) represent the bottom left of the screen and (1,1) represents the top right. Therefore (0,1,0,1) represents the entire area. Arguments must be between 0 and 1.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td VALIGN=&quot;top&quot;&gt;&lt;code&gt;aspectRatio&lt;/code&gt;&lt;/td&gt;&lt;td&gt;The aspectRatio of the &lt;code&gt;GraphicsOutput&lt;/code&gt;. When this is left to &lt;code&gt;None&lt;/code&gt; &lt;code&gt;makeCamera&lt;/code&gt; uses the aspectRatio of the default window.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td VALIGN=&quot;top&quot;&gt;&lt;code&gt;camName&lt;/code&gt;&lt;/td&gt;&lt;td&gt;The name of the node that represents this camera in the scene graph&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;

Cameras render whatever is connected to their ancestors in the scene graph. Therefore if you want a truly independent scene you have to start a new scene graph. Create a dummy [[The Scene Graph|NodePath]] and now &lt;code&gt;reparentTo&lt;/code&gt; the new camera to this node. Now you can treat the new scene and the new camera like you would [[Scene Graph Manipulations|render]] and your scene gets drawn to your &lt;code&gt;GraphicsOuptut&lt;/code&gt;.

However, any state changes you make to the NodePath &lt;code&gt;camera&lt;/code&gt; will no longer affect your new camera. Also, since the standard mouse controls work on the &lt;code&gt;camera&lt;/code&gt; NodePath, these will not work either. You can alternatively use the Camera class method &lt;code&gt;setScene(scenePath)&lt;/code&gt;, where &lt;code&gt;scenePath&lt;/code&gt; is the top of the scene graph you want to draw. This preserves the standard heirarchy stated in [[Camera Control]].

&lt;code python&gt;
# I use a GraphicsBuffer only because this is a process you
# probably want the user to see
myBuffer=myWindow.makeTextureBuffer(&quot;Another Scene&quot;, 800,600)

# You must pass a string to the NodePath constructor or
# attempts to set it as a parent will remove the child from the graph
myNewScene=NodePath(&quot;myRender&quot;)
myNewCamera=base.makeCamera(myBuffer)
myNewCamera.reparentTo(myNewScene)
#or myNewCamera.node().setScene(myNewScene)

#You can now get a texture that represents anything
# you do in this new scene (that is still automatically updated)
myTexture=myBuffer.getTexture()
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>The Graphics Engine</title>
    <ns>0</ns>
    <id>1149</id>
      <sha1>phoiac9h4m842xq45sp7s6u21eteeq1</sha1>
    <revision>
      <id>7322</id>
      <timestamp>2011-09-15T18:28:38Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <comment>Empty outdated page to reduce confusion</comment>
      <text xml:space="preserve" bytes="0" />
    </revision>
  </page>
  <page>
    <title>The Graphics Pipe</title>
    <ns>0</ns>
    <id>1148</id>
      <sha1>4npj0k6avlkwjxx33mmd8m9egn982ek</sha1>
    <revision>
      <id>2430</id>
      <timestamp>2005-10-09T15:58:31Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="3087">The &lt;code&gt;GraphicsPipe&lt;/code&gt; class is Panda3D's interface to the available 3-D API's, for instance OpenGL or DirectX.  In order to create a window that renders using a particular API, you must have a GraphicsPipe for that API.

Normally, there is one default graphics pipe created for you automatically when you import DirectStart, accessible as &lt;code&gt;base.pipe&lt;/code&gt;.  For most applications, there is no need to create any additional graphics pipes.

There are two Config.prc variables that determine the graphics pipe or pipes that will be available to an application:

&lt;b&gt;load-display&lt;/b&gt;: this variable specifies the first choice for the graphics pipe.  It names the type of GraphicsPipe that should be attempted first, e.g. pandagl or pandadx8.  If for some reason a GraphicsPipe of this type cannot be created, for instance because of lack of driver support, then Panda3D will fall back to the next variable:

&lt;b&gt;aux-display&lt;/b&gt;: this variable can be repeated multiple times, and should list all of the available GraphicsPipe implementations.  If Panda3D is unable to open a pipe of the type named by load-display, then it will walk through the list of pipes named by aux-display, in the order they appear in the Config.prc file, and try them one at a time until one is successfully opened.

Note that the name specified to each of the above variables, e.g. pandagl, actually names a Windows DLL or Unix shared-library file.  Panda3D will put &quot;lib&quot; in front of the name and &quot;.dll&quot; or &quot;.so&quot; (according to the operating system) after the name, and then attempts to import that library.  This means that &quot;load-display pandagl&quot; really means to try to import the file &quot;libpandagl.dll&quot;.  The various display DLL's are written so that when they are successfully imported, they will register support for the kind of GraphicsPipe they implement.

You can create additional graphics pipes, for instance to provide an in-game interface to switch between OpenGL and DirectX rendering.  The easiest way to do this is to call &lt;code&gt;base.makeAllPipes()&lt;/code&gt;.  Then you can walk through the list of GraphicsPipes in &lt;code&gt;base.pipeList&lt;/code&gt; to see all of the available GraphicsPipes available in particular environment.

When you walk through the GraphicsPipes in base.pipeList, you can call the following interface methods on each one:

&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;code&gt;pipe.isValid()&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Returns True if the pipe is available for rendering, False if it can't be used.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;code&gt;pipe.getDisplayWidth()&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Returns the width of the desktop, or the maximum width of any buffer for an offscreen-only GraphicsPipe.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;code&gt;pipe.getDisplayHeight()&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Returns the height of the desktop, or the maximum height of any buffer for an offscreen-only GraphicsPipe.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;code&gt;pipe.getInterfaceName()&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Returns the name of the API that this GraphicsPipe impements, e.g. &quot;OpenGL&quot; or &quot;DirectX8&quot;.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;code&gt;pipe.getType()&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Returns a unique TypeHandle object for each kind of pipe.&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;</text>
    </revision>
  </page>
  <page>
    <title>The HeightfieldTesselator</title>
    <ns>0</ns>
    <id>2228</id>
    <redirect title="The Heightfield Tesselator" />
      <sha1>37es23yugcdre7rwy4owbxoqgqadleg</sha1>
    <revision>
      <id>5241</id>
      <timestamp>2008-03-15T11:01:25Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[The Heightfield Tesselator]]</comment>
      <text xml:space="preserve" bytes="40">#REDIRECT [[The Heightfield Tesselator]]</text>
    </revision>
  </page>
  <page>
    <title>The Heightfield Tesselator</title>
    <ns>0</ns>
    <id>1130</id>
      <sha1>0hoz9h490fnguvf7f9rrv5j1s50reg7</sha1>
    <revision>
      <id>5239</id>
      <timestamp>2008-03-15T11:00:57Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>[[Generating Heightfield Terrain]] moved to [[The Heightfield Tesselator]]: To avoid confusion with geoMipTerrain(PGMM).</comment>
      <text xml:space="preserve" bytes="1534">The HeightfieldTesselator converts a height field in the form of a greyscale image into a scene consisting of a number of GeomNodes.
The tesselation uses an LOD algorithm. You supply a &quot;focal point&quot; (X,Y) which tells the tesselator where the bulk of the detail should be concentrated. The intent is that as the player walks around the terrain, you should occasionally move the focal point to wherever the player is. You should not move the focal point every frame: tesselation is not that fast. Also, changing the focal point may cause popping, so it is best to minimize the number of changes. There are a number of parameters that you can use to control tesselation, such as a target polygon count, and a visibility radius.

The heightfield needs to be a multiple of 128 pixels in each dimension. It does not need to be square, and it does not need to be a power of two. For example, a 384 x 640 heightfield is fine. Be aware that tesselation time is proportional to heightfield area, so if you plan to use a size larger than about 512x512, it may be desirable to benchmark.

Altering parameters, such as the poly count, the view radius, or the focal point, does not alter any GeomNodes already generated. Parameter changes only affect subsequently-generated GeomNodes. It is possible to cache many different tesselations of the same terrain.

&lt;b&gt;Note:&lt;/b&gt; Various other algorithms for terrain LOD have been contributed by users at the Forums.

&lt;h2&gt;Incomplete Section&lt;/h2&gt;

Note: this section is incomplete.  It will be updated soon.</text>
    </revision>
  </page>
  <page>
    <title>The IRC Channel</title>
    <ns>0</ns>
    <id>2233</id>
      <sha1>fj7fp6ltb6sjlss77t2ow3yym14623i</sha1>
    <revision>
      <id>60492</id>
      <timestamp>2015-05-09T11:35:23Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <text xml:space="preserve" bytes="876">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

The IRC channel is a great place to talk to other developers that use Panda3D, and to ask questions about anything related to Panda3D.

{|
|-
! align=&quot;left&quot; | Network
| align=&quot;left&quot; | [http://freenode.net FreeNode]
|-
! align=&quot;left&quot; | Server
| align=&quot;left&quot; | chat.freenode.net
|-
! align=&quot;left&quot; | Channel
| align=&quot;left&quot; | [irc://irc.freenode.net/panda3d #panda3d]
|}

You need an IRC client to connect to the channel. If you do not have an IRC client, you can use the web client:
http://webchat.freenode.net/?channels=panda3d

Although you will often get a response fairly quickly, depending on the time of day and timezone of our users, it may take longer for people to notice your message and respond.  It is recommended that you stay on the channel after asking your question.  Asking whether you may ask a question is pointless.</text>
    </revision>
  </page>
  <page>
    <title>The Open Dynamics Engine</title>
    <ns>0</ns>
    <id>2282</id>
    <redirect title="Using ODE with Panda3D" />
      <sha1>9tz4aayremfwhn93jx9pxy9m39wwsg9</sha1>
    <revision>
      <id>5525</id>
      <timestamp>2008-10-14T11:28:45Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[Using ODE with Panda3D]]</comment>
      <text xml:space="preserve" bytes="36">#REDIRECT [[Using ODE with Panda3D]]</text>
    </revision>
  </page>
  <page>
    <title>The Python Debugger</title>
    <ns>0</ns>
    <id>1026</id>
      <sha1>e9et2x69jb2qlmkkex2uf309il4k6hl</sha1>
    <revision>
      <id>5227</id>
      <timestamp>2008-03-15T06:12:30Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="2641">Python is a very powerful interactive and interpreted language. Python's development cycle is very fast. Often the most effective way to to debug is to output relevant information. Having said that, there are many ways to enhance productivity with knowledge of good debugging techniques.


&lt;h2&gt;Using python -i mode&lt;/h2&gt;

Python programs may be developed and tested with the help of the interactive mode of the Python interpreter, which, allows program components to be debugged, traced, profiled, and tested interactively. When invoking python with -i, this ensures that an interactive session of python is invoked. With regards to Panda3D this requires a little explanation. Panda3D programs typically have a command called run() to start rendering, so here's one way to start an interactive session. On the command prompt type:

&lt;pre class=&quot;codeblock&quot;&gt;
python -i myPandaFile.py
&lt;/pre&gt;

After Panda3D has loaded, make sure the command window has focus and type Ctrl-C. This will show a python prompt like so:

&lt;pre class=&quot;codeblock&quot;&gt;
&amp;gt;&amp;gt;&amp;gt;
&lt;/pre&gt;

Now on the command prompt you can execute any python commands, related or unrelated to your Panda3D program. This is useful for looking at information at that specific point in time. You could even change that information for that running instance of the program.

&lt;h2&gt;pdb&lt;/h2&gt;

Python offers hooks enabling interactive debugging. Module pdb supplies a simple text-mode interactive debugger. It supports setting (conditional) breakpoints and single stepping at the source line level, inspection of stack frames, source code listing, and evaluation of arbitrary Python code in the context of any stack frame. It also supports post-mortem debugging and can be called under program control.

The debugger's prompt is &quot;(Pdb) &quot;. There are many ways to enter the debugger. Typical usage to run a program under control of the debugger is:

&lt;pre class=&quot;codeblock&quot;&gt;
&amp;gt;&amp;gt;&amp;gt; import pdb
&amp;gt;&amp;gt;&amp;gt; import &lt;mymodule&gt;
&amp;gt;&amp;gt;&amp;gt;  pdb.run('mymodule.test()')
&amp;gt; &amp;lt;string&amp;gt;(0)?()
(Pdb) continue
&amp;gt; &amp;lt;string&amp;gt;(1)?()
(Pdb) continue
 NameError: 'spam'
 &amp;lt;string&amp;gt;(1)?()
 (Pdb)
&lt;/pre&gt;


Detailed information about pdb can be found [http://www.python.org/doc/current/lib/module-pdb.html here]. In addition to pdb, python also has two modules called &lt;code&gt;inspect&lt;/code&gt; and &lt;code&gt;traceback&lt;/code&gt;. &lt;code&gt;inspect&lt;/code&gt; supplies functions to extract information from all kinds of objects, including the Python call stack and source files. The &lt;code&gt;traceback&lt;/code&gt; module lets you extract, format and output information about tracebacks as normally produced by uncaught exceptions.</text>
    </revision>
  </page>
  <page>
    <title>The Rigid Body Combiner</title>
    <ns>0</ns>
    <id>2264</id>
      <sha1>93kj4mzeguqlpsujjcesbf0vmxjl1sd</sha1>
    <revision>
      <id>7712</id>
      <timestamp>2012-03-09T10:44:05Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>new import system</comment>
      <text xml:space="preserve" bytes="3058">==The Rigid Body Combiner==

&lt;p&gt;When you are developing a complex game, you will most likely run into the problem that you will have [[Performance Issue: Too Many Meshes|too many meshes]] in your scene. Panda3D's flattening methods can help you reducing the number of nodes, but often when you have hundreds of moving bodies this is not always an option. Therefore, Panda3D has a feature to help you reduce the number of nodes, even if they are moving: the &lt;i&gt;RigidBodyCombiner&lt;/i&gt;.&lt;/p&gt;

&lt;p&gt;The RigidBodyCombiner is designed to reduce the number of nodes actually sent to the graphics card, just like the flattening functions. But instead of flattening everything into one node immediately, the RigidBodyCombiner keeps your original node structure intact, still allowing you to apply transforms (e.g. moving around, rotating or scaling) sub-nodes. But what's actually sent to the graphics cards is just one node, a combined version of all these sub-nodes. If you want to see the combined version of these nodes (not likely), you can call &lt;code&gt;getInternalScene()&lt;/code&gt;, this function will return the NodePath that is actually sent to the graphics card.&lt;/p&gt;

&lt;p&gt;The RigidBodyCombiner class is just another kind of PandaNode. All of the standard node interfaces apply. Thus, the easiest way to add nodes to a RigidBodyCombiner is to wrap a NodePath around it, and then use the standard &lt;code&gt;reparentTo()&lt;/code&gt; interfaces to parent the nodes you want to combine to this NodePath.&lt;/p&gt;

&lt;p&gt;When you are done with reparenting the nodes, you need to call &lt;code&gt;collect()&lt;/code&gt; on the original &lt;code&gt;RigidBodyCombiner&lt;/code&gt; instance. This is a fairly expensive call and you should normally only call this once -- but after you called &lt;code&gt;collect()&lt;/code&gt; you may freely transform all nodes below without having to call this again. If you later add more children to the RBC, though, you will need to call &lt;code&gt;collect()&lt;/code&gt; again.&lt;/p&gt;

&lt;p&gt;The vertices of the objects you attach to the RigidBodyCombiner must be transformed each frame on the CPU.  For this reason, you may find a performance advantage in limiting the number of vertices in the models you use.  Also, be sure you do not have normals on your models unless you are actually using lighting.&lt;/p&gt;

&lt;p&gt;Here is a small example showing a random cloud of boxes:

&lt;code python&gt;
from direct.directbase.DirectStart import *
from panda3d.core import RigidBodyCombiner, NodePath, Vec3
import random

rbc = RigidBodyCombiner(&quot;rbc&quot;)
rbcnp = NodePath(rbc)
rbcnp.reparentTo(render)

for i in range(200):
    pos = Vec3(random.uniform(-100, 100),
               random.uniform(-100, 100),
               random.uniform(-100, 100))
    
    f = loader.loadModel(&quot;box.egg&quot;)
    f.setPos(pos)
    f.reparentTo(rbcnp)

rbc.collect()
run()

&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Note:&lt;/b&gt; [[RenderEffects]] such as [[Billboards]] are not supported below this node.&lt;/p&gt;

&lt;p&gt;For more information and a complete list of RigidBodyCombiner 
functions please see the [http://panda3d.org/apiref.php?page=RigidBodyCombiner API reference].&lt;/p&gt;</text>
    </revision>
  </page>
  <page>
    <title>The SG</title>
    <ns>0</ns>
    <id>2194</id>
    <redirect title="The Scene Graph" />
      <sha1>2bzfp3zmf61rwkbz0docndz38qi1vyl</sha1>
    <revision>
      <id>4825</id>
      <timestamp>2008-03-12T14:43:49Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>redirected</comment>
      <text xml:space="preserve" bytes="29">#REDIRECT [[The Scene Graph]]</text>
    </revision>
  </page>
  <page>
    <title>The Scene Editor</title>
    <ns>0</ns>
    <id>1027</id>
      <sha1>6jufxayd3ueu9j97wqez3bycv2hhni1</sha1>
    <revision>
      <id>7397</id>
      <timestamp>2011-12-03T16:33:45Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="2213">Note: the scene editor on this page is deprecated and not useful for newer versions of the engine.

At the [http://www.etc.cmu.edu Entertainment Technology Center] ([http://www.cmu.edu Carnegie Mellon University]) we have developed a Scene Editor to enable layout of objects in a 3D environment. This tool also allows you to do lighting, animation blending, creation of mopaths etc. This is just a first version of the tool and will be updated to encompass new features and improvements in the future.

To run the scene editor, run &quot;sceneEditor.py&quot; in the contrib/src/sceneeditor directory. (For older versions, the directory may be called SceneEditor or might not even exist at all.)

The scene editor's primary functions are:
	&lt;ul&gt;
		&lt;li&gt;Object loading and manipulation
		&lt;li&gt;Animation loading and blending
		&lt;li&gt;Lighting
		&lt;li&gt;Motion path generation
		&lt;li&gt;Particle system generation
		&lt;li&gt;Setting up collision detection
	&lt;/ul&gt;

The scene editor will set up your scene for you and then output the layout at a normal python file. This file can then be used, edited as you desire. This tool is meant to give a visual interface for many functions that typically would have to be done manually in code. The best way to learn about the scene editor is to watch the Scene Editor Lectures:

&lt;ul&gt;
	&lt;li&gt;[http://panda3d.org/videolectures/scene/1_Introduction.avi Introduction] (48 mb)
	&lt;li&gt;[http://panda3d.org/videolectures/scene/2_Camera_Control_And_Object_Manipulation.avi Camera Control and Object Manipulation] (18mb)

	&lt;li&gt;[http://panda3d.org/videolectures/scene/3_Animation_Loading.avi Animation Loading] (8 mb)
	&lt;li&gt;[http://panda3d.org/videolectures/scene/4_Lighting.avi Lighting] (11 mb)
	&lt;li&gt;[http://panda3d.org/videolectures/scene/5_Animation_Blending.avi Animation Blending] (26 mb)
	&lt;li&gt;[http://panda3d.org/videolectures/scene/6_Motion_Paths.avi Motion Paths] (24 mb)
	&lt;li&gt;[http://panda3d.org/videolectures/scene/7_Particles.avi Particles] (38 mb)
	&lt;li&gt;[http://panda3d.org/videolectures/scene/8_Collision.avi Collision] (34 mb)
	&lt;li&gt;[http://panda3d.org/videolectures/scene/9_Misc1.avi Miscellaneous Part I] (20 mb)
	&lt;li&gt;[http://panda3d.org/videolectures/scene/10_Misc2.avi Miscellaneous Part II] (16 mb)
&lt;/ul&gt;</text>
    </revision>
  </page>
  <page>
    <title>The Scene Graph</title>
    <ns>0</ns>
    <id>941</id>
      <sha1>bcu6lrvgczrrt28feawwnpre2ymiekf</sha1>
    <revision>
      <id>7408</id>
      <timestamp>2011-12-07T09:10:47Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="5509">&lt;b&gt;The Scene Graph: a Tree of Nodes&lt;/b&gt;

Many simple 3D engines maintain a list of 3D models to render every frame.  In these simple engines, one must allocate a 3D model (or load it from disk), and then insert it into the list of models to render.  The model is not &quot;visible&quot; to the renderer until it is inserted into the list.

Panda3D is slightly more sophisticated.  Instead of maintaining a list of objects to render, it maintains a tree of objects to render.  An object is not visible to the renderer until it is inserted into the tree.

The tree consists of objects of class &lt;code&gt;PandaNode&lt;/code&gt;.  This is actually
a superclass for a number of other classes: &lt;code&gt;ModelNode&lt;/code&gt;, &lt;code&gt;GeomNode&lt;/code&gt;, &lt;code&gt;LightNode&lt;/code&gt;, and so forth.  Throughout this manual, it is common for us to refer to objects of these classes as simply &lt;i&gt;nodes&lt;/i&gt;.  The root of the tree is a node called &lt;code&gt;render&lt;/code&gt;.  (Note: there may be additional roots for specialized purposes, like &lt;code&gt;render2d&lt;/code&gt; for 2D objects)

Panda3D's &quot;tree of things to render&quot; is named the &lt;i&gt;scene graph.&lt;/i&gt;

&lt;b&gt;What you Need to Know about the Hierarchical Scene Graph&lt;/b&gt;

Here are the most important things you need to know about the
hierarchical arrangement of the scene graph:

&lt;ol&gt;
&lt;li&gt;You control where objects go in the tree.  When you insert an object into
the tree, you specify where to insert it.  You can move branches
of the tree around.  You can make the tree as deep or as shallow as you like.
&lt;br&gt;&lt;br&gt;&lt;/li&gt;
&lt;li&gt;Positions of objects are specified relative to their parent in the tree.  For example, if you have a 3D model of a hat, you might want to specify that it always stays five units above a 3D model of a certain person's head.  Insert the hat as a child of the head, and set the position of the hat to (0,0,5).
&lt;br&gt;&lt;br&gt;&lt;/li&gt;
&lt;li&gt;When models are arranged in a tree, any &lt;i&gt;rendering attributes&lt;/i&gt; you assign to a node will propagate to its children.  For example, if you specify that a given node should be rendered with depth fog, then its children will also be rendered with depth fog, unless you explicitly override at the child level.
&lt;br&gt;&lt;br&gt;&lt;/li&gt;
&lt;li&gt;Panda3D generates bounding boxes for each node in the tree.  A good
organizational hierarchy can speed frustum and occlusion culling.  If the
bounding box of an entire branch is outside the frustum, there is no need to examine the children.&lt;/li&gt;
&lt;/ol&gt;

Beginners usually choose to make their tree completely flat--everything
is inserted immediately beneath the root.  This is actually a very good
initial design.  Eventually, you will find a reason to want to add a little
more depth to the hierarchy.  But it is wise not to get complicated until
you have a clear, specific reason to do so.

&lt;b&gt;NodePaths&lt;/b&gt;

There is a helper class called &lt;code&gt;NodePath&lt;/code&gt; which is a very
small object containing a pointer to a node, plus some 
administrative information.  For now, you can ignore the administrative information; it will be explained in a [[Instancing|later section]]
of the manual. It is the intent of the panda designers that you
should think of a NodePath as a handle to a node.  Any function that
creates a node returns a &lt;code&gt;NodePath&lt;/code&gt; that refers
to the newly-created node.

A NodePath isn't exactly a pointer to a node; it's a &quot;handle&quot; to a node.
Conceptually, this is almost a distinction without a difference.  However,
there are certain API functions that expect you to pass in a NodePath,
and there are other API functions that expect you to pass in a node
pointer.  Because of this, although there is little conceptual difference between them, you still need to know that both exist.

You can convert a NodePath into a &quot;regular&quot; pointer at any time by calling &lt;code&gt;nodePath.node()&lt;/code&gt;.  However, there is no unambiguous way to convert back.
That's important: sometimes you &lt;i&gt;need&lt;/i&gt; a NodePath, sometimes you
&lt;i&gt;need&lt;/i&gt; a node pointer.  Because of this, it is recommended that you
store NodePaths, not node pointers.  When you pass parameters, you should
probably pass NodePaths, not node pointers.  The callee can always convert
the NodePath to a node pointer if it needs to.

&lt;b&gt;NodePath-Methods and Node-Methods&lt;/b&gt;

There are many methods that you can invoke on NodePaths, which are appropriate for nodes of any type.  Specialized node types, like LODNodes and Cameras (for instance), provide additional methods that are available only for nodes of that type, which you must invoke on the node itself.  Here are some assorted examples:

[python]&lt;code python&gt;
# NODEPATH METHODS:
myNodePath.setPos(x, y, z)
myNodePath.setColor(banana)

# LODNODE METHODS:
myNodePath.node().addSwitch(1000, 100)
myNodePath.node().setCenter(Point3(0, 5, 0))

# CAMERA NODE METHODS:
myNodePath.node().setLens(PerspectiveLens())
myNodePath.node().getCameraMask()
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
// NODEPATH METHODS:
myNodePath.set_pos(x, y, z);
myNodePath.set_color(banana);

// LODNODE METHODS:
myNodePath.node()-&gt;add_switch(1000, 100);
myNodePath.node()-&gt;set_center(LPoint3f(0, 5, 0));

// CAMERA NODE METHODS:
myNodePath.node()-&gt;set_lens(new PerspectiveLens());
myNodePath.node()-&gt;get_camera_mask();
&lt;/code&gt;[/cxx]

Always remember: when you invoke a method of &lt;code&gt;NodePath&lt;/code&gt;, you
are actually performing an operation on the node to which it points.

In the example above, we call node-methods by first converting the
NodePath into a node, and then immediately calling the node-method.
This is the recommended style.</text>
    </revision>
  </page>
  <page>
    <title>The Scene Graph Browser</title>
    <ns>0</ns>
    <id>1028</id>
      <sha1>9zgss375jo1gxfrfw54nv4au9vt2yax</sha1>
    <revision>
      <id>2318</id>
      <timestamp>2005-05-01T02:07:23Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="917">The Scene Graph Browser is only available when 'Direct Tools' are enabled.  Information on enabling 'Direct Tools' is available in the [[Panda Tools]] section.

In the main Direct Session window, there are several scene placement tools available through the tabs at the right side of the screen. Clicking on these tabs will bring up a dialog box with the various properties for these aspects. On the left side of the panel is a collapsible scene graph for the render parent node. Right click any of the objects to bring up a list of possible commands.

[[Image:directtools3.jpg]]

Of particular interest is the placer panel, selected by the place command for an object. This brings up a separate window that may alter the position, orientation, and scale for the selected object. A dialog box at the top of the window allows these movements to be relative to another object in the program.

[[Image:directtools4.jpg]]</text>
    </revision>
  </page>
  <page>
    <title>The Shader Generator</title>
    <ns>0</ns>
    <id>2167</id>
      <sha1>jpxc2fe15frw5pmvv1js3bzty44b3ha</sha1>
    <revision>
      <id>7383</id>
      <timestamp>2011-11-29T11:43:43Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>fog is available in ShaderGenerator since 1.8.0</comment>
      <text xml:space="preserve" bytes="8293">&lt;h2&gt;The Shader Generator&lt;/h2&gt;

As of version 1.5.0, panda supports several new features:

* per-pixel lighting
* normal mapping
* gloss mapping
* glow mapping
* high-dynamic range rendering
* cartoon shading

It's not that these things weren't possible before: they were.  But previously, you had to write shaders to accomplish these things.  This is no longer necessary.  As of version 1.5.0, all that has to happen is for the artist
to apply a normal map, gloss map, or glow map in the 3D modeling program.
Then, the programmer gives permission for shader generation, and Panda3D
handles the rest.

A few of these features do require minimal involvement from the programmer:
for instance, high-dynamic range rendering requires the programmer to choose a tone-mapping operator from a small set of options.  But that's it: the amount of work required of the programmer is vastly less than before.

Many of these features are complementary with [[Common Image Filters|image postprocessing operations]], some of which are now nearly-automatic as well.
For example, HDR combines very nicely with the bloom filter, and cartoon
shading goes very well with cartoon inking.

Individually, these features are not documented in this chapter of the manual.  Instead, they're documented in the portion of the manual where they make the
most sense.  For example, normal mapping, gloss mapping, and glow mapping
are all documented in the section on [[Texturing]].  HDR and cartoon shading
are documented under Render Attributes in the subsection on [[Light Ramps]].  

However, to enable any of these features, you need to tell Panda3D that it's OK to automatically generate shaders and send them to the video card.  The call to do this is:

[python]&lt;code python&gt;
nodepath.setShaderAuto()
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
nodepath.set_shader_auto();
&lt;/code&gt;[/cxx]

If you don't do this, none of the features listed above will have any effect.  Panda will simply ignore normal maps, HDR, and so forth if shader generation is not enabled.  It would be reasonable to enable shader generation for the entire game, using this call:

[python]&lt;code python&gt;
render.setShaderAuto()
&lt;/code&gt;[/python]
[cxx]&lt;code cxx&gt;
window-&gt;get_render().set_shader_auto();
&lt;/code&gt;[/cxx]

&lt;h2&gt;Sample Programs&lt;/h2&gt;

Three of the sample programs demonstrate the shader generator in action:

* [[Sample Programs: Cartoon Shader]]
* [[Sample Programs: Glow Filter]]
* [[Sample Programs: Normal Mapping]]

In each case, the sample program provides two versions: Basic and Advanced.
The Basic version relies on the shader generator to make everything automatic.
The Advanced version involves writing shaders explicitly.

&lt;h2&gt;Per-Pixel Lighting&lt;/h2&gt;

Simply turning on &lt;code&gt;[func]setShaderAuto[/func]&lt;/code&gt; causes one immediate change:
all lighting calculations are done per-pixel instead of per-vertex.
This means that models do not have to be highly tesselated in order to
get nice-looking spotlights or specular highlights.

Of course, the real magic of &lt;code&gt;[func]setShaderAuto[/func]&lt;/code&gt; is that it enables
you to use powerful features like normal maps and the like.

&lt;h2&gt;Known Limitations&lt;/h2&gt;

The shader generator replaces the fixed-function pipeline with a shader.  To make this work, we have to duplicate the functionality of the &lt;i&gt;entire&lt;/i&gt; fixed function pipeline.  That's a lot of stuff.  We haven't implemented all of it yet.  Here's what's supported: (as of version 1.7.0)

&lt;ul&gt;
&lt;li&gt;flat colors, vertex colors and color scales
&lt;li&gt;lighting
&lt;li&gt;normal maps
&lt;li&gt;gloss maps
&lt;li&gt;glow maps
&lt;li&gt;materials, but not updates to materials
&lt;li&gt;1D, 2D, 3D, cube textures
&lt;li&gt;most texture stage and combine modes
&lt;li&gt;light ramps (for cartoon shading)
&lt;li&gt;some texgen modes
&lt;li&gt;texmatrix
&lt;/ul&gt;

Here's what's known to be missing:

&lt;ul&gt;
&lt;li&gt;some texgen modes
&lt;li&gt;fog (added in Panda3D 1.8.0)
&lt;/ul&gt;

These functions are high on the list of priorities, and will probably be coming sometime in the next month or so.

Note that although vertex colors are supported by the ShaderGenerator, in order to render vertex colors you need to apply a &lt;code&gt;[func]ColorAttrib.makeVertex()[/func]&lt;/code&gt; attrib to the render state. One easy way to do this is to call &lt;code&gt;[func]NodePath.setColorOff()[/func]&lt;/code&gt; (that is, turn off scene graph color, and let vertex color be visible). In the fixed-function renderer, vertex colors will render with or without this attrib, so you might not notice if you fail to apply it. Models that come in via the egg loader should have this attribute applied already. However, if you are using your own model loader or generating models procedurally you will need to set it yourself.

&lt;h2&gt;How the Shader Generator Works&lt;/h2&gt;

When panda goes to render something marked &lt;code&gt;[func]setShaderAuto[/func]&lt;/code&gt;, it synthesizes a shader to render that object.  In order to generate the shader, it examines all the attributes of the object: the lights, the material, the fog setting, the color, the vertex colors... almost everything.  It takes into account all of these factors when generating the shader.  For instance, if the object has a material attrib, then material color support is inserted into the shader.  If the object has lights, then lighting calculations are inserted into the shader.  If the object has vertex colors, then the shader is made to use those.

&lt;h2&gt;Caching and the Shader Generator&lt;/h2&gt;

If two objects are rendered using the same RenderState (ie, the exact same attributes), then the shader is only generated once.  But even a single change to the RenderState will cause the shader to be regenerated.  This is not entirely cheap.  Making changes to the RenderState of an object should be avoided when shader generation is enabled, because this necessitates regeneration of the shader.  

A few alterations don't count as RenderState modifications: in particular, changing the positions and colors of the lights doesn't count as a change to the RenderState, and therefore, does not require shader regeneration.  This can be useful: if you just want to tint an object, apply a light to it then change the color of the light.

There is a second level of caching.  If the system generates a shader, it will then compare that shader to the other shaders it has generated previously.  If it matches a previously-generated shader, it will not need to compile the shader again.

So, to save the full cost, use the same RenderState.  To save most of the cost, use two RenderStates that are similar.  By &quot;similar,&quot; I mean having the same general structure: ie, two models that both have a texture and a normal map, and both have no vertex colors and neither has a material applied.

&lt;h2&gt;Combining Automatic Shaders with Manual Shaders&lt;/h2&gt;

Sometimes, you will want to write most of a game using panda's automatic shader generation abilitites, but you'll want to use a few of your own shaders.  A typical example would be a scene with some houses, trees, and a pond.  You can probably do the houses and trees using panda's built-in abilities.  However, Panda doesn't contain anything that particularly looks like pond-water: for that, you'll probably need to write your own shader.

When you use &lt;code&gt;render.[func]setShaderAuto[/func]()&lt;/code&gt;, that propagates down the scene  graph just like any other render attribute.  If you assign a specific shader to a node using &lt;code&gt;nodepath.[func]setShader[/func](myshader)&lt;/code&gt;, that overrides any shader assignment propagated down from above, including an &lt;i&gt;Auto&lt;/i&gt; shader assignment from above.  So that means it is easy, in the example above, to enable auto shader generation for the scene as a whole, and then override that at the pond-nodepath.

&lt;h2&gt;Creating your own Shader Generator&lt;/h2&gt;

We anticipate that people who are writing full-fledged commercial games using
Panda3D might want to write their own shader generators.  In this
way, you can get any effect you imagine without having to give up the
convenience and elegance of being able to simply apply a normal map
or a gloss map to a model, and having it &quot;just work.&quot;

To create your own shader generator, you will need to delve into Panda3D's C++ code.  Class ShaderGenerator is meant to be subclassed, and a hook function is provided to enable you to turn on your own generator.</text>
    </revision>
  </page>
  <page>
    <title>The Standard Finite State Machine</title>
    <ns>0</ns>
    <id>1029</id>
      <sha1>b2n7phgolhp8g6etkumlk04pu2o745u</sha1>
    <revision>
      <id>2319</id>
      <timestamp>2005-05-01T01:55:40Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="3851">Where the classic finite state machine required one large function to define all states of a FSM, the current finite state machine system creates these states implicitly. To prevent confusion, it may be best to create this finite state machine as its own class.

&lt;table class=&quot;code&quot;&gt;&lt;tr&gt;&lt;td&gt;
from direct.fsm import FSM
&lt;br&gt;from direct.fsm import State
&lt;br&gt;
&lt;br&gt;class NewFSM (FSM.FSM):
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

Like the classic finite state machine, this machine requires enter and exit functions. The name of the state is derived from the names of the entrance and exit functions, and is usually capitalized. There is also a third function, a filter function that may be called for each state. This filter function is called when a request for transition is made, and it checks the current state’s filter to see if it is indeed a legal transition. If there is no filter function for a state, then a default filter command is called, which will change the state. However, if there is a filter function provided for the state, then the default filter command will simply reject any transition.

The traffic light finite state machine is provided as an example of how to write for the new finite state machine system.

&lt;table class=&quot;code&quot;&gt;&lt;tr&gt;&lt;td&gt;
from direct.fsm import FSM
&lt;br&gt;from direct.fsm import State
&lt;br&gt;class NewStyle(FSM.FSM):
&lt;br&gt;
&lt;br&gt;&amp;nbsp;&amp;nbsp;def enterRed(self, oldState, newState):
&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;print &quot;enterRed(self, '%s', '%s')&quot; % (oldState, newState)
&lt;br&gt;
&lt;br&gt;&amp;nbsp;&amp;nbsp;def filterRed(self, request, args):
&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;print &quot;filterRed(self, '%s', %s)&quot; % (request, args)
&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;if request == 'advance':
&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;return 'Green'
&lt;br&gt;&amp;nbsp;&amp;nbsp;return self.defaultFilter(request, args)
&lt;br&gt;
&lt;br&gt;&amp;nbsp;&amp;nbsp;def exitRed(self, oldState, newState):
&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;print &quot;exitRed(self, '%s', '%s')&quot; % (oldState, newState)
&lt;br&gt;
&lt;br&gt;&amp;nbsp;&amp;nbsp;def enterYellow(self, oldState, newState):
&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;print &quot;enterYellow(self, '%s', '%s')&quot; % (oldState, newState)
&lt;br&gt;
&lt;br&gt;&amp;nbsp;&amp;nbsp;def filterYellow(self, request, args):
&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;print &quot;filterYellow(self, '%s', %s)&quot; % (request, args)
&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;if request == 'advance':
&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;return 'Red'
&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;return self.defaultFilter(request, args)
&lt;br&gt;
&lt;br&gt;&amp;nbsp;&amp;nbsp;def exitYellow(self, oldState, newState):
&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;print &quot;exitYellow(self, '%s', '%s')&quot; % (oldState, newState)
&lt;br&gt;
&lt;br&gt;&amp;nbsp;&amp;nbsp;def enterGreen(self, oldState, newState):
&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;print &quot;enterGreen(self, '%s', '%s')&quot; % (oldState, newState)
&lt;br&gt;
&lt;br&gt;&amp;nbsp;&amp;nbsp;def filterGreen(self, request, args):
&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;print &quot;filterGreen(self, '%s', %s)&quot; % (request, args)
&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;if request == 'advance':
&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;return 'Yellow'
&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;return self.defaultFilter(request, args)
&lt;br&gt;
&lt;br&gt;&amp;nbsp;&amp;nbsp;def exitGreen(self, oldState, newState):
&lt;br&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;print &quot;exitGreen(self, '%s', '%s')&quot; % (oldState, newState)
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

The new finite state machine uses the filter functions to determine the new state. Instead of having to provide the actual name of the state, this example used the string “advance.” With this, the filter function called knew which state to move to. Otherwise, it returned the default filter. Since there is an existing filter for the state, the default filter simply sends a message saying that the request has been denied.

Just like the classic finite state machine, the standard one has a request command. It is also able to force a transition.

&lt;table class=&quot;code&quot;&gt;&lt;tr&gt;&lt;td&gt;
request.(‘&lt;String&gt;’)
&lt;br&gt;forceTransition(‘&lt;State Name&gt;’)
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</text>
    </revision>
  </page>
  <page>
    <title>The Window Framework</title>
    <ns>0</ns>
    <id>2080</id>
      <sha1>gp32s84izsoqmxk8qbyd8s6wb7lliu7</sha1>
    <revision>
      <id>7498</id>
      <timestamp>2011-12-24T13:31:56Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>typo</comment>
      <text xml:space="preserve" bytes="3661">[python]The WindowFramework class is for use in C++ only. If you use Python, you can just use DirectStart to open a window and skip this page.[/python]

[cxx]This page will explain how to use the WindowFramework class in C++ to open a blank window.
First of all, we need to include the appropriate header files:
&lt;code cxx&gt;
#include &quot;pandaFramework.h&quot;
#include &quot;pandaSystem.h&quot;
&lt;/code&gt;
Second, we need to create an instance of the WindowFramework class and open the main int of course.
&lt;code cxx&gt;
PandaFramework framework;
int main(int argc, char *argv[]) {
&lt;/code&gt;
Now, we must open the framework, give the window a nice title and open the window:
&lt;code cxx&gt;
framework.open_framework(argc, argv);
framework.set_window_title(&quot;Hello World!&quot;);
// Open it!
WindowFramework *window = framework.open_window();
&lt;/code&gt;
Optionally, we can enable keyboard support, in case we want to check for keyboard presses, and we can enable the default camera trackball. Note that you also need to enable keyboard support to receive mouse button events (sic).

&lt;code cxx&gt;
// Enable keyboard detection
window-&gt;enable_keyboard();
// Enable default camera movement
window-&gt;setup_trackball();
&lt;/code&gt;
Now, we're going to check if the window has opened successfully.
If so, the main loop must be called, using the function &lt;i&gt;framework.main_loop()&lt;/i&gt;. This is equal to the &lt;i&gt;run()&lt;/i&gt; function in Python.
&lt;code cxx&gt;
if (window != (WindowFramework *)NULL) {
  nout &lt;&lt; &quot;Opened the window successfully!\n&quot;;

  // Put here your own code, such as the loading of your models

  framework.main_loop();
} else {
  nout &lt;&lt; &quot;Could not load the window!\n&quot;;
}
&lt;/code&gt;
Afterwards, we need to close the framework:
&lt;code cxx&gt;
  framework.close_framework();
  return (0);
}
&lt;/code&gt;
Now, [[How to build a CXX Panda3D game|compile and run]] your file and you have your own window opened!

For the lazy ones among us, here is the full code:
&lt;code cxx&gt;
// Include all the stuff
#include &quot;pandaFramework.h&quot;
#include &quot;pandaSystem.h&quot;

// Init the PandaFramework class
PandaFramework framework;

int main(int argc, char *argv[]) {
  // Open the framework
  framework.open_framework(argc, argv);
  // Set a nice title
  framework.set_window_title(&quot;Hello World!&quot;);
  // Open it!
  WindowFramework *window = framework.open_window();

  // Check whether the window is loaded correctly
  if (window != (WindowFramework *)NULL) {
    nout &lt;&lt; &quot;Opened the window successfully!\n&quot;;

    window-&gt;enable_keyboard(); // Enable keyboard detection
    window-&gt;setup_trackball(); // Enable default camera movement

    // Put here your own code, such as the loading of your models

    // Do the main loop
    framework.main_loop();
  } else {
    nout &lt;&lt; &quot;Could not load the window!\n&quot;;
  }
  // Close the framework
  framework.close_framework();
  return (0);
}
&lt;/code&gt;

The WindowFramework class also provides all the basic things the python ShowBase / DirectStart equivalent would normally take care of:
&lt;code cxx&gt;
const NodePath &amp;get_render();
const NodePath &amp;get_render_2d();
const NodePath &amp;get_aspect_2d();

void set_wireframe(bool enable);
void set_texture(bool enable);
void set_two_sided(bool enable);
void set_one_sided_reverse(bool enable);
void set_lighting(bool enable);

const NodePath &amp;get_camera_group();

INLINE int get_num_cameras() const;
INLINE Camera *get_camera(int n) const;

// WindowFramework also provides access to the GraphicsWindow.
// for example, to set the background color to black, you can do this:
window-&gt;get_graphics_window()-&gt;set_clear_color(Colorf(0,0,0,1));
&lt;/code&gt;
It's very useful to study the file panda/src/framework/windowFramework.h, since you will need to use it often.[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>The appRunner.dom object</title>
    <ns>0</ns>
    <id>2423</id>
      <sha1>kdg1mkllll1mz0i6fftl7bxxxa0l6lh</sha1>
    <revision>
      <id>6659</id>
      <timestamp>2010-02-08T21:59:20Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="967">Another important member of base.appRunner is the &quot;dom&quot; object.  This is the top of the JavaScript DOM (&quot;Document Object Model&quot;) hierarchy, and corresponds to the global scope (that is, the &quot;window&quot; object) in JavaScript.

In general, global objects and functions in JavaScript will be visible to the Python code as members of appRunner.dom.  In particular, base.appRunner.dom.document corresponds to the toplevel &quot;document&quot; object, which you can use to access the contents of the embedding web page itself.

For example, to update the value in a field called &quot;username&quot; on form called &quot;login&quot; on the web page, you could write Python code like this:

&lt;code python&gt;
login = base.appRunner.dom.document.getElementById('login')
login.username.value = 'username'
&lt;/code&gt;

In general, anything you can do in JavaScript, you can do in Python, via the base.appRunner.dom object.

The dom object is always available; it is not limited by the [[P3D origin security]] features.</text>
    </revision>
  </page>
  <page>
    <title>The appRunner.main object</title>
    <ns>0</ns>
    <id>2422</id>
      <sha1>lfwcdma06crx2ria4t93qf9x40lmuja</sha1>
    <revision>
      <id>7129</id>
      <timestamp>2011-03-30T08:16:09Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>Fixed the JavaScript code to actually work. Firefox rightfully complained about document.getObjectById not existing. getElementById proves to work.</comment>
      <text xml:space="preserve" bytes="1672">The most important member of base.appRunner is the &quot;main&quot; object.  This object is the same object as plugin.main as seen from the JavaScript side (where &quot;plugin&quot; is the DOM object corresponding to the application's &lt;object&gt; element).

That is to say, any data members you store on base.appRunner.main will be visible to JavaScript as members of plugin.main.  Any function pointers that you store on base.appRunner.main will be callable from JavaScript as functions of plugin.main.  Any objects that you store on base.appRunner.main will be visible as objects of plugin.main, along with all methods and nested objects.  (But see [[P3D origin security]].)

Conversely, any members stored on plugin.main by JavaScript will be accessible as members of base.appRunner.main on the Python side, and similarly for functions and nested objects.

For instance, if you write Python code that does this:

&lt;code python&gt;
base.appRunner.main.base = base
&lt;/code&gt;

Then your JavaScript code could do this:

&lt;code javascript&gt;
plugin = document.getElementById('myPlugin')
plugin.main.base.toggleWireframe()
&lt;/code&gt;

which calls base.toggleWireframe(), a method that toggles wireframe rendering in the Panda3D window.

Normally, you would use base.appRunner.main as a place to store values, objects, and functions that you want to make accessible to your JavaScript code.

Note that, for security purposes, by default JavaScript is prevented from doing any of this: it cannot access base.appRunner.main, or call any Python methods that you expose either intentionally or unintentionally, unless you specifically allow it, by setting the p3d file's script_origin.  See [[P3D origin security]].</text>
    </revision>
  </page>
  <page>
    <title>The package system</title>
    <ns>0</ns>
    <id>2405</id>
      <sha1>ecbn9qe8kz412ybff9rrkg4xmkbvuy0</sha1>
    <revision>
      <id>6652</id>
      <timestamp>2010-02-08T21:28:12Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <comment>try to clarify version string</comment>
      <text xml:space="preserve" bytes="3316">The Panda3D plugin uses a system of &quot;packages&quot; to manage additional content needed by p3d files.

A package is a Panda multifile, similar to a p3d file.  Like a p3d file, it can contain Python code, C++ code, models, and textures, or really anything an application might need to run; but unlike a p3d file, it does not (necessarily) contain an application.  

Everything that the Panda3D plugin downloads, other than the p3d file itself, is downloaded as part of a package file.  For instance, if your applicationm makes use of audio, you will build it with &quot;-r audio&quot; on the packp3d command line, which tells Panda3D to download and install the audio package before beginning your application.  Even Panda3D itself, which the plugin downloads to run your application, is downloaded in a package.

A package is identified with four pieces of information:

* The package name
* The package &quot;version&quot; name, may be empty
* The current platform string, empty for any platform
* The host URL

It all starts with the host URL.  The host URL is used throughout the Panda3D plugin system to refer to a particular download server.  It is possible to build and host your own packages that the plugin can download; you will need to supply a host URL.  You should be careful to always specify the host URL with precisely the same string, because that is a unique identifier within the plugin system; for instance, don't use &quot;http://myhost.mydomain.net:/my/root_dir&quot; in one place, and &quot;http://myhost.mydomain.net:/my/root_dir/&quot; in another, even though the two URL's are technically equivalent.

This can be any URL, but there must exist a file called contents.xml at that URL, e.g. if the host URL is &quot;http://myhost.mydomain.net/my/root_dir&quot;, then there must exist a file &quot;http://myhost.mydomain.net/my/root_dir/contents.xml&quot;.  This file is the key piece of information that the plugin uses to determine which packages are provided by that host, and whether they need to be updated for a particular user.

The package name and version are used together to uniquely identify a particular package file on a given host URL.

Note that the &quot;version&quot; is &lt;em&gt;not&lt;/em&gt; intended to represent sequential releases made for a package.  The version is not a number that you increment with each update you make to a package; rather, the version is a completely arbitrary string that differentiates mutually-incompatible variations of the package.  A p3d file will reference a package by its name and version, and it will automatically download the most recent update available for a particular name/version combination.  However, if you release a different version of a particular package using a different version string, existing p3d files will not download that different version--it's considered a different series.

The platform string is either empty if the package can be used on any platform, or it is a string such as &quot;win32&quot; or &quot;osx_i386&quot; to indicate the particular platform for which this version of the package is built.  If a package contains platform-specific content such as compiled dll's or exe's, its platform string should be nonempty.  There may be a different form of the package for each supported platform on a given host.  The Panda3D runtime will automatically download the platform-appropriate package, if available.</text>
    </revision>
  </page>
  <page>
    <title>The pdef syntax</title>
    <ns>0</ns>
    <id>2411</id>
      <sha1>fhmnpxggjov17y0oce7cnpae8cqpgk0</sha1>
    <revision>
      <id>6965</id>
      <timestamp>2010-10-25T17:35:44Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>clarify 'optional required flag'</comment>
      <text xml:space="preserve" bytes="3230">A package definition looks something like a Python class definition:
&lt;code python&gt;
class mypackage(package):
    file('neededfile.dll')
    module('my.python.module')
    dir('/c/my/root_dir')
&lt;/code&gt;

In fact, you can put any Python syntax you like into a pdef file, and it will be executed by ppackage.  A pdef file is really just a special kind of Python program.  The class syntax shown above is just the convention by which packages are declared.

The above sample generates a package called &quot;mypackage&quot;, which contains the file neededfile.dll and the Python module my/python/module.py, as well as all files that those two files reference in turn; it also includes all of the contents of c:\my\root_dir .

More details of the pdef syntax will be provided soon.  In the meantime, you can also examine the file direct/src/p3d/panda3d.pdef, for a sample file that produces the panda3d package itself (as well as some related packages).  

You can also examine the file direct/src/p3d/Packager.py; any method of Packager named do_foo() produces a package function you can call named foo().  For instance, there is a Packager.do_file() method that accepts a Filename (as well as other optional parameters); this method is called when file() appears within a class definition in a pdef file.

Sometimes the files and modules you wish to include are not on the path, and thus can not be found. To see what is on the path is when your pdef file is run, you can use this at the top of your pdef file:
&lt;code python&gt;
import sys
print sys.path
&lt;/code&gt;

Often when building packages, it's useful to have the working directory on the path, but it may be missing. It can be added with:
&lt;code python&gt;
import sys
sys.path.insert(0,'') #add the working directory as the first entry in sys.path
&lt;/code&gt;

When making p3d packages, you use p3d instead of package for the class. An example p3d could be as follows:
&lt;code python&gt;
import sys
# add the working directory to the path so local files and modules can be found
sys.path.insert(0,'') 

class MyP3D(p3d):
    require('morepy','panda3d','somePackage') # include some other packages
        
    config( 
        version=&quot;0.0&quot;, 
        display_name=&quot;MyP3D&quot;) 
    
    module('core.*') # include the python package core, and its submodules
    dir('data',newDir='data') # include a folder called data
    mainModule('main') # include and set the main module that runs when the p3d is run
    file('events.txt') # include a text file
&lt;/code&gt;

Generally what ppackage is pretty good about finding what modules are imported and automatically including them, but there are cases where this fails and explicitly specifying something like &quot;module('api.*.*')&quot; is useful.

As of Panda3D 1.7.1, you can specify an optional 'required' parameter to the file() or module() function call.  By setting it to true, you can indicate that this file is vital to the package.  Basically, when the file is missing and the required flag is set, it will refuse to build the package (rather than just emitting a warning).

You can put loops, if statements (based on os.name for example) and other flow control inside packages, but calling functions outside of them that add files and modules and such will not work.</text>
    </revision>
  </page>
  <page>
    <title>The runtime Panda3D directory</title>
    <ns>0</ns>
    <id>2472</id>
      <sha1>fd7fwztlw1ywdofcd6npet4dh0zvmsa</sha1>
    <revision>
      <id>6655</id>
      <timestamp>2010-02-08T21:46:49Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="3078">When the Panda3D runtime (including the web plugin) runs a p3d file, it must download key files into a particular directory on your hard disk.  This directory's location depends on the operating system (and, to a certain extent, the browser) in use.

On Windows, the Panda3D directory is %LocalAppData%\Panda3D.  This usually translates to:

* C:\Documents and Settings\&lt;your name&gt;\Local Settings\Application Data\Panda3D on Windows XP, or
* C:\Users\&lt;your name&gt;\AppData\Local\Panda3D on Windows Vista or Windows 7.

However, when you are running via IE on Windows Vista or Windows 7, the operating system remaps %LocalAppData% to a new location, which is:

* C:\Users\&lt;your name&gt;\AppData\LocalLow\Panda3D

On Mac OSX, the Panda3D directory is ~/Library/Caches/Panda3D, which is:

* /Users/&lt;your name&gt;/Library/Caches/Panda3D

On Linux, the Panda3D directory is ~/.panda3d .

The contents of the Panda3D directory will gradually fill up over time as new packages are downloaded and installed.  Later versions of the Panda3D runtime will automatically manage this space and remove old packages as needed, but at the moment, the current release of the runtime does not do this; thus, you may need to occasionally clean up this directory by hand.

There are several subdirectories within the Panda3D directory.  They are:

* certs - this contains any certificates you have approved in the past.  If you remove this directory and all its contents, you will have to re-approve any certificates before running any p3d files.

* coreapi - this is a temporary cache that stores the &quot;core API&quot; used to manage the runtime code itself.  If you remove this directory, it will automatically be re-downloaded the next time you run.

* hosts - this contains the packages downloaded and installed from various webservers.  Each server will have its own subdirectory within this directory.  This is likely to be the largest directory in this structure.  You can remove any or all of these host subdirectories at will; if needed again, the required data will be re-downloaded automatically.

* log - this contains the various log files created by past executions of the runtime.  In particular, &quot;p3dsession.log&quot; is the output from the Python session of the most recent p3d file you have run (unless the p3d file specifies a different, custom logfile name).  You may find this file useful to help debug issues while you are developing your own p3d files.

* prc - this is an empty directory in which you may place your own custom prc files to customize the Panda3D runtime for all p3d files.  For instance, if you know your graphics card runs better in DirectX9 than in OpenGL, you can place a prc file in this directory with the line &quot;load-display pandadx9&quot; to specify that DirectX9 should be used by preference in all p3d files.

* start - this is the default working directory when a p3d file starts up.  Some p3d files may record their game state information in files in this directory.  If you remove this directory and its contents, it may reset some of your p3d files to their initial state.</text>
    </revision>
  </page>
  <page>
    <title>Third-party dependencies and license info</title>
    <ns>0</ns>
    <id>2494</id>
      <sha1>paku2dg9wh18m7h1e8ui3dvm8jvfekt</sha1>
    <revision>
      <id>60303</id>
      <timestamp>2014-12-06T15:55:18Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>/* MP3 */</comment>
      <text xml:space="preserve" bytes="11023">== License Info  ==
While Panda3D itself uses the Modified BSD license, it brings together many third-party libraries released under different licenses. This page provides information on the different libraries and their licenses.  Panda3D builds with some of these libraries by default, however, some of them are linked only into plug-ins that can be easily removed from the distribution.

== Disclaimer ==
Panda3D takes no responsibility for any act committed using the information presented here. For legal advice, it is recommended to consult a lawyer.

== Building Panda3D ==
When building Panda3D yourself on your computer you'll notice that makepanda.py looks up if you have some libraries installed. On operating systems with a packaging system, like most GNU/Linux distros have, you'll most likely find all dependencies as packages in the official repositories. Otherwise you have to take care of the libraries yourself.

Here you have a list of all third party libraries Panda3D must or can be compiled against.  All of them are optional, but some features of Panda3D depend on certain libraries being available; omitting certain libraries will omit the corresponding features from Panda3D.

== Recommended Libraries ==

== Python ==
http://www.python.org/ &lt;br /&gt;
Panda3D is way easier and faster to code with when using Python bindings. &lt;br /&gt;
License: [http://www.python.org/download/releases/2.6.2/license PSF license]

=== ZLib ===
http://www.zlib.net/ &lt;br /&gt;
Used for a range of compression and decompression tasks, particularly .pz files. &lt;br /&gt;
License: [http://www.zlib.net/zlib_license.html zlib license]

=== libjpeg ===
http://www.ijg.org &lt;br /&gt;
JPEG library.  Required to read and save JPEG files. &lt;br /&gt;
License: libjpeg license

=== libpng ===
http://www.libpng.org &lt;br /&gt;
Portable Network Graphics library.  Required to read and save PNG files. &lt;br /&gt;
License: [http://www.libpng.org/pub/png/src/libpng-LICENSE.txt libpng license]

=== OpenSSL ===
http://www.openssl.org &lt;br /&gt;
Provides some networking and encryption support.  Required for HTTPClient, and for pencrypt/pdecrypt and related functionality.
License: [http://www.openssl.org/source/license.html OpenSSL license] &lt;br /&gt;
License note:  &lt;br /&gt;
Must include this acknowledgement with distribution:
&lt;code text&gt;This product includes software written by Tim Hudson (tjh@cryptsoft.com)&lt;/code&gt;
[http://rechten.uvt.nl/koops/cryptolaw Some governments] place restrictions on cryptography.

=== libvorbis ===
http://xiph.org/vorbis/ &lt;br /&gt;
Used to load .ogg files encoded with Vorbis encoding. &lt;br /&gt;
License: [http://svn.xiph.org/trunk/vorbis/COPYING BSD] &lt;br /&gt;

=== Freetype ===
http://freetype.sourceforge.net &lt;br /&gt;
Font library.  Required to use dynamic fonts such as TTF files.  Even without this library, however, Panda can use static fonts stored in egg files, as generated by the tool egg-mkfont (however, the tool egg-mkfont itself requires Freetype). &lt;br /&gt;
License: [http://freetype.sourceforge.net/FTL.TXT FreeType License] or [http://freetype.sourceforge.net/GPL.TXT GPL] &lt;br /&gt;
License note: To distribute under a proprietary license, FreeType License must be chosen instead of GPLv2.  Use of FreeType must be acknowledged in product documentation.

=== GTK2 ===
http://www.gtk.org &lt;br /&gt;
The Gimp ToolKit is used by only by the PStats server on non-Windows platforms.  This is a separate utility that can easily be deleted and is only used when profiling applications.  &lt;br /&gt;
License: [http://www.gnu.org/licenses/old-licenses/lgpl-2.1.html GNU LGPL]

=== OpenAL Soft ===
http://openal-soft.org
The Open Audio Library is a free alternative to FMOD and supports nearly the same features, including 3D surround sound.  We ship the OpenAL Soft implementation by default on Windows.  It can be easily removed from the distribution. &lt;br /&gt;
License: LGPL &lt;br /&gt;

=== Cg Toolkit ===
http://developer.nvidia.com/object/cg_toolkit.html &lt;br /&gt;
Nvidia's Cg Toolkit is required for Panda's Cg support. &lt;br /&gt;
License: [http://developer.download.nvidia.com/cg/Cg_2.2/license.pdf Proprietary] &lt;br /&gt;
License note: Required to use the Panda3D Shader Generator, which utilizes Nvidia Cg.

=== Eigen ===
http://eigen.tuxfamily.org/ &lt;br /&gt;
Optimized linear algebra library.  Optional, but improves performance of matrix operations significantly. &lt;br /&gt;
License: [http://www.mozilla.org/MPL/2.0/ MPL2]

=== libsquish ===
http://code.google.com/p/libsquish/ &lt;br /&gt;
Libsquish gives DXT support.  This improves Panda's support for pre-compressed texture images such as dds files, and it allows Panda to streamline compression of textures images at load time.  However, even without this library, Panda can still compress and use compressed textures, by relying on the interfaces built into your graphics driver. &lt;br /&gt;
License: MIT license

=== libtiff ===
http://www.remotesensing.org/libtiff &lt;br/&gt;
Tiff image format support. &lt;br/&gt;
License: [http://www.epsiia.com/licenses/libtiff.html libtiff license]

=== DirectX (Windows only) ===
http://msdn.microsoft.com/en-us/directx/default.aspx &lt;br/&gt;
Windows DirectX libraries. &lt;br /&gt;
License: Proprietary

=== X libraries (Linux/FreeBSD only) ===
http://www.x.org/ &lt;br /&gt;
X libraries: X11 (display system), Xrandr (support for changing resolution), Xxf86dga (provides relative mouse mode), Xcursor (provides custom cursor image support). &lt;br /&gt;
License: [http://opensource.org/licenses/mit-license.php MIT License]

=== MFC (Windows only) ===
http://msdn.microsoft.com/en-us/library/d06h2x6e%28VS.80%29.aspx &lt;br/&gt;
Windows MFC libraries.  Used by the ActiveX plug-in. &lt;br /&gt;
License: Proprietary

=== NPAPI ===
https://code.google.com/p/npapi-sdk/ &lt;br /&gt;
Netscape plugin API (a set of interfaces to write browser plug-ins). It is only necessary to compile the Panda3D browser plug-in. &lt;br /&gt;

== Optional ==

=== FFMPEG ===
http://ffmpeg.org &lt;br /&gt;
Library for video and audio.  Required to load and play video textures.  As of Panda3D 1.9.0, libp3ffmpeg.dll is an optional module that can be easily removed, and is no longer required for .ogg and .wav files. &lt;br /&gt;
License: [http://www.ffmpeg.org/legal.html LGPL] &lt;br /&gt;
License note: Must link dynamically. 

=== FMOD Ex ===
http://www.fmod.org &lt;br /&gt;
FMOD Ex is a proprietary audio library that supports various effects and surround sound.  You must have one of FMOD or OpenAL to build support for Panda's sound interfaces.  (However, you can use external sound libraries such as pygame, even without these two.) &lt;br /&gt;
License: [http://www.fmod.org/index.php/sales Proprietary] &lt;br /&gt;
License note: Non-commercial distribution costs nothing.
Commercial distribution costs between US$100 and US$6000 depending on FMOD licensing option.

=== Bullet Physics ===
http://bulletphysics.org &lt;br /&gt;
Physics Library. &lt;br /&gt;
License: [http://www.zlib.net/zlib_license.html zlib license]

=== PhysX ===
https://developer.nvidia.com/physx &lt;br /&gt;
NVIDIA physics library. &lt;br /&gt;
License: Proprietary.

=== Open Dynamics Engine (ODE)===
http://www.ode.org &lt;br /&gt;
One of the most versatile, free physics engines. &lt;br /&gt;
License: [http://www.ode.org/ode-license.html LGPL or Modified BSD License]

=== OpenGL ES ===
http://www.khronos.org/opengles/ &lt;br /&gt;
OpenGL for embedded systems: GLES (http://www.khronos.org/registry/gles/), GLES2 (http://www.khronos.org/opengles/2_X/) and EGL (http://www.khronos.org/registry/egl/) libraries.

=== 3ds Max SDK ===
http://www.autodesk.com/products/autodesk-3ds-max/overview &lt;br /&gt;
Used to create exporters for Autodesk 3ds Max. &lt;br /&gt;
License: Proprietary.

=== Maya SDK ===
http://www.autodesk.com/products/autodesk-maya/overview &lt;br /&gt;
Used to create exporters for Maya. &lt;br /&gt;
License: Proprietary.

=== speedtree ===
http://www.speedtree.com/ &lt;br /&gt;
Library for rendering trees. &lt;br /&gt;
License: Proprietary.

=== libRocket ===
http://librocket.com/ &lt;br/&gt;
C++ user interface middleware package based on the HTML and CSS standards. &lt;br/&gt;
License: [http://librocket.com/wiki/license MIT License]

=== OpenCV ===
http://opencv.willowgarage.com &lt;br /&gt;
An alternate library that provides support for video textures and webcam , similar to FFMPEG. &lt;br /&gt;
License: BSD license

=== FCollada ===
https://collada.org/mediawiki/index.php/FCollada &lt;br /&gt;
FCollada is an open-source C++ library which offers support for COLLADA interoperability, used for dae2egg and for loading dae files directly into Panda. &lt;br /&gt;
License: MIT license

=== FFTW ===
http://www.fftw.org &lt;br /&gt;
Fast Fourier Fransforms library for lossy animation compression in bam files.  Compressed animation files may be as small as 10% of the uncompressed animation, but this is only an on-disk and/or download savings.
License: [http://www.fftw.org/fftw3_doc/License-and-Copyright.html GPL or Proprietary] &lt;br /&gt;
License note: To distribute under a proprietary license, GPL must not be used, and FFTW proprietary license must be purchased.

=== ARToolKit ===
http://www.hitl.washington.edu/artoolkit/ &lt;br /&gt;
A library for augmented reality. It makes possible detecting 3D planes in live webcam video streams and applying 3D geometry to those, for integrating 3D graphics with a live video feed. &lt;br /&gt;
License: [http://www.hitl.washington.edu/artoolkit/license.html GPL or Proprietary] &lt;br /&gt;
License note: To distribute under a proprietary license, GPL must not be used, and ARToolKit proprietary license must be purchased.

=== VRPN ===
http://www.cs.unc.edu/Research/vrpn &lt;br/&gt;
Virtual-Reality Peripheral Network, for using a range of different types of trackers and controllers with Panda3D. &lt;br/&gt;
License: [http://www.cs.unc.edu/Research/vrpn/obtaining_vrpn.html Public domain]

=== awesomium ===
http://awesomium.com/ &lt;br /&gt;
Windowless port of Chromium/WebKit. Can be used to render HTML pages.&lt;br /&gt;
License: [https://awesomium.com/buy/ Proprietary]

== Build Tools (for compilation only) ==
=== Bison ===
http://www.gnu.org/software/bison/ &lt;br /&gt;
General-purpose parser generator.

=== Flex ===
http://flex.sourceforge.net/ &lt;br /&gt;
The Fast Lexical Analyzer.

==Patent Restriction Issues==
===MP3===
&lt;p&gt;MPEG-1 Audio Layer 3 (MP3), while commonly used, is recommended against. The format has patent and licensing issues in many countries. Unlicensed use of MP3 runs the risk of infringing in these countries. [http://mp3licensing.com/royalty/games.html Licensing] the use of MP3 costs at minimum royalties of US$2500 per title for games and $15000 per calendar year for other software.&lt;/p&gt;

===MPEG===
&lt;p&gt;Other MPEG related formats are restricted by [http://www.mpegla.com/main/default.aspx patents] as well. Finding the prices of licenses for these formats is not even as easy as it is with MP3. More info [http://bemasc.net/wordpress/2010/02/02/no-you-cant-do-that-with-h264/ here].&lt;/p&gt;

===Recommended Alternatives===
&lt;p&gt;Free alternatives exist and are highly encouraged. These formats include [http://www.vorbis.com Ogg Vorbis] (lossy) and [http://flac.sourceforge.net Ogg FLAC] (lossless) for audio, and [http://www.theora.org Ogg Theora] for video.&lt;/p&gt;</text>
    </revision>
  </page>
  <page>
    <title>Thread</title>
    <ns>0</ns>
    <id>2298</id>
    <redirect title="Threading" />
      <sha1>mvg5zlr2s8t6mro2bg6nedzefbrzsjm</sha1>
    <revision>
      <id>5617</id>
      <timestamp>2008-11-22T10:34:39Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <comment>Redirecting to [[Threading]]</comment>
      <text xml:space="preserve" bytes="23">#REDIRECT [[Threading]]</text>
    </revision>
  </page>
  <page>
    <title>Threading</title>
    <ns>0</ns>
    <id>2297</id>
      <sha1>fbhsgxedav5y7xoj49nkomvu7itj1nw</sha1>
    <revision>
      <id>7691</id>
      <timestamp>2012-03-09T10:09:27Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>new import system</comment>
      <text xml:space="preserve" bytes="8828">'''Note:''' In versions 1.6.0 and above, Panda3D provides a safe threading interface you can use, which works very similar to Python's threading modules.  Beginning in version 1.8.0, Panda3D is compiled by default to use &quot;true&quot; threading, which makes it safe to use Python threading interfaces (or any other threading library) in conjunction with or in lieu of Panda's own built-in threading interfaces described below.

If you want to test whether threading is enabled in your build of panda, use the following program:
[python]
&lt;code python&gt;
from panda3d.core import Thread
print Thread.isThreadingSupported()
&lt;/code&gt;
[/python]
[cxx]
&lt;code cxx&gt;
#include &quot;thread.h&quot;

int main () {
  cerr &lt;&lt; Thread::is_threading_supported() &lt;&lt; endl;
  return 0;
}&lt;/code&gt;[/cxx]
If threading is enabled, it's also possible to turn it off, for example if you want to test if a certain problem you are experiencing is related to threading.
Put this in your [[Config.prc]]:
&lt;code prc&gt;support-threads #f&lt;/code&gt;

&lt;h1&gt;Asynchronous Operations&lt;/h1&gt;
Panda3D provides several useful functions for loading models and doing other expensive operations in a thread, so the user of your application will not notice chugs in the frame rate.

&lt;h3&gt;Model loading&lt;/h3&gt;
For example, &lt;code&gt;loader.loadModel&lt;/code&gt; call also accepts an optional 'callback' argument.
If callback is not None, then the model load will be performed asynchronously. In this case, &lt;code&gt;loadModel()&lt;/code&gt; will initiate a background load and return immediately. The return value will be an object that may later be passed to &lt;code&gt;loader.cancelRequest()&lt;/code&gt; to cancel the asynchronous request. At some later point, when the requested model(s) have finished loading, the callback function will be invoked with the n loaded models passed as its parameter list. It is possible that the callback will be invoked immediately, even before &lt;code&gt;loadModel()&lt;/code&gt; returns. If you use callback, you may also specify a priority, which specifies the relative importance over this model over all of the other asynchronous load requests (higher numbers are loaded first).

True asynchronous model loading requires Panda to have been compiled with threading support enabled. In the absence of threading support, the asynchronous interface still exists and still behaves exactly as described, except that &lt;code&gt;loadModel()&lt;/code&gt; might not return immediately.

&lt;h3&gt;Model flattening&lt;/h3&gt;
Similarly, there is &lt;code&gt;loader.asyncFlattenStrong&lt;/code&gt;. This performs a &lt;code&gt;model.[func]flattenStrong[/func]()&lt;/code&gt; operation in a sub-thread (if threading is compiled into Panda). The model may be a single NodePath, or it may be a list of NodePaths.&lt;br&gt;
Each model is duplicated and flattened in the sub-thread.
If the optional &lt;code&gt;inPlace&lt;/code&gt; parameter is True, then when the flatten operation completes, the newly flattened copies are automatically dropped into the scene graph, in place the original models.&lt;br&gt;
If a callback is specified, then it is called after the operation is finished, receiving the flattened model (or a list of flattened models).&lt;br&gt;
The &lt;code&gt;loader.cancelRequest()&lt;/code&gt; method works for asyncFlattenStrong as well.

&lt;h3&gt;Texture uploading&lt;/h3&gt;
In addition, you can further ask textures to be loaded to the graphics card asynchronously. This means that the first time you look at a particular model, the texture might not be available; but instead of holding up the frame while we wait for it to be loaded, Panda can render the model immediately, with a flat color instead of the texture; and start the texture loading in the background. When the texture is eventually loaded, it will be applied. This results in fewer frame-rate chugs, but it means that the model looks a little weird at first. It has the greatest advantage when you are using lazy-load textures as well as texture compression, because it means these things will happen in the background.
You will need these configuration options to enable this behavior:
&lt;code prc&gt;preload-textures 0
preload-simple-textures 1
texture-compression 1
allow-incomplete-render 1&lt;/code&gt;

&lt;h3&gt;Animation loading&lt;/h3&gt;
A similar behavior can be enabled for Actors, so that when you have an Actor with a large number of animations (too many to preload them all at once), you can have the Actor load them on-demand, so that when you play an animation, the animation may not start playing immediately, but will instead be loaded in the background. Until it is ready, the actor will hold its last pose, and then when the animation is fully loaded, the actor will start playing where it would have been had the animation been loaded from the beginning. To make this work, you have to run all of the animations through &lt;code&gt;egg-optchar&lt;/code&gt; with the &lt;code&gt;-preload&lt;/code&gt; option, and you might also want to set:
&lt;code prc&gt;allow-async-bind 1
restore-initial-pose 0&lt;/code&gt;

&lt;h1&gt;Threading&lt;/h1&gt;
If you want to use threading with Panda3D, it's not recommended to use Python's built-in threading modules, since you will most likely run into issues (for Panda3D is written in C++ and thus does not use the Python threading modules).
However, Panda3D offers a threading implementation that is safe to use, by reimplementing Python's &quot;thread&quot; and &quot;threading&quot; modules, these work the same as the Python built-in threading modules but are actually safe to use with Panda3D.

You can get access to Panda3D's implementation of Python's &quot;thread&quot; module by importing the &quot;thread&quot; module from direct.stdpy:
&lt;code python&gt;# WRONG:
import thread
# RIGHT:
from direct.stdpy import thread&lt;/code&gt;

For the Python module &quot;threading&quot;, Panda3D offers two equivalents, &quot;threading&quot; and &quot;threading2&quot;, which you can find both in direct.stdpy also.
The &quot;threading&quot; module implements the threading module with a thin layer over Panda's threading constructs.  As such, the semantics are close to, but not precisely, the semantics documented for Python's standard threading module.  If you really do require strict adherence to Python's semantics, see the threading2 module instead.

In fact, the threading2 module is a bald-face copy of Python's threading module from Python 2.5, with a few lines at the top to import Panda's thread reimplementation instead of the system thread module, and so it is therefore layered on top of Panda's thread implementation.

However, if you don't need such strict adherence to Python's original semantics, the &quot;threading&quot; module is probably a better choice.  It is likely to be slightly faster than the threading2 module (and even slightly faster than Python's own threading module).  It is also better integrated with Panda's threads, so that Panda's thread debug mechanisms will be easier to use and understand.

&lt;code python&gt;# WRONG:
import threading
# RIGHT:
from direct.stdpy import threading
# ALSO RIGHT:
from direct.stdpy import threading2 as threading&lt;/code&gt;

It is permissible to mix-and-match both threading and threading2
within the same application.

&lt;h1&gt;File I/O&lt;/h1&gt;
In versions 1.6.0 and above, Panda3D also offers a thread-safe replacement for the Python file module. You can find it in direct.stdpy.file. The interface is exactly the same as Python's, so it's safe to put this import above all the files where you want to use the &quot;file&quot; or &quot;open&quot; functions:
&lt;code python&gt;from direct.stdpy.file import *&lt;/code&gt;
This module reimplements Python's file I/O mechanisms using Panda constructs.  This enables Python to interface more easily with Panda's virtual file system, and it also better-supports Panda's SIMPLE_THREADS model, by avoiding blocking all threads while waiting for I/O to complete.

&lt;h1&gt;Compiling Panda3D with threading support&lt;/h1&gt;
There are two different interfaces for threading which you can enable using the definitions HAVE_THREADS and SIMPLE_THREADS. The former is a full and heavy implementation of threading and compiling with that option will slow down the Panda3D build, unless you fully make use of the benefits that threading gives. The latter, however, is a more simple threading interface (introduced in Panda3D 1.6.0) that doesn't give you the runtime overhead HAVE_THREADS gives you. In Panda3D 1.6.1 and higher, SIMPLE_THREADS is enabled in the default build.

Note that you will have to define both HAVE_THREADS and SIMPLE_THREADS at the same time to enable the simple interface, or you will not have threading.

In the makepanda system, SIMPLE_THREADS is automatically defined for you. If you don't want it, or want to use the more heavy HAVE_THREADS instead, you will need to edit the makepanda.py script and change the definitions.

The public Panda3D 1.8.0 builds enable true threading by default, so you will not need to build Panda3D yourself if you want to take advantage of true threading.

If you use ppremake, you will just need to define either in your Config.pp file.</text>
    </revision>
  </page>
  <page>
    <title>Timing</title>
    <ns>0</ns>
    <id>1708</id>
      <sha1>aha0a3s3mmutm0gvyxa3uxk3mde65mq</sha1>
    <revision>
      <id>7689</id>
      <timestamp>2012-03-09T09:57:06Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="133">While Python's &quot;time&quot; module can do a decent job of timing, Panda3D has a built in timing system that allows for lag and CPU stutter.</text>
    </revision>
  </page>
  <page>
    <title>Tinting and Recoloring</title>
    <ns>0</ns>
    <id>2217</id>
      <sha1>ci894l7uzebwzd56o8ks6l7p3orkis4</sha1>
    <revision>
      <id>60226</id>
      <timestamp>2014-07-24T19:57:30Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="4438">==Color and the Model Loader==

When you create a 3D model in Max, Maya, or the like, you can color the model right in the modeling program.  I'm not talking about using a texture.  I'm talking about just setting a single color to the model as whole.  This is called a &quot;flat color.&quot;  These art programs also allow you to &quot;paint vertex colors&quot;: you can color each vertex of the model a different color.  Of course, sometimes you do neither, in which case the model is just white.

Every model you load &lt;i&gt;already has&lt;/i&gt; a color attribute.  Color Attributes are usually not created by the programmer explicitly, they're usually created by the model loader only.  There are three possible color attributes created by the model loader:

{| border=&quot;1&quot; cellpadding=&quot;5&quot;
| '''Method''' || '''Explanation'''
|-
| class=&quot;code&quot; | ColorAttrib.makeVertex() || Used by the model loader to indicate that the model has vertex colors stored in its vertex arrays.
|-
| class=&quot;code&quot; | ColorAttrib.makeFlat(Vec4(R,G,B,A)) || Used by the model loader to indicate that the model has a single flat color.
|-
| class=&quot;code&quot; | ColorAttrib.makeOff() || Used by the model loader to indicate that no particular color was specified.  Essentially the same as flat white, but possibly a little faster to render.
|}

Panda combines these color attributes with the textures.  If you are accustomed to Photoshop, you should think of the model's color as the bottom (background) layer, and the textures go above that.  By default, each texture is modulated (multiplied) with the previous layer, but as in Photoshop, that can be changed.


==Recoloring the Model==

If you wish, you can manually override the color attribute which has been specified by the model loader.

&lt;pre class=&quot;codeblock&quot;&gt;
nodePath.setColor(r,g,b,a)
&lt;/pre&gt;

Again, this is an &lt;i&gt;override&lt;/i&gt;.  If the model already had vertex colors, these will disappear: the &lt;code&gt;setColor&lt;/code&gt; method is replacing those colors with a new one.  If the model already had a flat color, that will be replaced with the new flat color.

It should be mentioned that the color attribute created by the model loader has low priority.  That means that even a default-priority &lt;code&gt;setColor&lt;/code&gt; is enough to override it.

You can remove a previous &lt;code&gt;setColor&lt;/code&gt; using &lt;code&gt;clearColor&lt;/code&gt;.

==Tinting the Model==

Sometimes, you don't want to &lt;i&gt;replace&lt;/i&gt; the existing color, sometimes, you want to &lt;i&gt;tint&lt;/i&gt; the existing colors.  For this, you need &lt;i&gt;setColorScale&lt;/i&gt;:

&lt;pre class=&quot;codeblock&quot;&gt;
nodePath.setColorScale(r,g,b,a)
&lt;/pre&gt;

This color will be modulated (multiplied) with the existing color.

You can remove a previous &lt;code&gt;setColorScale&lt;/code&gt; using &lt;code&gt;clearColorScale&lt;/code&gt;.

==Demonstration==

To see the difference between &lt;code&gt;setColor&lt;/code&gt; and &lt;code&gt;setColorScale&lt;/code&gt;, try the code sample below.  You will need the nik-dragon model from the Cartoon Shading sample program, which has
vertex colors and no texture:

&lt;code python&gt;
import direct.directbase.DirectStart
from panda3d.core import ColorAttrib

# Load three copies of Nik's dragon, which has vertex colors.
model1 = loader.loadModel(&quot;nik-dragon&quot;)
model2 = loader.loadModel(&quot;nik-dragon&quot;)
model3 = loader.loadModel(&quot;nik-dragon&quot;)

# Put them in the scene.
model1.reparentTo(render)
model2.reparentTo(render)
model3.reparentTo(render)

# Arrange them left-to-right
model1.setPos(-10,50,0)
model2.setPos(  0,50,0)
model3.setPos( 10,50,0)

# Model 1 will be left alone, so you can see the original.
# Model 2 will be recolored light blue.
# Model 3 will be tinted light blue.
model2.setColor(0.6, 0.6, 1.0, 1.0)
model3.setColorScale(0.6, 0.6, 1.0, 1.0)

run()
&lt;/code&gt;

This produces the following output:

[[Image:Tinting-and-recoloring1.jpg]]

The model on the left is the original, unaltered model.  Nik has used vertex colors throughout.  The yellow of the belly, the black eyes, the red mouth, these are all vertex colors.  The one in the
middle has been &lt;code&gt;setColor&lt;/code&gt;ed to a medium-blue color.  As you can see, the &lt;code&gt;setColor&lt;/code&gt; completely replaces the vertex colors.  The one on the right bas been &lt;code&gt;setColorScale&lt;/code&gt;ed to the same medium-blue color, but this only tints the model.

== Related Classes ==
*[http://panda3d.net/apiref.php?page=ColorScaleAttrib ColorScaleAttrib]
*[http://panda3d.net/apiref.php?page=ColorAttrib ColorAttrib]
*[http://panda3d.net/apiref.php?page=NodePath NodePath]</text>
    </revision>
  </page>
  <page>
    <title>Transmitting Data</title>
    <ns>0</ns>
    <id>2045</id>
      <sha1>pariju0hqmb0oiqraexyj3pe4k6mn22</sha1>
    <revision>
      <id>6323</id>
      <timestamp>2009-11-06T15:57:21Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>code tags</comment>
      <text xml:space="preserve" bytes="2828">Once a connection has been established, data can be transmitted from one Panda program to another using the classes described in this section. Communication can happen in both directions (i.e. client-to-server or server-to-client); once the connection has been established, either side may send messages along the connection to the other side.

This section describes message passing in detail, first transmission, then receipt of a message.

&lt;h2&gt;Sending a message&lt;/h2&gt;

To send a message along an established connection, the sender must first construct a PyDatagram containing the message. This involves instantiating a PyDatagram object and then populating its contents with the desired data. The type of the data is determined by the functions used to pack it; see the full documentation of the PyDatagram class for more details.

&lt;code python&gt;
# Developer-defined constants, telling the server what to do.
# Your style of how to store this information may differ; this is
# only one way to tackle the problem
PRINT_MESSAGE = 1

def myNewPyDatagram(self):
  # Send a test message
  myPyDatagram = PyDatagram()
  myPyDatagram.addUint8(PRINT_MESSAGE)
  myPyDatagram.addString(&quot;Hello, world!&quot;)
  return myPyDatagram
&lt;/code&gt;

As shown in the previous section, once the datagram is constructed you may then send it using a ConnectionWriter.

&lt;code python&gt;
cWriter.send(myPyDatagram, aConnection)
&lt;/code&gt;

&lt;h2&gt;Receiving a message&lt;/h2&gt;

As shown in the previous section, when a message is received via a QueuedConnectionReader, it can be retrieved into a NetDatagram:

&lt;code python&gt;
datagram = NetDatagram()
if cReader.getData(datagram):
  myProcessDataFunction(datagram)
&lt;/code&gt;

A NetDatagram contains the original information that was stored in the transmitted PyDatagram. It also contains knowledge of the connection over which it was received and the address of the connection. To retrieve the connection, use the getConnection method:

&lt;code python&gt;
sourceOfMessage = datagram.getConnection()
&lt;/code&gt;

To retrieve the contents of the message, use the PyDatagramIterator. The iterator class acts as the complement of the PyDatagram class; its methods can be used to retrieve the content that was encoded using PyDatagram. 

&lt;code python&gt;
def myProcessDataFunction(netDatagram):
  myIterator = PyDatagramIterator(netDatagram)
  msgID = myIterator.getUint8()
  if msgID == PRINT_MESSAGE:
    messageToPrint = myIterator.getString()
    print messageToPrint
&lt;/code&gt;

&lt;b&gt;Note&lt;/b&gt;: It is assumed that the message recipient will retrieve the same type of content in the same order that the message sender packed the content. No mechanism exists in the PyDatagramIterator to ensure that the data being unpacked matches the requested type. Unpacking the data using a different type function will probably result in unexpected behavior.</text>
    </revision>
  </page>
  <page>
    <title>Transparency and Blending</title>
    <ns>0</ns>
    <id>1067</id>
      <sha1>jv1azxar5k8pekn0bomlyzu6f6ty9h3</sha1>
    <revision>
      <id>6906</id>
      <timestamp>2010-08-19T22:03:24Z</timestamp>
      <contributor>
        <username>Gogg</username>
        <id>389</id>
      </contributor>
      <text xml:space="preserve" bytes="6103">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

&lt;b&gt;Dealing with Depth-Sorting&lt;/b&gt;

&lt;!--Note: this page is cut-and-pasted from a howto we found.  We'll polish it later.--&gt;

Usually transparency works as expected in Panda automatically, but
sometimes it just seems to go awry, where a semitransparent object in
the background seems to partially obscure a semitransparent object in
front of it.  This is especially likely to happen with large flat
polygon cutouts, or when a transparent object is contained within
another transparent object, or when parts of a transparent object can
be seen behind other parts of the same object.

The fundamental problem is that correct transparency, in the absence
of special hardware support involving extra framebuffer bits, requires
drawing everything in order from farthest away to nearest.  This means
sorting each polygon--actually, each pixel, for true correctness--into
back-to-front order before drawing the scene.

It is, of course, impossible to split up every transparent object into
individual pixels or polygons for sorting individually, so Panda sorts
objects at the Geom level, according to the center of the bounding
volume.  This works well 95% of the time.

You run into problems with large flat polygons, though, since these
tend to have parts that are far away from the center of their bounding
volume.  The bounding-volume sorting is especially likely to go awry
when you have two or more large flats close behind the other, and you
view them from slightly off-axis.  (Try drawing a picture, of the two
flats as seen from the top, and imagine yourself viewing them from
different directions.  Also imagine where the center of the bounding
volumes is.)

Now, there are a number of solutions to this sort of problem.  No one
solution is right for every situation.

First, the easiest thing to do is to use M_dual transparency.  This is
a special transparency mode in which the completely invisible parts of
the object aren't drawn into the Z-buffer at all, so that they don't
have any chance of obscuring things behind them.  This only works well
if the flats are typical cutouts, where there is a big solid part
(alpha == 1.0) and a big transparent part (alpha == 0.0), and not a
lot of semitransparent parts (0.0 &lt; alpha &lt; 1.0).  It is also a
slightly more expensive rendering mode than the default of M_alpha, so
it's not enabled by default in Panda.  But egg-palettize will turn it
on automatically for a particular model if it detects textures that
appear to be cutouts of the appropriate nature, which is another
reason to use egg-palettize if you are not using it already.

If you don't use egg-palettize (you really should, you know), you can
just hand-edit the egg files to put the line:
&lt;code prc&gt;
&lt;Scalar&gt; alpha { dual }
&lt;/code&gt;
within the &lt;Texture&gt; reference for the textures in question.

A second easy option is to use M_multisample transparency, which
doesn't have any ordering issues at all, but it only looks good on
very high-end cards that have special multisample bits to support
full-screen antialiasing.  Also, at the present it only looks good on
these high-end cards in OpenGL mode (since our pandadx drivers don't
support M_multisample explicitly right now).  But if M_multisample is
not supported by a particular hardware or panda driver, it
automatically falls back to M_binary, which also doesn't have any
ordering issues, but it always has jaggy edges along the cutout edge.
This only works well on texture images that represent cutouts, like
M_dual, above.

If you use egg-palettize, you can engage M_multisample mode by putting
the keyword &quot;ms&quot; on the line with the texture(s).  Without
egg-palettize, hand-edit the egg files to put the line:
&lt;code prc&gt;
&lt;Scalar&gt; alpha { ms }
&lt;/code&gt;
within the &lt;Texture&gt; reference for the textures in question.

A third easy option is to chop up one or both competing models into
smaller pieces, each of which can be sorted independently by Panda.
For instance, you can split one big polygon into a grid of little
polygons, and the sorting is more likely to be accurate for each piece
(because the center of the bounding volume is closer to the pixels).
You can draw a picture to see how this works.  In order to do this
properly, you can't just make it one big mesh of small polygons, since
Panda will make a mesh into a single Geom of tristrips; instead, it
needs to be separate meshes, so that each one will become its own
Geom.  Obviously, this is slightly more expensive too, since you are
introducing additional vertices and adding more objects to the sort
list; so you don't want to go too crazy with the smallness of your
polygons.

A fourth option is simply to disable the depth write on your
transparent objects.  This is most effective when you are trying to
represent something that is barely visible, like glass or a soap
bubble.  Doing this doesn't improve the likelihood of correct sorting,
but it will tend to make the artifacts of an incorrect sorting less
obvious.  You can achieve this by using the transparency option
&quot;blend_no_occlude&quot; in an egg file, or by explicitly disabling the
depth write on a loaded model with node_path.set_depth_write(false).
You should be careful only to disable depth write on the transparent
pieces, and not on the opaque parts.

A final option is to make explicit sorting requests to Panda.  This is
often the last resort because it is more difficult, and doesn't
generalize well, but it does have the advantage of not adding
additional performance penalties to your scene.  It only works well
when the transparent objects can be sorted reliably with respect to
everything else behind them.  For instance, clouds in the sky can
reliably be drawn before almost everything else in the scene, except
the sky itself.  Similarly, a big flat that is up against an opaque
wall can reliably be drawn after all of the opaque objects, but before
any other transparent object, regardless of where the camera happens
to be placed in the scene.  See howto.control_render_order.txt for
more information about explicitly controlling the rendering order.</text>
    </revision>
  </page>
  <page>
    <title>Troubleshooting makepanda on Linux</title>
    <ns>0</ns>
    <id>1089</id>
      <sha1>0m05svpa27gd4iht1c7t1zzw09bdx1y</sha1>
    <revision>
      <id>5592</id>
      <timestamp>2008-11-06T13:17:13Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>oops, added linebreak</comment>
      <text xml:space="preserve" bytes="813">This page describes potential build issues that may arise when building Panda3D using the Makepanda build system on the Linux platform, and possible solutions.

&lt;h2&gt;Undefined reference to `__isoc99_sscanf'&lt;/h2&gt;

If you're building Panda3D on 64-bits linux, and run into this error:
&lt;pre class=&quot;codeblock&quot;&gt;g++ -o built/bin/apply_patch -Lbuilt/lib -L/usr/X11R6/lib built/tmp/apply_patch_apply_patch.o
-lpanda -lpandaexpress -lp3dtool -lp3dtoolconfig -lp3pystub -lz -lssl -lpthread -ldl
built/lib/libpanda.so: undefined reference to `__isoc99_sscanf'
collect2: ld returned 1 exit status&lt;/pre&gt;
This error is related to the ffmpeg thirdparty package, which has been compiled with a very recent version of glibc. You either need to upgrade your system's glibc version (recommended) or you can compile with --no-ffmpeg .</text>
    </revision>
  </page>
  <page>
    <title>Troubleshooting makepanda on Windows</title>
    <ns>0</ns>
    <id>1088</id>
      <sha1>c0un9xsv3h42rtwbo0kcdwa1yfcjmma</sha1>
    <revision>
      <id>60541</id>
      <timestamp>2015-08-08T20:06:21Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <text xml:space="preserve" bytes="504">This page describes potential build issues that may arise when building Panda3D using the Makepanda build system on the Windows platform, and possible solutions.

== Build takes long ==

Due to flaws in the Microsoft Visual C++ compiler, a build with Eigen enabled can take many hours to complete.  It is advised to add the --no-eigen option when compiling Panda3D to disable this optional feature, sacrificing a tiny amount of runtime performance for a build that completes in minutes rather than hours.</text>
    </revision>
  </page>
  <page>
    <title>Troubleshooting ppremake on Linux</title>
    <ns>0</ns>
    <id>1087</id>
      <sha1>3nvmepdbmjy2ijsk0ccioipkvpb0kcx</sha1>
    <revision>
      <id>5590</id>
      <timestamp>2008-11-06T13:11:21Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>build error for 1.5.3</comment>
      <text xml:space="preserve" bytes="950">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt; 
This page describes potential build issues that may arise when building Panda3D using the PPremake build system on the Linux platform, and possible solutions.

&lt;h2&gt;Undeclared 'vector_string'&lt;/h2&gt;

If you compile Panda3D 1.5.3 using ppremake, you might get this error:
&lt;pre class=&quot;codeblock&quot;&gt;filename.h:136: error: ‘vector_string’ has not been declared&lt;/pre&gt;
This error occurs because some header files in the &quot;ppremake&quot; directory were accidentally truncated in the 1.5.3 source.
This bug has been fixed in 1.5.4. If you still want to compile on 1.5.3, you will need to grab a newer version of the &quot;ppremake&quot; directory from CVS, for example using this command:
&lt;pre class=&quot;codeblock&quot;&gt;rm -rf ppremake
cvs -d :pserver:anonymous@panda3d.cvs.sourceforge.net:/cvsroot/panda3d checkout -A -r panda3d_1_5_4 ppremake&lt;/pre&gt;
Make sure you have cd'ed to the root of the source tree before executing those commands.</text>
    </revision>
  </page>
  <page>
    <title>Troubleshooting ppremake on Windows</title>
    <ns>0</ns>
    <id>1083</id>
      <sha1>9o1954n5ujxe5ulakkjxiv7t865iufw</sha1>
    <revision>
      <id>7508</id>
      <timestamp>2011-12-24T14:13:34Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>typos</comment>
      <text xml:space="preserve" bytes="3726">This page describes potential build issues that may arise when building Panda3D using the PPremake build system on the Windows platform, and possible solutions.


&lt;h2&gt;ppremake doesn't run (access violation 0xc0000005)&lt;/h2&gt;

The April/May 2005 version of Cygwin may have had an issue with getopt. 

Simply open config.h in the ppremake directory, replace &quot;#define HAVE_GETOPT 1&quot; with &quot;#undef HAVE_GETOPT&quot;, then rerun &quot;make&quot; and &quot;make install&quot;.

&lt;h2&gt;invalid link option /DEBUG, when running make&lt;/h2&gt;

This error (or something similar) is caused by the make running Cygwin's link rather than your msvc link.exe.  Simply rename /usr/bin/link to /usr/bin/_link, and rerun make.

&lt;h2&gt;Building using Microsoft Visual C++ Toolkit 2003&lt;/h2&gt;

Basically follow the official build instructions, using Cygwin as configuration platform and Microsoft Visual C++ Toolkit 2003 as compiler (you have to pretty much, this is very close to the primary configuration they support).

Pre-requisites:
*Microsoft Visual C++ Toolkit 2003
*msvcrt.lib and msvcprt.lib (see See Notes on Microsoft Visual CPP Toolkit 2003)
*DirectX (even though we're not using it, you need the headers
*Cygwin
*Panda source-code

The Panda source-code zip contains Python.

*First, you'll need to set up your variables for MSVC, within Cygwin.  What you can do is to personalize the following file for yourself, and save it to /usr/local/panda/bin/setvars:

&lt;pre&gt;
PATH=$PATH:&quot;/cygdrive/f/Program Files/Microsoft Visual C++ Toolkit 2003/bin&quot;
PATH=$PATH:/usr/local/panda/bin
PATH=$PATH:/usr/local/panda/lib
PATH=$PATH:/cygdrive/f/dev/panda3d-1.0.2-cyg/thirdparty/win-python

export CL=&quot; /I\&quot;F:\Program Files\Microsoft Visual C++ Toolkit 2003\include\&quot; &quot; 
export CL=&quot;$CL /I\&quot;F:\Program Files\Microsoft Visual C++ Toolkit 2003\include\&quot; &quot; 
export CL=&quot;$CL /I\&quot;F:\program Files\Microsoft SDK\include\&quot; &quot; 
export CL=&quot;$CL /I\&quot;F:\Program Files\Microsoft DirectX 9.0 SDK\include\&quot; &quot; 
export CL=&quot;$CL /I\&quot;F:\dev\panda3d-1.0.2-cyg\thirdparty\win-python\include\&quot; &quot; 

export LINK=&quot; /LIBPATH:\&quot;F:\Program Files\Microsoft Visual C++ Toolkit 2003\lib\&quot; &quot;
export LINK=&quot;$LINK /LIBPATH:\&quot;F:\Program Files\Microsoft Visual C++ Toolkit 2003\lib\&quot; &quot;
export LINK=&quot;$LINK /LIBPATH:\&quot;F:\Program Files\Microsoft SDK\lib\&quot; &quot;
export LINK=&quot;$LINK /LIBPATH:\&quot;F:\Program Files\Microsoft DirectX 9.0 SDK\lib\&quot; &quot;
export LINK=&quot;$LINK /LIBPATH:\&quot;F:\dev\panda3d-1.0.2-cyg\thirdparty\win-python\libs\&quot; &quot;

export PANDA_ROOT='F:\Cygwin'

export PYTHONPATH=&quot;f:\dev\panda3d-1.0.2-cyg\thirdparty\win-python;f:\cygwin\usr\local\panda\lib&quot;
&lt;/pre&gt;

*then run this file from Cygwin

   . /usr/local/panda/bin/setvars

(note that there's a . at the start, and a space between the . and the rest of the command)
*also, you will need to rename /usr/bin/link to /usr/bin/_link , in order that cygwin finds msvc link, and not the gcc link

*Open cgywin/usr/local/panda/Config.pp (create the file, if you didn't already), and add the following lines:

   #define HAVE_DX

*The HAVE_DX line means that you will not use DirectX (sic), which is a good thing, unless you happen to have an old DirectX 8 SDK lying around (current version at microsoft.com is 9)
*Note that linking dynamically is the default; and this the configuration which builds easiest

*The Visual C++ Toolkit doesn't contain lib, only link, which can do the same thing, so open, in the panda source directory, dtool/pptempl/compilerSettings.pp, and replace

   #define LIBBER lib

with

   #define LIBBER link /lib

*Now, you're ready to run ppremake, make and so on in dtool, then panda, as per the instructions.

(These notes taken from: [http://manageddreams.com/osmpwiki/index.php?title=Panda3D http://manageddreams.com/osmpwiki/index.php?title=Panda3D]).</text>
    </revision>
  </page>
  <page>
    <title>Tutorial: &quot;A Panda3D Hello World&quot;</title>
    <ns>0</ns>
    <id>2475</id>
    <redirect title="A Panda3D Hello World Tutorial" />
      <sha1>k6osuf9x2zd62zpygg1wjeybvjx5bah</sha1>
    <revision>
      <id>6691</id>
      <timestamp>2010-02-24T11:54:57Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>[[Tutorial: &quot;A Panda3D Hello World&quot;]] moved to [[A Panda3D Hello World Tutorial]]: Remove special characters for CHM stuff</comment>
      <text xml:space="preserve" bytes="44">#REDIRECT [[A Panda3D Hello World Tutorial]]</text>
    </revision>
  </page>
  <page>
    <title>Tutorial: Compiling the Panda3D Source on Windows</title>
    <ns>0</ns>
    <id>2238</id>
      <sha1>52asz073sp4cstrc132fv3forjwrihi</sha1>
    <revision>
      <id>60297</id>
      <timestamp>2014-11-29T00:19:42Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>GIT</comment>
      <text xml:space="preserve" bytes="5102">&lt;b&gt;Note:&lt;/b&gt; The information below applies to Panda3D versions between 1.6.0 and 1.8.2. Versions before that use Visual C++ 2005, and versions after that use Visual C++ 2010.

=Compiling Panda3D on Windows=

==Step 1: Installing the Requirements==

If you don't have it already, download and install Visual C++ from:

http://www.microsoft.com/express/2008/

If you have the Express version and not the full version, you will need to download and install the Microsoft Platform SDK. This version is the only one I found that includes ATL (which is required):

http://www.microsoft.com/downloads/details.aspx?familyid=0baf2b35-c656-4969-ace8-e4c0c0716adb&amp;displaylang=en

Next download and install the DirectX SDK from:

http://www.microsoft.com/downloads/details.aspx?FamilyID=C72D9F1E-53F3-4747-8490-6801D8E8B4EF&amp;displaylang=en

If all goes well you are all set to use makepanda to compile panda.

==Step 2: Download the source==
You can download the latest stable version of the Panda 3D source available at:

https://www.panda3d.org/download.php

Extract to an easily accessible place on your HDD (example: C:\panda_source)

Or alternatively you can get the newest git version with these commands. You'll need to have a git client installed.

&lt;pre&gt;
git clone https://github.com/panda3d/panda3d
&lt;/pre&gt;

==Step 3: Open a command prompt==
Easiest way is:
START-&gt;RUN and type cmd, hit ok.

You will now have a command prompt open.

You will most likely be in the C:\Documents and Settings\&lt;your user name&gt; folder.

Type: &lt;code&gt;cd C:\panda_source&lt;/code&gt;

This command cd &quot;change directory&quot; changes the directory to C:\panda_source

Type: &lt;code&gt;makepanda\makepanda.bat&lt;/code&gt;

This brings up all the command options for makepanda.bat

For more info on dos commands: http://www.google.com/search?q=dos+prompt+for+beginners

==Step 4: &quot;The simplest way to compile panda is to just type...&quot;==
As the help text says:

Type: &lt;code&gt;makepanda\makepanda.bat --everything&lt;/code&gt;

This process will take an hour or so, so it is best to go do something else because your comp will be using most of its resources on compiling.

For more information on using the makepanda tool to compile, please read the [https://github.com/panda3d/panda3d/blob/master/doc/INSTALL-MK INSTALL-MK] document, which is also available within the doc directory of your source tree.

&lt;b&gt;Alternative way:&lt;/b&gt; In the directory &quot;makepanda&quot;, you will find a &quot;makepanda.sln&quot; file. If you open it, it should launch the Visual Studio environment, you can also compile Panda3D from within there. Internally, this just invokes the makepanda script. If you use this method instead, be sure to set the build configuration to &quot;Release&quot; (unless you want a debug build of course.)

==Step 5: Make an installer==

&lt;b&gt;Note:&lt;/b&gt; If you've used the .sln file to build Panda, and used &quot;Release&quot; mode, the installer .exe has already been created for you.

Type: &lt;code&gt;makepanda\makepanda.bat --everything --installer&lt;/code&gt;

This should take much less time because if you notice there will be a &quot;built&quot; folder in your C:\panda_source, this was created in the previous step.
If you've used different compile options than just --everything in the previous step, make sure those options are the same in this step.

==Using newer June 2010 DirectX SDK and Windows 7.1 SDK==

    The latest version of makepanda.py includes built-in support for recent directX and Microsoft Platform SDKs such as June 2010 Dx Sdk and Win7.1 SDK. The builder will always default to the latest SDKs found on the user's system unless told otherwise with the switches --dxSdk, --MSPlatSdk. If you are using a specific version of the SDK that is not explicitly support by makepanda or if makepanda has problems locating a custom installion of the SDK, then amend SdkLocateDirectX and  SdkLocateMSPlatform in makepandacore.py appropriately.

    Newer versions of the DirectX and MSPlatform SDK omits files such as qedit.h and ddraw.lib that certain Panda modules depend on. 99% of the problems originate with the Panda directcam and vision libraries and can be avoided by compiling with --no-directcam --no-vision. If you need support for the directcam or vision packages, then you will have to locate an old version of the appropriate SDK and place the file into the compiler search path such as placing (an old copy of) ddraw.lib into ..\Microsoft DirectX SDK (June 2010)\Lib\x86 .

   If you really want to build the directcam module, you will have to edit webcamVideoDs.cxx, changing the appropriate lines to:

[code]
#pragma include_alias( &quot;dxtrans.h&quot;, &quot;qedit.h&quot; )
#define __IDxtCompositor_INTERFACE_DEFINED__
#define __IDxtAlphaSetter_INTERFACE_DEFINED__
#define __IDxtJpeg_INTERFACE_DEFINED_
#define __IDxtKey_INTERFACE_DEFINED__
#define IDXEffect IUnknown
#include &lt;tchar.h&gt; 
#include &lt;Dshow.h&gt; 
#include &lt;uuids.h&gt; 
#pragma comment(lib, &quot;strmiids.lib&quot;) 

#include &lt;qedit.h&gt;
struct __declspec(uuid(&quot;6B652FFF-11FE-4fce-92AD-0266B5D7C78F&quot;)) ISampleGrabber;
#include &lt;atlbase.h&gt;[/code]


==Conclusion==
And that's it. Depending on your needs you can configure Panda3D any way you wish.</text>
    </revision>
  </page>
  <page>
    <title>Tutorial: Compiling the Panda 3D Source on Windows</title>
    <ns>0</ns>
    <id>2467</id>
    <redirect title="Tutorial: Compiling the Panda3D Source on Windows" />
      <sha1>qwtik2hpttacx88v7thxvnp3z6r0s6f</sha1>
    <revision>
      <id>6626</id>
      <timestamp>2010-02-07T04:43:56Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>[[Tutorial: Compiling the Panda 3D Source on Windows]] moved to [[Tutorial: Compiling the Panda3D Source on Windows]]: Panda3D is the name of the engine; not Panda 3D. (Consistency with the rest of the Manual.)</comment>
      <text xml:space="preserve" bytes="63">#REDIRECT [[Tutorial: Compiling the Panda3D Source on Windows]]</text>
    </revision>
  </page>
  <page>
    <title>Tutorial End</title>
    <ns>0</ns>
    <id>2453</id>
      <sha1>qzl2iv34mcgj9mssjrwrhhx26numq6z</sha1>
    <revision>
      <id>6597</id>
      <timestamp>2010-02-07T04:30:58Z</timestamp>
      <contributor>
        <username>Xidram</username>
        <id>412</id>
      </contributor>
      <comment>Added page to inform the reader that the tutorial has ended and provide links to further help resources</comment>
      <text xml:space="preserve" bytes="421">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

&lt;p&gt;This concludes the &quot;A Panda Hello World&quot; tutorial. For more information on any part of the Panda3D engine, consult the rest of the [[Main_Page | Manual]]. If you still have questions, don't hesitate to ask on the [http://www.panda3d.org/phpbb2/ Panda3D Forum] or on the [[The_IRC_Channel | Panda3D IRC channel]].&lt;/p&gt;

&lt;p&gt;Have fun developing 3D applications with Panda3D!&lt;/p&gt;</text>
    </revision>
  </page>
  <page>
    <title>Tutorials</title>
    <ns>0</ns>
    <id>2191</id>
    <redirect title="General Preparation" />
      <sha1>5xg1dgrnhc4iv4ppiw3a1fzlxfvct24</sha1>
    <revision>
      <id>4788</id>
      <timestamp>2008-03-07T10:42:04Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <comment>[[Tutorials]] moved to [[General Preparation]]</comment>
      <text xml:space="preserve" bytes="33">#REDIRECT [[General Preparation]]</text>
    </revision>
  </page>
  <page>
    <title>Tweaking an Existing Model</title>
    <ns>0</ns>
    <id>1126</id>
      <sha1>60afaahdz0ymmx19o9sqbqqmxxlwf1g</sha1>
    <revision>
      <id>2407</id>
      <timestamp>2005-06-07T13:55:39Z</timestamp>
      <contributor>
        <username>Kmensah</username>
        <id>13</id>
      </contributor>
      <text xml:space="preserve" bytes="3811">NOTE: This API is changing in Panda 1.1 I'll hold off explaining till it comes out.

If you want to change part of an existing model you have to get the [[Manipulating a Piece of a Model||NodePath of the part]] you want to change. This &lt;code&gt;NodePath&lt;/code&gt; will be holding a &lt;code&gt;GeomNode&lt;/code&gt;, which are used to represent onscreen geometry. Every object that gets render in the scene graph eventually has &lt;code&gt;GeomNode&lt;/code&gt; objects at its leaf.

Note: For examples, the teapot included in the &lt;code&gt;.../models&lt;/code&gt; directory will be used.

&lt;code&gt;GeomNode&lt;/code&gt; objects are actually wrappers around object from the &lt;code&gt;Geom&lt;/code&gt; class. These object hold the primitives that actually get drawn to the screen. However, &lt;code&gt;Geom&lt;/code&gt; objects can only be created when loading a model. See [[Creating Geometry from Scratch]] if you want to generate primitives.

&lt;h2&gt;Geom Class&lt;/h2&gt;
Since the &lt;code&gt;Geom&lt;/code&gt; is what actually defines drawable geometry, we will discuss it first. There are a number of subclasses that represent specific primitive (&lt;code&gt;GeomQuad&lt;/code&gt;, &lt;code&gt;GeomTri&lt;/code&gt;,...) but none of them have add meaningful functionality on top of the &lt;code&gt;Geom&lt;/code&gt;. Therefore, just looking at the &lt;code&gt;Geom&lt;/code&gt; will be enough.

As stated above this class and its subclasses do not have public constructors defined. They are only made when loading model. To actually get a &lt;code&gt;Geom&lt;/code&gt; object look below at the &lt;code&gt;GeomNode&lt;/code&gt; class. However, for the purpose of exapmle code assume we already have &lt;code&gt;myGeom&lt;/code&gt; setup.

FINISHME


&lt;h2&gt;GeomNode Class&lt;/h2&gt;
To get a specific &lt;code&gt;Geom&lt;/code&gt; from a &lt;code&gt;GeomNode&lt;/code&gt; you use the &lt;code&gt;getGeom(index)&lt;/code&gt; where &lt;code&gt;index&lt;/code&gt; is the number of the &lt;code&gt;Geom&lt;/code&gt; you want. You must be careful though, since (just like [[Instancing]]) &lt;code&gt;Geom&lt;/code&gt; objects can be shared between many &lt;code&gt;GeomNode&lt;/code&gt; objects. If you want to alter a &lt;code&gt;Geom&lt;/code&gt;, you should use &lt;code&gt;getUniqueGeom(index)&lt;/code&gt; which returns a copy of the &lt;code&gt;Geom&lt;/code&gt; object if it is used in more than one place.

&lt;table class=&quot;code&quot;&gt;&lt;tr&gt;&lt;td&gt;
teapot=loader.loadModel('teapot')
&lt;br&gt;body=teapot.find('**/body')
&lt;br&gt;
&lt;br&gt;#remeber the difference between a Node and a NodePath
&lt;br&gt;bodyGeomNode=body.node()
&lt;br&gt;
&lt;br&gt;#just use 0 to get the &quot;first&quot; Geom
&lt;br&gt;fstGeom=bodyGeomNode.getGeom(0)
&lt;br&gt;sndGeom=bodyGeomNode.getUniqueGeom(1)
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;


If you want to add &lt;code&gt;Geom&lt;/code&gt; to a &lt;code&gt;GeomNode&lt;/code&gt; you can use the function &lt;code&gt;addGeom(newGeom, renderState)&lt;/code&gt;. EXPLAINME: renderState. If renderState is not given, the &lt;code&gt;newGeom&lt;/code&gt; completely inherits the &lt;code&gt;renderState&lt;/code&gt; of it's parent. There is also &lt;code&gt;addGeomsFrom(otherGeomNode)&lt;/code&gt; which effectively calls &lt;code&gt;addGeom&lt;/code&gt; to all the &lt;code&gt;Geom&lt;/code&gt; objects from &lt;code&gt;otherGeomNode&lt;/code&gt;. There are also &lt;code&gt;removeGeom(index)&lt;/code&gt; and &lt;code&gt;removeAllGeoms()&lt;/code&gt; which repectively remove a certain piece of geometry and remove all pieces of geometry.

&lt;table class=&quot;code&quot;&gt;&lt;tr&gt;&lt;td&gt;
handle=teapot.find('**/handle')
&lt;br&gt;handleGeomNode=handle.node()
&lt;br&gt;spout=teapot.find('**/spout')
&lt;br&gt;spoutGeomNode=spout.node()
&lt;br&gt;
&lt;br&gt;bodyGeomNode.addGeom(spoutGeomNode.getGeom(0))
&lt;br&gt;bodyGeomNode.addGeomsFrom(handleGeomNode)
&lt;br&gt;
&lt;br&gt;#after this, a call to bodyGeomNode.reomve(0) will remove the node that used &lt;br&gt;#&amp;nbsp;&amp;nbsp;&amp;nbsp;to be indexed at 1
&lt;br&gt;bodyGeomNode.remove(0)
&lt;br&gt;bodyGeomNode.removeAllGeoms()
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

You can also get the &lt;code&gt;RenderState&lt;/code&gt; of a certain &lt;code&gt;Geome&lt;/code&gt; using &lt;code&gt;getGeomState(index)&lt;/code&gt;. You can also get the number of &lt;code&gt;Geom&lt;/code&gt; objects in a &lt;code&gt;GeomNode&lt;/code&gt; by using &lt;code&gt;getNumGeoms()&lt;/code&gt;.

See API Reference for advanced functionality.</text>
    </revision>
  </page>
  <page>
    <title>Types of forces</title>
    <ns>0</ns>
    <id>1781</id>
      <sha1>19emt1xuq2d4xyl611vn05veenyrg8d</sha1>
    <revision>
      <id>7449</id>
      <timestamp>2011-12-24T11:53:06Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="2393">Panda3D provides two types of forces that you can apply to an object. 


== LinearVectorForce ==
A &lt;code&gt;LinearVectorForce&lt;/code&gt; treats the object as a point mass. It applies an acceleration in Newtons to the center of mass of the object it was added to. The direction of this force is relative to the orientation of the &lt;code&gt;ForceNode&lt;/code&gt; that the &lt;code&gt;LinearVectorForce&lt;/code&gt; was applied to.

''Note: Since &lt;code&gt;LinearVectorForce&lt;/code&gt; treats the object as a point mass, it is not possible to apply a rotation of any kind to your object. For rotational forces, see &lt;code&gt;AngularVectorForce&lt;/code&gt; below.''

'''Example:'''
&lt;code python&gt; 
lvf=LinearVectorForce(1,0,0)  # Push 1 newton in the positive-x direction 
forceNode.addForce(lvf)  # Determine coordinate space of this force node
actorNode.getPhysical(0).addLinearForce(lvf) # Add the force to the object
&lt;/code&gt;


== AngularVectorForce ==

The &lt;code&gt;AngularVectorForce&lt;/code&gt; applies a torque to the object it is attached to. The acceleration is in Newtons, and &lt;code&gt;AngularVectorForce&lt;/code&gt; may be treated in much the same way as &lt;code&gt;LinearVectorForce&lt;/code&gt;. There are, however, some minor differences that that should be taken into account.

&lt;code&gt;AngularVectorForce&lt;/code&gt; does not have a &lt;code&gt;.setDependantMass()&lt;/code&gt; . The reason for this is simple: mass '''must''' be used in the torque calculations. As such, you will want to make sure your forces are sufficiently small or your masses are sufficiently large to keep your rotational velocity sane.

'''Example:'''
&lt;code python&gt; 
avf=AngularVectorForce(1,0,0) # Spin around the positive-x axis 
forceNode.addForce(avf) # Determine which positive-x axis we use for calculation
actorNode.getPhysical(0).addAngularForce(avf) # Add the force to the object
&lt;/code&gt;

One additional caveat with &lt;code&gt;AngularVectorForce&lt;/code&gt;: Angular forces will not be processed on your object until an &lt;code&gt;AngularIntegrator&lt;/code&gt; is added to the &lt;code&gt;PhysicsManager&lt;/code&gt;. 

'''Example:'''
&lt;code python&gt; 
from panda3d.physics import AngularEulerIntegrator

angleInt = AngularEulerIntegrator() # Instantiate an AngleIntegrator()
base.physicsMgr.attachAngularIntegrator(angleInt) # Attatch the AngleIntegrator to the PhysicsManager
&lt;/code&gt;


''Editor's Note: Each type of force should be given it's own page with much more in depth examples, and perhaps a small sample program.''</text>
    </revision>
  </page>
  <page>
    <title>Uneven Terrain</title>
    <ns>0</ns>
    <id>2595</id>
      <sha1>9o266kqol6uzniwi64mldpaagpdd0wb</sha1>
    <revision>
      <id>7709</id>
      <timestamp>2012-03-09T10:33:56Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>same</comment>
      <text xml:space="preserve" bytes="14596">&lt;b&gt;UNEVEN TERRAIN PATHFINDING :&lt;/b&gt;


{{#ev:youtube|ozja1l4rpo4}}


-----


In PandAI, use it via :

Modifying the Roaming Ralph tutorial to always stay on the terrain.


-----


&lt;b&gt;The code for this tutorial :&lt;/b&gt;

&lt;code python&gt;
# PandAI Author: Srinavin Nair
# Original Author: Ryan Myers
# Models: Jeff Styers, Reagan Heller


# Last Updated: 6/13/2005
#
# This tutorial provides an example of creating a character
# and having it walk around on uneven terrain, as well
# as implementing a fully rotatable camera.
# It uses PandAI pathfinding to move the character.

import direct.directbase.DirectStart
from panda3d.core import CollisionTraverser,CollisionNode
from panda3d.core import CollisionHandlerQueue,CollisionRay
from panda3d.core import Filename
from panda3d.core import PandaNode,NodePath,Camera,TextNode
from panda3d.core import Vec3,Vec4,BitMask32
from direct.gui.OnscreenText import OnscreenText
from direct.actor.Actor import Actor
from direct.task.Task import Task
from direct.showbase.DirectObject import DirectObject
import random, sys, os, math

#for Pandai
from panda3d.ai import *

SPEED = 0.5

# Figure out what directory this program is in.
MYDIR=os.path.abspath(sys.path[0])
MYDIR=Filename.fromOsSpecific(MYDIR).getFullpath()

font = loader.loadFont(&quot;cmss12&quot;)

# Function to put instructions on the screen.
def addInstructions(pos, msg):
    return OnscreenText(text=msg, style=1, fg=(1,1,1,1), font = font,
                        pos=(-1.3, pos), align=TextNode.ALeft, scale = .05)

# Function to put title on the screen.
def addTitle(text):
    return OnscreenText(text=text, style=1, fg=(1,1,1,1), font = font,
                        pos=(1.3,-0.95), align=TextNode.ARight, scale = .07)

class World(DirectObject):

    def __init__(self):
        
        #self.switchState = False
        self.switchState = True
        self.switchCam = False
        self.path_no = 1
        self.keyMap = {&quot;left&quot;:0, &quot;right&quot;:0, &quot;forward&quot;:0, &quot;cam-left&quot;:0, &quot;cam-right&quot;:0}
        base.win.setClearColor(Vec4(0,0,0,1))
        base.cam.setPosHpr(17.79,-87.64,90.16,38.66,325.36,0)
        # Post the instructions

        self.title = addTitle(&quot;Pandai Tutorial: Roaming Ralph (Walking on Uneven Terrain) working with pathfinding&quot;)
        self.inst1 = addInstructions(0.95, &quot;[ESC]: Quit&quot;)
        self.inst2 = addInstructions(0.90, &quot;[Space - do Only once]: Start Pathfinding&quot;)
        self.inst3 = addInstructions(0.85, &quot;[Enter]: Change camera view&quot;)
        #self.inst4 = addInstructions(0.80, &quot;[Up Arrow]: Run Ralph Forward&quot;)
        #self.inst6 = addInstructions(0.70, &quot;[A]: Rotate Camera Left&quot;)
        #self.inst7 = addInstructions(0.65, &quot;[S]: Rotate Camera Right&quot;)
        
        # Set up the environment
        #
        # This environment model contains collision meshes.  If you look
        # in the egg file, you will see the following:
        #
        #    &lt;Collide&gt; { Polyset keep descend }
        #
        # This tag causes the following mesh to be converted to a collision
        # mesh -- a mesh which is optimized for collision, not rendering.
        # It also keeps the original mesh, so there are now two copies ---
        # one optimized for rendering, one for collisions.  

        self.environ = loader.loadModel(&quot;models/world&quot;)
        self.environ.reparentTo(render)
        self.environ.setPos(12,0,0)
        
        self.box = loader.loadModel(&quot;models/box&quot;)  
        self.box.reparentTo(render)
        self.box.setPos(-29.83,0,0)
        self.box.setScale(1)
        
        self.box1 = loader.loadModel(&quot;models/box&quot;)  
        self.box1.reparentTo(render)
        self.box1.setPos(-51.14,-17.90,0)
        self.box1.setScale(1)
        
        # Create the main character, Ralph

        #ralphStartPos = self.environ.find(&quot;**/start_point&quot;).getPos()
        ralphStartPos = Vec3(-98.64,-20.60,0)
        self.ralph = Actor(&quot;models/ralph&quot;,
                                 {&quot;run&quot;:&quot;models/ralph-run&quot;,
                                  &quot;walk&quot;:&quot;models/ralph-walk&quot;})
        self.ralph.reparentTo(render)
        self.ralph.setScale(1)
        self.ralph.setPos(ralphStartPos)
        
        ralphaiStartPos = Vec3(-50,20,0)
        self.ralphai = Actor(&quot;models/ralph&quot;,
                                 {&quot;run&quot;:&quot;models/ralph-run&quot;,
                                  &quot;walk&quot;:&quot;models/ralph-walk&quot;})
        
        self.pointer = loader.loadModel(&quot;models/arrow&quot;)
        self.pointer.setColor(1,0,0)
        self.pointer.setPos(-7.5,-1.2,0)
        self.pointer.setScale(3)
        self.pointer.reparentTo(render)
        
        self.pointer1 = loader.loadModel(&quot;models/arrow&quot;)
        self.pointer1.setColor(1,0,0)
        self.pointer1.setPos(-98.64,-20.60,0)
        self.pointer1.setScale(3)
        #self.pointer.reparentTo(render)

        # Create a floater object.  We use the &quot;floater&quot; as a temporary
        # variable in a variety of calculations.
        
        self.floater = NodePath(PandaNode(&quot;floater&quot;))
        self.floater.reparentTo(render)

        # Accept the control keys for movement and rotation

        self.accept(&quot;escape&quot;, sys.exit)
        self.accept(&quot;enter&quot;, self.activateCam)
        self.accept(&quot;arrow_left&quot;, self.setKey, [&quot;left&quot;,1])
        self.accept(&quot;arrow_right&quot;, self.setKey, [&quot;right&quot;,1])
        self.accept(&quot;arrow_up&quot;, self.setKey, [&quot;forward&quot;,1])
        self.accept(&quot;a&quot;, self.setKey, [&quot;cam-left&quot;,1])
        self.accept(&quot;s&quot;, self.setKey, [&quot;cam-right&quot;,1])
        self.accept(&quot;arrow_left-up&quot;, self.setKey, [&quot;left&quot;,0])
        self.accept(&quot;arrow_right-up&quot;, self.setKey, [&quot;right&quot;,0])
        self.accept(&quot;arrow_up-up&quot;, self.setKey, [&quot;forward&quot;,0])
        self.accept(&quot;a-up&quot;, self.setKey, [&quot;cam-left&quot;,0])
        self.accept(&quot;s-up&quot;, self.setKey, [&quot;cam-right&quot;,0])

        #taskMgr.add(self.move,&quot;moveTask&quot;)

        # Game state variables
        self.isMoving = False

        # Set up the camera
        
        #base.disableMouse()
        #base.camera.setPos(self.ralph.getX(),self.ralph.getY()+10,2)
        
        # We will detect the height of the terrain by creating a collision
        # ray and casting it downward toward the terrain.  One ray will
        # start above ralph's head, and the other will start above the camera.
        # A ray may hit the terrain, or it may hit a rock or a tree.  If it
        # hits the terrain, we can detect the height.  If it hits anything
        # else, we rule that the move is illegal.

        self.cTrav = CollisionTraverser()

        self.ralphGroundRay = CollisionRay()
        self.ralphGroundRay.setOrigin(0,0,1000)
        self.ralphGroundRay.setDirection(0,0,-1)
        self.ralphGroundCol = CollisionNode('ralphRay')
        self.ralphGroundCol.addSolid(self.ralphGroundRay)
        self.ralphGroundCol.setFromCollideMask(BitMask32.bit(0))
        self.ralphGroundCol.setIntoCollideMask(BitMask32.allOff())
        self.ralphGroundColNp = self.ralph.attachNewNode(self.ralphGroundCol)
        self.ralphGroundHandler = CollisionHandlerQueue()
        self.cTrav.addCollider(self.ralphGroundColNp, self.ralphGroundHandler)

        self.camGroundRay = CollisionRay()
        self.camGroundRay.setOrigin(0,0,1000)
        self.camGroundRay.setDirection(0,0,-1)
        self.camGroundCol = CollisionNode('camRay')
        self.camGroundCol.addSolid(self.camGroundRay)
        self.camGroundCol.setFromCollideMask(BitMask32.bit(0))
        self.camGroundCol.setIntoCollideMask(BitMask32.allOff())
        self.camGroundColNp = base.camera.attachNewNode(self.camGroundCol)
        self.camGroundHandler = CollisionHandlerQueue()
        self.cTrav.addCollider(self.camGroundColNp, self.camGroundHandler)

        # Uncomment this line to see the collision rays
        #self.ralphGroundColNp.show()
        #self.camGroundColNp.show()
       
        #Uncomment this line to show a visual representation of the 
        #collisions occuring
        #self.cTrav.showCollisions(render)
       
        self.setAI()

    
    def activateCam(self):
        self.switchCam = not self.switchCam
        if(self.switchCam == True):
            base.cam.setPosHpr(0,0,0,0,0,0)
            base.cam.reparentTo(self.ralph)
            base.cam.setY(base.cam.getY() + 30)
            base.cam.setZ(base.cam.getZ() + 10)
            base.cam.setHpr(180,-15,0)
        else:
            base.cam.reparentTo(render)        
            base.cam.setPosHpr(17.79,-87.64,90.16,38.66,325.36,0)
            #base.camera.setPos(self.ralph.getX(),self.ralph.getY()+10,2)
            
    
    #Records the state of the arrow keys
    def setKey(self, key, value):
        self.keyMap[key] = value
    

    # Accepts arrow keys to move either the player or the menu cursor,
    # Also deals with grid checking and collision detection
    def move(self):

        # Get the time elapsed since last frame. We need this
        # for framerate-independent movement.
        elapsed = globalClock.getDt()

        # If the camera-left key is pressed, move camera left.
        # If the camera-right key is pressed, move camera right.
        if(self.switchState==False):    
            base.camera.lookAt(self.ralph)
            if (self.keyMap[&quot;cam-left&quot;]!=0):
                base.camera.setX(base.camera, -(elapsed*20))
            if (self.keyMap[&quot;cam-right&quot;]!=0):
                base.camera.setX(base.camera, +(elapsed*20))

        # save ralph's initial position so that we can restore it,
        # in case he falls off the map or runs into something.

        startpos = self.ralph.getPos()

        # If a move-key is pressed, move ralph in the specified direction.

        if (self.keyMap[&quot;left&quot;]!=0):
            self.ralph.setH(self.ralph.getH() + elapsed*300)
        if (self.keyMap[&quot;right&quot;]!=0):
            self.ralph.setH(self.ralph.getH() - elapsed*300)
        if (self.keyMap[&quot;forward&quot;]!=0):
            self.ralph.setY(self.ralph, -(elapsed*25))

        # If ralph is moving, loop the run animation.
        # If he is standing still, stop the animation.

        if (self.keyMap[&quot;forward&quot;]!=0) or (self.keyMap[&quot;left&quot;]!=0) or (self.keyMap[&quot;right&quot;]!=0):
            if self.isMoving is False:
                self.ralph.loop(&quot;run&quot;)
                self.isMoving = True
        else:
            if self.isMoving:
                self.ralph.stop()
                self.ralph.pose(&quot;walk&quot;,5)
                self.isMoving = False

        # If the camera is too far from ralph, move it closer.
        # If the camera is too close to ralph, move it farther.
        if(self.switchState==False):
            camvec = self.ralph.getPos() - base.camera.getPos()
            camvec.setZ(0)
            camdist = camvec.length()
            camvec.normalize()
            if (camdist &gt; 10.0):
                base.camera.setPos(base.camera.getPos() + camvec*(camdist-10))
                camdist = 10.0
            if (camdist &lt; 5.0):
                base.camera.setPos(base.camera.getPos() - camvec*(5-camdist))
                camdist = 5.0

        # Now check for collisions.

        self.cTrav.traverse(render)

        # Adjust ralph's Z coordinate.  If ralph's ray hit terrain,
        # update his Z. If it hit anything else, or didn't hit anything, put
        # him back where he was last frame.

        #print(self.ralphGroundHandler.getNumEntries())

        entries = []
        for i in range(self.ralphGroundHandler.getNumEntries()):
            entry = self.ralphGroundHandler.getEntry(i)
            entries.append(entry)
        entries.sort(lambda x,y: cmp(y.getSurfacePoint(render).getZ(),
                                     x.getSurfacePoint(render).getZ()))
        if (len(entries)&gt;0) and (entries[0].getIntoNode().getName() == &quot;terrain&quot;):
            self.ralph.setZ(entries[0].getSurfacePoint(render).getZ())
        else:
            self.ralph.setPos(startpos)

        # Keep the camera at one foot above the terrain,
        # or two feet above ralph, whichever is greater.
        
        if(self.switchState==False):
            entries = []
            for i in range(self.camGroundHandler.getNumEntries()):
                entry = self.camGroundHandler.getEntry(i)
                entries.append(entry)
            entries.sort(lambda x,y: cmp(y.getSurfacePoint(render).getZ(),
                                         x.getSurfacePoint(render).getZ()))
            if (len(entries)&gt;0) and (entries[0].getIntoNode().getName() == &quot;terrain&quot;):
                base.camera.setZ(entries[0].getSurfacePoint(render).getZ()+1.0)
            if (base.camera.getZ() &lt; self.ralph.getZ() + 2.0):
                base.camera.setZ(self.ralph.getZ() + 2.0)
                
            # The camera should look in ralph's direction,
            # but it should also try to stay horizontal, so look at
            # a floater which hovers above ralph's head.
            
            self.floater.setPos(self.ralph.getPos())
            self.floater.setZ(self.ralph.getZ() + 2.0)
            base.camera.setZ(base.camera.getZ())
            base.camera.lookAt(self.floater)
        
        self.ralph.setP(0)
        return Task.cont
    
    def setAI(self):
        #Creating AI World
        self.AIworld = AIWorld(render)
        
        self.accept(&quot;space&quot;, self.setMove)
        self.AIchar = AICharacter(&quot;ralph&quot;,self.ralph, 60, 0.05, 25)
        self.AIworld.addAiChar(self.AIchar)
        self.AIbehaviors = self.AIchar.getAiBehaviors()
        
        self.AIbehaviors.initPathFind(&quot;models/navmesh.csv&quot;)
        
        #AI World update        
        taskMgr.add(self.AIUpdate,&quot;AIUpdate&quot;)
        
    def setMove(self):
        self.AIbehaviors.addStaticObstacle(self.box)
        self.AIbehaviors.addStaticObstacle(self.box1)
        self.AIbehaviors.pathFindTo(self.pointer)
        self.ralph.loop(&quot;run&quot;)
    
    #to update the AIWorld    
    def AIUpdate(self,task):
        self.AIworld.update()
        self.move()

        if(self.path_no == 1 and self.AIbehaviors.behaviorStatus(&quot;pathfollow&quot;) == &quot;done&quot;):
           self.path_no = 2  
           self.AIbehaviors.pathFindTo(self.pointer1, &quot;addPath&quot;)
           print(&quot;inside&quot;)
        
        if(self.path_no == 2 and self.AIbehaviors.behaviorStatus(&quot;pathfollow&quot;) == &quot;done&quot;):
           print(&quot;inside2&quot;)
           self.path_no = 1  
           self.AIbehaviors.pathFindTo(self.pointer, &quot;addPath&quot;)
             
        return Task.cont
    


w = World()
run()

&lt;/code&gt;


-----


&lt;b&gt;The full working demo can be downloaded at :&lt;/b&gt;

https://sites.google.com/site/etcpandai/documentation/pathfinding/UnevenTerrainPathFinding.zip?attredirects=0&amp;d=1</text>
    </revision>
  </page>
  <page>
    <title>User Contributed Tutorials and Examples</title>
    <ns>0</ns>
    <id>1710</id>
      <sha1>1d8n10inei2u2lv4900kmix1nfytbuw</sha1>
    <revision>
      <id>60289</id>
      <timestamp>2014-11-11T09:39:09Z</timestamp>
      <contributor>
        <username>Redgui</username>
        <id>22857</id>
      </contributor>
      <minor/>
      <comment>/* Code snippets */</comment>
      <text xml:space="preserve" bytes="2760">The following are some open source games and some example code snippets made by Panda3D users. They are by private individuals not affiliated with the Panda3D core development team, we cannot vouch that they are valid with every version of Panda3D.
This is not a complete and up-to-date list of all the open source games and code snippets. Check the appropriate forum sections for all the contributions.

== Tutorials ==

MyGameFast: http://www.mygamefast.com/

== Open source games ==

Tagger: http://www.panda3d.org/forums/viewtopic.php?t=7794

Pac-Bat pac-man clone: http://www.panda3d.org/forums/viewtopic.php?t=11796

A3P: http://www.panda3d.org/forums/viewtopic.php?t=7807

Naith: http://code.google.com/p/naith/

GravityHook clone: http://www.panda3d.org/forums/viewtopic.php?t=6582

3d-rama pong: http://www.panda3d.org/forums/viewtopic.php?t=10025

== Code snippets ==

Demomaster application framework with wxpython navigator: http://www.panda3d.org/forums/viewtopic.php?t=5915

Panda3d Terrain System: https://github.com/Craig-Macomber/Panda3D-Terrain-System

Panda3d Shader Generator: https://github.com/Craig-Macomber/Panda3D-Shader-Generator

Infinite Procedural Terrain Engine: http://www.panda3d.org/forums/viewtopic.php?t=10244&amp;start=0

Improved distortion sample: http://www.panda3d.org/forums/viewtopic.php?t=7406

Onscreen IDE &amp; dynamic instant update: http://www.panda3d.org/forums/viewtopic.php?t=3875

ODE Middleware: http://www.panda3d.org/forums/viewtopic.php?t=7913

pause/resume scene (intervals-tasks-actors-sounds-movies): http://www.panda3d.org/forums/viewtopic.php?t=4439

rope samples: http://www.panda3d.org/forums/viewtopic.php?t=5510

Paraboloid Shadow Map + PCF Smooth: http://www.panda3d.org/forums/viewtopic.php?t=9946

PSSM Shadows: http://www.panda3d.org/forums/viewtopic.php?t=11235

Fade from one camera to another: http://www.panda3d.org/forums/viewtopic.php?t=12643

Minecraft-like chunk generator: http://www.panda3d.org/forums/viewtopic.php?t=12421

Hardware and Geometry Shader Instancing: http://www.panda3d.org/forums/viewtopic.php?t=8680

Fractal Map Generator: http://www.panda3d.org/forums/viewtopic.php?t=11112

Doom3-alike GUI (embedded in 3D scene): http://www.panda3d.org/forums/viewtopic.php?t=10630

Load image as 3d plane: http://www.panda3d.org/forums/viewtopic.php?t=11268

Interactive scene: http://www.panda3d.org/forums/viewtopic.php?t=11009

Using tags: http://www.panda3d.org/forums/viewtopic.php?t=11461

Another Camera Controller, Orbit style: http://www.panda3d.org/forums/viewtopic.php?t=12414

edge screen tracking: http://panda3d.org/phpbb2/viewtopic.php?t=1276

Developing a First Person Camera with Panda3D and C++ (pdf download): http://www.imagenetz.de/f7bdc2255/FPC_tutorial.pdf.html</text>
    </revision>
  </page>
  <page>
    <title>User Contributed Video Tutorials</title>
    <ns>0</ns>
    <id>1168</id>
      <sha1>5d2bs4v42jyl8wd5y4xzm047vze0kq4</sha1>
    <revision>
      <id>6248</id>
      <timestamp>2009-10-17T16:51:44Z</timestamp>
      <contributor>
        <username>Nemesis</username>
        <id>193</id>
      </contributor>
      <comment>deleted broken links and beautified the rest a bit</comment>
      <text xml:space="preserve" bytes="1609">=== This is a list of video tutorials contributed by Panda3D users. ===


'''[http://www.youtube.com/watch?v=M7CkxQYRl1w Blender2Panda: normalmaps]'''&lt;br /&gt;
This youtube video shows how to do normalmapping with Blender and export it to panda3d.
Featuring:&lt;br /&gt;
* baking of normal maps from highpoly to lowpoly model
* applying the normalmaps and previewing in Blender
* export of model and texture using the chicken exporter, and a pview session f the model


'''[http://www.youtube.com/watch?v=dw5DxESx_1Q Blender2Panda: Tags and Dummys]'''&lt;br /&gt;
This youtube video shows how to do dummys and tags in Blender and export it to panda3d.
Featuring:&lt;br /&gt;
* creation and usage of dummy objects
* adding tags
* exporting
* using dummys and tags in panda + recursive dummys


'''[http://www.youtube.com/watch?v=bz9lfHk2dPg Blender2Panda: Animations]'''&lt;br /&gt;
This youtube video shows how to do animation in Blender and export it to panda3d.
Featuring:&lt;br /&gt;
* low poly modelling
* armature creation
* connecting meshes
* basic armature animation
* exporting


'''[http://www.youtube.com/watch?v=_4N2_530xss Panda3D + OpenCV for head-tracking]'''&lt;br /&gt;
This youtube video shows the result of some tinkering with opencv and panda3d.  Opencv does the head-tracking while panda3d runs a slightly modified version of the &quot;ball-in-a-maze&quot; sample. Both are running as individual process communicating via sockets to exchange the face-position data.
It's running in realtime as you can see. Webcam delivers ~30fps, panda3d runs with 60fps (capped to monitor refresh rate)
Its all written with a hand full of python lines.</text>
    </revision>
  </page>
  <page>
    <title>Using Bullet with Panda3D</title>
    <ns>0</ns>
    <id>2605</id>
      <sha1>4wq0elbf3e7rjkb5hyxqos37bmg1ab4</sha1>
    <revision>
      <id>60454</id>
      <timestamp>2015-01-08T20:43:05Z</timestamp>
      <contributor>
        <username>ThomasEgi</username>
        <id>111</id>
      </contributor>
      <minor/>
      <comment>replace enn0x's p3pd link to the samples with a working one</comment>
      <text xml:space="preserve" bytes="1950">Bullet is a modern and open source physics engine used in many games or simulations. Bullet can be compiled on many platforms, among them Windows, Linux and MacOSX. Bullet features include collision detection, rigid body dynamics, soft body dynamics and a kinematic character controller.

This section is about how to use the Panda3D Bullet module. 

&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;ol type=&quot;a&quot;&gt;
&lt;li&gt;[[Bullet Hello World]]&lt;/li&gt;
&lt;li&gt;[[Bullet Debug Renderer]]&lt;/li&gt;
&lt;li&gt;[[Bullet Collision Shapes]]&lt;/li&gt;
&lt;li&gt;[[Bullet Collision Filtering]]&lt;/li&gt;
&lt;li&gt;[[Bullet Continuous Collision Detection]]&lt;/li&gt;
&lt;li&gt;[[Bullet Queries]]&lt;/li&gt;
&lt;li&gt;[[Bullet Ghosts]]&lt;/li&gt;
&lt;li&gt;[[Bullet Character Controller]]&lt;/li&gt;
&lt;li&gt;[[Bullet Constraints]]&lt;/li&gt;
&lt;li&gt;[[Bullet Vehicles]]&lt;/li&gt;
&lt;li&gt;[[Bullet Softbodies]]&lt;/li&gt;
&lt;li&gt;[[Bullet Softbody Rope]]&lt;/li&gt;
&lt;li&gt;[[Bullet Softbody Patch]]&lt;/li&gt;
&lt;li&gt;[[Bullet Softbody Triangles]]&lt;/li&gt;
&lt;li&gt;[[Bullet Softbody Tetrahedron]]&lt;/li&gt;
&lt;li&gt;[[Bullet Softbody Config]]&lt;/li&gt;
&lt;li&gt;[[Bullet Config Options]]&lt;/li&gt;
&lt;li&gt;[[Bullet FAQ]]&lt;/li&gt;
&lt;li&gt;[[Bullet Samples]]&lt;/li&gt;
&lt;/ol&gt;

All Bullet classes are prefixed with &quot;Bullet&quot;. A list of all classes and their methods can be found within the [http://www.panda3d.org/reference/python/namespace!panda3d.bullet API reference]. However, the class and function descriptions are still missing.

&lt;b&gt;Note:&lt;/b&gt;The Panda3D Bullet module makes great effort to integrate Bullet physics as tight as possible (and reasonable) with the code Panda3D classes. However, when implementing collision detection and physics, you can not mix Bullet's internal physics &amp; collision system, ODE, PhysX and Bullet. More explicitly: Bullet bodies won't collide with ODE bodies, and they won't collide with CollisionNodes.

Samples on how to use the Panda3D Bullet module can be found in the following archive:
https://www.panda3d.org/download/noversion/bullet-samples.zip
[cxx]
&lt;b&gt;Note: &lt;/b&gt; All samples are currently available in Python code only.
[/cxx]</text>
    </revision>
  </page>
  <page>
    <title>Using CXX</title>
    <ns>0</ns>
    <id>2079</id>
      <sha1>1xpb0n7clozoqcj5brnvkx8tdtxko5z</sha1>
    <revision>
      <id>5612</id>
      <timestamp>2008-11-19T21:02:17Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="1005">Though Panda3D is often used with Python, it is possible to program a complete game in C++ without any line of Python.
To start a C++ project, rebuilding Panda3D from source is not needed. This is done by including the right headers and linking with the right libraries.

This section will explain how to use C++ to create your Panda3D programs instead of the default Python language.

The manual and the API are mainly focused at the use of Python, so you will need to keep a few things in mind:
*You need to include the file &lt;i&gt;pandabase.h&lt;/i&gt;, which is needed to initialize the Panda3D library.
*There's no DirectStart. You need to create windows yourself using the [[The Window Framework|Window Framework]].
*You can import the classes you need just by including their header file, like this:
:&lt;pre class=&quot;codeblock&quot;&gt;#import &quot;textNode.h&quot;&lt;/pre&gt;
*The functions are called the same way, but in lowercase and spaces between the words.
:So &lt;i&gt;instanceTo()&lt;/i&gt; in Python becomes &lt;i&gt;instance_to()&lt;/i&gt; in C++.</text>
    </revision>
  </page>
  <page>
    <title>Using Cg Shaders</title>
    <ns>0</ns>
    <id>1718</id>
    <redirect title="Shader Basics" />
      <sha1>4u2bht2qj2g0hfk0d81sv0q92ibaacf</sha1>
    <revision>
      <id>3212</id>
      <timestamp>2006-03-01T17:01:35Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <comment>Using Cg Shaders moved to Shader Basics</comment>
      <text xml:space="preserve" bytes="27">#redirect [[Shader Basics]]</text>
    </revision>
  </page>
  <page>
    <title>Using Command Prompt to Run your Program</title>
    <ns>0</ns>
    <id>2387</id>
    <redirect title="Running your Program" />
      <sha1>45l8beblcgql8ivxambwks5infs1k74</sha1>
    <revision>
      <id>6184</id>
      <timestamp>2009-09-29T10:29:45Z</timestamp>
      <contributor>
        <username>Gogg</username>
        <id>389</id>
      </contributor>
      <comment>[[Using Command Prompt to Run your Program]] moved to [[Running your Program]]: name change so that it's language agnostic</comment>
      <text xml:space="preserve" bytes="34">#REDIRECT [[Running your Program]]</text>
    </revision>
  </page>
  <page>
    <title>Using Intervals to move the Panda</title>
    <ns>0</ns>
    <id>939</id>
      <sha1>knmmpci0zru3qpdm2cyxicibvhqtl1u</sha1>
    <revision>
      <id>7838</id>
      <timestamp>2012-08-15T11:21:47Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <comment>PandaFramework framework; static init blah blah</comment>
      <text xml:space="preserve" bytes="8415">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

== Intervals and Sequences ==
=== [[Intervals]] ===
&lt;p&gt;&lt;i&gt;Intervals&lt;/i&gt; are tasks that change a property from one value to another over a specified period of time. Starting an interval effectively starts a background process that modifies the property over the specified period of time.&lt;/p&gt;

=== [python][[Sequences_and_Parallels | Sequences]][/python][cxx][[Sequences_and_Parallels | MetaIntervals]][/cxx] ===
&lt;p&gt;&lt;i&gt;[python]Sequences[/python][cxx]MetaIntervals[/cxx]&lt;/i&gt; are tasks that execute one interval after another.&lt;/p&gt;

== The Program ==
=== Update the Code===
&lt;p&gt;The next step is to cause the panda to actually
move back and forth. Update the code to the following:&lt;/p&gt;

[python]&lt;code python&gt;
from math import pi, sin, cos

from direct.showbase.ShowBase import ShowBase
from direct.task import Task
from direct.actor.Actor import Actor
from direct.interval.IntervalGlobal import Sequence
from panda3d.core import Point3

class MyApp(ShowBase):
    def __init__(self):
        ShowBase.__init__(self)
 
        # Disable the camera trackball controls.
        self.disableMouse()

        # Load the environment model.
        self.environ = self.loader.loadModel(&quot;models/environment&quot;)
        # Reparent the model to render.
        self.environ.reparentTo(self.render)
        # Apply scale and position transforms on the model.
        self.environ.setScale(0.25, 0.25, 0.25)
        self.environ.setPos(-8, 42, 0)
 
        # Add the spinCameraTask procedure to the task manager.
        self.taskMgr.add(self.spinCameraTask, &quot;SpinCameraTask&quot;)
 
        # Load and transform the panda actor.
        self.pandaActor = Actor(&quot;models/panda-model&quot;,
                                {&quot;walk&quot;: &quot;models/panda-walk4&quot;})
        self.pandaActor.setScale(0.005, 0.005, 0.005)
        self.pandaActor.reparentTo(self.render)
        # Loop its animation.
        self.pandaActor.loop(&quot;walk&quot;)

        # Create the four lerp intervals needed for the panda to
        # walk back and forth.
        pandaPosInterval1 = self.pandaActor.posInterval(13,
                                                        Point3(0, -10, 0),
                                                        startPos=Point3(0, 10, 0))
        pandaPosInterval2 = self.pandaActor.posInterval(13,
                                                        Point3(0, 10, 0),
                                                        startPos=Point3(0, -10, 0))
        pandaHprInterval1 = self.pandaActor.hprInterval(3,
                                                        Point3(180, 0, 0),
                                                        startHpr=Point3(0, 0, 0))
        pandaHprInterval2 = self.pandaActor.hprInterval(3,
                                                        Point3(0, 0, 0),
                                                        startHpr=Point3(180, 0, 0))

        # Create and play the sequence that coordinates the intervals.
        self.pandaPace = Sequence(pandaPosInterval1,
                                  pandaHprInterval1,
                                  pandaPosInterval2,
                                  pandaHprInterval2,
                                  name=&quot;pandaPace&quot;)
        self.pandaPace.loop()
 
    # Define a procedure to move the camera.
    def spinCameraTask(self, task):
        angleDegrees = task.time * 6.0
        angleRadians = angleDegrees * (pi / 180.0)
        self.camera.setPos(20 * sin(angleRadians), -20.0 * cos(angleRadians), 3)
        self.camera.setHpr(angleDegrees, 0, 0)
        return Task.cont

app = MyApp()
app.run()
&lt;/code&gt;
Note: In Panda3D versions older than 1.7, the package panda3d.core is instead pandac.PandaModules. Thus, the import line would be this:
&lt;code python&gt;
from pandac.PandaModules import Point3
&lt;/code&gt;
[/python]
[cxx]&lt;code cxx&gt;#include &quot;pandaFramework.h&quot;
#include &quot;pandaSystem.h&quot;

#include &quot;genericAsyncTask.h&quot;
#include &quot;asyncTaskManager.h&quot;

#include &quot;cIntervalManager.h&quot;
#include &quot;cLerpNodePathInterval.h&quot;
#include &quot;cMetaInterval.h&quot;

// Global stuff
PT(AsyncTaskManager) taskMgr = AsyncTaskManager::get_global_ptr(); 
PT(ClockObject) globalClock = ClockObject::get_global_clock();
NodePath camera;

// Task to move the camera
AsyncTask::DoneStatus SpinCameraTask(GenericAsyncTask* task, void* data) {
  double time = globalClock-&gt;get_real_time();
  double angledegrees = time * 6.0;
  double angleradians = angledegrees * (3.14 / 180.0);
  camera.set_pos(20*sin(angleradians),-20.0*cos(angleradians),3);
  camera.set_hpr(angledegrees, 0, 0);

  return AsyncTask::DS_cont;
}

int main(int argc, char *argv[]) {
  // Open a new window framework and set the title
  PandaFramework framework;
  framework.open_framework(argc, argv);
  framework.set_window_title(&quot;My Panda3D Window&quot;);

  // Open the window
  WindowFramework *window = framework.open_window();
  camera = window-&gt;get_camera_group(); // Get the camera and store it

  // Load the environment model
  NodePath environ = window-&gt;load_model(framework.get_models(),
    &quot;models/environment&quot;);
  environ.reparent_to(window-&gt;get_render());
  environ.set_scale(0.25 , 0.25, 0.25);
  environ.set_pos(-8, 42, 0);

  // Load our panda
  NodePath pandaActor = window-&gt;load_model(framework.get_models(),
    &quot;panda-model&quot;);
  pandaActor.set_scale(0.005);
  pandaActor.reparent_to(window-&gt;get_render());
  
  // Load the walk animation
  window-&gt;load_model(pandaActor, &quot;panda-walk4&quot;);
  window-&gt;loop_animations(0);

  // Create the lerp intervals needed to walk back and forth
  PT(CLerpNodePathInterval) pandaPosInterval1, pandaPosInterval2,
    pandaHprInterval1, pandaHprInterval2;
  pandaPosInterval1 = new CLerpNodePathInterval(&quot;pandaPosInterval1&quot;,
    13.0, CLerpInterval::BT_no_blend,
    true, false, pandaActor, NodePath());
  pandaPosInterval1-&gt;set_start_pos(LPoint3f(0, 10, 0));
  pandaPosInterval1-&gt;set_end_pos(LPoint3f(0, -10, 0));

  pandaPosInterval2 = new CLerpNodePathInterval(&quot;pandaPosInterval2&quot;,
    13.0, CLerpInterval::BT_no_blend,
    true, false, pandaActor, NodePath());
  pandaPosInterval2-&gt;set_start_pos(LPoint3f(0, -10, 0));
  pandaPosInterval2-&gt;set_end_pos(LPoint3f(0, 10, 0));

  pandaHprInterval1 = new CLerpNodePathInterval(&quot;pandaHprInterval1&quot;, 3.0,
    CLerpInterval::BT_no_blend,
    true, false, pandaActor, NodePath());
  pandaHprInterval1-&gt;set_start_hpr(LPoint3f(0, 0, 0));
  pandaHprInterval1-&gt;set_end_hpr(LPoint3f(180, 0, 0));

  pandaHprInterval2 = new CLerpNodePathInterval(&quot;pandaHprInterval2&quot;, 3.0,
    CLerpInterval::BT_no_blend,
    true, false, pandaActor, NodePath());
  pandaHprInterval2-&gt;set_start_hpr(LPoint3f(180, 0, 0));
  pandaHprInterval2-&gt;set_end_hpr(LPoint3f(0, 0, 0));
  
  // Create and play the sequence that coordinates the intervals
  PT(CMetaInterval) pandaPace;
  pandaPace = new CMetaInterval(&quot;pandaPace&quot;);
  pandaPace-&gt;add_c_interval(pandaPosInterval1, 0,
    CMetaInterval::RS_previous_end);
  pandaPace-&gt;add_c_interval(pandaHprInterval1, 0,
    CMetaInterval::RS_previous_end);
  pandaPace-&gt;add_c_interval(pandaPosInterval2, 0,
    CMetaInterval::RS_previous_end);
  pandaPace-&gt;add_c_interval(pandaHprInterval2, 0,
    CMetaInterval::RS_previous_end);
  pandaPace-&gt;loop();

  // Add our task.
  taskMgr-&gt;add(new GenericAsyncTask(&quot;Spins the camera&quot;,
    &amp;SpinCameraTask, (void*) NULL));
  
  // This is a simpler way to do stuff every frame,
  // if you're too lazy to create a task.
  Thread *current_thread = Thread::get_current_thread();
  while(framework.do_frame(current_thread)) {
    // Step the interval manager
    CIntervalManager::get_global_ptr()-&gt;step();
  }

  framework.close_framework();
  return (0);
}&lt;/code&gt;[/cxx]

&lt;p&gt;When the &lt;code&gt;pandaPosInterval1&lt;/code&gt; interval is started, it will gradually adjust the position of the panda from (0, 10, 0) to (0, -10, 0) over a period of 13 seconds. Similarly, when the &lt;code&gt;pandaHprInterval1&lt;/code&gt; interval is started,
the heading of the panda will rotate 180 degrees over a period of 3 seconds.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;pandaPace&lt;/code&gt; sequence above causes the panda to move in a straight line, turn, move in the opposite straight line, and finally turn again. The code &lt;code&gt;pandaPace[-&gt;]loop()&lt;/code&gt; causes the [python]Sequence[/python][cxx]MetaInterval[/cxx] to be started in looping mode.&lt;/p&gt;

=== Run the Program ===
&lt;p&gt;The result of all this is to cause the panda to pace back and forth from one tree to the other.&lt;/p&gt;</text>
    </revision>
  </page>
  <page>
    <title>Using Intervals to move the Panda (CXX)</title>
    <ns>0</ns>
    <id>2160</id>
      <sha1>5ifwg0sp89mjlar0z4lb5ex7n1nlrp7</sha1>
    <revision>
      <id>5143</id>
      <timestamp>2008-03-15T03:35:54Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <text xml:space="preserve" bytes="4813">&lt;span class=&quot;suppress-screenshots&quot;&gt;&lt;/span&gt;

The next step is to cause the panda to actually
move back and forth.  Add the following lines of code:

&lt;pre class=&quot;codeblock&quot;&gt;
#include &quot;pandaFramework.h&quot;
#include &quot;pandaSystem.h&quot;

#include &quot;cIntervalManager.h&quot;
#include &quot;cLerpNodePathInterval.h&quot;
#include &quot;cMetaInterval.h&quot;

PandaFramework framework;

int main(int argc, char *argv[]) {
    //open a new window framework and set title
  framework.open_framework(argc, argv);
  framework.set_window_title(&quot;My Panda3D Window&quot;);
  
    //open the window
  WindowFramework *window = framework.open_window();
  NodePath cam = window-&gt;get_camera_group(); //get the camera and store it
 
    //load the environment model
  NodePath environ = window-&gt;load_model(framework.get_models(),&quot;models/environment&quot;);
  environ.reparent_to(window-&gt;get_render());
  environ.set_scale(0.25,0.25,0.25);
  environ.set_pos(-8,42,0);

    //load our panda
  NodePath pandaActor = window-&gt;load_model(framework.get_models(),&quot;panda-model&quot;);
  pandaActor.set_scale(0.005,0.005,0.005);
  pandaActor.reparent_to(window-&gt;get_render());
  
    //load the walk animation
  window-&gt;load_model(pandaActor,&quot;panda-walk4&quot;);
  window-&gt;loop_animations(0);

    //create the lerp intervals needed to walk back and forth
  PT(CLerpNodePathInterval) pandaPosInterval1;
  pandaPosInterval1 = new CLerpNodePathInterval(&quot;pandaPosInterval1&quot;,13.0,CLerpInterval::BT_no_blend,
                              true,false,pandaActor,window-&gt;get_render());
  pandaPosInterval1-&gt;set_start_pos(LPoint3f(0,10,0));
  pandaPosInterval1-&gt;set_end_pos(LPoint3f(0,-10,0));
  PT(CLerpNodePathInterval) pandaPosInterval2;
  pandaPosInterval2 = new CLerpNodePathInterval(&quot;pandaPosInterval2&quot;,13.0,CLerpInterval::BT_no_blend,
                              true,false,pandaActor,window-&gt;get_render());
  pandaPosInterval2-&gt;set_start_pos(LPoint3f(0,-10,0));
  pandaPosInterval2-&gt;set_end_pos(LPoint3f(0,10,0));
  PT(CLerpNodePathInterval) pandaHprInterval1;
  pandaHprInterval1 = new CLerpNodePathInterval(&quot;pandaHprInterval1&quot;,3.0,CLerpInterval::BT_no_blend,
                              true,false,pandaActor,window-&gt;get_render());
  pandaHprInterval1-&gt;set_start_hpr(LPoint3f(0,0,0));
  pandaHprInterval1-&gt;set_end_hpr(LPoint3f(180,0,0));
  PT(CLerpNodePathInterval) pandaHprInterval2;
  pandaHprInterval2 = new CLerpNodePathInterval(&quot;pandaHprInterval2&quot;,3.0,CLerpInterval::BT_no_blend,
                              true,false,pandaActor,window-&gt;get_render());
  pandaHprInterval2-&gt;set_start_hpr(LPoint3f(180,0,0));
  pandaHprInterval2-&gt;set_end_hpr(LPoint3f(0,0,0));
  
    //create and play the sequence that coordinates the intervals
  PT(CMetaInterval) pandaPace;
  pandaPace = new CMetaInterval(&quot;pandaPace&quot;);
  pandaPace-&gt;add_c_interval(pandaPosInterval1,0,CMetaInterval::RS_previous_end);
  pandaPace-&gt;add_c_interval(pandaHprInterval1,0,CMetaInterval::RS_previous_end);
  pandaPace-&gt;add_c_interval(pandaPosInterval2,0,CMetaInterval::RS_previous_end);
  pandaPace-&gt;add_c_interval(pandaHprInterval2,0,CMetaInterval::RS_previous_end);
  pandaPace-&gt;loop();

    //do the main loop:
  ClockObject* clock (ClockObject::get_global_clock()); //get the global clock object
  Thread *current_thread = Thread::get_current_thread();
  while(framework.do_frame(current_thread)) {
    CIntervalManager::get_global_ptr()-&gt;step(); //step the interval manager
    double time = clock-&gt;get_real_time(); //get the time in seconds
    double angledegrees = time * 6.0; //the angle of the camera in degrees
    double angleradians = angledegrees * (3.14 / 180.0); //in radians
    cam.set_pos(20*sin(angleradians),-20.0*cos(angleradians),3); //set the position
    cam.set_hpr(angledegrees, 0, 0); //set the hpr
  }

    //close the window framework
  framework.close_framework();
  return (0);
}

&lt;/pre&gt;

&lt;i&gt;Intervals&lt;/i&gt; are tasks that change a property
from one value to another over a specified period of time.  Starting
an interval effectively starts a background process that modifies the
property over the specified period of time. For example, consider the
&lt;code&gt;pandaPosInterval1&lt;/code&gt; above.  When that interval is
started, it will gradually adjust the position of the panda from
(0,10,0) to (0,-10,0) over a period of 13 seconds.  Similarly,
when the &lt;code&gt;pandaHprInterval1&lt;/code&gt; is started,
the orientation of the panda will rotate 180 degrees over a period of 3 seconds.

&lt;i&gt;MetaIntervals&lt;/i&gt; are tasks that execute one interval
after another.  The &lt;code&gt;pandaPace&lt;/code&gt; sequence above
causes the panda to move in a straight line, then turn, then in the
opposite straight line, then to turn again.  The code &lt;code&gt;pandaPace-&gt;loop()&lt;/code&gt; causes the MetaInterval to be started
in looping mode.

The result of all this is to cause the panda to pace
back and forth from one tree to the other.</text>
    </revision>
  </page>
  <page>
    <title>Using MSVC</title>
    <ns>0</ns>
    <id>2084</id>
    <redirect title="Using Microsoft Visual Studio" />
      <sha1>qfh22qtlfpmllf3x9ml7v4ze6i51f5l</sha1>
    <revision>
      <id>4205</id>
      <timestamp>2007-03-10T10:47:17Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>Redirecting to [[Using Microsoft Visual Studio]]</comment>
      <text xml:space="preserve" bytes="43">#REDIRECT [[Using Microsoft Visual Studio]]</text>
    </revision>
  </page>
  <page>
    <title>Using Microsoft Visual Studio</title>
    <ns>0</ns>
    <id>2070</id>
      <sha1>phoiac9h4m842xq45sp7s6u21eteeq1</sha1>
    <revision>
      <id>6041</id>
      <timestamp>2009-07-29T17:31:44Z</timestamp>
      <contributor>
        <username>Sorcus</username>
        <id>239</id>
      </contributor>
      <text xml:space="preserve" bytes="0" />
    </revision>
  </page>
  <page>
    <title>Using ODE with Panda3D</title>
    <ns>0</ns>
    <id>2279</id>
      <sha1>65fdex0gayzvq6gasj5vnv06x534kdc</sha1>
    <revision>
      <id>6870</id>
      <timestamp>2010-05-22T22:43:50Z</timestamp>
      <contributor>
        <username>Croxis</username>
        <id>430</id>
      </contributor>
      <text xml:space="preserve" bytes="1417">Panda3D also provides integration for the Open Dynamics Engine. This is a platform-independent open-source physics engine with advanced types and built-in collision detection. Panda3D provides support for ODE because sometimes Panda's limited built-in physics system might not always be enough to suit more complex needs.

From Panda3D version 1.5.3, ODE support is included in the downloadable binaries. Before that version, you would have to download the source packages and include ODE yourself.

This section will explain how to use this ODE system with Panda3D.

&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;ol type=&quot;a&quot;&gt;
&lt;li&gt;[[Worlds, Bodies and Masses]]
&lt;li&gt;[[Simulating the Physics World]]
&lt;li&gt;[[Attaching Bodies using Joints]]
&lt;li&gt;[[Collision Detection with ODE]]
&lt;/ol&gt;

&lt;h2&gt;More information&lt;/h2&gt;
* The [http://www.panda3d.org/reference/python/namespace!panda3d.ode API reference] can list the classes and methods available (all of the classes are prefixed with Ode), although the function descriptions are lacking. It might also be useful to look at the [http://pyode.sourceforge.net/api-1.2.0/public/ode-module.html PyODE API reference], which uses very similar class and method names.
* Developers from Walt Disney VR Studio have held a lecture about using the ODE system with Panda3D. Click [http://video.google.com/videoplay?docid=6429726243770234547&amp;hl=en here] to watch a video recording of it. (Recorded June 18, 2008)</text>
    </revision>
  </page>
  <page>
    <title>Using Pixel Shaders in Cg</title>
    <ns>0</ns>
    <id>1058</id>
    <redirect title="Using Cg Shaders" />
      <sha1>k2h7scbc4up8iuhk2w6luzc1olaklvg</sha1>
    <revision>
      <id>2344</id>
      <timestamp>2005-04-17T01:42:46Z</timestamp>
      <contributor>
        <username>Admin</username>
        <id>1</id>
      </contributor>
      <comment>Using Pixel Shaders in Cg moved to Using Cg Shaders</comment>
      <text xml:space="preserve" bytes="31">#REDIRECT [[Using Cg Shaders]]
</text>
    </revision>
  </page>
  <page>
    <title>Using packp3d</title>
    <ns>0</ns>
    <id>2392</id>
      <sha1>imzues6cavtrzsopos6vc9c8hg1n4jb</sha1>
    <revision>
      <id>6793</id>
      <timestamp>2010-04-07T20:32:40Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <comment>fix panda3d/packp3d confusion</comment>
      <text xml:space="preserve" bytes="3434">The easiest way to create a p3d file is to use the packp3d tool.  This
program is distributed with the development distribution of Panda3D.
(It happens to be a p3d file itself, but that's just a detail.)  You
should use the packp3d program that comes with the version of Panda3D
you were using to develop your application, because packp3d is tied to
its own particular version of Panda3D, and will build a p3d file that
runs with that particular version.

You have to run packp3d from the command line.  From the command
shell, run the command:

&lt;code bash&gt;
packp3d -o myapp.p3d -d c:/myapp
&lt;/code&gt;

where &quot;myapp.p3d&quot; is the p3d file you want to produce, and &quot;c:/myapp&quot;
is the folder containing your application, including all of its code
and models.

Note that you need to have the panda3d executable on your PATH in order for the above to work.  The panda3d executable should have been installed when you installed
the Panda3D runtime (this is a separate download from the Panda3D SDK).  You might need to extend your PATH variable to
locate it automatically on the command line, by adding the plugin
installation folder to your PATH.  On Windows, this is the folder
c:\Program Files\Panda3D by default.

The above command will scan the contents of c:/myapp and add all
relevant files found in that directory and below into the p3d file
myapp.p3d, creating a packaged application.  There are some
conventions you need to understand.

* packp3d assumes that the starting point of your application is in the Python file &quot;main.py&quot;, which is found within the toplevel of the application folder.  If you have a different Python file that starts the application, you can name this file with the -m parameter to packp3d, e.g. &quot;-m mystart.py&quot;.

* If your application is written entirely in C++, it must still have a Python entry point to be used by the Panda3D plugin system, so you will need to provide a trivial bit of Python code to load and start your C++ application.

* Any prc files within the toplevel of the application folder will be loaded automatically at runtime, as if $PANDA_PRC_DIR were set to your application folder name; you don't need to load them explicitly in your Python code.

* Any egg files found within the application folder will be automatically converted to bam files for storing in the p3d file. Bam files are usually a much better choice for distributing an application, because they're smaller and they load much faster. However, this does mean that you can't specify the &quot;.egg&quot; extension to your model files when you load your models in code, because they won't have that extension within the p3d file; you must omit the filename extension altogether.  If you want to keep some of your egg files as they are, without converting them to bam files, you must use the more advanced ppackage utility to create your p3d file.

* Any model files that your application loads from some source outside of the application folder won't be found.  You must ensure that these are copied into the application folder and loaded from there. (However, texture files that are referenced by egg or bam files within the application folder will automatically be copied into the p3d file, no matter where they were found on disk.)

* There are additional options to packp3d for more advanced usage.  As with any Panda3D command-line application, you may specify &quot;-h&quot; on the command line to list the full set of available options.</text>
    </revision>
  </page>
  <page>
    <title>Using ppackage</title>
    <ns>0</ns>
    <id>2410</id>
      <sha1>cc8hs7ezp6h4qvjzmtg4n4jd8bbqzn0</sha1>
    <revision>
      <id>6670</id>
      <timestamp>2010-02-09T10:00:41Z</timestamp>
      <contributor>
        <username>Rdb</username>
        <id>110</id>
      </contributor>
      <text xml:space="preserve" bytes="1419">The ppackage utility is Panda's utility for building packages.  You can also use ppackage to build a p3d file; this gives you much more control over the p3d file than packp3d's simple interface.

To use ppackage, you must first create a pdef file, or a package definition file.  This is a file that defines precisely what package(s) or p3d file(s) are to be produced, and what contents should go into each one.  The syntax of the pdef file is described on the next page.

Once you have the pdef file, you can run ppackage as follows:

&lt;code bash&gt;
ppackage -i c:/output_dir myfile.pdef
&lt;/code&gt;

The directory named with -i is the directory into which the contents of the package(s) named in the pdef file will be placed.  It doesn't have to exist before you run ppackage, but if it does already exist from a previous ppackage session, new contents will be added to it.  You must eventually copy this directory to a web host to make the packages available for use; see Hosting packages, below.

As with packp3d, you must have panda3d on your path; and you can omit the panda3d prefix on Linux and Mac.

Also like packp3d, you should use the version of ppackage.p3d that is distributed with the particular version of Panda3D that you are using for development--ppackage.p3d is associated with the version of Panda3D that was used to produce it, and by default will generate packages that depend on that version of Panda3D.</text>
    </revision>
  </page>
  <page>
    <title>Using the Particle Panel</title>
    <ns>0</ns>
    <id>1030</id>
      <sha1>2rgtmov9ln3klijn0j5g96du47h2c1w</sha1>
    <revision>
      <id>7378</id>
      <timestamp>2011-11-13T16:21:58Z</timestamp>
      <contributor>
        <username>Community</username>
        <id>527</id>
      </contributor>
      <comment>added something to the page, so things are still missing</comment>
      <text xml:space="preserve" bytes="8180">The Particle Panel can be invoked by running the Particle Panel sample program, which should be located at &lt;b&gt;Panda3D-1.X.X/samples/Particles&lt;/b&gt; in Windows. The Panda3d engine uses text files for storing particle effects. You don't need to use the Particle Panel to create particle effects, you can just create those files in your text editor, or set all the parameters in your code, however it makes everything a lot easier and you can see all your changes immediately in the 3d view.

[[Image:Ppanel1.png]]

1. Load Params, Save Params, Print Params or Quit.
You can load or save your Panda Particle Files (*.ptf), which are ordinary text files.
You can also print the content of the ptf file to the console.
Quit exits the Particle Panel program.

2. Toggle between Active or Passive modes (Active by default).

3. Find out general info about the Particle Panel program or toggle Baloon Help (on by default).

4. Select effect to configure or create new effect.
Options: Create new Effect, Select Particle Effect, Place Particle Effect, Toggle Effect Vis, Enable/Disable.

5. Select effect to configure or create new effect.

6. Select particles object to configure or add new particles object to current effect.

&lt;b&gt;7. System:&lt;/b&gt;

[[Image:Ppanel2.png]]

1) Max number of simultaneous particles. More amount of particles won't exist at the same time.

2) Seconds between particle births. No new particles will be generated during this period.

3) Number of particles created at each birth.

4) Variation in litter size, so exactly the same amount of particles won't be generated at each birth as set in the &quot;Litter Size&quot;.

5) Age in seconds at which the system (vs. Particles) should die. Default is 0, which means the particle generator won't die.

6) Whether or not velocities are absolute.

7) System has a lifespan or not. Lenght set in &quot;Lifespan&quot;.

8) Particle system position (0,0,0 by default)

9) Particle system orientation (0,0,0 by default)

Some of this information can also be found in the Particle Effect Basic Parameters
page.

&lt;b&gt;8. Factory:&lt;/b&gt;

[[Image:Ppanel3.png]]

1)  Type of the particle factory.
The differences between these factories lie in the orientation and rotational abilities. 

2) Average particle lifespan in seconds. Sets how long each particle should exist.

3) Variation in lifespan. Default is 0, which means all particles will have the same lifespan.

4) Average particle mass.

5) Variation in particle mass.

6) Average particle terminal velocity.

7) Variation in terminal velocity.

Some of this information can also be found in the Particle Factories
page.

&lt;b&gt;9. Emitter:&lt;/b&gt;

[[Image:Ppanel4.png]]

1) There are a large number of particle emitters, each categorized by the volume of space they represent.

2) All emitters have three modes: explicit, radiate, and custom. Explicit mode emits the particles in parallel in the same direction. Radiate mode emits particles away from a specific point. Custom mode emits particles with a velocity determined by the particular emitter. 

3) Launch velocity multiplier (all emission modes)

4) Spread for launch velocity multiplier (all emission modes)

5) Velocity vector applied to all particles.

6) All particles launch with this velocity in Explicit mode.

7) Particles launch away from this point in Radiate mode.

Some of this information can also be found in the Particle Emitters page.

&lt;b&gt;10. Renderer:&lt;/b&gt;

[[Image:Ppanel5.png]]

1) Renderer Type sets the type of particle renderer. These are LineParticleRenderer, GeomParticleRenderer, PointParticleRenderer, SparkleParticleRenderer and SpriteParticleRenderer.

2) Alpha setting over particle's lifetime:
NO_ALPHA,  ALPHA_IN,  ALPHA_OUT,  ALPHA_IN_OUT,  ALPHA_USER.

3) Alpha value for ALPHA_USER alpha mode.

&lt;u&gt;1. LineParticleRenderer&lt;/u&gt;

LineParticleRenderer is useful for effects such as rain. You can't use the SpriteParticleRenderer for the same effect, as the lines would always face the camera.
Each Particle Renderer has it's own unique options, so we are going to  explain them separately.

[[Image:Ppanel6.png]]

&lt;br&gt;1.1 – 1.2)  Head color and tail color of the line can be different.
&lt;br&gt;1.3) You can set the lenght of the line here.

&lt;u&gt;2. GeomParticleRender&lt;/u&gt;

GeomParticleRender renders particles as full 3D objects. This requires a geometry node. Just type the path to the egg file you want to use.

[[Image:Ppanel7.png]]

undocumented

[[Image:Ppanel8.png]]

&lt;br&gt;2.1) If you enable these, then the values from 3 and 5 and 7 won't be ignored, the values between Initial X/Y/Z and Final X/Y/Z will be interpolated over particle's life.
&lt;br&gt;2.2, 2.4, 2.6) Initial X/Y/Z scales. You can set the scales of particles here.
&lt;br&gt;2.3, 2.5, 2.7) Final X/Y/Z scales. If the &quot;X Scale&quot;,&quot;Y Scale&quot; and &quot;Z Scale&quot; are enabled, then the the values between Initial X/Y/Z and Final X/Y/Z will be interpolated over particle's life.

[[Image:Ppanel9.png]]

Segments can be used to change the colour of particles during their lifetime.

&lt;u&gt;3. PointParticleRender&lt;/u&gt;

Renders particles as pixel points.

[[Image:Ppanel10.png]]

&lt;br&gt;3.1) Size of the points (1 pixel by default)
&lt;br&gt;3.2 – 3.3) Starting and ending colors. The colors the points will have during their birth and death.
&lt;br&gt;3.4) How the particles blend from the start color to the end color.
&lt;br&gt;3.5) Interpolation method between colors.

&lt;u&gt;4. SparkleParticleRender&lt;/u&gt;

Renders particles as star or sparkle objects, three equal-length perpendicular axial lines, much like jacks. Sparkle particles appear to sparkle when viewed as being smaller than a pixel. 

[[Image:Ppanel11.png]]

&lt;br&gt;4.1 – 4.2) Color of the center and color of the edges.
&lt;br&gt;4.3 – 4.4) Initial sparkle radius and final sparkle radius
&lt;br&gt;4.5) Whether or not sparkle is always of radius birthRadius

&lt;u&gt;5. SpriteParticleRender&lt;/u&gt;

Renders particles as an image, using a Panda3D texture object. The image is always facing the user.

[[Image:Ppanel12.png]]

&lt;br&gt;5.1.1) On: Multitexture node will be animated, Off: only the first frame of a node will be rendered. One way to make such a node (textured quad) is egg-texture-cards program, which will take your image files and generate an egg file for you.
To add such a node, click on (5.4) Add Animation button.
&lt;br&gt;5.1.2) The frame rate of the animation, enable Animation first.
&lt;br&gt;5.1.3) Add a texture.
&lt;br&gt;5.1.4) Add a node intended for animations.
&lt;br&gt;5.1.5 - 5.1.6) Write the name of the texture file. You won't see changes before you click &quot;Update&quot;.
You can see the default texture file used by the program.
Use the X button to remove the texture.

[[Image:Ppanel13.png]]

&lt;br&gt;5.2.1) If you enable these, then the values from 4 and 6 won't be ignored, the values between Initial X/Y and Final X/Y will be interpolated over particle's life.
&lt;br&gt;5.2.2) On: particles that are set to spin on the Z axis will spin appropriately.
&lt;br&gt;5.2.3, 5.2.5) Initial X/Y scales. You can set the scales of particles here.
&lt;br&gt;5.2.4, 5.2.6) Final X/Y scales. If the &quot;X Scale&quot; and &quot;Y Scale&quot; are enabled, then the the values between Initial X/Y and Final X/Y will be interpolated over particle's life.
&lt;br&gt;5.2.7) If animAngle is false: counter-clockwise Z rotation of all sprites

[[Image:Ppanel14.png]]

undocumented

[[Image:Ppanel15.png]]

Segments can be used to change the colour of particles during their lifetime. Here's an example of using a Linear Segment:

[[Image:Rocket-particles.png]]

&lt;b&gt;11. Force&lt;/b&gt;

[[Image:Ppanel16.png]]

&lt;br&gt;You can add different forces to your particle effects here. For example you can use the &lt;b&gt;Noise Force&lt;/b&gt; to add some randomness to the movement of particles such as for falling particles used in a snow effect.

Note: There isn't an option in the Particle Panel to set what the individual particles should be relative to. If you want to set that explicitly, use the &lt;code&gt;renderParent&lt;/code&gt; argument in the &lt;code&gt;start()&lt;/code&gt; call in your code. You will find this useful for particle effects on moving objects, or for example rain and snow.

Note: resizing the particle Panel GUI window might crash the program.

&lt;h2&gt;Incomplete Section&lt;/h2&gt;

Note: this section is incomplete.  It will be updated soon.</text>
    </revision>
  </page>
  <page>
    <title>Using the libRocket UI</title>
    <ns>0</ns>
    <id>49975</id>
      <sha1>qboucjhyfvlzxzu22y166hpzk9ijk5k</sha1>
    <revision>
      <id>58183</id>
      <timestamp>2014-03-18T09:18:58Z</timestamp>
      <contributor>
        <username>Gczuczy</username>
        <id>21758</id>
      </contributor>
      <text xml:space="preserve" bytes="11472">Panda3D comes with the libRocket User Interface middlewhere which allows making UIs out of HTML4/CSS-ish tools. Panda3D's integration with libRocket goes as far as hooking up with various subsystems, like the rendering context, event and input handlers, the VFS layer and such like. This means that libRocket has to be initialized to make all the hooks applied, then documents can be made and interacted with. After this point to handle libRocket specific UI specifics it's all the libRocket API, and not Panda3D's.

This tutorial focuses on show how the initalization part is being done in Panda3D, what do you need to set up to use libRocket in your project, and shows some basic and commonly used methods as a starting point.

The goal is to introduce the read into using rocket with Panda3D and make him able to use librocket's own documentation on his own to implement more complex tasks.

== librocket basics ==

Librocket basically works with HTML4-ish markups and CSS2-ish style sheets. Exactly these are so called RML and RCSS files, R stands for Rocket. RML is a subset of HTML4, and RCSS is a subset of CSS2, with a small amount of differences.

The documentation of RML and RCSS can be found on the librocket website, please refer to these documentation for understanding the details of these:
 * [http://librocket.com/wiki/documentation/RML RML Documentation]
 * [http://librocket.com/wiki/documentation/RCSS RCSS Documentation]
 * [http://librocket.com/wiki/documentation Librocket Documentation]

Librocket is a middleware, which means, it is designed to be used within other applications, and not on its own. Therefore it has been designed to be hooked up with other frameworks, therefore making them able to utilize librocket internally, and this is the exact integration what the Panda3D framework has. So, this is handled in Panda3D already, we won't have to deal with this when making games in Panda, however a few specifics still have to be triggered, as will be shown later.

[cxx]
== Setting up the build environment ==

Panda3D comes integrated with libRocket, however to build projects in C++ with libRocket, you still need to have librocket headers (and on Windows the .lib files) accessable, which is currently not shipped with the Panda3D SDK.

If you are using an official SDK release, download the thirdparty packages on the download page of that SDK version.  If you are using the 1.9 trunk (which requires VC 2010 instead of 2008), use these thirdparty packages found [https://www.panda3d.org/forums/viewtopic.php?f=9&amp;t=16346 here].

After getting these, add librocket's include directory to your include path, as you'll need it.

After this the linker have to be told to link against the following libraries as well:
&lt;code cxx&gt;
libp3rocket
RocketCore
RocketControls
&lt;/code&gt;

The first (libp3rocket) is part of Panda3D, the others can be found in the thirdparty files, therefore you might also need to add that directory to your linker's paths.
[/cxx]

== Initalizing the librocket context ==

Once the environment is set up, the Rocket context will need to be initialized. To achieve this a panda framework and window has to be opened in the usual way. Panda provides some bindings at this initialization level, which can be found in the RocketRegion class:

[cxx]
Under C++ some additional work is also needed, because librocket is also usig Python bindings, therefore even if the project is not using Python, it has to be initialized explicitly, otherwise the code will fault.

&lt;code cxx&gt;
// Panda includes
#include &quot;pandaFramework.h&quot;
#include &quot;pandaSystem.h&quot;
#define NDEBUG // if you get Rocket::Core::Assert unresolved linker errors
#include &quot;rocketRegion.h&quot;

// Rocket includes
#include &lt;Rocket/Core/Factory.h&gt;
#include &lt;Rocket/Core.h&gt;
#undef NDEBUG


int main(int argc, char *argv[]) {
  //open a new window framework
  PandaFramework framework;
  framework.open_framework(argc, argv);
  framework.set_window_title(&quot;Panda Rocket&quot;);
  WindowFramework *window = framework.open_window();

  // important, because librocket has python bindings enabled
  // segfaults without this
#ifdef HAVE_ROCKET_PYTHON
  Py_Initialize();
#endif

  // Initialize a RocketRegion, using Panda's integration
  PT(RocketRegion) r = RocketRegion::make(&quot;Panda Rocket&quot;, window-&gt;get_graphics_window());
  r-&gt;set_active(true);

  // Initialize a Rocket context using Panda's integration.
  PT(RocketRegion) r = RocketRegion::make(&quot;PPORocket&quot;, window-&gt;get_graphics_window());

  // attach rocket's input handler to panda's
  PT(RocketInputHandler) rih = new RocketInputHandler();
  window-&gt;get_mouse().attach_new_node(rih);
  r-&gt;set_input_handler(rih);

  //do the main loop, equal to run() in python
  framework.main_loop();

  //close the window framework
  framework.close_framework();
  return 0;
}


&lt;/code&gt;

The rocket documentation says all needed is Rocket/Core.h, however it gave some errors regarding templating confusions for Factory.h. Checking the code it all seemed fine, but hinted that Factory got included in the header a bit later, therefore if you get those errors it can be fixed by manually including Rocket/Core/Factory.h before Rocket/Core.h.

The Py_Initialize is very important, since without that librocket just faults. The HAVE_ROCKET_PYTHON indicates whether rocket had been built with python support, and if so, python needs explicitly to be initialized. It is possible to build Panda3D and rocket independently with or without Python support, so take some care at this point.

Rocket is also using the NDEBUG macro, therefore you have to hide some debugging symbols depending on what kind of lib you are linking to. Since Panda's rocketRegion.h is also including Rocket headers, NDEBUG has to be taken care of at that level, after that it can be undefined to avoid any other interferences.
[/cxx]

With this Panda is initialized, Python init is also done, and RocketRegion initialized Rocket, and made a context ready to used. The following lines are attaching the mouse controls to the Rocket Contexts, means that Panda's mouse events are made valid on Rocket objects, making interaction possible.

With this code rocket is initalized and is ready to take documents.

== Handling rocket documents ==

To add a rocket document, first a document is needed, then to add that to the code. For this it is highly recommended to have a basic RCSS script, which set up the basics. Luckily librocket provides one in its manual, right [http://librocket.com/wiki/documentation/RML/HTML4StyleSheet here]. Please save this sheet as &lt;code&gt;pandarocket.rcss&lt;/code&gt;, which will be used in this example later on.

Let's make a document, named &lt;code&gt;pandarocket.rml&lt;/code&gt;, with the following content:

&lt;code rml&gt;
&lt;rml&gt;
&lt;head&gt;
 &lt;title&gt;Panda Rocket&lt;/title&gt;
 &lt;link type=&quot;text/rcss&quot; href=&quot;pandarocket.rcss&quot;/&gt;
&lt;/head&gt;
&lt;body class=&quot;window&quot;&gt;
Hello World!
&lt;/body&gt;
&lt;/rml&gt;
&lt;/code&gt;

Using the Rocket Context we can load this document in the application:

[cxx]
&lt;code cxx&gt;
  // Load the document
  Rocket::Core::ElementDocument *rdoc = rc-&gt;LoadDocument(&quot;pandarocket.rml&quot;);
  // Display the document:
  rdoc-&gt;Show();
&lt;/code&gt;
[/cxx]

The LoadDocument call loads a document, and returns its representation, which can be displayed. It's important to note here, that rocket's file handling is also hooked up with Panda's VFS layer, meaning that if you have a document in a multifile file, then LoadDocument is also able to load it from that point.

To specify things like the size of the document, background color, borders, spawning location, etc, please see the RCSS documentation. These are style properties which can be set from the style sheet. Also, the librocket API provides methods for setting properties and attributes of Rocket Elements, therefore the same can be done from the code as well.

== Basic Rocket Controls ==

In the above initialization code snippet, Rocket's input handler is bound to Panda, therefore we can have some interactions. First, to make this work the document has to be told on the points where interaction is possible, and how to handle it.

By modifying the above RML file to the following, a separate title div is created, to which a moving handler is attached, and also a resizing handler is attached to the body:

&lt;code rml&gt;
&lt;rml&gt;
&lt;head&gt;
 &lt;title&gt;Panda Rocket&lt;/title&gt;
 &lt;link type=&quot;text/rcss&quot; href=&quot;pandarocket.rcss&quot;/&gt;
&lt;/head&gt;
&lt;body class=&quot;window&quot;&gt;
 &lt;div id=&quot;title-bar&quot;&gt;
  &lt;handle move_target=&quot;#document&quot;&gt;
    &lt;span id=&quot;title&quot;&gt;Panda World!&lt;/span&gt;
  &lt;/handle&gt;
&lt;/div&gt;

Hello World!
&lt;handle size_target=&quot;#document&quot; style=&quot;position:absolute; width: 16px; height:16px; bottom: 0px; right: 0px;&quot;/&gt;
&lt;/body&gt;
&lt;/rml&gt;
&lt;/code&gt;

With this holding the left mouse button on the title div the whole document can be moved around in the Panda scene, and by holding the left mouse button on the lower-right 16x16px of the body, the document can be resized.

== Handling User Input ==

User input handling is also integrated into Panda, and RML is using the usual nodes from HTML, with a few differences. The librocket [http://librocket.com/wiki/documentation/RML/Forms form documentation] explains most of the available tags, please consult it for details.

[cxx]
To have input boxes work in C++ a few additional steps are needed, since Controls are a plugin in librocket, therefore this needs to be included, linked and initialized.

The application has to be linked to the following library as well:
&lt;code&gt;
RocketControl
&lt;/code&gt;

After the Core Rocket header the Control header also has to be included:
&lt;code cxx&gt;
#include &lt;Rocket/Controls.h&gt;
&lt;/code&gt;

And finally the Rocket::Controls plugin has to be initialized, because in C++ it's not implicit:
&lt;code cxx&gt;
  // Initialize the Rocket::Controls plugin
  Rocket::Controls::Initialise();
&lt;/code&gt;

Initializing Controls is fine anytime after getting the context, because &lt;code&gt;RocketRegion::make()&lt;/code&gt; Does the basic initialization generally.
[/cxx]

To have input fields on the UI simply add such tags into the RML file, like shown below:
&lt;code rml&gt;
&lt;form name=&quot;pandaform&quot; onsubmit=&quot;close()&quot;&gt;
 &lt;br/&gt;&lt;input type=&quot;text&quot; name=&quot;pandainput&quot; size=&quot;16&quot; maxlength=&quot;32&quot; /&gt;
 &lt;br/&gt;&lt;input type=&quot;submit&quot; name=&quot;pandasubmit&quot; value=&quot;GO!&quot; size=&quot;4&quot;&gt;GO!&lt;/input&gt;
&lt;/form&gt;
&lt;/code&gt;

On styling these, please consult the RCSS documentation.

Upon receiving any user input, let it be keystrokes or mouse interaction (clicks, mouseovers, etc) Rocket will emit events which can be handled later.

== Things good to know ==

There are a couple of important things which are good to know when using rocket. Some of these are related to Panda3D's integration, some of them are not, but keeping these in mind makes things swifter.

=== Font handling ===

Technically libRocket doesn't have a way to directly hook up with the already loaded fonts, and because of this Panda3D is unable to pass the loaded fonts' structures to libRocket.

The result of this is, fonts have to be loaded manually into libRocket. This is a fairly easy task, given libRocket's API regarding this is quite simple, you can find it [http://librocket.com/doxygen/html/classRocket_1_1Core_1_1FontDatabase.html here] how fonts can be loaded into libRocket.

The code would look something like this:

[cxx]
&lt;code cxx&gt;
#include &lt;FontDatabase.h&gt;
...
Rocket::Core::FontDatabase::LoadFontFace(&quot;MyFont.ttf&quot;);
&lt;/code&gt;
[/cxx]

LibRocket is able to handle both truetype(.ttf) (by default support is built in) and opentype(.otf) fonts, so both should be fine.</text>
    </revision>
  </page>
  <page>
    <title>VR Helmets and Trackers</title>
    <ns>0</ns>
    <id>1032</id>
      <sha1>ffw5ljuyxm3j8wmc3f3dwa9xzxghx80</sha1>
    <revision>
      <id>7681</id>
      <timestamp>2012-03-08T20:31:14Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="2592">This section is especially geared towards Carnegie Mellon University's virtual reality equipment. The tracking setup used consists of a magnetic tracker base that receives signals, a virtual reality headmount, and four small trackers, one of which is attached to the headmount. These magnetic trackers may be held in the hand or implanted in non-metallic objects, and they will relay their position and orientation to the tracker base, which then supplies it to the program.

First, make sure that the VRHandler is in the same folder as your python files. Then, import it as you would any Panda3D module.

&lt;code python&gt;
from VRHandler import *
&lt;/code&gt;

Once imported, the VRHandler functions are now available. Make a constant in your code that controls whether or not the tracker is used.

&lt;code python&gt;
USE_TRACKER = True
&lt;/code&gt;

or

&lt;code python&gt;
USE_TRACKER = False
&lt;/code&gt;

Then, activate the tracker if required:

&lt;code python&gt;
if USE_TRACKER:
  self.tracker = Tracker()
  camera.reparentTo(self.tracker.getHMDHelper())
else:
  print &quot;Using Mouse and Keyboard Controls&quot;
  self.controls = MouseAndKeyboardControls()
  self.controls.start()
&lt;/code&gt;

If the tracker is not being used, the above code enables first-person-shooter style controls, using WASD to move, R and F for height, and the mouse to look around. You can add the following lines to your code if you want to customize the feel of the controls:

&lt;code python&gt;
&amp;#35; Keyboard control constants
self.controls.acceleration = 15
self.controls.maxSpeed = 5
self.controls.friction = 6
&lt;/code&gt;

Change those three numbers to whatever feels right for your world.

Typically, the tracker base is 6.5 feet off the ground, and the range of the trackers is from three or so inches from the tracker base to around the knees of an average person. The tracker base is treated as a NodePath, so it may be moved around. If you want the guest to move around the world while his real-life feet stay put, get the tracker base helper and move that around:

&lt;code python&gt;
self.trackerBaseHelper = self.tracker.getTrackerBaseHelper()
self.trackerBaseHelper.setPos(0, 3, 0)
&lt;/code&gt;

Finally, objects within the Panda3D application may be reparented to the trackers. The four trackers are HMDHelper, YellowHelper, GreenHelper, and BlueHelper. Also, remember that reparenting may create some strange inheritance issues.

&lt;code python&gt;
NodePath.reparentTo(self.tracker.getHMDHelper() )
NodePath.reparentTo(self.tracker.getYellowHelper() )
NodePath.reparentTo(self.tracker.getGreenHelper() )
NodePath.reparentTo(self.tracker.getBlueHelper() )
&lt;/code&gt;</text>
    </revision>
  </page>
  <page>
    <title>Vertices in Panda3D</title>
    <ns>0</ns>
    <id>1157</id>
      <sha1>jmj8ai7e4migtmifmuxlx75d42kpftr</sha1>
    <revision>
      <id>2438</id>
      <timestamp>2005-10-09T14:28:27Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="10762">&lt;h2&gt;How Panda Stores Vertex Information&lt;/h2&gt;
As with any major 3D engine, geometry in Panda3D is primarily defined by vertices.  So before we discuss how to actually make geometry we have to discuss how Panda3D handles them.&lt;b&gt;The following information only applies to Panda3D 1.1.&lt;/b&gt; For more information you can visit the [http://manageddreams.com/pandawiki/  Panda Developers Wiki]

&lt;h2&gt;Vertex Format&lt;/h2&gt;
In order to define a vertex Panda3D has to know what format the vertex has. The format decides what information the vertex can store(such as color, texture coordinate, normals, etc..). That information is stored in an object from the &lt;code&gt;GeomVertexFormat&lt;/code&gt; class. Panda3D comes with several predefined formats which you can get from the &lt;code&gt;GeomVertexFormat.get*()&lt;/code&gt; family of functions. The naming format for these functions are:

&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;V3&lt;/b&gt;&lt;/td&gt;&lt;td&gt;This means the position of the vertex is encoded in the format. All formats begin with this.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;&lt;b&gt;n3&lt;/b&gt;&lt;/td&gt;&lt;td&gt;This means the normal (3 components) of each vertex is encoded in the format.&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;&lt;b&gt;cp&amp;nbsp;or&amp;nbsp;c4&lt;/b&gt;&lt;/td&gt;&lt;td&gt;This means the color of each vertex is encoded in the format. &lt;b&gt;cp&lt;/b&gt; means the color will be packed DirectX style while &lt;b&gt;c4&lt;/b&gt; means the color will be stored in four bytes, OpenGL style. Panda will automatically convert the types at runtime if you are not using the native backend (cp for OpenGl or c4 for DirectX).&lt;/td&gt;&lt;/tr&gt;

&lt;tr&gt;&lt;td&gt;&lt;b&gt;t2&lt;/b&gt;&lt;/td&gt;&lt;td&gt;This means the texture coordinates (2 components) of each vertex are encoded in the format.&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/center&gt;

You can omit options you dont want but the formats have to be added in the order listed above. For example:
&lt;table class=&quot;code&quot;&gt;&lt;tr&gt;&lt;td&gt;
&amp;nbsp;#this is valid 
&lt;br&gt;GeomVertexFormat.getV3n3()
&lt;br&gt;#this isnt valid(V3 must always come first)
&lt;br&gt;GeomVertexFormat.getn3V3()
&lt;br&gt;#this is valid 
&lt;br&gt;GeomVertexFormat.getV3cpt2()
&lt;br&gt;#this isnt valid (color must come before texture)
&lt;br&gt;GeomVertexFormat.getV3t2cp()
&lt;br&gt;#this is plain wrong 
&lt;br&gt;GeomVertexFormat.getcpV3t2n3()
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;h2&gt;Making Your Own Custom Format&lt;/h2&gt;
In addition to the formats that come with Panda you can define your own. However this is advance usage and will only be touched upon here. See the Panda 1.1 documentation (which should be out soon) for more information. &lt;code&gt;GeomVertexFormat&lt;/code&gt; is really a container of &lt;code&gt;GeomVertexArrayFormat&lt;/code&gt; objects.These objects are made up of &lt;code&gt;GeomVertexColumn&lt;/code&gt; objects which describe what attributes the format encodes in the vertices. Having one &lt;code&gt;GeomVertexArrayFormat&lt;/code&gt; object with all the &lt;code&gt;GeomVertexColumn&lt;/code&gt; objects is practically the same as having a seperate &lt;code&gt;GeomVertexArrayFormat&lt;/code&gt; object for each &lt;code&gt;GeomVertexColumn&lt;/code&gt;. The following example should make things clearer:

&lt;table class=&quot;code&quot;&gt;&lt;tr&gt;&lt;td&gt;
format=GeomVertexFormat()
&lt;br&gt;
&lt;br&gt;formatArray=GeomVertexArrayFormat()
&lt;br&gt;
&lt;br&gt;#we use the addColumn(name, numComponents, NumericType, Contents) function
&lt;br&gt;#Contents tell Panda how to update the information, if neccessary
&lt;br&gt;#i.e. if you apply a transformation to this geometry all columns that have &lt;br&gt;#Geom.CPoint for Contents will be updated appropriately
&lt;br&gt;
&lt;br&gt;#the hard way to get the V3n3cpt2 format
&lt;br&gt;formatArray.addColumn(InternalName.make(&quot;vertex&quot;), 3,Geom.NTFloat32, Geom.CPoint)
&lt;br&gt;formatArray.addColumn(InternalName.make(&quot;color&quot;), 4,Geom.NTPackedDcba, Geom.CColor)
&lt;br&gt;formatArray.addColumn(InternalName.make(&quot;normal&quot;), 3,Geom.NTFloat32, Geom.CVector)
&lt;br&gt;formatArray.addColumn(InternalName.make(&quot;texcoord&quot;), 2,Geom.NTFloat32, Geom.CTexcoord)
&lt;br&gt;
&lt;br&gt;#if we can keep adding more GeomVertexArrayFormat objects as long as none of &lt;br&gt;#the columns have the same name
&lt;br&gt;format.addArray(formatArray)
&lt;br&gt;
&lt;br&gt;#we have to register formats before we use them.
&lt;br&gt;format=GeomVertexFormat.registerFormat(format)
&lt;br&gt;
&lt;br&gt;#now format can be used just as any other GeomVertexFormat
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

None of the &lt;code&gt;GeomVertexArrayFormat&lt;/code&gt; objects can have &lt;code&gt;GeomVertexColumn&lt;/code&gt; objects with the same name. Furthermore, the column names &quot;vertex&quot;, &quot;color&quot;, &quot;normal&quot;, and &quot;texcoord&quot; are the only attributes that directly map to their counterpart (&quot;vertex&quot; will hold the current position of the vertex in Panda, &quot;color&quot; will hold the current color assigned through Panda, etc...). The standard formats above are already setup to use these default names. Any attributes you add other than these have no meaning to Panda (not unlike the &lt;code&gt;setTag&lt;/code&gt; interface for NodePaths).



&lt;h2&gt;Vertex Data&lt;/h2&gt;
&lt;code&gt;GeomVertexData&lt;/code&gt; objects are used to hold the information encoded in vertices. They have a row for each vertex and a column for each attribute the vertex should have (i.e. color, etc...). You need to have at least one of these objects before you can make any vertices of your own. You can create them using &lt;code&gt;GeomVertexData(name, format, usageHint)&lt;/code&gt;. &lt;code&gt;name&lt;/code&gt; is just the arbitrary name you want to give it. &lt;code&gt;format&lt;/code&gt; is an object from the &lt;code&gt;GeomVertexFormat&lt;/code&gt; class. This lets the &lt;code&gt;GeomVertexData&lt;/code&gt; object know how many columns it should have. The last parameter &lt;code&gt;usageHint&lt;/code&gt; tells Panda what optimizations it can perform on the vertices in this &lt;code&gt;GeomVertexData&lt;/code&gt; object. The types of usage hints are:

&lt;center&gt;&lt;table&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Geom.UHClient&lt;/b&gt;&lt;/td&gt;&lt;td&gt;Don't attempt to upload the data; always keep it on the client.  This is used for very special purposes only; typically you would use Geom.UHStream instead.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Geom.UHStream&lt;/b&gt;&lt;/td&gt;&lt;td&gt;For objects that are going to be rendered a few times and then discarded.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Geom.UHDynamic&lt;/b&gt;&lt;/td&gt;&lt;td&gt;For objects that will have their data modified by the program.&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;b&gt;Geom.UHStatic&lt;/b&gt;&lt;/td&gt;&lt;td&gt;For objects that will not have their state change during the program (This does not count animations or scene graph transformations).&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;
These hints are ordered from most dynamic to most static.  The most common usage hint, by far, is &lt;code&gt;Geom.UHStatic&lt;/code&gt;; if you have any uncertainty, you should probably use this one.

Using the constructor is the only functionality of the &lt;code&gt;GeomVertexData&lt;/code&gt; class that you should really use. Use &lt;code&gt;GeomVertexReader&lt;/code&gt; to read the information in a &lt;code&gt;GeomVertexData&lt;/code&gt; object or &lt;code&gt;GeomVertexWriter&lt;/code&gt; to change/add information (both classes are discussed below).

An example:
&lt;table class=&quot;code&quot;&gt;&lt;tr&gt;&lt;td&gt;
format=GeomVertexFormat.getV3n3cpt2()
&lt;br&gt;
&lt;br&gt;#use this if you want to create vertices whose information wont change often
&lt;br&gt;myVertexData=GeomVertexData(&quot;holds my vertices&quot;, format, Geom.UHStatic)
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;h2&gt;Reading and Writing Vertex Information&lt;/h2&gt;
Messing around directly with &lt;code&gt;GeomVertexData&lt;/code&gt; objects directly leaves a lot of room for error. The preferred way to read/write information from/to a &lt;code&gt;GeomVertexData&lt;/code&gt; object is to use the &lt;code&gt;GeomVertexReader&lt;/code&gt; and &lt;code&gt;GeomVertexWriter&lt;/code&gt; classes. Both are optimized for reading/writing down the same column (the same attribute). You can change columns if you need to using their &lt;code&gt;setColumn&lt;/code&gt; functions, but if you have to change columns often it is more efficient to create multiple &lt;code&gt;GeomVertexReader&lt;/code&gt;/&lt;code&gt;GeomVertexWriter&lt;/code&gt; objects, one for each column. 

Whenever you perform a read/write function with these classes they automatically move down to the next row (next vertex). You can get the row you are currently on by calling &lt;code&gt;getReadRow()&lt;/code&gt; and &lt;code&gt;getWriteRow()&lt;/code&gt; respectively. You can also set the row using the &lt;code&gt;setRow(newRow)&lt;/code&gt; function for both classes. To find out if you are at the end of column use &lt;code&gt;isAtEnd()&lt;/code&gt;.

If you are reading and writing at the same time you must create the &lt;code&gt;GeomVertexWriter&lt;/code&gt; objects before &lt;code&gt;GeomVertexReader&lt;/code&gt; objects. However using the class &lt;code&gt;GeomVertexRewriter&lt;/code&gt;, which has the functionality of both classes, is the preferred way to read/write data at the same time.

&lt;h2&gt;GeomVertexWriter&lt;/h2&gt;
This class has two sets of functions. The &lt;code&gt;setData*(...)&lt;/code&gt; functions will crash if you try to write when &lt;code&gt;isAtEnd()&lt;/code&gt; is True. Use this set of functions if you wish to modify the vertices in a &lt;code&gt;GeomVertexData&lt;/code&gt; object but not add to them. The &lt;code&gt;addData*(...)&lt;/code&gt; functions will automatically add a row to the &lt;code&gt;GeomVertexData&lt;/code&gt; object if it reaches the end.

The syntax is the same for both sets of functions. You have &lt;code&gt;setData&lt;/code&gt; or &lt;code&gt;addData&lt;/code&gt; followed by the number of components (1,2,3 or 4) and then followed by the type(i for integer or f for float). For example:

&lt;table class=&quot;code&quot;&gt;&lt;tr&gt;&lt;td&gt;
&amp;nbsp;#assume a V3n3cpt2 format
&lt;br&gt;#the constructor takes the GeomVertexData object you want to modify and the column you want 
&lt;br&gt;#to go down. If you dont specify the column you start out at the zeroth column in vdata.
myWriter=GeomVertexWriter(vdata, &quot;vertex&quot;)
&lt;br&gt;
&lt;br&gt;#this will crash if there are no vertices
&lt;br&gt;myWriter.setData3f(0.0,0.0,0.0)
&lt;br&gt;
&lt;br&gt;#this will work no matter what
&lt;br&gt;myWriter.addData3f(0.0, 0.0, 0.0)
&lt;br&gt;
&lt;br&gt;#now we want to edit the texture coordinats
&lt;br&gt;myWriter=GeomVertexWriter(vdata, &quot;texcoord&quot;)
&lt;br&gt;
&lt;br&gt;#now we use addData2f instead since this is only two components
&lt;br&gt;myWriter.addData2f(0.0,0.0)
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

All the &lt;code&gt;setData&lt;/code&gt; and &lt;code&gt;addData&lt;/code&gt; functions have a vector counterpart where appropriate.

&lt;h2&gt;GeomVertexReader&lt;/h2&gt;
This class only has one set of functions, the &lt;code&gt;getData*(....)&lt;/code&gt; functions. Their naming syntax follows the same rules as the &lt;code&gt;setData&lt;/code&gt; and &lt;code&gt;addData&lt;/code&gt; functions but you can only use &quot;f&quot; as the type. The &lt;code&gt;getData*(...)&lt;/code&gt; functions all return vecotrs of the appropriate type when neccessary (Vec4 for four components, but just the number for one component attributes).

A brief example:
&lt;table class=&quot;code&quot;&gt;&lt;tr&gt;&lt;td&gt;
&amp;nbsp;#assume a V3n3cpt2 format
&lt;br&gt;#the constructor takes the GeomVertexData object you want to read and the column you want 
&lt;br&gt;#to go down. If you dont specify the column you start out at the zeroth column in vdata.
myReader=GeomVertexReader(vdata, &quot;vertex&quot;)
&lt;br&gt;
&lt;br&gt;#this will crash if there are no vertices
&lt;br&gt;position=myReader.getData3f()
&lt;br&gt;
&lt;br&gt;#now we want to read the texture coordinats
&lt;br&gt;myReader=GeomVertexReader(vdata, &quot;texcoord&quot;)
&lt;br&gt;
&lt;br&gt;#now we use getData2f instead since this is only two components
&lt;br&gt;texcoord=myReader.getData2f()
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</text>
    </revision>
  </page>
  <page>
    <title>Video Lectures</title>
    <ns>0</ns>
    <id>2058</id>
    <redirect title="Video Tutorials" />
      <sha1>f4xwtpiw8p1lrexwm011haxislmm0mz</sha1>
    <revision>
      <id>4073</id>
      <timestamp>2007-02-15T15:55:56Z</timestamp>
      <contributor>
        <username>Pro-rsoft</username>
        <id>110</id>
      </contributor>
      <comment>[[Video Lectures]] moved to [[Video Tutorials]]</comment>
      <text xml:space="preserve" bytes="29">#REDIRECT [[Video Tutorials]]</text>
    </revision>
  </page>
  <page>
    <title>Video Tutorials</title>
    <ns>0</ns>
    <id>1070</id>
      <sha1>gvg39j52tyew8b71psxqgfmmd6u1euo</sha1>
    <revision>
      <id>37362</id>
      <timestamp>2013-11-10T13:46:45Z</timestamp>
      <contributor>
        <username>ThomasEgi</username>
        <id>111</id>
      </contributor>
      <comment>Deleted my blender2panda vids as they were made for anchient blender+exporter versions.</comment>
      <text xml:space="preserve" bytes="2896">== Video lessons by Disney ==
David Rose, from Walt Disney VR Studio, occasionally holds classes based on the fundamentals and working of Panda3D. Below are a few of these lectures.


'''[https://www.youtube.com/watch?v=sePa3e7-lZQ Characters Part I]'''&lt;br /&gt;
''Recorded October 8, 2003''&lt;br /&gt;
Eggs, Characters and Actors

'''[https://www.youtube.com/watch?v=uPBc0OMttm8 Characters Part II]'''&lt;br /&gt;
''Recorded October 22, 2003''&lt;br /&gt;
This is a recap of character animation in Panda3D.

'''[https://www.youtube.com/watch?v=OZcgfryLdUQ PStats]'''&lt;br /&gt;
''Recorded February 24, 2004''&lt;br /&gt;
Demonstrating the use of Panda's built-in performance analysis tool.

'''[https://www.youtube.com/watch?v=aRaGM-9Vvr8 Threading]'''&lt;br /&gt;
''Recorded March 26, 2008''&lt;br /&gt;
The current state-of-the-art in multiprogramming in Panda.

'''[https://www.youtube.com/watch?v=hJEgWNBv8XY Windows, Buffers, and Cameras]'''&lt;br /&gt;
''Recorded April 9, 2008''&lt;br /&gt;
Fundamentals of managing windows and offscreen buffers, and connecting them up to cameras for rendering.

'''[https://www.youtube.com/watch?v=G2gO9ISrlxc Scene Graph]'''&lt;br /&gt;
''Recorded April 2, 2008''&lt;br /&gt;
Fundamentals of Panda's scene graph, tricks you can do with it, and how it is implemented.

'''[https://www.youtube.com/watch?v=JsgCFVpXQtQ DistributedObjects]'''&lt;br /&gt;
''Recorded April 16, 2008''&lt;br /&gt;
How to use Panda's DistributedObject system, for the Python developer.

'''[https://www.youtube.com/watch?v=r_ZP9SInPcs DistributedObjects and the OTP Server]'''&lt;br /&gt;
''Recorded April 23, 2008''&lt;br /&gt;
Panda's DistributedObject system, and how it relates to the VR Studio's OTP Server.

'''[https://www.youtube.com/watch?v=SzybRdxjYoA The OTP Server]'''&lt;br /&gt;
''Recorded April 30, 2008''&lt;br /&gt;
What's inside the VR Studio's OTP Server (not part of Panda).

'''[https://www.youtube.com/watch?v=zpOYFcH7_w4 The PRC System]'''&lt;br /&gt;
''Recorded May 7, 2008''&lt;br /&gt;
All about Panda's run-time configuration system.

'''[https://www.youtube.com/watch?v=5tWcRvqpk7k Collisions]'''&lt;br /&gt;
''Recorded May 14, 2008''&lt;br /&gt;
How to use Panda's built-in collision system, and how it works.

'''[https://www.youtube.com/watch?v=t_4-PkJDJiE egg-palettize]'''&lt;br /&gt;
''Recorded May 21, 2008''&lt;br /&gt;
How to use egg-palettize, and why you'd want to.

'''[https://www.youtube.com/watch?v=rh8X5pImzrI interrogate]'''&lt;br /&gt;
''Recorded June 4, 2008''&lt;br /&gt;
How interrogate works to generate Panda's Python/C++ interface.

'''[https://www.youtube.com/watch?v=9qgPyk22Zls ODE in Panda]'''&lt;br /&gt;
''Recorded June 18, 2008''&lt;br /&gt;
How Panda's built-in ODE integration is intended to be used.

'''[https://www.youtube.com/watch?v=L1j0BMck4Z0 Inside an Actor]'''&lt;br /&gt;
''Recorded July 2, 2008''
How the Actor class is implemented, and how to use it.

'''[http://vimeo.com/14704672 Plugin flow]'''&lt;br /&gt;
''Recorded August 31, 2010''
The Panda3D web plugin design and flow.</text>
    </revision>
  </page>
  <page>
    <title>Videos Lectures</title>
    <ns>0</ns>
    <id>1031</id>
      <sha1>qdx1mgyeozm21x968g1vgi77dkzszvt</sha1>
    <revision>
      <id>2321</id>
      <timestamp>2005-04-16T21:44:57Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="177">In the following pages, we list the available tutorial videos for Panda3D and its components. All videos are DivX encoded. Download Divx from [http://www.divx.com www.divx.com].</text>
    </revision>
  </page>
  <page>
    <title>Virtual Reality</title>
    <ns>0</ns>
    <id>1076</id>
    <redirect title="VR Helmets and Trackers" />
      <sha1>g3luaqad4odmusqls8t9l4wlggmxbgy</sha1>
    <revision>
      <id>2307</id>
      <timestamp>2005-04-30T22:49:06Z</timestamp>
      <contributor>
        <username>Josh Yelon</username>
        <id>2</id>
      </contributor>
      <comment>Virtual Reality moved to VR Helmets and Trackers</comment>
      <text xml:space="preserve" bytes="38">#REDIRECT [[VR Helmets and Trackers]]
</text>
    </revision>
  </page>
  <page>
    <title>Wander</title>
    <ns>0</ns>
    <id>2586</id>
      <sha1>ti6sgmxa825s0epw2bs0jx4eadsnnts</sha1>
    <revision>
      <id>7699</id>
      <timestamp>2012-03-09T10:24:46Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <comment>Panda's &quot;direct&quot; package has nothing to do with &quot;DirectX&quot;</comment>
      <text xml:space="preserve" bytes="2549">&lt;b&gt;'Wander'&lt;/b&gt; is an AI behavior where an AICharacter will move in a random direction to generate realistic movement around an environment with no goal position in mind.


{{#ev:youtube|jy6F6HnenoE}}


In PandAI, 'Wander' is defined as :
&lt;code python&gt;
aiBehaviors.wander(double wander_radius, int flag, double aoe, float priority)
&lt;/code&gt;

where :

&lt;b&gt;Wander Radius&lt;/b&gt; represents the degree of wandering. This is implemented via a guiding circle in front of the AI Character.

&lt;b&gt;Flag&lt;/b&gt; represents which plane to wander in (0 - XY, 1 - YZ, 2 - XZ, 3 - XYZ). By default, it is in the XY plane.

&lt;b&gt;Area of Effect&lt;/b&gt; is the radius from the starting point where the AICharacter would wander within.

&lt;b&gt;priority&lt;/b&gt; is by default set to 1.0 and is used when using two or more steering behaviors on an AICharacter.


-----

The velocity at which the AICharacter wanders is determined when you first create your AICharacter object using the AICharacter constructor.

-----

The full working code for this in Panda3D :

&lt;code python&gt;
import direct.directbase.DirectStart
from panda3d.core import *
from direct.showbase.DirectObject import DirectObject
from direct.task import Task
from direct.actor.Actor import Actor
#for Pandai
from panda3d.ai import *

# Globals
speed = 0.75

class World(DirectObject):

    def __init__(self):
        base.disableMouse()
        base.cam.setPosHpr(0,0,55,0,-90,0)
        
        self.loadModels()
        self.setAI()

    def loadModels(self):
        # Seeker
        ralphStartPos = Vec3(0, 0, 0)
        self.wanderer = Actor(&quot;models/ralph&quot;,
                                 {&quot;run&quot;:&quot;models/ralph-run&quot;})
        self.wanderer.reparentTo(render)
        self.wanderer.setScale(0.5)
        self.wanderer.setPos(ralphStartPos)
      
    def setAI(self):
        #Creating AI World
        self.AIworld = AIWorld(render)
 
        self.AIchar = AICharacter(&quot;wanderer&quot;,self.wanderer, 100, 0.05, 5)
        self.AIworld.addAiChar(self.AIchar)
        self.AIbehaviors = self.AIchar.getAiBehaviors()
        
        self.AIbehaviors.wander(5, 0, 10, 1.0)
        self.wanderer.loop(&quot;run&quot;)

        #AI World update        
        taskMgr.add(self.AIUpdate,&quot;AIUpdate&quot;)
        
    #to update the AIWorld    
    def AIUpdate(self,task):
        self.AIworld.update()            
        return Task.cont
 
w = World()
run()

&lt;/code&gt;

&lt;b&gt;To get the full working demo, please visit :&lt;/b&gt;

https://sites.google.com/site/etcpandai/documentation/steering-behaviors/wander/PandAIWanderExample.zip?attredirects=0&amp;d=1</text>
    </revision>
  </page>
  <page>
    <title>Windows and Buffers</title>
    <ns>0</ns>
    <id>2274</id>
      <sha1>phoiac9h4m842xq45sp7s6u21eteeq1</sha1>
    <revision>
      <id>5499</id>
      <timestamp>2008-10-06T14:17:57Z</timestamp>
      <contributor>
        <username>Drwr</username>
        <id>6</id>
      </contributor>
      <text xml:space="preserve" bytes="0" />
    </revision>
  </page>
  <page>
    <title>Woodgrain Example</title>
    <ns>0</ns>
    <id>1202</id>
      <sha1>eeqqa4z27m33l6ivyet8gehzafmdxb5</sha1>
    <revision>
      <id>7730</id>
      <timestamp>2012-03-10T07:07:16Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <text xml:space="preserve" bytes="4331">The following program will generate and write out a 3-D texture to simulate woodgrain:

&lt;code python&gt;
from direct.directbase.DirectStart import *
from panda3d.core import *
import math

# These constants define the RGB colors of the light and dark bands in
# the woodgrain.
lightGrain = (0.72, 0.72, 0.45)
darkGrain = (0.49, 0.33, 0.11)

def chooseGrain(p, xi, yi, radius):
    &quot;&quot;&quot; Applies the appropriate color to pixel (xi, yi), based on
    radius, the computed distance from the center of the trunk. &quot;&quot;&quot;

    # Get the fractional part of radius.
    t = radius - math.floor(radius)
    
    # Now t ranges from 0 to 1.  Make it see-saw from 0 to 1 and back.
    t = abs(t - 0.5) * 2
    
    # Now interpolate colors.
    p.setXel(xi, yi,
             lightGrain[0] + t * (darkGrain[0] - lightGrain[0]),
             lightGrain[1] + t * (darkGrain[1] - lightGrain[1]),
             lightGrain[2] + t * (darkGrain[2] - lightGrain[2]))

def calcRadius(xn, yn, x, y, z, noiseAmp):
    &quot;&quot;&quot; Calculates radius, the distance from the center of the trunk,
    for the 3-d point (x, y, z).  The point is perturbed with noise to
    make the woodgrain seem more organic. &quot;&quot;&quot;
    
    xp = x + xn.noise(x, y, z) * noiseAmp
    yp = y + yn.noise(x, y, z) * noiseAmp
    
    return math.sqrt(xp * xp + yp * yp)

def makeWoodgrain(texSize, texZSize, noiseScale, noiseZScale,
                  noiseAmp, ringScale):

    &quot;&quot;&quot; Generate a 3-D texture of size texSize x texSize x texZSize
    that suggests woodgrain, with the grain running along the Z (W)
    direction.  Since there is not as much detail parallel to the
    grain as across it, the texture does not need to be as large in
    the Z dimension as in the other two dimensions.

    The woodgrain shape is perturbed with Perlin noise to make it more
    organic.  The parameters noiseScale and noiseZScale controls the
    frequency of the noise; larger numbers make smoother rings.  The
    parameter noiseAmp controls the effect of the noise; larger
    numbers make more dramatic distortions.

    ringScale controls the number of rings visible in the cross
    section of the texture.  A larger number makes more, denser rings.
    &quot;&quot;&quot;

    # First, create the two PerlinNoise objects to perturb the rings
    # in two dimensions.  This class is defined in Panda3D.
    xn = PerlinNoise3(noiseScale, noiseScale, noiseZScale)
    yn = PerlinNoise3(noiseScale, noiseScale, noiseZScale)

    # Start by creating a empty 3-D texture.
    tex = Texture('woodgrain')
    tex.setup3dTexture()

    for zi in range(texZSize):
        z = float(zi) / float(texZSize - 1) - 0.5

        # Walk through the Z slices of the texture one at a time.  For
        # each slice, we create a PNMImage, very much as if we were
        # reading the texture from disk.
        print zi
        p = PNMImage(texSize, texSize)

        # But instead of reading the PNMImage, we fill it in with the
        # ring pattern.
        for yi in range(texSize):
            y = float(yi) / float(texSize - 1) - 0.5
            for xi in range(texSize):
                x = float(xi) / float(texSize - 1) - 0.5

                radius = calcRadius(xn, yn, x, y, z, noiseAmp)
                chooseGrain(p, xi, yi, radius * ringScale)

        # Now load the current slice into the texture.
        tex.load(p, zi, 0)
        
    return tex

# Create a 3-D texture.
tex = makeWoodgrain(texSize = 256, texZSize = 8, noiseScale = 0.4,
                    noiseZScale = 0.8, noiseAmp = 0.12, ringScale = 40)

# Write out the texture.  This will generate woodgrain_0.png,
# woodgrain_1.png, and so on, in the current directory.
tex.write(Filename('woodgrain_#.png'), 0, 0, True, False)    
&lt;/code&gt;

The resulting images look like this:

[[Image:Woodgrain 0.jpg]]
[[Image:Woodgrain 1.jpg]]
[[Image:Woodgrain 2.jpg]]
[[Image:Woodgrain 3.jpg]]
[[Image:Woodgrain 4.jpg]]
[[Image:Woodgrain 5.jpg]]
[[Image:Woodgrain 6.jpg]]
[[Image:Woodgrain 7.jpg]]


To get consistent (over multiple runs of the programm) values from the PerlinNoise functions a seed value != 0 has to be used, seed values equal to 0 will randomize it&lt;br&gt;
The table_size is 256 by default.&lt;br&gt;
&lt;br&gt;
PerlinNoise3( scaleX, scaleY, scaleZ, table_size, seed)&lt;br&gt;
PerlinNoise2( scaleX, scaleY, table_size, seed)&lt;br&gt;
PerlinNoise( table_size, seed )&lt;br&gt;</text>
    </revision>
  </page>
  <page>
    <title>Worlds, Bodies and Masses</title>
    <ns>0</ns>
    <id>2285</id>
      <sha1>614x2w18fr3cj3z2i9s187muiwdjx2b</sha1>
    <revision>
      <id>7685</id>
      <timestamp>2012-03-09T09:45:15Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>new import system</comment>
      <text xml:space="preserve" bytes="4904">&lt;h2&gt;Worlds&lt;/h2&gt;
To use the ODE physics system, you need to have an OdeWorld. A world is an essential component in the physics structure, it holds all your rigid bodies and joints, and controls global parameters, such as gravity, for the scene.
[python]
&lt;code python&gt;
from panda3d.ode import OdeWorld
myWorld = OdeWorld()
myWorld.setGravity(0, 0, -9.81)
&lt;/code&gt;
[/python]
[cxx]
&lt;code cxx&gt;
#include &quot;odeWorld.h&quot;

OdeWorld myWorld;
myWorld.set_gravity(0, 0, -9.81);
&lt;/code&gt;
[/cxx]
As you can see, the gravity is set to a downward vector with length 9.81. This value is the average gravity acceleration on Earth. If you want objects to fall faster or slower, (e.g. if your game plays on the Moon, where the gravity acceleration is 1.62 m/s²) you need to change this value, but in most cases you want to leave it around 9.81 m/s².

&lt;h2&gt;Bodies and masses&lt;/h2&gt;
In physics space, the objects that matter are called &lt;i&gt;bodies&lt;/i&gt;. In order to have something affected by physics, you need to create an OdeBody, and set an OdeMass on it.

An OdeMass does not just define how much an object weighs. You roughly have to specify a shape so ODE will know how the mass is divided over the body. Also, ODE will have to know either the density of the object or the mass.

In the following example the geometry is assumed to be a box-shaped object made of lead, and the box has a width, length and height of 1 meter.
[python]
&lt;code python&gt;
from panda3d.ode import OdeBody, OdeMass
myBody = OdeBody(myWorld)
myBody.setPosition(somePandaObject.getPos(render))
myBody.setQuaternion(somePandaObject.getQuat(render))
myMass = OdeMass()
myMass.setBox(11340, 1, 1, 1)
myBody.setMass(myMass)
&lt;/code&gt;
[/python]
[cxx]
&lt;code cxx&gt;
#include &quot;odeBody.h&quot;
#include &quot;odeMass.h&quot;

OdeBody myBody (myWorld);
myBody.set_position(somePandaObject.get_pos(render));
myBody.set_quaternion(somePandaObject.get_quat(render));
OdeMass myMass;
myMass.set_box(11340, 1, 1, 1);
myBody.set_mass(myMass);
&lt;/code&gt;
[/cxx]
First, the position and quaternion are set of the body, this is directly copied from the NodePath's pos and quat; do note that when using [func]getPos[/func] and [func]getQuat[/func], you need to get them in global coordinate space, this is done here by specifying &lt;code&gt;render&lt;/code&gt; as first argument.

Then, a mass is set for the body. The first argument specified in the [func]setBox[/func] call is the [http://en.wikipedia.org/wiki/Density density] of the object, the second is the dimensions (lx, ly, lz) of the box. Each material has it's own density, for example, water has a density of 1000 kg/m³, copper usually between 8920 and 8960 kg/m³. The value shown in the example above is the density for lead.

There are of course cases where you don't know the density (although it is easy to calculate), or when the object is not easy to fit in a box shape. OdeMass provides the following methods:
* &lt;code&gt;[func]setZero[/func]()&lt;/code&gt;: Sets all the mass parameters to 0, meaning it will have no mass at all.
* &lt;code&gt;[func]setSphere[/func](density, radius)&lt;/code&gt;: This specifies that the object's mass is spherical with the given radius.
* &lt;code&gt;[func]setSphereTotal[/func](total_mass, radius)&lt;/code&gt;: Use this if you don't know the density but do know the total mass of the object.
* &lt;code&gt;[func]setBox[/func](density, lx, ly, lz)&lt;/code&gt;: Use this for box-shaped objects.
* &lt;code&gt;[func]setBoxTotal[/func](total_mass, lx, ly, lz)&lt;/code&gt;: The same as the former, but specifies the total mass instead of the density.
* &lt;code&gt;[func]setCylinder[/func](density, direction, radius, length)&lt;/code&gt;: To be used for objects shaped like a cylinder.
* &lt;code&gt;[func]setCylinderTotal[/func](total_mass, direction, radius, length)&lt;/code&gt;: Again the same cylinder, but specifies the mass instead of the density.
* &lt;code&gt;[func]setCapsule[/func](density, direction, radius, length)&lt;/code&gt;: A capsule is similar to a cylinder, but has capped edges.
* &lt;code&gt;[func]setCapsuleTotal[/func](total_mass, direction, radius, length)&lt;/code&gt;: Use this if you only have a mass and not the density.
* &lt;code&gt;add(other)&lt;/code&gt;: Adds an other OdeMass object to this mass.
* &lt;code&gt;adjust(total_mass)&lt;/code&gt;: Adjusts the mass parameters to have the specified mass.
* &lt;code&gt;rotate(matrix)&lt;/code&gt;: Rotates the matrix using the specified Mat3 object.
More methods are listed in the [http://panda3d.org/apiref.php?page=OdeMass API reference].

For more complex shapes, you might want to decompose the object into several simple ones, and use the &lt;code&gt;add(other)&lt;/code&gt; method to add the masses together. If that still isn't enough, you might want to set the individual parameters of the mass using &lt;code&gt;[func]setParameters[/func]&lt;/code&gt;, which is not explained here because it that goes beyond the scope of this manual page.
Note that the shape you set is not actually used for collisions: it's just used to roughly determine how the mass is divided in the object.</text>
    </revision>
  </page>
  <page>
    <title>Writing 3D Models out to Disk</title>
    <ns>0</ns>
    <id>1129</id>
      <sha1>0i4cufa9mh8glrqtpquwtcz5okbck46</sha1>
    <revision>
      <id>7665</id>
      <timestamp>2012-03-08T18:56:14Z</timestamp>
      <contributor>
        <username>Preusser</username>
        <id>541</id>
      </contributor>
      <minor/>
      <comment>python code tags</comment>
      <text xml:space="preserve" bytes="4142">Panda has two native file formats for models. 

Egg files (with the extension &lt;code&gt;.egg&lt;/code&gt;) are written in an ASCII human readable format.  The egg format is designed to be easy to read and modify if necessary, and easy to write a convert into from another third-party format.  Also, the egg format is intended to be backward-compatible from all future versions of Panda3D, so if you have an egg file that Panda can load now, it should always be able to load that file.  (Well, we can't really make guarantees, but this is what we shoot for.)  See [[Parsing and Generating Egg Files]] for more information about the egg format.

==BAM Files==
Because of the way the egg syntax is designed, an egg file might be very large, sometimes many times larger than the file it was converted from.  It can also sometimes take several seconds for Panda to load a large egg file.

Bam files (with the extension &lt;code&gt;.bam&lt;/code&gt;), on the other hand, are binary files that are closely tied to a particular version of Panda3D.  The bam format is designed to be as similar as possible to the actual Panda data structures, so that a bam file is relatively small and can be loaded very quickly.  However, you should not consider the bam file format to be a good long-term storage format for your models, since a future version of Panda3D may not be able to load bam files from older versions.

You can always convert egg files to bam files using the program [[Converting Egg to Bam|egg2bam]].  For many simple models, it is also possible to convert back again with the program [[List of Panda Executables|bam2egg]], but you should not rely on this, since it does not convert advanced features like animation; and some structure of the original egg file may be lost in the conversion.

You can load files of these formats, as well as [[Model Export|any other supported format]], using the [[Scene Graph Manipulations|loader.loadModel]] interface.  Any file types other than &lt;code&gt;.bam&lt;/code&gt; or &lt;code&gt;.egg&lt;/code&gt; will be automatically converted at runtime, exactly as if you had run the appropriate command-line conversion tool first.

&lt;h2&gt;The Bam Interface&lt;/h2&gt;
The easiest way to save geometry is to use to call &lt;code&gt;writeBamFile(filename)&lt;/code&gt; from the NodePath that contains your geometry.

&lt;code python&gt;
myPanda=loader.loadModel(&quot;panda&quot;)

#do some fancy calculations on the normals, or texture coordinates that you dont
#want to do at runtime

#Save your new custom Panda
myPanda.writeBamFile(&quot;customPanda.bam&quot;)
&lt;/code&gt;

&lt;h2&gt;The Egg Interface&lt;/h2&gt;
One easy way to create &lt;code&gt;.egg&lt;/code&gt; file for geometry that has already been made is to create a &lt;code&gt;.bam&lt;/code&gt; file and use bam2egg.  However, you will often want to use the egg interface to create geometry in the first place; this is usually the easiest way to create geometry in Panda3D.

The complete documentation for using the egg interfaces has yet to be written, but the egg library is really quite simple to use.  The basic idea is that you create an EggData, and an EggVertexPool to hold your vertices; and then you can create a series of EggVertex and EggPolygon objects.  If you want to create some structure in your egg file, you can create one or more EggGroups to separate the polygons into different groups.  Here is an example:

&lt;code python&gt;
def makeWedge(angleDegrees = 360, numSteps = 16):
    data = EggData()

    vp = EggVertexPool('fan')
    data.addChild(vp)

    poly = EggPolygon()
    data.addChild(poly)

    v = EggVertex()
    v.setPos(Point3D(0, 0, 0))
    poly.addVertex(vp.addVertex(v))

    angleRadians = deg2Rad(angleDegrees)

    for i in range(numSteps + 1):
        a = angleRadians * i / numSteps
        y = math.sin(a)
        x = math.cos(a)

        v = EggVertex()
        v.setPos(Point3D(x, 0, y))
        poly.addVertex(vp.addVertex(v))

    # To write the egg file to disk, use this:
    data.writeEgg(Filename(&quot;wedge.egg&quot;))

    # To load the egg file and render it immediately, use this:
    node = loadEggData(data)
    return NodePath(node)
&lt;/code&gt;

See the generated API documentation for more complete information about the egg library.</text>
    </revision>
  </page>
</mediawiki>
